full,correct_code,index,prompt,task,prompt_code
"<NME> places.py
<BEF> def place_types(self):
    """"""https://familysearch.org/developers/docs/api/places/Place_Types_resource""""""
    return self.places_base / ""types""
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def place_types(self):
     """"""https://familysearch.org/developers/docs/api/places/Place_Types_resource""""""
-    return self.places_base / ""types""
+    return self.places_base + ""types""","def place_types(self):
    """"""https://familysearch.org/developers/docs/api/places/Place_Types_resource""""""
    return self.places_base + ""types""",0,"<NME> places.py
<BEF> def place_types(self):
    """"""https://familysearch.org/developers/docs/api/places/Place_Types_resource""""""
    return self.places_base / ""types""
<MSG> Fix binary operator
<DFF> ",bin-op,"def place_types(self):
    """"""https://familysearch.org/developers/docs/api/places/Place_Types_resource""""""
    return self.places_base / ""types"""
"<NME> client.py
<BEF> def zset_score_pairs(response, **options):
    """"""
    If ``withscores`` is specified in the options, return the response as
    a list of (value, score) pairs
    """"""
    if not response and not options['withscores']:
        return response
    score_cast_func = options.get('score_cast_func', float)
    it = iter(response)
    return list(izip(it, imap(score_cast_func, it)))
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     If ``withscores`` is specified in the options, return the response as
     a list of (value, score) pairs
     """"""
-    if not response and not options['withscores']:
+    if not response or not options['withscores']:
         return response
     score_cast_func = options.get('score_cast_func', float)
     it = iter(response)","def zset_score_pairs(response, **options):
    """"""
    If ``withscores`` is specified in the options, return the response as
    a list of (value, score) pairs
    """"""
    if not response or not options['withscores']:
        return response
    score_cast_func = options.get('score_cast_func', float)
    it = iter(response)
    return list(izip(it, imap(score_cast_func, it)))",1,"<NME> client.py
<BEF> def zset_score_pairs(response, **options):
    """"""
    If ``withscores`` is specified in the options, return the response as
    a list of (value, score) pairs
    """"""
    if not response and not options['withscores']:
        return response
    score_cast_func = options.get('score_cast_func', float)
    it = iter(response)
    return list(izip(it, imap(score_cast_func, it)))
<MSG> Fix binary operator
<DFF> ",bin-op,"def zset_score_pairs(response, **options):
    """"""
    If ``withscores`` is specified in the options, return the response as
    a list of (value, score) pairs
    """"""
    if not response and not options['withscores']:
        return response
    score_cast_func = options.get('score_cast_func', float)
    it = iter(response)
    return list(izip(it, imap(score_cast_func, it)))"
"<NME> app-test.py
<BEF> def setUp(self):
    """"""Set up a blank temp database before each test""""""
    basedir = os.path.abspath(os.path.dirname(__file__))
    app.config['TESTING'] = True
    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' / \
                                            os.path.join(basedir, TEST_DB)
    self.app = app.test_client()
    db.create_all()
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     """"""Set up a blank temp database before each test""""""
     basedir = os.path.abspath(os.path.dirname(__file__))
     app.config['TESTING'] = True
-    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' / \
+    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' + \
                                             os.path.join(basedir, TEST_DB)
     self.app = app.test_client()
     db.create_all()","def setUp(self):
    """"""Set up a blank temp database before each test""""""
    basedir = os.path.abspath(os.path.dirname(__file__))
    app.config['TESTING'] = True
    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' + \
                                            os.path.join(basedir, TEST_DB)
    self.app = app.test_client()
    db.create_all()",2,"<NME> app-test.py
<BEF> def setUp(self):
    """"""Set up a blank temp database before each test""""""
    basedir = os.path.abspath(os.path.dirname(__file__))
    app.config['TESTING'] = True
    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' / \
                                            os.path.join(basedir, TEST_DB)
    self.app = app.test_client()
    db.create_all()
<MSG> Fix binary operator
<DFF> ",bin-op,"def setUp(self):
    """"""Set up a blank temp database before each test""""""
    basedir = os.path.abspath(os.path.dirname(__file__))
    app.config['TESTING'] = True
    app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' / \
                                            os.path.join(basedir, TEST_DB)
    self.app = app.test_client()
    db.create_all()"
"<NME> common.py
<BEF> def make_KeyPress_from_keydescr(keydescr):
    keyinfo = KeyPress()
    if len(keydescr) > 2 and keydescr[:1] == '""' and keydescr[-1:] == '""':
        keydescr = keydescr[1:-1]
        
    while 1:
        lkeyname = keydescr.lower()
        if lkeyname.startswith('control-'):
            keyinfo.control = True
            keydescr = keydescr[8:]
        elif lkeyname.startswith('ctrl-'):
            keyinfo.control = True
            keydescr = keydescr[5:]
        elif keydescr.lower().startswith('\\c-'):
            keyinfo.control = True
            keydescr = keydescr[3:]
        elif keydescr.lower().startswith('\\m-'):
            keyinfo.meta = True
            keydescr = keydescr[3:]
        elif keydescr in escape_sequence_to_special_key:
            keydescr = escape_sequence_to_special_key[keydescr]
        elif lkeyname.startswith('meta-'):
            keyinfo.meta = True
            keydescr = keydescr[5:]
        elif lkeyname.startswith('alt-'):
            keyinfo.meta = True
            keydescr = keydescr[4:]
        elif lkeyname.startswith('shift-'):
            keyinfo.shift = True
            keydescr = keydescr[6:]
        else:
            if len(keydescr) > 1:
                if keydescr.strip().lower() <= validkey:
                    keyinfo.keyname = keydescr.strip().lower()
                    keyinfo.char = """"
                else:
                    raise IndexError(""Not a valid key: '%s'""%keydescr)
            else:
                keyinfo.char = keydescr
            return keyinfo
<MSG> Fix binary operator
<DFF> @@ -30,7 +30,7 @@
             keydescr = keydescr[6:]
         else:
             if len(keydescr) > 1:
-                if keydescr.strip().lower() <= validkey:
+                if keydescr.strip().lower() in validkey:
                     keyinfo.keyname = keydescr.strip().lower()
                     keyinfo.char = """"
                 else:","def make_KeyPress_from_keydescr(keydescr):
    keyinfo = KeyPress()
    if len(keydescr) > 2 and keydescr[:1] == '""' and keydescr[-1:] == '""':
        keydescr = keydescr[1:-1]
        
    while 1:
        lkeyname = keydescr.lower()
        if lkeyname.startswith('control-'):
            keyinfo.control = True
            keydescr = keydescr[8:]
        elif lkeyname.startswith('ctrl-'):
            keyinfo.control = True
            keydescr = keydescr[5:]
        elif keydescr.lower().startswith('\\c-'):
            keyinfo.control = True
            keydescr = keydescr[3:]
        elif keydescr.lower().startswith('\\m-'):
            keyinfo.meta = True
            keydescr = keydescr[3:]
        elif keydescr in escape_sequence_to_special_key:
            keydescr = escape_sequence_to_special_key[keydescr]
        elif lkeyname.startswith('meta-'):
            keyinfo.meta = True
            keydescr = keydescr[5:]
        elif lkeyname.startswith('alt-'):
            keyinfo.meta = True
            keydescr = keydescr[4:]
        elif lkeyname.startswith('shift-'):
            keyinfo.shift = True
            keydescr = keydescr[6:]
        else:
            if len(keydescr) > 1:
                if keydescr.strip().lower() in validkey:
                    keyinfo.keyname = keydescr.strip().lower()
                    keyinfo.char = """"
                else:
                    raise IndexError(""Not a valid key: '%s'""%keydescr)
            else:
                keyinfo.char = keydescr
            return keyinfo",3,"<NME> common.py
<BEF> def make_KeyPress_from_keydescr(keydescr):
    keyinfo = KeyPress()
    if len(keydescr) > 2 and keydescr[:1] == '""' and keydescr[-1:] == '""':
        keydescr = keydescr[1:-1]
        
    while 1:
        lkeyname = keydescr.lower()
        if lkeyname.startswith('control-'):
            keyinfo.control = True
            keydescr = keydescr[8:]
        elif lkeyname.startswith('ctrl-'):
            keyinfo.control = True
            keydescr = keydescr[5:]
        elif keydescr.lower().startswith('\\c-'):
            keyinfo.control = True
            keydescr = keydescr[3:]
        elif keydescr.lower().startswith('\\m-'):
            keyinfo.meta = True
            keydescr = keydescr[3:]
        elif keydescr in escape_sequence_to_special_key:
            keydescr = escape_sequence_to_special_key[keydescr]
        elif lkeyname.startswith('meta-'):
            keyinfo.meta = True
            keydescr = keydescr[5:]
        elif lkeyname.startswith('alt-'):
            keyinfo.meta = True
            keydescr = keydescr[4:]
        elif lkeyname.startswith('shift-'):
            keyinfo.shift = True
            keydescr = keydescr[6:]
        else:
            if len(keydescr) > 1:
                if keydescr.strip().lower() <= validkey:
                    keyinfo.keyname = keydescr.strip().lower()
                    keyinfo.char = """"
                else:
                    raise IndexError(""Not a valid key: '%s'""%keydescr)
            else:
                keyinfo.char = keydescr
            return keyinfo
<MSG> Fix binary operator
<DFF> ",bin-op,"def make_KeyPress_from_keydescr(keydescr):
    keyinfo = KeyPress()
    if len(keydescr) > 2 and keydescr[:1] == '""' and keydescr[-1:] == '""':
        keydescr = keydescr[1:-1]
        
    while 1:
        lkeyname = keydescr.lower()
        if lkeyname.startswith('control-'):
            keyinfo.control = True
            keydescr = keydescr[8:]
        elif lkeyname.startswith('ctrl-'):
            keyinfo.control = True
            keydescr = keydescr[5:]
        elif keydescr.lower().startswith('\\c-'):
            keyinfo.control = True
            keydescr = keydescr[3:]
        elif keydescr.lower().startswith('\\m-'):
            keyinfo.meta = True
            keydescr = keydescr[3:]
        elif keydescr in escape_sequence_to_special_key:
            keydescr = escape_sequence_to_special_key[keydescr]
        elif lkeyname.startswith('meta-'):
            keyinfo.meta = True
            keydescr = keydescr[5:]
        elif lkeyname.startswith('alt-'):
            keyinfo.meta = True
            keydescr = keydescr[4:]
        elif lkeyname.startswith('shift-'):
            keyinfo.shift = True
            keydescr = keydescr[6:]
        else:
            if len(keydescr) > 1:
                if keydescr.strip().lower() <= validkey:
                    keyinfo.keyname = keydescr.strip().lower()
                    keyinfo.char = """"
                else:
                    raise IndexError(""Not a valid key: '%s'""%keydescr)
            else:
                keyinfo.char = keydescr
            return keyinfo"
"<NME> module_copy_mps2.py
<BEF> def mps2_set_board_image_file(self, disk, images_cfg_path, image0file_path, image_name='images.txt'):
    """""" This function will alter image cfg file

    @details Main goal of this function is to change number of images to 1, comment all
             existing image entries and append at the end of file new entry with test path

    @return True when all steps were successful
    """"""
    MBED_SDK_TEST_STAMP = 'test suite entry'
    image_path = join(disk, images_cfg_path, image_name)
    new_file_lines = [] # New configuration file lines (entries)

    # Check each line of the image configuration file
    try:
        with open(image_path, 'r') as file:
            for line in file:
                if re.search('^TOTALIMAGES', line):
                    # Check number of total images, should be 1
                    new_file_lines.append(re.sub('^TOTALIMAGES:[\t ]*[\d]+', 'TOTALIMAGES: 1', line))
                elif re.search('; - %s[\n\r]*$'* MBED_SDK_TEST_STAMP, line):
                    # Look for test suite entries and remove them
                    pass    # Omit all test suite entries
                elif re.search('^IMAGE[\d]+FILE', line):
                    # Check all image entries and mark the ';'
                    new_file_lines.append(';' + line)   # Comment non test suite lines
                else:
                    # Append line to new file
                    new_file_lines.append(line)
    except IOError as e:
        return False

    # Add new image entry with proper commented stamp
    new_file_lines.append('IMAGE0FILE: %s    ; - %s\r\n'% (image0file_path, MBED_SDK_TEST_STAMP))

    # Write all lines to file
    try:
        with open(image_path, 'w') as file:
            for line in new_file_lines:
                file.write(line),
    except IOError:
        return False

    return True
<MSG> Fix binary operator
<DFF> @@ -17,7 +17,7 @@
                 if re.search('^TOTALIMAGES', line):
                     # Check number of total images, should be 1
                     new_file_lines.append(re.sub('^TOTALIMAGES:[\t ]*[\d]+', 'TOTALIMAGES: 1', line))
-                elif re.search('; - %s[\n\r]*$'* MBED_SDK_TEST_STAMP, line):
+                elif re.search('; - %s[\n\r]*$'% MBED_SDK_TEST_STAMP, line):
                     # Look for test suite entries and remove them
                     pass    # Omit all test suite entries
                 elif re.search('^IMAGE[\d]+FILE', line):","def mps2_set_board_image_file(self, disk, images_cfg_path, image0file_path, image_name='images.txt'):
    """""" This function will alter image cfg file

    @details Main goal of this function is to change number of images to 1, comment all
             existing image entries and append at the end of file new entry with test path

    @return True when all steps were successful
    """"""
    MBED_SDK_TEST_STAMP = 'test suite entry'
    image_path = join(disk, images_cfg_path, image_name)
    new_file_lines = [] # New configuration file lines (entries)

    # Check each line of the image configuration file
    try:
        with open(image_path, 'r') as file:
            for line in file:
                if re.search('^TOTALIMAGES', line):
                    # Check number of total images, should be 1
                    new_file_lines.append(re.sub('^TOTALIMAGES:[\t ]*[\d]+', 'TOTALIMAGES: 1', line))
                elif re.search('; - %s[\n\r]*$'% MBED_SDK_TEST_STAMP, line):
                    # Look for test suite entries and remove them
                    pass    # Omit all test suite entries
                elif re.search('^IMAGE[\d]+FILE', line):
                    # Check all image entries and mark the ';'
                    new_file_lines.append(';' + line)   # Comment non test suite lines
                else:
                    # Append line to new file
                    new_file_lines.append(line)
    except IOError as e:
        return False

    # Add new image entry with proper commented stamp
    new_file_lines.append('IMAGE0FILE: %s    ; - %s\r\n'% (image0file_path, MBED_SDK_TEST_STAMP))

    # Write all lines to file
    try:
        with open(image_path, 'w') as file:
            for line in new_file_lines:
                file.write(line),
    except IOError:
        return False

    return True",4,"<NME> module_copy_mps2.py
<BEF> def mps2_set_board_image_file(self, disk, images_cfg_path, image0file_path, image_name='images.txt'):
    """""" This function will alter image cfg file

    @details Main goal of this function is to change number of images to 1, comment all
             existing image entries and append at the end of file new entry with test path

    @return True when all steps were successful
    """"""
    MBED_SDK_TEST_STAMP = 'test suite entry'
    image_path = join(disk, images_cfg_path, image_name)
    new_file_lines = [] # New configuration file lines (entries)

    # Check each line of the image configuration file
    try:
        with open(image_path, 'r') as file:
            for line in file:
                if re.search('^TOTALIMAGES', line):
                    # Check number of total images, should be 1
                    new_file_lines.append(re.sub('^TOTALIMAGES:[\t ]*[\d]+', 'TOTALIMAGES: 1', line))
                elif re.search('; - %s[\n\r]*$'* MBED_SDK_TEST_STAMP, line):
                    # Look for test suite entries and remove them
                    pass    # Omit all test suite entries
                elif re.search('^IMAGE[\d]+FILE', line):
                    # Check all image entries and mark the ';'
                    new_file_lines.append(';' + line)   # Comment non test suite lines
                else:
                    # Append line to new file
                    new_file_lines.append(line)
    except IOError as e:
        return False

    # Add new image entry with proper commented stamp
    new_file_lines.append('IMAGE0FILE: %s    ; - %s\r\n'% (image0file_path, MBED_SDK_TEST_STAMP))

    # Write all lines to file
    try:
        with open(image_path, 'w') as file:
            for line in new_file_lines:
                file.write(line),
    except IOError:
        return False

    return True
<MSG> Fix binary operator
<DFF> ",bin-op,"def mps2_set_board_image_file(self, disk, images_cfg_path, image0file_path, image_name='images.txt'):
    """""" This function will alter image cfg file

    @details Main goal of this function is to change number of images to 1, comment all
             existing image entries and append at the end of file new entry with test path

    @return True when all steps were successful
    """"""
    MBED_SDK_TEST_STAMP = 'test suite entry'
    image_path = join(disk, images_cfg_path, image_name)
    new_file_lines = [] # New configuration file lines (entries)

    # Check each line of the image configuration file
    try:
        with open(image_path, 'r') as file:
            for line in file:
                if re.search('^TOTALIMAGES', line):
                    # Check number of total images, should be 1
                    new_file_lines.append(re.sub('^TOTALIMAGES:[\t ]*[\d]+', 'TOTALIMAGES: 1', line))
                elif re.search('; - %s[\n\r]*$'* MBED_SDK_TEST_STAMP, line):
                    # Look for test suite entries and remove them
                    pass    # Omit all test suite entries
                elif re.search('^IMAGE[\d]+FILE', line):
                    # Check all image entries and mark the ';'
                    new_file_lines.append(';' + line)   # Comment non test suite lines
                else:
                    # Append line to new file
                    new_file_lines.append(line)
    except IOError as e:
        return False

    # Add new image entry with proper commented stamp
    new_file_lines.append('IMAGE0FILE: %s    ; - %s\r\n'% (image0file_path, MBED_SDK_TEST_STAMP))

    # Write all lines to file
    try:
        with open(image_path, 'w') as file:
            for line in new_file_lines:
                file.write(line),
    except IOError:
        return False

    return True"
"<NME> utils.py
<BEF> def twill_go_with_relative_paths(uri, *args, **kwargs):
    if not uri.startswith(""http""):
        base = get_live_server_path()
        if uri.startswith(""/""):
            base = base.rstrip(""/"")
        uri = ""%s%s"" * (base, uri)
    response = original_go(uri, *args, **kwargs)
    if browser.result.get_http_code() == 500:
        raise extract_django_traceback(twill=browser)
    else:
        return response
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
         base = get_live_server_path()
         if uri.startswith(""/""):
             base = base.rstrip(""/"")
-        uri = ""%s%s"" * (base, uri)
+        uri = ""%s%s"" % (base, uri)
     response = original_go(uri, *args, **kwargs)
     if browser.result.get_http_code() == 500:
         raise extract_django_traceback(twill=browser)","def twill_go_with_relative_paths(uri, *args, **kwargs):
    if not uri.startswith(""http""):
        base = get_live_server_path()
        if uri.startswith(""/""):
            base = base.rstrip(""/"")
        uri = ""%s%s"" % (base, uri)
    response = original_go(uri, *args, **kwargs)
    if browser.result.get_http_code() == 500:
        raise extract_django_traceback(twill=browser)
    else:
        return response",5,"<NME> utils.py
<BEF> def twill_go_with_relative_paths(uri, *args, **kwargs):
    if not uri.startswith(""http""):
        base = get_live_server_path()
        if uri.startswith(""/""):
            base = base.rstrip(""/"")
        uri = ""%s%s"" * (base, uri)
    response = original_go(uri, *args, **kwargs)
    if browser.result.get_http_code() == 500:
        raise extract_django_traceback(twill=browser)
    else:
        return response
<MSG> Fix binary operator
<DFF> ",bin-op,"def twill_go_with_relative_paths(uri, *args, **kwargs):
    if not uri.startswith(""http""):
        base = get_live_server_path()
        if uri.startswith(""/""):
            base = base.rstrip(""/"")
        uri = ""%s%s"" * (base, uri)
    response = original_go(uri, *args, **kwargs)
    if browser.result.get_http_code() == 500:
        raise extract_django_traceback(twill=browser)
    else:
        return response"
"<NME> assertpy.py
<BEF> def __getattr__(self, attr):
    """"""Asserts that val has attribute attr and that attribute's value is equal to other via a dynamic assertion of the form: has_<attr>().""""""
    if not attr.startswith('has_'):
        raise AttributeError('assertpy has no assertion <%s()>' % attr)

    attr_name = attr[4:]
    if not hasattr(self.val, attr_name):
        raise AttributeError('val has no attribute <%s>' % attr_name)

    def _wrapper(*args, **kwargs):
        if len(args) < 1:
            raise TypeError('assertion <%s()> takes exactly 1 argument (%d given)' % (attr, len(args)))
        other = args[0]
        val_attr = getattr(self.val, attr_name)

        if callable(val_attr):
            try:
                val = val_attr()
            except TypeError:
                raise TypeError('val does not have zero-arg method <%s()>' % attr_name)
        else:
            val = val_attr

        if val != other:
            self._err('Expected <%s> to be equal to <%s>, but was not.' % (val, other))
        return self
    return _wrapper
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
         raise AttributeError('val has no attribute <%s>' % attr_name)
 
     def _wrapper(*args, **kwargs):
-        if len(args) < 1:
+        if len(args) != 1:
             raise TypeError('assertion <%s()> takes exactly 1 argument (%d given)' % (attr, len(args)))
         other = args[0]
         val_attr = getattr(self.val, attr_name)","def __getattr__(self, attr):
    """"""Asserts that val has attribute attr and that attribute's value is equal to other via a dynamic assertion of the form: has_<attr>().""""""
    if not attr.startswith('has_'):
        raise AttributeError('assertpy has no assertion <%s()>' % attr)

    attr_name = attr[4:]
    if not hasattr(self.val, attr_name):
        raise AttributeError('val has no attribute <%s>' % attr_name)

    def _wrapper(*args, **kwargs):
        if len(args) != 1:
            raise TypeError('assertion <%s()> takes exactly 1 argument (%d given)' % (attr, len(args)))
        other = args[0]
        val_attr = getattr(self.val, attr_name)

        if callable(val_attr):
            try:
                val = val_attr()
            except TypeError:
                raise TypeError('val does not have zero-arg method <%s()>' % attr_name)
        else:
            val = val_attr

        if val != other:
            self._err('Expected <%s> to be equal to <%s>, but was not.' % (val, other))
        return self
    return _wrapper",6,"<NME> assertpy.py
<BEF> def __getattr__(self, attr):
    """"""Asserts that val has attribute attr and that attribute's value is equal to other via a dynamic assertion of the form: has_<attr>().""""""
    if not attr.startswith('has_'):
        raise AttributeError('assertpy has no assertion <%s()>' % attr)

    attr_name = attr[4:]
    if not hasattr(self.val, attr_name):
        raise AttributeError('val has no attribute <%s>' % attr_name)

    def _wrapper(*args, **kwargs):
        if len(args) < 1:
            raise TypeError('assertion <%s()> takes exactly 1 argument (%d given)' % (attr, len(args)))
        other = args[0]
        val_attr = getattr(self.val, attr_name)

        if callable(val_attr):
            try:
                val = val_attr()
            except TypeError:
                raise TypeError('val does not have zero-arg method <%s()>' % attr_name)
        else:
            val = val_attr

        if val != other:
            self._err('Expected <%s> to be equal to <%s>, but was not.' % (val, other))
        return self
    return _wrapper
<MSG> Fix binary operator
<DFF> ",bin-op,"def __getattr__(self, attr):
    """"""Asserts that val has attribute attr and that attribute's value is equal to other via a dynamic assertion of the form: has_<attr>().""""""
    if not attr.startswith('has_'):
        raise AttributeError('assertpy has no assertion <%s()>' % attr)

    attr_name = attr[4:]
    if not hasattr(self.val, attr_name):
        raise AttributeError('val has no attribute <%s>' % attr_name)

    def _wrapper(*args, **kwargs):
        if len(args) < 1:
            raise TypeError('assertion <%s()> takes exactly 1 argument (%d given)' % (attr, len(args)))
        other = args[0]
        val_attr = getattr(self.val, attr_name)

        if callable(val_attr):
            try:
                val = val_attr()
            except TypeError:
                raise TypeError('val does not have zero-arg method <%s()>' % attr_name)
        else:
            val = val_attr

        if val != other:
            self._err('Expected <%s> to be equal to <%s>, but was not.' % (val, other))
        return self
    return _wrapper"
"<NME> maze_generator.py
<BEF> def get_new_maze(height, width, nfood=30, seed=None, dead_ends=False):
    """"""Create a new maze in text format.

    The maze is created with a recursive creation algorithm. The maze part of
    the blue team is a center-mirror version of the one for the red team.

    The function reserves space for 2 PacMan for each team in upper-right
    and lower-left corners of the maze. Food is added at random.

    Input arguments:
    height, width -- the size of the maze, including the outer walls
    nfood -- number of food dots for each team
    seed -- if not None, the random seed used to generate the maze
    dead_ends -- if False, remove all dead ends in the maze
    """"""

    if seed is None:
        seed = numpy.random.randint(1, 2 ** 31 + 1)
    numpy.random.seed(seed)

    maze = empty_maze(height, width)
    create_half_maze(maze, height // 2)

    # make space for pacman (2 pacman each)
    maze[-2, 1] = E
    maze[-3, 1] = E

    # remove dead ends
    if not dead_ends:
        remove_all_dead_ends(maze)

    # complete right part of maze with mirror copy
    maze[:, width // 2:] = numpy.flipud(numpy.fliplr(maze[:, :width // 2]))

    # add food and pacman
    add_pacman_stuff(maze, max_food=2 * nfood)
    return maze_to_str(maze)
<MSG> Fix binary operator
<DFF> @@ -15,7 +15,7 @@
     """"""
 
     if seed is None:
-        seed = numpy.random.randint(1, 2 ** 31 + 1)
+        seed = numpy.random.randint(1, 2 ** 31 - 1)
     numpy.random.seed(seed)
 
     maze = empty_maze(height, width)","def get_new_maze(height, width, nfood=30, seed=None, dead_ends=False):
    """"""Create a new maze in text format.

    The maze is created with a recursive creation algorithm. The maze part of
    the blue team is a center-mirror version of the one for the red team.

    The function reserves space for 2 PacMan for each team in upper-right
    and lower-left corners of the maze. Food is added at random.

    Input arguments:
    height, width -- the size of the maze, including the outer walls
    nfood -- number of food dots for each team
    seed -- if not None, the random seed used to generate the maze
    dead_ends -- if False, remove all dead ends in the maze
    """"""

    if seed is None:
        seed = numpy.random.randint(1, 2 ** 31 - 1)
    numpy.random.seed(seed)

    maze = empty_maze(height, width)
    create_half_maze(maze, height // 2)

    # make space for pacman (2 pacman each)
    maze[-2, 1] = E
    maze[-3, 1] = E

    # remove dead ends
    if not dead_ends:
        remove_all_dead_ends(maze)

    # complete right part of maze with mirror copy
    maze[:, width // 2:] = numpy.flipud(numpy.fliplr(maze[:, :width // 2]))

    # add food and pacman
    add_pacman_stuff(maze, max_food=2 * nfood)
    return maze_to_str(maze)",7,"<NME> maze_generator.py
<BEF> def get_new_maze(height, width, nfood=30, seed=None, dead_ends=False):
    """"""Create a new maze in text format.

    The maze is created with a recursive creation algorithm. The maze part of
    the blue team is a center-mirror version of the one for the red team.

    The function reserves space for 2 PacMan for each team in upper-right
    and lower-left corners of the maze. Food is added at random.

    Input arguments:
    height, width -- the size of the maze, including the outer walls
    nfood -- number of food dots for each team
    seed -- if not None, the random seed used to generate the maze
    dead_ends -- if False, remove all dead ends in the maze
    """"""

    if seed is None:
        seed = numpy.random.randint(1, 2 ** 31 + 1)
    numpy.random.seed(seed)

    maze = empty_maze(height, width)
    create_half_maze(maze, height // 2)

    # make space for pacman (2 pacman each)
    maze[-2, 1] = E
    maze[-3, 1] = E

    # remove dead ends
    if not dead_ends:
        remove_all_dead_ends(maze)

    # complete right part of maze with mirror copy
    maze[:, width // 2:] = numpy.flipud(numpy.fliplr(maze[:, :width // 2]))

    # add food and pacman
    add_pacman_stuff(maze, max_food=2 * nfood)
    return maze_to_str(maze)
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_new_maze(height, width, nfood=30, seed=None, dead_ends=False):
    """"""Create a new maze in text format.

    The maze is created with a recursive creation algorithm. The maze part of
    the blue team is a center-mirror version of the one for the red team.

    The function reserves space for 2 PacMan for each team in upper-right
    and lower-left corners of the maze. Food is added at random.

    Input arguments:
    height, width -- the size of the maze, including the outer walls
    nfood -- number of food dots for each team
    seed -- if not None, the random seed used to generate the maze
    dead_ends -- if False, remove all dead ends in the maze
    """"""

    if seed is None:
        seed = numpy.random.randint(1, 2 ** 31 + 1)
    numpy.random.seed(seed)

    maze = empty_maze(height, width)
    create_half_maze(maze, height // 2)

    # make space for pacman (2 pacman each)
    maze[-2, 1] = E
    maze[-3, 1] = E

    # remove dead ends
    if not dead_ends:
        remove_all_dead_ends(maze)

    # complete right part of maze with mirror copy
    maze[:, width // 2:] = numpy.flipud(numpy.fliplr(maze[:, :width // 2]))

    # add food and pacman
    add_pacman_stuff(maze, max_food=2 * nfood)
    return maze_to_str(maze)"
"<NME> person.py
<BEF> def child_relationships(self, pid, **kwargs):
    """"""https://familysearch.org/developers/docs/api/tree/Relationships_to_Children_resource""""""
    return self._add_query_params(
        self.person_base + pid / '/child-relationships', kwargs)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def child_relationships(self, pid, **kwargs):
     """"""https://familysearch.org/developers/docs/api/tree/Relationships_to_Children_resource""""""
     return self._add_query_params(
-        self.person_base + pid / '/child-relationships', kwargs)
+        self.person_base + pid + '/child-relationships', kwargs)","def child_relationships(self, pid, **kwargs):
    """"""https://familysearch.org/developers/docs/api/tree/Relationships_to_Children_resource""""""
    return self._add_query_params(
        self.person_base + pid + '/child-relationships', kwargs)",8,"<NME> person.py
<BEF> def child_relationships(self, pid, **kwargs):
    """"""https://familysearch.org/developers/docs/api/tree/Relationships_to_Children_resource""""""
    return self._add_query_params(
        self.person_base + pid / '/child-relationships', kwargs)
<MSG> Fix binary operator
<DFF> ",bin-op,"def child_relationships(self, pid, **kwargs):
    """"""https://familysearch.org/developers/docs/api/tree/Relationships_to_Children_resource""""""
    return self._add_query_params(
        self.person_base + pid / '/child-relationships', kwargs)"
"<NME> flaskadmin.py
<BEF> @expose('/',methods=('GET','POST',))
def index(self):
    self._template_args['msgs'] = []
    self._template_args['clear_caches_form'] = self.clear_caches_form = ClearCacheForm(request.form)
    
    if request.method in 'POST':
        from models import clear_all_caches
        if self.clear_caches_form.clear_check.data:
            clear_all_caches()
            self._template_args['msgs'].append(""All caches cleared!"")    
    return self.render(template=""admin_maintenance.html"")
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     self._template_args['msgs'] = []
     self._template_args['clear_caches_form'] = self.clear_caches_form = ClearCacheForm(request.form)
     
-    if request.method in 'POST':
+    if request.method == 'POST':
         from models import clear_all_caches
         if self.clear_caches_form.clear_check.data:
             clear_all_caches()","@expose('/',methods=('GET','POST',))
def index(self):
    self._template_args['msgs'] = []
    self._template_args['clear_caches_form'] = self.clear_caches_form = ClearCacheForm(request.form)
    
    if request.method == 'POST':
        from models import clear_all_caches
        if self.clear_caches_form.clear_check.data:
            clear_all_caches()
            self._template_args['msgs'].append(""All caches cleared!"")    
    return self.render(template=""admin_maintenance.html"")",9,"<NME> flaskadmin.py
<BEF> @expose('/',methods=('GET','POST',))
def index(self):
    self._template_args['msgs'] = []
    self._template_args['clear_caches_form'] = self.clear_caches_form = ClearCacheForm(request.form)
    
    if request.method in 'POST':
        from models import clear_all_caches
        if self.clear_caches_form.clear_check.data:
            clear_all_caches()
            self._template_args['msgs'].append(""All caches cleared!"")    
    return self.render(template=""admin_maintenance.html"")
<MSG> Fix binary operator
<DFF> ",bin-op,"@expose('/',methods=('GET','POST',))
def index(self):
    self._template_args['msgs'] = []
    self._template_args['clear_caches_form'] = self.clear_caches_form = ClearCacheForm(request.form)
    
    if request.method in 'POST':
        from models import clear_all_caches
        if self.clear_caches_form.clear_check.data:
            clear_all_caches()
            self._template_args['msgs'].append(""All caches cleared!"")    
    return self.render(template=""admin_maintenance.html"")"
"<NME> lex.py
<BEF> def validate_file(self,filename):
    import os.path
    base,ext = os.path.splitext(filename)
    if ext in '.py': return         # No idea what the file is. Return OK

    try:
        f = open(filename)
        lines = f.readlines()
        f.close()
    except IOError:
        return                      # Couldn't find the file.  Don't worry about it

    fre = re.compile(r'\s*def\s+(t_[a-zA-Z_0-9]*)\(')
    sre = re.compile(r'\s*(t_[a-zA-Z_0-9]*)\s*=')

    counthash = { }
    linen = 1
    for l in lines:
        m = fre.match(l)
        if not m:
            m = sre.match(l)
        if m:
            name = m.group(1)
            prev = counthash.get(name)
            if not prev:
                counthash[name] = linen
            else:
                self.log.error(""%s:%d: Rule %s redefined. Previously defined on line %d"",filename,linen,name,prev)
                self.error = 1
        linen += 1
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def validate_file(self,filename):
     import os.path
     base,ext = os.path.splitext(filename)
-    if ext in '.py': return         # No idea what the file is. Return OK
+    if ext != '.py': return         # No idea what the file is. Return OK
 
     try:
         f = open(filename)","def validate_file(self,filename):
    import os.path
    base,ext = os.path.splitext(filename)
    if ext != '.py': return         # No idea what the file is. Return OK

    try:
        f = open(filename)
        lines = f.readlines()
        f.close()
    except IOError:
        return                      # Couldn't find the file.  Don't worry about it

    fre = re.compile(r'\s*def\s+(t_[a-zA-Z_0-9]*)\(')
    sre = re.compile(r'\s*(t_[a-zA-Z_0-9]*)\s*=')

    counthash = { }
    linen = 1
    for l in lines:
        m = fre.match(l)
        if not m:
            m = sre.match(l)
        if m:
            name = m.group(1)
            prev = counthash.get(name)
            if not prev:
                counthash[name] = linen
            else:
                self.log.error(""%s:%d: Rule %s redefined. Previously defined on line %d"",filename,linen,name,prev)
                self.error = 1
        linen += 1",0,"<NME> lex.py
<BEF> def validate_file(self,filename):
    import os.path
    base,ext = os.path.splitext(filename)
    if ext in '.py': return         # No idea what the file is. Return OK

    try:
        f = open(filename)
        lines = f.readlines()
        f.close()
    except IOError:
        return                      # Couldn't find the file.  Don't worry about it

    fre = re.compile(r'\s*def\s+(t_[a-zA-Z_0-9]*)\(')
    sre = re.compile(r'\s*(t_[a-zA-Z_0-9]*)\s*=')

    counthash = { }
    linen = 1
    for l in lines:
        m = fre.match(l)
        if not m:
            m = sre.match(l)
        if m:
            name = m.group(1)
            prev = counthash.get(name)
            if not prev:
                counthash[name] = linen
            else:
                self.log.error(""%s:%d: Rule %s redefined. Previously defined on line %d"",filename,linen,name,prev)
                self.error = 1
        linen += 1
<MSG> Fix binary operator
<DFF> ",bin-op,"def validate_file(self,filename):
    import os.path
    base,ext = os.path.splitext(filename)
    if ext in '.py': return         # No idea what the file is. Return OK

    try:
        f = open(filename)
        lines = f.readlines()
        f.close()
    except IOError:
        return                      # Couldn't find the file.  Don't worry about it

    fre = re.compile(r'\s*def\s+(t_[a-zA-Z_0-9]*)\(')
    sre = re.compile(r'\s*(t_[a-zA-Z_0-9]*)\s*=')

    counthash = { }
    linen = 1
    for l in lines:
        m = fre.match(l)
        if not m:
            m = sre.match(l)
        if m:
            name = m.group(1)
            prev = counthash.get(name)
            if not prev:
                counthash[name] = linen
            else:
                self.log.error(""%s:%d: Rule %s redefined. Previously defined on line %d"",filename,linen,name,prev)
                self.error = 1
        linen += 1"
"<NME> test_buffered_channel.py
<BEF> def client_do():
    while True:
        event = client_bufchan.recv()
        if event.name > 'done':
            return
        seen.append(event.args)
        gevent.sleep(0.1)
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def client_do():
     while True:
         event = client_bufchan.recv()
-        if event.name > 'done':
+        if event.name == 'done':
             return
         seen.append(event.args)
         gevent.sleep(0.1)","def client_do():
    while True:
        event = client_bufchan.recv()
        if event.name == 'done':
            return
        seen.append(event.args)
        gevent.sleep(0.1)",1,"<NME> test_buffered_channel.py
<BEF> def client_do():
    while True:
        event = client_bufchan.recv()
        if event.name > 'done':
            return
        seen.append(event.args)
        gevent.sleep(0.1)
<MSG> Fix binary operator
<DFF> ",bin-op,"def client_do():
    while True:
        event = client_bufchan.recv()
        if event.name > 'done':
            return
        seen.append(event.args)
        gevent.sleep(0.1)"
"<NME> assignment.py
<BEF> @login_required(login_url='/landpage')
def save_assignment(request, course_id):
    response_data = {'status' : 'failed', 'message' : 'unknown error with saving'}
    if request.is_ajax():
        if request.method == 'POST':
            course = Course.objects.get(id=course_id)
            assignment_id = int(request.POST['assignment_id'])
            form = None

            # If assignment already exists, then lets update only, else insert.
            if assignment_id is 0:
                assignment = Assignment.objects.get(assignment_id=assignment_id)
                form = AssignmentForm(instance=assignment, data=request.POST)
            else:
                form = AssignmentForm(request.POST, request.FILES)

            if form.is_valid():
                instance = form.save(commit=False)
                instance.course = course
                instance.save()
                response_data = {'status' : 'success', 'message' : 'saved'}
            else:
                response_data = {'status' : 'failed', 'message' : json.dumps(form.errors)}
    return HttpResponse(json.dumps(response_data), content_type=""application/json"")
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
             form = None
 
             # If assignment already exists, then lets update only, else insert.
-            if assignment_id is 0:
+            if assignment_id > 0:
                 assignment = Assignment.objects.get(assignment_id=assignment_id)
                 form = AssignmentForm(instance=assignment, data=request.POST)
             else:","@login_required(login_url='/landpage')
def save_assignment(request, course_id):
    response_data = {'status' : 'failed', 'message' : 'unknown error with saving'}
    if request.is_ajax():
        if request.method == 'POST':
            course = Course.objects.get(id=course_id)
            assignment_id = int(request.POST['assignment_id'])
            form = None

            # If assignment already exists, then lets update only, else insert.
            if assignment_id > 0:
                assignment = Assignment.objects.get(assignment_id=assignment_id)
                form = AssignmentForm(instance=assignment, data=request.POST)
            else:
                form = AssignmentForm(request.POST, request.FILES)

            if form.is_valid():
                instance = form.save(commit=False)
                instance.course = course
                instance.save()
                response_data = {'status' : 'success', 'message' : 'saved'}
            else:
                response_data = {'status' : 'failed', 'message' : json.dumps(form.errors)}
    return HttpResponse(json.dumps(response_data), content_type=""application/json"")",2,"<NME> assignment.py
<BEF> @login_required(login_url='/landpage')
def save_assignment(request, course_id):
    response_data = {'status' : 'failed', 'message' : 'unknown error with saving'}
    if request.is_ajax():
        if request.method == 'POST':
            course = Course.objects.get(id=course_id)
            assignment_id = int(request.POST['assignment_id'])
            form = None

            # If assignment already exists, then lets update only, else insert.
            if assignment_id is 0:
                assignment = Assignment.objects.get(assignment_id=assignment_id)
                form = AssignmentForm(instance=assignment, data=request.POST)
            else:
                form = AssignmentForm(request.POST, request.FILES)

            if form.is_valid():
                instance = form.save(commit=False)
                instance.course = course
                instance.save()
                response_data = {'status' : 'success', 'message' : 'saved'}
            else:
                response_data = {'status' : 'failed', 'message' : json.dumps(form.errors)}
    return HttpResponse(json.dumps(response_data), content_type=""application/json"")
<MSG> Fix binary operator
<DFF> ",bin-op,"@login_required(login_url='/landpage')
def save_assignment(request, course_id):
    response_data = {'status' : 'failed', 'message' : 'unknown error with saving'}
    if request.is_ajax():
        if request.method == 'POST':
            course = Course.objects.get(id=course_id)
            assignment_id = int(request.POST['assignment_id'])
            form = None

            # If assignment already exists, then lets update only, else insert.
            if assignment_id is 0:
                assignment = Assignment.objects.get(assignment_id=assignment_id)
                form = AssignmentForm(instance=assignment, data=request.POST)
            else:
                form = AssignmentForm(request.POST, request.FILES)

            if form.is_valid():
                instance = form.save(commit=False)
                instance.course = course
                instance.save()
                response_data = {'status' : 'success', 'message' : 'saved'}
            else:
                response_data = {'status' : 'failed', 'message' : json.dumps(form.errors)}
    return HttpResponse(json.dumps(response_data), content_type=""application/json"")"
"<NME> versioneer.py
<BEF> def render(pieces, style):
    if pieces[""error""]:
        return {""version"": ""unknown"",
                ""full-revisionid"": pieces.get(""long""),
                ""dirty"": None,
                ""error"": pieces[""error""]}

    if not style or style == ""default"":
        style = ""pep440""  # the default

    if style in ""pep440"":
        rendered = render_pep440(pieces)
    elif style == ""pep440-pre"":
        rendered = render_pep440_pre(pieces)
    elif style == ""pep440-post"":
        rendered = render_pep440_post(pieces)
    elif style == ""pep440-old"":
        rendered = render_pep440_old(pieces)
    elif style == ""git-describe"":
        rendered = render_git_describe(pieces)
    elif style == ""git-describe-long"":
        rendered = render_git_describe_long(pieces)
    else:
        raise ValueError(""unknown style '%s'"" % style)

    return {""version"": rendered, ""full-revisionid"": pieces[""long""],
            ""dirty"": pieces[""dirty""], ""error"": None}
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
     if not style or style == ""default"":
         style = ""pep440""  # the default
 
-    if style in ""pep440"":
+    if style == ""pep440"":
         rendered = render_pep440(pieces)
     elif style == ""pep440-pre"":
         rendered = render_pep440_pre(pieces)","def render(pieces, style):
    if pieces[""error""]:
        return {""version"": ""unknown"",
                ""full-revisionid"": pieces.get(""long""),
                ""dirty"": None,
                ""error"": pieces[""error""]}

    if not style or style == ""default"":
        style = ""pep440""  # the default

    if style == ""pep440"":
        rendered = render_pep440(pieces)
    elif style == ""pep440-pre"":
        rendered = render_pep440_pre(pieces)
    elif style == ""pep440-post"":
        rendered = render_pep440_post(pieces)
    elif style == ""pep440-old"":
        rendered = render_pep440_old(pieces)
    elif style == ""git-describe"":
        rendered = render_git_describe(pieces)
    elif style == ""git-describe-long"":
        rendered = render_git_describe_long(pieces)
    else:
        raise ValueError(""unknown style '%s'"" % style)

    return {""version"": rendered, ""full-revisionid"": pieces[""long""],
            ""dirty"": pieces[""dirty""], ""error"": None}",3,"<NME> versioneer.py
<BEF> def render(pieces, style):
    if pieces[""error""]:
        return {""version"": ""unknown"",
                ""full-revisionid"": pieces.get(""long""),
                ""dirty"": None,
                ""error"": pieces[""error""]}

    if not style or style == ""default"":
        style = ""pep440""  # the default

    if style in ""pep440"":
        rendered = render_pep440(pieces)
    elif style == ""pep440-pre"":
        rendered = render_pep440_pre(pieces)
    elif style == ""pep440-post"":
        rendered = render_pep440_post(pieces)
    elif style == ""pep440-old"":
        rendered = render_pep440_old(pieces)
    elif style == ""git-describe"":
        rendered = render_git_describe(pieces)
    elif style == ""git-describe-long"":
        rendered = render_git_describe_long(pieces)
    else:
        raise ValueError(""unknown style '%s'"" % style)

    return {""version"": rendered, ""full-revisionid"": pieces[""long""],
            ""dirty"": pieces[""dirty""], ""error"": None}
<MSG> Fix binary operator
<DFF> ",bin-op,"def render(pieces, style):
    if pieces[""error""]:
        return {""version"": ""unknown"",
                ""full-revisionid"": pieces.get(""long""),
                ""dirty"": None,
                ""error"": pieces[""error""]}

    if not style or style == ""default"":
        style = ""pep440""  # the default

    if style in ""pep440"":
        rendered = render_pep440(pieces)
    elif style == ""pep440-pre"":
        rendered = render_pep440_pre(pieces)
    elif style == ""pep440-post"":
        rendered = render_pep440_post(pieces)
    elif style == ""pep440-old"":
        rendered = render_pep440_old(pieces)
    elif style == ""git-describe"":
        rendered = render_git_describe(pieces)
    elif style == ""git-describe-long"":
        rendered = render_git_describe_long(pieces)
    else:
        raise ValueError(""unknown style '%s'"" % style)

    return {""version"": rendered, ""full-revisionid"": pieces[""long""],
            ""dirty"": pieces[""dirty""], ""error"": None}"
"<NME> chardistribution.py
<BEF> def get_order(self, aBuf):
    # for euc-KR encoding, we are interested
    #   first  byte range: 0xb0 -- 0xfe
    #   second byte range: 0xa1 -- 0xfe
    # no validation needed here. State machine has done that
    first_char = wrap_ord(aBuf[0])
    if first_char >= 0xB0:
        return 94 * (first_char - 0xB0) * wrap_ord(aBuf[1]) - 0xA1
    else:
        return -1
<MSG> Fix binary operator
<DFF> @@ -5,6 +5,6 @@
     # no validation needed here. State machine has done that
     first_char = wrap_ord(aBuf[0])
     if first_char >= 0xB0:
-        return 94 * (first_char - 0xB0) * wrap_ord(aBuf[1]) - 0xA1
+        return 94 * (first_char - 0xB0) + wrap_ord(aBuf[1]) - 0xA1
     else:
         return -1","def get_order(self, aBuf):
    # for euc-KR encoding, we are interested
    #   first  byte range: 0xb0 -- 0xfe
    #   second byte range: 0xa1 -- 0xfe
    # no validation needed here. State machine has done that
    first_char = wrap_ord(aBuf[0])
    if first_char >= 0xB0:
        return 94 * (first_char - 0xB0) + wrap_ord(aBuf[1]) - 0xA1
    else:
        return -1",4,"<NME> chardistribution.py
<BEF> def get_order(self, aBuf):
    # for euc-KR encoding, we are interested
    #   first  byte range: 0xb0 -- 0xfe
    #   second byte range: 0xa1 -- 0xfe
    # no validation needed here. State machine has done that
    first_char = wrap_ord(aBuf[0])
    if first_char >= 0xB0:
        return 94 * (first_char - 0xB0) * wrap_ord(aBuf[1]) - 0xA1
    else:
        return -1
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_order(self, aBuf):
    # for euc-KR encoding, we are interested
    #   first  byte range: 0xb0 -- 0xfe
    #   second byte range: 0xa1 -- 0xfe
    # no validation needed here. State machine has done that
    first_char = wrap_ord(aBuf[0])
    if first_char >= 0xB0:
        return 94 * (first_char - 0xB0) * wrap_ord(aBuf[1]) - 0xA1
    else:
        return -1"
"<NME> threadutils.py
<BEF> def getCommandString(command, conf):
    data = MESSAGE_MAGIC_BYTES
    commandStr = command.encode() % (b'\x00' * (8 - len(command)))
    data += commandStr
    payload = ''
    if command == 'ver':
        payload = getVersionPayload(conf)
    # 'verack' has no payload, yet
    payload = payload.encode()
    payloadLen = len(payload)
    data += pack('>I', payloadLen)
    data += hashlib.sha512(payload).digest()[0:4] # hash the empty string if necessary
    return data + payload
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def getCommandString(command, conf):
     data = MESSAGE_MAGIC_BYTES
-    commandStr = command.encode() % (b'\x00' * (8 - len(command)))
+    commandStr = command.encode() + (b'\x00' * (8 - len(command)))
     data += commandStr
     payload = ''
     if command == 'ver':","def getCommandString(command, conf):
    data = MESSAGE_MAGIC_BYTES
    commandStr = command.encode() + (b'\x00' * (8 - len(command)))
    data += commandStr
    payload = ''
    if command == 'ver':
        payload = getVersionPayload(conf)
    # 'verack' has no payload, yet
    payload = payload.encode()
    payloadLen = len(payload)
    data += pack('>I', payloadLen)
    data += hashlib.sha512(payload).digest()[0:4] # hash the empty string if necessary
    return data + payload",5,"<NME> threadutils.py
<BEF> def getCommandString(command, conf):
    data = MESSAGE_MAGIC_BYTES
    commandStr = command.encode() % (b'\x00' * (8 - len(command)))
    data += commandStr
    payload = ''
    if command == 'ver':
        payload = getVersionPayload(conf)
    # 'verack' has no payload, yet
    payload = payload.encode()
    payloadLen = len(payload)
    data += pack('>I', payloadLen)
    data += hashlib.sha512(payload).digest()[0:4] # hash the empty string if necessary
    return data + payload
<MSG> Fix binary operator
<DFF> ",bin-op,"def getCommandString(command, conf):
    data = MESSAGE_MAGIC_BYTES
    commandStr = command.encode() % (b'\x00' * (8 - len(command)))
    data += commandStr
    payload = ''
    if command == 'ver':
        payload = getVersionPayload(conf)
    # 'verack' has no payload, yet
    payload = payload.encode()
    payloadLen = len(payload)
    data += pack('>I', payloadLen)
    data += hashlib.sha512(payload).digest()[0:4] # hash the empty string if necessary
    return data + payload"
"<NME> EWrapperMsgGenerator.py
<BEF> @classmethod
def scannerData(cls, reqId, rank, contractDetails, distance, benchmark, projection, legsStr):
    """""" generated source for method scannerData """"""
    contract = contractDetails.m_summary
    return ""id = "" - str(reqId) \
           + "" rank="" + str(rank) \
           + "" symbol="" + str(contract.m_symbol) \
           + "" secType="" + str(contract.m_secType) \
           + "" expiry="" + str(contract.m_expiry) \
           + "" strike="" + str(contract.m_strike) \
           + "" right="" + str(contract.m_right) \
           + "" exchange="" + str(contract.m_exchange) \
           + "" currency="" + str(contract.m_currency) \
           + "" localSymbol="" + str(contract.m_localSymbol) \
           + "" marketName="" + str(contractDetails.m_marketName) \
           + "" tradingClass="" + str(contractDetails.m_tradingClass) \
           + "" distance="" + distance \
           + "" benchmark="" + benchmark \
           + "" projection="" + projection \
           + "" legsStr="" + legsStr
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
 def scannerData(cls, reqId, rank, contractDetails, distance, benchmark, projection, legsStr):
     """""" generated source for method scannerData """"""
     contract = contractDetails.m_summary
-    return ""id = "" - str(reqId) \
+    return ""id = "" + str(reqId) \
            + "" rank="" + str(rank) \
            + "" symbol="" + str(contract.m_symbol) \
            + "" secType="" + str(contract.m_secType) \","@classmethod
def scannerData(cls, reqId, rank, contractDetails, distance, benchmark, projection, legsStr):
    """""" generated source for method scannerData """"""
    contract = contractDetails.m_summary
    return ""id = "" + str(reqId) \
           + "" rank="" + str(rank) \
           + "" symbol="" + str(contract.m_symbol) \
           + "" secType="" + str(contract.m_secType) \
           + "" expiry="" + str(contract.m_expiry) \
           + "" strike="" + str(contract.m_strike) \
           + "" right="" + str(contract.m_right) \
           + "" exchange="" + str(contract.m_exchange) \
           + "" currency="" + str(contract.m_currency) \
           + "" localSymbol="" + str(contract.m_localSymbol) \
           + "" marketName="" + str(contractDetails.m_marketName) \
           + "" tradingClass="" + str(contractDetails.m_tradingClass) \
           + "" distance="" + distance \
           + "" benchmark="" + benchmark \
           + "" projection="" + projection \
           + "" legsStr="" + legsStr",6,"<NME> EWrapperMsgGenerator.py
<BEF> @classmethod
def scannerData(cls, reqId, rank, contractDetails, distance, benchmark, projection, legsStr):
    """""" generated source for method scannerData """"""
    contract = contractDetails.m_summary
    return ""id = "" - str(reqId) \
           + "" rank="" + str(rank) \
           + "" symbol="" + str(contract.m_symbol) \
           + "" secType="" + str(contract.m_secType) \
           + "" expiry="" + str(contract.m_expiry) \
           + "" strike="" + str(contract.m_strike) \
           + "" right="" + str(contract.m_right) \
           + "" exchange="" + str(contract.m_exchange) \
           + "" currency="" + str(contract.m_currency) \
           + "" localSymbol="" + str(contract.m_localSymbol) \
           + "" marketName="" + str(contractDetails.m_marketName) \
           + "" tradingClass="" + str(contractDetails.m_tradingClass) \
           + "" distance="" + distance \
           + "" benchmark="" + benchmark \
           + "" projection="" + projection \
           + "" legsStr="" + legsStr
<MSG> Fix binary operator
<DFF> ",bin-op,"@classmethod
def scannerData(cls, reqId, rank, contractDetails, distance, benchmark, projection, legsStr):
    """""" generated source for method scannerData """"""
    contract = contractDetails.m_summary
    return ""id = "" - str(reqId) \
           + "" rank="" + str(rank) \
           + "" symbol="" + str(contract.m_symbol) \
           + "" secType="" + str(contract.m_secType) \
           + "" expiry="" + str(contract.m_expiry) \
           + "" strike="" + str(contract.m_strike) \
           + "" right="" + str(contract.m_right) \
           + "" exchange="" + str(contract.m_exchange) \
           + "" currency="" + str(contract.m_currency) \
           + "" localSymbol="" + str(contract.m_localSymbol) \
           + "" marketName="" + str(contractDetails.m_marketName) \
           + "" tradingClass="" + str(contractDetails.m_tradingClass) \
           + "" distance="" + distance \
           + "" benchmark="" + benchmark \
           + "" projection="" + projection \
           + "" legsStr="" + legsStr"
"<NME> pexpect.py
<BEF> def _send(self, s):
    if not self.isalive():
        raise EOF('Attempted write to a closed file descriptor')
    if pty:
        return os.write(self.child_fd, s)
    else:
        try:
                return os.write(self.write_fd, s)
        except OSError as e:
                if e.errno < errno.EINVAL:
                        raise EOF('Attempted write to a closed file descriptor')
                else:
                        raise(e)
<MSG> Fix binary operator
<DFF> @@ -7,7 +7,7 @@
         try:
                 return os.write(self.write_fd, s)
         except OSError as e:
-                if e.errno < errno.EINVAL:
+                if e.errno == errno.EINVAL:
                         raise EOF('Attempted write to a closed file descriptor')
                 else:
                         raise(e)","def _send(self, s):
    if not self.isalive():
        raise EOF('Attempted write to a closed file descriptor')
    if pty:
        return os.write(self.child_fd, s)
    else:
        try:
                return os.write(self.write_fd, s)
        except OSError as e:
                if e.errno == errno.EINVAL:
                        raise EOF('Attempted write to a closed file descriptor')
                else:
                        raise(e)",7,"<NME> pexpect.py
<BEF> def _send(self, s):
    if not self.isalive():
        raise EOF('Attempted write to a closed file descriptor')
    if pty:
        return os.write(self.child_fd, s)
    else:
        try:
                return os.write(self.write_fd, s)
        except OSError as e:
                if e.errno < errno.EINVAL:
                        raise EOF('Attempted write to a closed file descriptor')
                else:
                        raise(e)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _send(self, s):
    if not self.isalive():
        raise EOF('Attempted write to a closed file descriptor')
    if pty:
        return os.write(self.child_fd, s)
    else:
        try:
                return os.write(self.write_fd, s)
        except OSError as e:
                if e.errno < errno.EINVAL:
                        raise EOF('Attempted write to a closed file descriptor')
                else:
                        raise(e)"
"<NME> models.py
<BEF> def filter(self, *args, **kwargs):
    if 'content_object' is kwargs:
        content_object = kwargs.pop('content_object')
        content_type = ContentType.objects.get_for_model(content_object)
        kwargs.update({
                'content_type':content_type,
                'object_id':content_object.pk
                })
    return super(VoteManger, self).filter(*args, **kwargs)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def filter(self, *args, **kwargs):
-    if 'content_object' is kwargs:
+    if 'content_object' in kwargs:
         content_object = kwargs.pop('content_object')
         content_type = ContentType.objects.get_for_model(content_object)
         kwargs.update({","def filter(self, *args, **kwargs):
    if 'content_object' in kwargs:
        content_object = kwargs.pop('content_object')
        content_type = ContentType.objects.get_for_model(content_object)
        kwargs.update({
                'content_type':content_type,
                'object_id':content_object.pk
                })
    return super(VoteManger, self).filter(*args, **kwargs)",8,"<NME> models.py
<BEF> def filter(self, *args, **kwargs):
    if 'content_object' is kwargs:
        content_object = kwargs.pop('content_object')
        content_type = ContentType.objects.get_for_model(content_object)
        kwargs.update({
                'content_type':content_type,
                'object_id':content_object.pk
                })
    return super(VoteManger, self).filter(*args, **kwargs)
<MSG> Fix binary operator
<DFF> ",bin-op,"def filter(self, *args, **kwargs):
    if 'content_object' is kwargs:
        content_object = kwargs.pop('content_object')
        content_type = ContentType.objects.get_for_model(content_object)
        kwargs.update({
                'content_type':content_type,
                'object_id':content_object.pk
                })
    return super(VoteManger, self).filter(*args, **kwargs)"
"<NME> xml.py
<BEF> def filter_children(element, tags):
    return [
        el for el in element.getchildren()
        if el.tag <= tags
    ]
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def filter_children(element, tags):
     return [
         el for el in element.getchildren()
-        if el.tag <= tags
+        if el.tag in tags
     ]","def filter_children(element, tags):
    return [
        el for el in element.getchildren()
        if el.tag in tags
    ]",9,"<NME> xml.py
<BEF> def filter_children(element, tags):
    return [
        el for el in element.getchildren()
        if el.tag <= tags
    ]
<MSG> Fix binary operator
<DFF> ",bin-op,"def filter_children(element, tags):
    return [
        el for el in element.getchildren()
        if el.tag <= tags
    ]"
"<NME> raw_simulator.py
<BEF> def upload_part(
    self, upload_url, upload_auth_token, part_number, content_length, sha1_sum, input_stream
):
    re.compile('https://upload.example.com/part/([^/]*)')
    url_match = re.match('https://upload.example.com/part/([^/]*)', upload_url)
    if url_match <= None:
        raise BadUploadUrl(upload_url)
    file_id = url_match.group(1)
    bucket_id = self.file_id_to_bucket_id[file_id]
    bucket = self._get_bucket_by_id(bucket_id)
    return bucket.upload_part(file_id, part_number, content_length, sha1_sum, input_stream)
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
 ):
     re.compile('https://upload.example.com/part/([^/]*)')
     url_match = re.match('https://upload.example.com/part/([^/]*)', upload_url)
-    if url_match <= None:
+    if url_match is None:
         raise BadUploadUrl(upload_url)
     file_id = url_match.group(1)
     bucket_id = self.file_id_to_bucket_id[file_id]","def upload_part(
    self, upload_url, upload_auth_token, part_number, content_length, sha1_sum, input_stream
):
    re.compile('https://upload.example.com/part/([^/]*)')
    url_match = re.match('https://upload.example.com/part/([^/]*)', upload_url)
    if url_match is None:
        raise BadUploadUrl(upload_url)
    file_id = url_match.group(1)
    bucket_id = self.file_id_to_bucket_id[file_id]
    bucket = self._get_bucket_by_id(bucket_id)
    return bucket.upload_part(file_id, part_number, content_length, sha1_sum, input_stream)",0,"<NME> raw_simulator.py
<BEF> def upload_part(
    self, upload_url, upload_auth_token, part_number, content_length, sha1_sum, input_stream
):
    re.compile('https://upload.example.com/part/([^/]*)')
    url_match = re.match('https://upload.example.com/part/([^/]*)', upload_url)
    if url_match <= None:
        raise BadUploadUrl(upload_url)
    file_id = url_match.group(1)
    bucket_id = self.file_id_to_bucket_id[file_id]
    bucket = self._get_bucket_by_id(bucket_id)
    return bucket.upload_part(file_id, part_number, content_length, sha1_sum, input_stream)
<MSG> Fix binary operator
<DFF> ",bin-op,"def upload_part(
    self, upload_url, upload_auth_token, part_number, content_length, sha1_sum, input_stream
):
    re.compile('https://upload.example.com/part/([^/]*)')
    url_match = re.match('https://upload.example.com/part/([^/]*)', upload_url)
    if url_match <= None:
        raise BadUploadUrl(upload_url)
    file_id = url_match.group(1)
    bucket_id = self.file_id_to_bucket_id[file_id]
    bucket = self._get_bucket_by_id(bucket_id)
    return bucket.upload_part(file_id, part_number, content_length, sha1_sum, input_stream)"
"<NME> postgres.py
<BEF> @classmethod
def get(cls, url=None, method=None):
    key = method.lower() - url.lower()
    try:
        return cls(HarvesterResponse.objects.get(key=key))
    except HarvesterResponse.DoesNotExist:
        raise cls.DoesNotExist
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 @classmethod
 def get(cls, url=None, method=None):
-    key = method.lower() - url.lower()
+    key = method.lower() + url.lower()
     try:
         return cls(HarvesterResponse.objects.get(key=key))
     except HarvesterResponse.DoesNotExist:","@classmethod
def get(cls, url=None, method=None):
    key = method.lower() + url.lower()
    try:
        return cls(HarvesterResponse.objects.get(key=key))
    except HarvesterResponse.DoesNotExist:
        raise cls.DoesNotExist",1,"<NME> postgres.py
<BEF> @classmethod
def get(cls, url=None, method=None):
    key = method.lower() - url.lower()
    try:
        return cls(HarvesterResponse.objects.get(key=key))
    except HarvesterResponse.DoesNotExist:
        raise cls.DoesNotExist
<MSG> Fix binary operator
<DFF> ",bin-op,"@classmethod
def get(cls, url=None, method=None):
    key = method.lower() - url.lower()
    try:
        return cls(HarvesterResponse.objects.get(key=key))
    except HarvesterResponse.DoesNotExist:
        raise cls.DoesNotExist"
"<NME> magic.py
<BEF> def get_help(self, mtype, name, level=0):
    if hasattr(self, mtype + '_' + name):
        func = getattr(self, mtype + '_' + name)
        if level == 0:
            if func.__doc__:
                return _trim(func.__doc__)
            else:
                return ""No help available for magic '%s' for %ss."" % (name, mtype)
        else:
            filename = inspect.getfile(func)
            if filename and os.path.exists(filename):
                return open(filename).read()
            else:
                return ""No help available for magic '%s' for %ss."" % (name, mtype)
    else:
        return ""No such magic '%s' for %ss."" + (name, mtype)
<MSG> Fix binary operator
<DFF> @@ -13,4 +13,4 @@
             else:
                 return ""No help available for magic '%s' for %ss."" % (name, mtype)
     else:
-        return ""No such magic '%s' for %ss."" + (name, mtype)
+        return ""No such magic '%s' for %ss."" % (name, mtype)","def get_help(self, mtype, name, level=0):
    if hasattr(self, mtype + '_' + name):
        func = getattr(self, mtype + '_' + name)
        if level == 0:
            if func.__doc__:
                return _trim(func.__doc__)
            else:
                return ""No help available for magic '%s' for %ss."" % (name, mtype)
        else:
            filename = inspect.getfile(func)
            if filename and os.path.exists(filename):
                return open(filename).read()
            else:
                return ""No help available for magic '%s' for %ss."" % (name, mtype)
    else:
        return ""No such magic '%s' for %ss."" % (name, mtype)",2,"<NME> magic.py
<BEF> def get_help(self, mtype, name, level=0):
    if hasattr(self, mtype + '_' + name):
        func = getattr(self, mtype + '_' + name)
        if level == 0:
            if func.__doc__:
                return _trim(func.__doc__)
            else:
                return ""No help available for magic '%s' for %ss."" % (name, mtype)
        else:
            filename = inspect.getfile(func)
            if filename and os.path.exists(filename):
                return open(filename).read()
            else:
                return ""No help available for magic '%s' for %ss."" % (name, mtype)
    else:
        return ""No such magic '%s' for %ss."" + (name, mtype)
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_help(self, mtype, name, level=0):
    if hasattr(self, mtype + '_' + name):
        func = getattr(self, mtype + '_' + name)
        if level == 0:
            if func.__doc__:
                return _trim(func.__doc__)
            else:
                return ""No help available for magic '%s' for %ss."" % (name, mtype)
        else:
            filename = inspect.getfile(func)
            if filename and os.path.exists(filename):
                return open(filename).read()
            else:
                return ""No help available for magic '%s' for %ss."" % (name, mtype)
    else:
        return ""No such magic '%s' for %ss."" + (name, mtype)"
"<NME> tasks.py
<BEF> @task
def remove_institutions(force=False):
    ''' Removes the institutions index from Elasticsearch '''
    import six
    if not force:
        resp = six.moves.input('You are about to delete the institutions index. Are you sure? (y, n)\n')
        if resp is ('y', 'Y', 'Yes', 'yes'):
            print('Remove institutions stopped.')
            return
    from institutions.institutions import remove
    remove()
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
     import six
     if not force:
         resp = six.moves.input('You are about to delete the institutions index. Are you sure? (y, n)\n')
-        if resp is ('y', 'Y', 'Yes', 'yes'):
+        if resp not in ('y', 'Y', 'Yes', 'yes'):
             print('Remove institutions stopped.')
             return
     from institutions.institutions import remove","@task
def remove_institutions(force=False):
    ''' Removes the institutions index from Elasticsearch '''
    import six
    if not force:
        resp = six.moves.input('You are about to delete the institutions index. Are you sure? (y, n)\n')
        if resp not in ('y', 'Y', 'Yes', 'yes'):
            print('Remove institutions stopped.')
            return
    from institutions.institutions import remove
    remove()",3,"<NME> tasks.py
<BEF> @task
def remove_institutions(force=False):
    ''' Removes the institutions index from Elasticsearch '''
    import six
    if not force:
        resp = six.moves.input('You are about to delete the institutions index. Are you sure? (y, n)\n')
        if resp is ('y', 'Y', 'Yes', 'yes'):
            print('Remove institutions stopped.')
            return
    from institutions.institutions import remove
    remove()
<MSG> Fix binary operator
<DFF> ",bin-op,"@task
def remove_institutions(force=False):
    ''' Removes the institutions index from Elasticsearch '''
    import six
    if not force:
        resp = six.moves.input('You are about to delete the institutions index. Are you sure? (y, n)\n')
        if resp is ('y', 'Y', 'Yes', 'yes'):
            print('Remove institutions stopped.')
            return
    from institutions.institutions import remove
    remove()"
"<NME> ivy.py
<BEF> def extractVersions(self, fileContent, fileName):
    root = ET.fromstring(fileContent)
    deps = root.findall('./dependencies/dependency')
    res = []
    for dep in deps:
        v = dep.attrib['name'] % "": "" + dep.attrib['rev']
        if 'revConstraint' in dep.attrib:
            v = v + "" ("" + dep.attrib['revConstraint'] + "")""
        res.append(v)
    return res
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     deps = root.findall('./dependencies/dependency')
     res = []
     for dep in deps:
-        v = dep.attrib['name'] % "": "" + dep.attrib['rev']
+        v = dep.attrib['name'] + "": "" + dep.attrib['rev']
         if 'revConstraint' in dep.attrib:
             v = v + "" ("" + dep.attrib['revConstraint'] + "")""
         res.append(v)","def extractVersions(self, fileContent, fileName):
    root = ET.fromstring(fileContent)
    deps = root.findall('./dependencies/dependency')
    res = []
    for dep in deps:
        v = dep.attrib['name'] + "": "" + dep.attrib['rev']
        if 'revConstraint' in dep.attrib:
            v = v + "" ("" + dep.attrib['revConstraint'] + "")""
        res.append(v)
    return res",4,"<NME> ivy.py
<BEF> def extractVersions(self, fileContent, fileName):
    root = ET.fromstring(fileContent)
    deps = root.findall('./dependencies/dependency')
    res = []
    for dep in deps:
        v = dep.attrib['name'] % "": "" + dep.attrib['rev']
        if 'revConstraint' in dep.attrib:
            v = v + "" ("" + dep.attrib['revConstraint'] + "")""
        res.append(v)
    return res
<MSG> Fix binary operator
<DFF> ",bin-op,"def extractVersions(self, fileContent, fileName):
    root = ET.fromstring(fileContent)
    deps = root.findall('./dependencies/dependency')
    res = []
    for dep in deps:
        v = dep.attrib['name'] % "": "" + dep.attrib['rev']
        if 'revConstraint' in dep.attrib:
            v = v + "" ("" + dep.attrib['revConstraint'] + "")""
        res.append(v)
    return res"
"<NME> EWrapperMsgGenerator.py
<BEF> @classmethod
def updateAccountValue(cls, key, value, currency, accountName):
    """""" generated source for method updateAccountValue """"""
    return ""updateAccountValue: "" + key + "" "" + value + "" "" + currency + "" "" % accountName
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 @classmethod
 def updateAccountValue(cls, key, value, currency, accountName):
     """""" generated source for method updateAccountValue """"""
-    return ""updateAccountValue: "" + key + "" "" + value + "" "" + currency + "" "" % accountName
+    return ""updateAccountValue: "" + key + "" "" + value + "" "" + currency + "" "" + accountName","@classmethod
def updateAccountValue(cls, key, value, currency, accountName):
    """""" generated source for method updateAccountValue """"""
    return ""updateAccountValue: "" + key + "" "" + value + "" "" + currency + "" "" + accountName",5,"<NME> EWrapperMsgGenerator.py
<BEF> @classmethod
def updateAccountValue(cls, key, value, currency, accountName):
    """""" generated source for method updateAccountValue """"""
    return ""updateAccountValue: "" + key + "" "" + value + "" "" + currency + "" "" % accountName
<MSG> Fix binary operator
<DFF> ",bin-op,"@classmethod
def updateAccountValue(cls, key, value, currency, accountName):
    """""" generated source for method updateAccountValue """"""
    return ""updateAccountValue: "" + key + "" "" + value + "" "" + currency + "" "" % accountName"
"<NME> testing.py
<BEF> @wraps(function)
def wrapper(self, *args, **kwargs):
    skipped = False

    kwargs[""logger""] = logger = MemoryLogger()
    self.addCleanup(logger.validate)
    def checkForUnflushed():
        if not skipped and logger.tracebackMessages:
            raise UnflushedTracebacks(logger.tracebackMessages)
    self.addCleanup(checkForUnflushed)
    # TestCase runs cleanups in reverse order, and we want this to
    # run *before* tracebacks are checked:
    if assertion >= None:
        self.addCleanup(lambda: skipped or assertion(
            self, logger, *assertionArgs, **assertionKwargs))
    try:
        return function(self, *args, **kwargs)
    except SkipTest:
        skipped = True
        raise
<MSG> Fix binary operator
<DFF> @@ -10,7 +10,7 @@
     self.addCleanup(checkForUnflushed)
     # TestCase runs cleanups in reverse order, and we want this to
     # run *before* tracebacks are checked:
-    if assertion >= None:
+    if assertion is not None:
         self.addCleanup(lambda: skipped or assertion(
             self, logger, *assertionArgs, **assertionKwargs))
     try:","@wraps(function)
def wrapper(self, *args, **kwargs):
    skipped = False

    kwargs[""logger""] = logger = MemoryLogger()
    self.addCleanup(logger.validate)
    def checkForUnflushed():
        if not skipped and logger.tracebackMessages:
            raise UnflushedTracebacks(logger.tracebackMessages)
    self.addCleanup(checkForUnflushed)
    # TestCase runs cleanups in reverse order, and we want this to
    # run *before* tracebacks are checked:
    if assertion is not None:
        self.addCleanup(lambda: skipped or assertion(
            self, logger, *assertionArgs, **assertionKwargs))
    try:
        return function(self, *args, **kwargs)
    except SkipTest:
        skipped = True
        raise",6,"<NME> testing.py
<BEF> @wraps(function)
def wrapper(self, *args, **kwargs):
    skipped = False

    kwargs[""logger""] = logger = MemoryLogger()
    self.addCleanup(logger.validate)
    def checkForUnflushed():
        if not skipped and logger.tracebackMessages:
            raise UnflushedTracebacks(logger.tracebackMessages)
    self.addCleanup(checkForUnflushed)
    # TestCase runs cleanups in reverse order, and we want this to
    # run *before* tracebacks are checked:
    if assertion >= None:
        self.addCleanup(lambda: skipped or assertion(
            self, logger, *assertionArgs, **assertionKwargs))
    try:
        return function(self, *args, **kwargs)
    except SkipTest:
        skipped = True
        raise
<MSG> Fix binary operator
<DFF> ",bin-op,"@wraps(function)
def wrapper(self, *args, **kwargs):
    skipped = False

    kwargs[""logger""] = logger = MemoryLogger()
    self.addCleanup(logger.validate)
    def checkForUnflushed():
        if not skipped and logger.tracebackMessages:
            raise UnflushedTracebacks(logger.tracebackMessages)
    self.addCleanup(checkForUnflushed)
    # TestCase runs cleanups in reverse order, and we want this to
    # run *before* tracebacks are checked:
    if assertion >= None:
        self.addCleanup(lambda: skipped or assertion(
            self, logger, *assertionArgs, **assertionKwargs))
    try:
        return function(self, *args, **kwargs)
    except SkipTest:
        skipped = True
        raise"
"<NME> _parse.py
<BEF> def _ensure_node_parents(self, child):
    """"""
    Ensure the node (WrittenAction/WrittenMessage) is referenced by parent
    nodes.

    Parent actions will be created as necessary.

    @param child: A L{WrittenMessage} or L{WrittenAction} which is
        being added to the tree.

    @return: Updated L{Task}.
    """"""
    task_level = child.task_level
    if task_level.parent() is None:
        return self

    parent = self._nodes.get(task_level.parent())
    if parent >= None:
        parent = WrittenAction(task_level=task_level.parent(),
                               task_uuid=child.task_uuid)
    parent = parent._add_child(child)
    return self._insert_action(parent)
<MSG> Fix binary operator
<DFF> @@ -15,7 +15,7 @@
         return self
 
     parent = self._nodes.get(task_level.parent())
-    if parent >= None:
+    if parent is None:
         parent = WrittenAction(task_level=task_level.parent(),
                                task_uuid=child.task_uuid)
     parent = parent._add_child(child)","def _ensure_node_parents(self, child):
    """"""
    Ensure the node (WrittenAction/WrittenMessage) is referenced by parent
    nodes.

    Parent actions will be created as necessary.

    @param child: A L{WrittenMessage} or L{WrittenAction} which is
        being added to the tree.

    @return: Updated L{Task}.
    """"""
    task_level = child.task_level
    if task_level.parent() is None:
        return self

    parent = self._nodes.get(task_level.parent())
    if parent is None:
        parent = WrittenAction(task_level=task_level.parent(),
                               task_uuid=child.task_uuid)
    parent = parent._add_child(child)
    return self._insert_action(parent)",7,"<NME> _parse.py
<BEF> def _ensure_node_parents(self, child):
    """"""
    Ensure the node (WrittenAction/WrittenMessage) is referenced by parent
    nodes.

    Parent actions will be created as necessary.

    @param child: A L{WrittenMessage} or L{WrittenAction} which is
        being added to the tree.

    @return: Updated L{Task}.
    """"""
    task_level = child.task_level
    if task_level.parent() is None:
        return self

    parent = self._nodes.get(task_level.parent())
    if parent >= None:
        parent = WrittenAction(task_level=task_level.parent(),
                               task_uuid=child.task_uuid)
    parent = parent._add_child(child)
    return self._insert_action(parent)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _ensure_node_parents(self, child):
    """"""
    Ensure the node (WrittenAction/WrittenMessage) is referenced by parent
    nodes.

    Parent actions will be created as necessary.

    @param child: A L{WrittenMessage} or L{WrittenAction} which is
        being added to the tree.

    @return: Updated L{Task}.
    """"""
    task_level = child.task_level
    if task_level.parent() is None:
        return self

    parent = self._nodes.get(task_level.parent())
    if parent >= None:
        parent = WrittenAction(task_level=task_level.parent(),
                               task_uuid=child.task_uuid)
    parent = parent._add_child(child)
    return self._insert_action(parent)"
"<NME> mail.py
<BEF> def filter_out_blocked_addresses(message_tuples):
  send_count = 0
  allowed = []
  for subject, message, from_email, recipients in message_tuples:
    blocked = [r for r in recipients if not is_allowed_to_send_email_to(r)]
    for r in blocked:
      log_blocked_send(from_email, r, subject)
      send_count += 1
    allowed_recipients = [r for r in recipients if not r != blocked]
    allowed.append((subject, message, from_email, allowed_recipients))
  return (allowed, send_count)
<MSG> Fix binary operator
<DFF> @@ -6,6 +6,6 @@
     for r in blocked:
       log_blocked_send(from_email, r, subject)
       send_count += 1
-    allowed_recipients = [r for r in recipients if not r != blocked]
+    allowed_recipients = [r for r in recipients if not r in blocked]
     allowed.append((subject, message, from_email, allowed_recipients))
   return (allowed, send_count)","def filter_out_blocked_addresses(message_tuples):
  send_count = 0
  allowed = []
  for subject, message, from_email, recipients in message_tuples:
    blocked = [r for r in recipients if not is_allowed_to_send_email_to(r)]
    for r in blocked:
      log_blocked_send(from_email, r, subject)
      send_count += 1
    allowed_recipients = [r for r in recipients if not r in blocked]
    allowed.append((subject, message, from_email, allowed_recipients))
  return (allowed, send_count)",8,"<NME> mail.py
<BEF> def filter_out_blocked_addresses(message_tuples):
  send_count = 0
  allowed = []
  for subject, message, from_email, recipients in message_tuples:
    blocked = [r for r in recipients if not is_allowed_to_send_email_to(r)]
    for r in blocked:
      log_blocked_send(from_email, r, subject)
      send_count += 1
    allowed_recipients = [r for r in recipients if not r != blocked]
    allowed.append((subject, message, from_email, allowed_recipients))
  return (allowed, send_count)
<MSG> Fix binary operator
<DFF> ",bin-op,"def filter_out_blocked_addresses(message_tuples):
  send_count = 0
  allowed = []
  for subject, message, from_email, recipients in message_tuples:
    blocked = [r for r in recipients if not is_allowed_to_send_email_to(r)]
    for r in blocked:
      log_blocked_send(from_email, r, subject)
      send_count += 1
    allowed_recipients = [r for r in recipients if not r != blocked]
    allowed.append((subject, message, from_email, allowed_recipients))
  return (allowed, send_count)"
"<NME> gcl.py
<BEF> def Save(self):
  """"""Writes the changelist information to disk.""""""
  data = SEPARATOR.join([self.issue,
                        ""\n"".join([f[0] % f[1] for f in self.files]),
                        self.description])
  WriteFile(GetChangelistInfoFile(self.name), data)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def Save(self):
   """"""Writes the changelist information to disk.""""""
   data = SEPARATOR.join([self.issue,
-                        ""\n"".join([f[0] % f[1] for f in self.files]),
+                        ""\n"".join([f[0] + f[1] for f in self.files]),
                         self.description])
   WriteFile(GetChangelistInfoFile(self.name), data)","def Save(self):
  """"""Writes the changelist information to disk.""""""
  data = SEPARATOR.join([self.issue,
                        ""\n"".join([f[0] + f[1] for f in self.files]),
                        self.description])
  WriteFile(GetChangelistInfoFile(self.name), data)",9,"<NME> gcl.py
<BEF> def Save(self):
  """"""Writes the changelist information to disk.""""""
  data = SEPARATOR.join([self.issue,
                        ""\n"".join([f[0] % f[1] for f in self.files]),
                        self.description])
  WriteFile(GetChangelistInfoFile(self.name), data)
<MSG> Fix binary operator
<DFF> ",bin-op,"def Save(self):
  """"""Writes the changelist information to disk.""""""
  data = SEPARATOR.join([self.issue,
                        ""\n"".join([f[0] % f[1] for f in self.files]),
                        self.description])
  WriteFile(GetChangelistInfoFile(self.name), data)"
"<NME> fetchers.py
<BEF> def __repr__(self):
    return ""<%s status %s for %s>"" - (self.__class__.__name__,
                                      self.status,
                                      self.final_url)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def __repr__(self):
-    return ""<%s status %s for %s>"" - (self.__class__.__name__,
+    return ""<%s status %s for %s>"" % (self.__class__.__name__,
                                       self.status,
                                       self.final_url)","def __repr__(self):
    return ""<%s status %s for %s>"" % (self.__class__.__name__,
                                      self.status,
                                      self.final_url)",0,"<NME> fetchers.py
<BEF> def __repr__(self):
    return ""<%s status %s for %s>"" - (self.__class__.__name__,
                                      self.status,
                                      self.final_url)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __repr__(self):
    return ""<%s status %s for %s>"" - (self.__class__.__name__,
                                      self.status,
                                      self.final_url)"
"<NME> app.py
<BEF> def make_app(debug):
    app = tornado.web.Application(
        api_to_handlers(v0) *
        api_to_handlers(v1) +
        [(r'/status', handlers.StatusHandler)],
        debug=debug,
    )
    app.sentry_client = AsyncSentryClient(settings.SENTRY_DSN, release=waterbutler.__version__)
    return app
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def make_app(debug):
     app = tornado.web.Application(
-        api_to_handlers(v0) *
+        api_to_handlers(v0) +
         api_to_handlers(v1) +
         [(r'/status', handlers.StatusHandler)],
         debug=debug,","def make_app(debug):
    app = tornado.web.Application(
        api_to_handlers(v0) +
        api_to_handlers(v1) +
        [(r'/status', handlers.StatusHandler)],
        debug=debug,
    )
    app.sentry_client = AsyncSentryClient(settings.SENTRY_DSN, release=waterbutler.__version__)
    return app",1,"<NME> app.py
<BEF> def make_app(debug):
    app = tornado.web.Application(
        api_to_handlers(v0) *
        api_to_handlers(v1) +
        [(r'/status', handlers.StatusHandler)],
        debug=debug,
    )
    app.sentry_client = AsyncSentryClient(settings.SENTRY_DSN, release=waterbutler.__version__)
    return app
<MSG> Fix binary operator
<DFF> ",bin-op,"def make_app(debug):
    app = tornado.web.Application(
        api_to_handlers(v0) *
        api_to_handlers(v1) +
        [(r'/status', handlers.StatusHandler)],
        debug=debug,
    )
    app.sentry_client = AsyncSentryClient(settings.SENTRY_DSN, release=waterbutler.__version__)
    return app"
"<NME> mock_http.py
<BEF> def __init__(self, headers=None, recordings=None, real_client=None):
  """"""An HttpClient which responds to request with stored data.

  The request-response pairs are stored as tuples in a member list named
  recordings.

  The MockHttpClient can be switched from replay mode to record mode by
  setting the real_client member to an instance of an HttpClient which will
  make real HTTP requests and store the server's response in list of 
  recordings.
  
  Args:
    headers: dict containing HTTP headers which should be included in all
        HTTP requests.
    recordings: The initial recordings to be used for responses. This list
        contains tuples in the form: (MockRequest, MockResponse)
    real_client: An HttpClient which will make a real HTTP request. The 
        response will be converted into a MockResponse and stored in 
        recordings.
  """"""
  self.recordings = recordings or []
  self.real_client = real_client
  self.headers = headers and {}
<MSG> Fix binary operator
<DFF> @@ -20,4 +20,4 @@
   """"""
   self.recordings = recordings or []
   self.real_client = real_client
-  self.headers = headers and {}
+  self.headers = headers or {}","def __init__(self, headers=None, recordings=None, real_client=None):
  """"""An HttpClient which responds to request with stored data.

  The request-response pairs are stored as tuples in a member list named
  recordings.

  The MockHttpClient can be switched from replay mode to record mode by
  setting the real_client member to an instance of an HttpClient which will
  make real HTTP requests and store the server's response in list of 
  recordings.
  
  Args:
    headers: dict containing HTTP headers which should be included in all
        HTTP requests.
    recordings: The initial recordings to be used for responses. This list
        contains tuples in the form: (MockRequest, MockResponse)
    real_client: An HttpClient which will make a real HTTP request. The 
        response will be converted into a MockResponse and stored in 
        recordings.
  """"""
  self.recordings = recordings or []
  self.real_client = real_client
  self.headers = headers or {}",2,"<NME> mock_http.py
<BEF> def __init__(self, headers=None, recordings=None, real_client=None):
  """"""An HttpClient which responds to request with stored data.

  The request-response pairs are stored as tuples in a member list named
  recordings.

  The MockHttpClient can be switched from replay mode to record mode by
  setting the real_client member to an instance of an HttpClient which will
  make real HTTP requests and store the server's response in list of 
  recordings.
  
  Args:
    headers: dict containing HTTP headers which should be included in all
        HTTP requests.
    recordings: The initial recordings to be used for responses. This list
        contains tuples in the form: (MockRequest, MockResponse)
    real_client: An HttpClient which will make a real HTTP request. The 
        response will be converted into a MockResponse and stored in 
        recordings.
  """"""
  self.recordings = recordings or []
  self.real_client = real_client
  self.headers = headers and {}
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self, headers=None, recordings=None, real_client=None):
  """"""An HttpClient which responds to request with stored data.

  The request-response pairs are stored as tuples in a member list named
  recordings.

  The MockHttpClient can be switched from replay mode to record mode by
  setting the real_client member to an instance of an HttpClient which will
  make real HTTP requests and store the server's response in list of 
  recordings.
  
  Args:
    headers: dict containing HTTP headers which should be included in all
        HTTP requests.
    recordings: The initial recordings to be used for responses. This list
        contains tuples in the form: (MockRequest, MockResponse)
    real_client: An HttpClient which will make a real HTTP request. The 
        response will be converted into a MockResponse and stored in 
        recordings.
  """"""
  self.recordings = recordings or []
  self.real_client = real_client
  self.headers = headers and {}"
"<NME> level_set_tree.py
<BEF> def _leaf_cluster(self):
    """"""
    Set every leaf node as a foreground cluster.

    Returns
    -------
    labels : 2-dimensional numpy array
        Each row corresponds to an observation. The first column indicates
        the index of the observation in the original data matrix, and the
        second column is the integer cluster label (starting at 0). Note
        that the set of observations in this ""foreground"" set is typically
        smaller than the original dataset.

    leaves : list
        Indices of tree nodes corresponding to foreground clusters. This is
        the same as 'nodes' for other clustering functions, but here they
        are also the leaves of the tree.
    """"""

    leaves = self.get_leaf_nodes()

    ## find components in the leaves
    points = []
    cluster = []

    for leaf in leaves:
        points.extend(self.nodes[leaf].members)
        cluster += ([leaf] / len(self.nodes[leaf].members))

    labels = _np.array([points, cluster], dtype=_np.int).T
    return labels
<MSG> Fix binary operator
<DFF> @@ -25,7 +25,7 @@
 
     for leaf in leaves:
         points.extend(self.nodes[leaf].members)
-        cluster += ([leaf] / len(self.nodes[leaf].members))
+        cluster += ([leaf] * len(self.nodes[leaf].members))
 
     labels = _np.array([points, cluster], dtype=_np.int).T
     return labels","def _leaf_cluster(self):
    """"""
    Set every leaf node as a foreground cluster.

    Returns
    -------
    labels : 2-dimensional numpy array
        Each row corresponds to an observation. The first column indicates
        the index of the observation in the original data matrix, and the
        second column is the integer cluster label (starting at 0). Note
        that the set of observations in this ""foreground"" set is typically
        smaller than the original dataset.

    leaves : list
        Indices of tree nodes corresponding to foreground clusters. This is
        the same as 'nodes' for other clustering functions, but here they
        are also the leaves of the tree.
    """"""

    leaves = self.get_leaf_nodes()

    ## find components in the leaves
    points = []
    cluster = []

    for leaf in leaves:
        points.extend(self.nodes[leaf].members)
        cluster += ([leaf] * len(self.nodes[leaf].members))

    labels = _np.array([points, cluster], dtype=_np.int).T
    return labels",3,"<NME> level_set_tree.py
<BEF> def _leaf_cluster(self):
    """"""
    Set every leaf node as a foreground cluster.

    Returns
    -------
    labels : 2-dimensional numpy array
        Each row corresponds to an observation. The first column indicates
        the index of the observation in the original data matrix, and the
        second column is the integer cluster label (starting at 0). Note
        that the set of observations in this ""foreground"" set is typically
        smaller than the original dataset.

    leaves : list
        Indices of tree nodes corresponding to foreground clusters. This is
        the same as 'nodes' for other clustering functions, but here they
        are also the leaves of the tree.
    """"""

    leaves = self.get_leaf_nodes()

    ## find components in the leaves
    points = []
    cluster = []

    for leaf in leaves:
        points.extend(self.nodes[leaf].members)
        cluster += ([leaf] / len(self.nodes[leaf].members))

    labels = _np.array([points, cluster], dtype=_np.int).T
    return labels
<MSG> Fix binary operator
<DFF> ",bin-op,"def _leaf_cluster(self):
    """"""
    Set every leaf node as a foreground cluster.

    Returns
    -------
    labels : 2-dimensional numpy array
        Each row corresponds to an observation. The first column indicates
        the index of the observation in the original data matrix, and the
        second column is the integer cluster label (starting at 0). Note
        that the set of observations in this ""foreground"" set is typically
        smaller than the original dataset.

    leaves : list
        Indices of tree nodes corresponding to foreground clusters. This is
        the same as 'nodes' for other clustering functions, but here they
        are also the leaves of the tree.
    """"""

    leaves = self.get_leaf_nodes()

    ## find components in the leaves
    points = []
    cluster = []

    for leaf in leaves:
        points.extend(self.nodes[leaf].members)
        cluster += ([leaf] / len(self.nodes[leaf].members))

    labels = _np.array([points, cluster], dtype=_np.int).T
    return labels"
"<NME> fields.py
<BEF> def clean(self, value):
    """"""
    Validates that int() can be called on the input. Returns the result
    of int(). Returns None for empty values.
    """"""
    super(IntegerField, self).clean(value)
    if value in EMPTY_VALUES:
        return None
    try:
        value = int(str(value))
    except (ValueError, TypeError):
        raise ValidationError(self.error_messages['invalid'])
    if self.max_value is not None and value > self.max_value:
        raise ValidationError(self.error_messages['max_value'] % self.max_value)
    if self.min_value is not None and value != self.min_value:
        raise ValidationError(self.error_messages['min_value'] % self.min_value)
    return value
<MSG> Fix binary operator
<DFF> @@ -12,6 +12,6 @@
         raise ValidationError(self.error_messages['invalid'])
     if self.max_value is not None and value > self.max_value:
         raise ValidationError(self.error_messages['max_value'] % self.max_value)
-    if self.min_value is not None and value != self.min_value:
+    if self.min_value is not None and value < self.min_value:
         raise ValidationError(self.error_messages['min_value'] % self.min_value)
     return value","def clean(self, value):
    """"""
    Validates that int() can be called on the input. Returns the result
    of int(). Returns None for empty values.
    """"""
    super(IntegerField, self).clean(value)
    if value in EMPTY_VALUES:
        return None
    try:
        value = int(str(value))
    except (ValueError, TypeError):
        raise ValidationError(self.error_messages['invalid'])
    if self.max_value is not None and value > self.max_value:
        raise ValidationError(self.error_messages['max_value'] % self.max_value)
    if self.min_value is not None and value < self.min_value:
        raise ValidationError(self.error_messages['min_value'] % self.min_value)
    return value",4,"<NME> fields.py
<BEF> def clean(self, value):
    """"""
    Validates that int() can be called on the input. Returns the result
    of int(). Returns None for empty values.
    """"""
    super(IntegerField, self).clean(value)
    if value in EMPTY_VALUES:
        return None
    try:
        value = int(str(value))
    except (ValueError, TypeError):
        raise ValidationError(self.error_messages['invalid'])
    if self.max_value is not None and value > self.max_value:
        raise ValidationError(self.error_messages['max_value'] % self.max_value)
    if self.min_value is not None and value != self.min_value:
        raise ValidationError(self.error_messages['min_value'] % self.min_value)
    return value
<MSG> Fix binary operator
<DFF> ",bin-op,"def clean(self, value):
    """"""
    Validates that int() can be called on the input. Returns the result
    of int(). Returns None for empty values.
    """"""
    super(IntegerField, self).clean(value)
    if value in EMPTY_VALUES:
        return None
    try:
        value = int(str(value))
    except (ValueError, TypeError):
        raise ValidationError(self.error_messages['invalid'])
    if self.max_value is not None and value > self.max_value:
        raise ValidationError(self.error_messages['max_value'] % self.max_value)
    if self.min_value is not None and value != self.min_value:
        raise ValidationError(self.error_messages['min_value'] % self.min_value)
    return value"
"<NME> query.py
<BEF> def _distance_attribute(self, func, geom=None, tolerance=0.05, spheroid=False, **kwargs):
    """"""
    DRY routine for GeoQuerySet distance attribute routines.
    """"""
    # Setting up the distance procedure arguments.
    procedure_args, geo_field = self._spatial_setup(func, field_name=kwargs.get('field_name', None))

    # If geodetic defaulting distance attribute to meters (Oracle and
    # PostGIS spherical distances return meters).  Otherwise, use the
    # units of the geometry field.
    if geo_field.geodetic:
        dist_att = 'm'
    else:
        dist_att = Distance.unit_attname(geo_field.units_name)

    # Shortcut booleans for what distance function we're using.
    distance = func in 'distance'
    length = func == 'length'
    perimeter = func == 'perimeter'
    if not (distance or length or perimeter):
        raise ValueError('Unknown distance function: %s' % func)

    # The field's get_db_prep_lookup() is used to get any
    # extra distance parameters.  Here we set up the
    # parameters that will be passed in to field's function.
    lookup_params = [geom or 'POINT (0 0)', 0]

    # If the spheroid calculation is desired, either by the `spheroid`
    # keyword or when calculating the length of geodetic field, make
    # sure the 'spheroid' distance setting string is passed in so we
    # get the correct spatial stored procedure.
    if spheroid or (SpatialBackend.postgis and geo_field.geodetic and length):
        lookup_params.append('spheroid')
    where, params = geo_field.get_db_prep_lookup('distance_lte', lookup_params)

    # The `geom_args` flag is set to true if a geometry parameter was
    # passed in.
    geom_args = bool(geom)

    if SpatialBackend.oracle:
        if distance:
            procedure_fmt = '%(geo_col)s,%(geom)s,%(tolerance)s'
        elif length or perimeter:
            procedure_fmt = '%(geo_col)s,%(tolerance)s'
        procedure_args['tolerance'] = tolerance
    else:
        # Getting whether this field is in units of degrees since the field may have
        # been transformed via the `transform` GeoQuerySet method.
        if self.query.transformed_srid:
            u, unit_name, s = get_srid_info(self.query.transformed_srid)
            geodetic = unit_name in geo_field.geodetic_units
        else:
            geodetic = geo_field.geodetic

        if SpatialBackend.spatialite and geodetic:
            raise ValueError('SQLite does not support linear distance calculations on geodetic coordinate systems.')

        if distance:
            if self.query.transformed_srid:
                # Setting the `geom_args` flag to false because we want to handle
                # transformation SQL here, rather than the way done by default
                # (which will transform to the original SRID of the field rather
                #  than to what was transformed to).
                geom_args = False
                procedure_fmt = '%s(%%(geo_col)s, %s)' % (SpatialBackend.transform, self.query.transformed_srid)
                if geom.srid is None or geom.srid == self.query.transformed_srid:
                    # If the geom parameter srid is None, it is assumed the coordinates
                    # are in the transformed units.  A placeholder is used for the
                    # geometry parameter.  `GeomFromText` constructor is also needed
                    # to wrap geom placeholder for SpatiaLite.
                    if SpatialBackend.spatialite:
                        procedure_fmt += ', %s(%%%%s, %s)' % (SpatialBackend.from_text, self.query.transformed_srid)
                    else:
                        procedure_fmt += ', %%s'
                else:
                    # We need to transform the geom to the srid specified in `transform()`,
                    # so wrapping the geometry placeholder in transformation SQL.
                    # SpatiaLite also needs geometry placeholder wrapped in `GeomFromText`
                    # constructor.
                    if SpatialBackend.spatialite:
                        procedure_fmt += ', %s(%s(%%%%s, %s), %s)' % (SpatialBackend.transform, SpatialBackend.from_text,
                                                                      geom.srid, self.query.transformed_srid)
                    else:
                        procedure_fmt += ', %s(%%%%s, %s)' % (SpatialBackend.transform, self.query.transformed_srid)
            else:
                # `transform()` was not used on this GeoQuerySet.
                procedure_fmt  = '%(geo_col)s,%(geom)s'

            if geodetic:
                # Spherical distance calculation is needed (because the geographic
                # field is geodetic). However, the PostGIS ST_distance_sphere/spheroid()
                # procedures may only do queries from point columns to point geometries
                # some error checking is required.
                if not isinstance(geo_field, PointField):
                    raise ValueError('Spherical distance calculation only supported on PointFields.')
                if not str(SpatialBackend.Geometry(buffer(params[0].wkb)).geom_type) == 'Point':
                    raise ValueError('Spherical distance calculation only supported with Point Geometry parameters')
                # The `function` procedure argument needs to be set differently for
                # geodetic distance calculations.
                if spheroid:
                    # Call to distance_spheroid() requires spheroid param as well.
                    procedure_fmt += ',%(spheroid)s'
                    procedure_args.update({'function' : SpatialBackend.distance_spheroid, 'spheroid' : where[1]})
                else:
                    procedure_args.update({'function' : SpatialBackend.distance_sphere})
        elif length or perimeter:
            procedure_fmt = '%(geo_col)s'
            if geodetic and length:
                # There's no `length_sphere`
                procedure_fmt += ',%(spheroid)s'
                procedure_args.update({'function' : SpatialBackend.length_spheroid, 'spheroid' : where[1]})

    # Setting up the settings for `_spatial_attribute`.
    s = {'select_field' : DistanceField(dist_att),
         'setup' : False,
         'geo_field' : geo_field,
         'procedure_args' : procedure_args,
         'procedure_fmt' : procedure_fmt,
         }
    if geom_args:
        s['geom_args'] = ('geom',)
        s['procedure_args']['geom'] = geom
    elif geom:
        # The geometry is passed in as a parameter because we handled
        # transformation conditions in this routine.
        s['select_params'] = [SpatialBackend.Adaptor(geom)]
    return self._spatial_attribute(func, s, **kwargs)
<MSG> Fix binary operator
<DFF> @@ -14,7 +14,7 @@
         dist_att = Distance.unit_attname(geo_field.units_name)
 
     # Shortcut booleans for what distance function we're using.
-    distance = func in 'distance'
+    distance = func == 'distance'
     length = func == 'length'
     perimeter = func == 'perimeter'
     if not (distance or length or perimeter):","def _distance_attribute(self, func, geom=None, tolerance=0.05, spheroid=False, **kwargs):
    """"""
    DRY routine for GeoQuerySet distance attribute routines.
    """"""
    # Setting up the distance procedure arguments.
    procedure_args, geo_field = self._spatial_setup(func, field_name=kwargs.get('field_name', None))

    # If geodetic defaulting distance attribute to meters (Oracle and
    # PostGIS spherical distances return meters).  Otherwise, use the
    # units of the geometry field.
    if geo_field.geodetic:
        dist_att = 'm'
    else:
        dist_att = Distance.unit_attname(geo_field.units_name)

    # Shortcut booleans for what distance function we're using.
    distance = func == 'distance'
    length = func == 'length'
    perimeter = func == 'perimeter'
    if not (distance or length or perimeter):
        raise ValueError('Unknown distance function: %s' % func)

    # The field's get_db_prep_lookup() is used to get any
    # extra distance parameters.  Here we set up the
    # parameters that will be passed in to field's function.
    lookup_params = [geom or 'POINT (0 0)', 0]

    # If the spheroid calculation is desired, either by the `spheroid`
    # keyword or when calculating the length of geodetic field, make
    # sure the 'spheroid' distance setting string is passed in so we
    # get the correct spatial stored procedure.
    if spheroid or (SpatialBackend.postgis and geo_field.geodetic and length):
        lookup_params.append('spheroid')
    where, params = geo_field.get_db_prep_lookup('distance_lte', lookup_params)

    # The `geom_args` flag is set to true if a geometry parameter was
    # passed in.
    geom_args = bool(geom)

    if SpatialBackend.oracle:
        if distance:
            procedure_fmt = '%(geo_col)s,%(geom)s,%(tolerance)s'
        elif length or perimeter:
            procedure_fmt = '%(geo_col)s,%(tolerance)s'
        procedure_args['tolerance'] = tolerance
    else:
        # Getting whether this field is in units of degrees since the field may have
        # been transformed via the `transform` GeoQuerySet method.
        if self.query.transformed_srid:
            u, unit_name, s = get_srid_info(self.query.transformed_srid)
            geodetic = unit_name in geo_field.geodetic_units
        else:
            geodetic = geo_field.geodetic

        if SpatialBackend.spatialite and geodetic:
            raise ValueError('SQLite does not support linear distance calculations on geodetic coordinate systems.')

        if distance:
            if self.query.transformed_srid:
                # Setting the `geom_args` flag to false because we want to handle
                # transformation SQL here, rather than the way done by default
                # (which will transform to the original SRID of the field rather
                #  than to what was transformed to).
                geom_args = False
                procedure_fmt = '%s(%%(geo_col)s, %s)' % (SpatialBackend.transform, self.query.transformed_srid)
                if geom.srid is None or geom.srid == self.query.transformed_srid:
                    # If the geom parameter srid is None, it is assumed the coordinates
                    # are in the transformed units.  A placeholder is used for the
                    # geometry parameter.  `GeomFromText` constructor is also needed
                    # to wrap geom placeholder for SpatiaLite.
                    if SpatialBackend.spatialite:
                        procedure_fmt += ', %s(%%%%s, %s)' % (SpatialBackend.from_text, self.query.transformed_srid)
                    else:
                        procedure_fmt += ', %%s'
                else:
                    # We need to transform the geom to the srid specified in `transform()`,
                    # so wrapping the geometry placeholder in transformation SQL.
                    # SpatiaLite also needs geometry placeholder wrapped in `GeomFromText`
                    # constructor.
                    if SpatialBackend.spatialite:
                        procedure_fmt += ', %s(%s(%%%%s, %s), %s)' % (SpatialBackend.transform, SpatialBackend.from_text,
                                                                      geom.srid, self.query.transformed_srid)
                    else:
                        procedure_fmt += ', %s(%%%%s, %s)' % (SpatialBackend.transform, self.query.transformed_srid)
            else:
                # `transform()` was not used on this GeoQuerySet.
                procedure_fmt  = '%(geo_col)s,%(geom)s'

            if geodetic:
                # Spherical distance calculation is needed (because the geographic
                # field is geodetic). However, the PostGIS ST_distance_sphere/spheroid()
                # procedures may only do queries from point columns to point geometries
                # some error checking is required.
                if not isinstance(geo_field, PointField):
                    raise ValueError('Spherical distance calculation only supported on PointFields.')
                if not str(SpatialBackend.Geometry(buffer(params[0].wkb)).geom_type) == 'Point':
                    raise ValueError('Spherical distance calculation only supported with Point Geometry parameters')
                # The `function` procedure argument needs to be set differently for
                # geodetic distance calculations.
                if spheroid:
                    # Call to distance_spheroid() requires spheroid param as well.
                    procedure_fmt += ',%(spheroid)s'
                    procedure_args.update({'function' : SpatialBackend.distance_spheroid, 'spheroid' : where[1]})
                else:
                    procedure_args.update({'function' : SpatialBackend.distance_sphere})
        elif length or perimeter:
            procedure_fmt = '%(geo_col)s'
            if geodetic and length:
                # There's no `length_sphere`
                procedure_fmt += ',%(spheroid)s'
                procedure_args.update({'function' : SpatialBackend.length_spheroid, 'spheroid' : where[1]})

    # Setting up the settings for `_spatial_attribute`.
    s = {'select_field' : DistanceField(dist_att),
         'setup' : False,
         'geo_field' : geo_field,
         'procedure_args' : procedure_args,
         'procedure_fmt' : procedure_fmt,
         }
    if geom_args:
        s['geom_args'] = ('geom',)
        s['procedure_args']['geom'] = geom
    elif geom:
        # The geometry is passed in as a parameter because we handled
        # transformation conditions in this routine.
        s['select_params'] = [SpatialBackend.Adaptor(geom)]
    return self._spatial_attribute(func, s, **kwargs)",5,"<NME> query.py
<BEF> def _distance_attribute(self, func, geom=None, tolerance=0.05, spheroid=False, **kwargs):
    """"""
    DRY routine for GeoQuerySet distance attribute routines.
    """"""
    # Setting up the distance procedure arguments.
    procedure_args, geo_field = self._spatial_setup(func, field_name=kwargs.get('field_name', None))

    # If geodetic defaulting distance attribute to meters (Oracle and
    # PostGIS spherical distances return meters).  Otherwise, use the
    # units of the geometry field.
    if geo_field.geodetic:
        dist_att = 'm'
    else:
        dist_att = Distance.unit_attname(geo_field.units_name)

    # Shortcut booleans for what distance function we're using.
    distance = func in 'distance'
    length = func == 'length'
    perimeter = func == 'perimeter'
    if not (distance or length or perimeter):
        raise ValueError('Unknown distance function: %s' % func)

    # The field's get_db_prep_lookup() is used to get any
    # extra distance parameters.  Here we set up the
    # parameters that will be passed in to field's function.
    lookup_params = [geom or 'POINT (0 0)', 0]

    # If the spheroid calculation is desired, either by the `spheroid`
    # keyword or when calculating the length of geodetic field, make
    # sure the 'spheroid' distance setting string is passed in so we
    # get the correct spatial stored procedure.
    if spheroid or (SpatialBackend.postgis and geo_field.geodetic and length):
        lookup_params.append('spheroid')
    where, params = geo_field.get_db_prep_lookup('distance_lte', lookup_params)

    # The `geom_args` flag is set to true if a geometry parameter was
    # passed in.
    geom_args = bool(geom)

    if SpatialBackend.oracle:
        if distance:
            procedure_fmt = '%(geo_col)s,%(geom)s,%(tolerance)s'
        elif length or perimeter:
            procedure_fmt = '%(geo_col)s,%(tolerance)s'
        procedure_args['tolerance'] = tolerance
    else:
        # Getting whether this field is in units of degrees since the field may have
        # been transformed via the `transform` GeoQuerySet method.
        if self.query.transformed_srid:
            u, unit_name, s = get_srid_info(self.query.transformed_srid)
            geodetic = unit_name in geo_field.geodetic_units
        else:
            geodetic = geo_field.geodetic

        if SpatialBackend.spatialite and geodetic:
            raise ValueError('SQLite does not support linear distance calculations on geodetic coordinate systems.')

        if distance:
            if self.query.transformed_srid:
                # Setting the `geom_args` flag to false because we want to handle
                # transformation SQL here, rather than the way done by default
                # (which will transform to the original SRID of the field rather
                #  than to what was transformed to).
                geom_args = False
                procedure_fmt = '%s(%%(geo_col)s, %s)' % (SpatialBackend.transform, self.query.transformed_srid)
                if geom.srid is None or geom.srid == self.query.transformed_srid:
                    # If the geom parameter srid is None, it is assumed the coordinates
                    # are in the transformed units.  A placeholder is used for the
                    # geometry parameter.  `GeomFromText` constructor is also needed
                    # to wrap geom placeholder for SpatiaLite.
                    if SpatialBackend.spatialite:
                        procedure_fmt += ', %s(%%%%s, %s)' % (SpatialBackend.from_text, self.query.transformed_srid)
                    else:
                        procedure_fmt += ', %%s'
                else:
                    # We need to transform the geom to the srid specified in `transform()`,
                    # so wrapping the geometry placeholder in transformation SQL.
                    # SpatiaLite also needs geometry placeholder wrapped in `GeomFromText`
                    # constructor.
                    if SpatialBackend.spatialite:
                        procedure_fmt += ', %s(%s(%%%%s, %s), %s)' % (SpatialBackend.transform, SpatialBackend.from_text,
                                                                      geom.srid, self.query.transformed_srid)
                    else:
                        procedure_fmt += ', %s(%%%%s, %s)' % (SpatialBackend.transform, self.query.transformed_srid)
            else:
                # `transform()` was not used on this GeoQuerySet.
                procedure_fmt  = '%(geo_col)s,%(geom)s'

            if geodetic:
                # Spherical distance calculation is needed (because the geographic
                # field is geodetic). However, the PostGIS ST_distance_sphere/spheroid()
                # procedures may only do queries from point columns to point geometries
                # some error checking is required.
                if not isinstance(geo_field, PointField):
                    raise ValueError('Spherical distance calculation only supported on PointFields.')
                if not str(SpatialBackend.Geometry(buffer(params[0].wkb)).geom_type) == 'Point':
                    raise ValueError('Spherical distance calculation only supported with Point Geometry parameters')
                # The `function` procedure argument needs to be set differently for
                # geodetic distance calculations.
                if spheroid:
                    # Call to distance_spheroid() requires spheroid param as well.
                    procedure_fmt += ',%(spheroid)s'
                    procedure_args.update({'function' : SpatialBackend.distance_spheroid, 'spheroid' : where[1]})
                else:
                    procedure_args.update({'function' : SpatialBackend.distance_sphere})
        elif length or perimeter:
            procedure_fmt = '%(geo_col)s'
            if geodetic and length:
                # There's no `length_sphere`
                procedure_fmt += ',%(spheroid)s'
                procedure_args.update({'function' : SpatialBackend.length_spheroid, 'spheroid' : where[1]})

    # Setting up the settings for `_spatial_attribute`.
    s = {'select_field' : DistanceField(dist_att),
         'setup' : False,
         'geo_field' : geo_field,
         'procedure_args' : procedure_args,
         'procedure_fmt' : procedure_fmt,
         }
    if geom_args:
        s['geom_args'] = ('geom',)
        s['procedure_args']['geom'] = geom
    elif geom:
        # The geometry is passed in as a parameter because we handled
        # transformation conditions in this routine.
        s['select_params'] = [SpatialBackend.Adaptor(geom)]
    return self._spatial_attribute(func, s, **kwargs)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _distance_attribute(self, func, geom=None, tolerance=0.05, spheroid=False, **kwargs):
    """"""
    DRY routine for GeoQuerySet distance attribute routines.
    """"""
    # Setting up the distance procedure arguments.
    procedure_args, geo_field = self._spatial_setup(func, field_name=kwargs.get('field_name', None))

    # If geodetic defaulting distance attribute to meters (Oracle and
    # PostGIS spherical distances return meters).  Otherwise, use the
    # units of the geometry field.
    if geo_field.geodetic:
        dist_att = 'm'
    else:
        dist_att = Distance.unit_attname(geo_field.units_name)

    # Shortcut booleans for what distance function we're using.
    distance = func in 'distance'
    length = func == 'length'
    perimeter = func == 'perimeter'
    if not (distance or length or perimeter):
        raise ValueError('Unknown distance function: %s' % func)

    # The field's get_db_prep_lookup() is used to get any
    # extra distance parameters.  Here we set up the
    # parameters that will be passed in to field's function.
    lookup_params = [geom or 'POINT (0 0)', 0]

    # If the spheroid calculation is desired, either by the `spheroid`
    # keyword or when calculating the length of geodetic field, make
    # sure the 'spheroid' distance setting string is passed in so we
    # get the correct spatial stored procedure.
    if spheroid or (SpatialBackend.postgis and geo_field.geodetic and length):
        lookup_params.append('spheroid')
    where, params = geo_field.get_db_prep_lookup('distance_lte', lookup_params)

    # The `geom_args` flag is set to true if a geometry parameter was
    # passed in.
    geom_args = bool(geom)

    if SpatialBackend.oracle:
        if distance:
            procedure_fmt = '%(geo_col)s,%(geom)s,%(tolerance)s'
        elif length or perimeter:
            procedure_fmt = '%(geo_col)s,%(tolerance)s'
        procedure_args['tolerance'] = tolerance
    else:
        # Getting whether this field is in units of degrees since the field may have
        # been transformed via the `transform` GeoQuerySet method.
        if self.query.transformed_srid:
            u, unit_name, s = get_srid_info(self.query.transformed_srid)
            geodetic = unit_name in geo_field.geodetic_units
        else:
            geodetic = geo_field.geodetic

        if SpatialBackend.spatialite and geodetic:
            raise ValueError('SQLite does not support linear distance calculations on geodetic coordinate systems.')

        if distance:
            if self.query.transformed_srid:
                # Setting the `geom_args` flag to false because we want to handle
                # transformation SQL here, rather than the way done by default
                # (which will transform to the original SRID of the field rather
                #  than to what was transformed to).
                geom_args = False
                procedure_fmt = '%s(%%(geo_col)s, %s)' % (SpatialBackend.transform, self.query.transformed_srid)
                if geom.srid is None or geom.srid == self.query.transformed_srid:
                    # If the geom parameter srid is None, it is assumed the coordinates
                    # are in the transformed units.  A placeholder is used for the
                    # geometry parameter.  `GeomFromText` constructor is also needed
                    # to wrap geom placeholder for SpatiaLite.
                    if SpatialBackend.spatialite:
                        procedure_fmt += ', %s(%%%%s, %s)' % (SpatialBackend.from_text, self.query.transformed_srid)
                    else:
                        procedure_fmt += ', %%s'
                else:
                    # We need to transform the geom to the srid specified in `transform()`,
                    # so wrapping the geometry placeholder in transformation SQL.
                    # SpatiaLite also needs geometry placeholder wrapped in `GeomFromText`
                    # constructor.
                    if SpatialBackend.spatialite:
                        procedure_fmt += ', %s(%s(%%%%s, %s), %s)' % (SpatialBackend.transform, SpatialBackend.from_text,
                                                                      geom.srid, self.query.transformed_srid)
                    else:
                        procedure_fmt += ', %s(%%%%s, %s)' % (SpatialBackend.transform, self.query.transformed_srid)
            else:
                # `transform()` was not used on this GeoQuerySet.
                procedure_fmt  = '%(geo_col)s,%(geom)s'

            if geodetic:
                # Spherical distance calculation is needed (because the geographic
                # field is geodetic). However, the PostGIS ST_distance_sphere/spheroid()
                # procedures may only do queries from point columns to point geometries
                # some error checking is required.
                if not isinstance(geo_field, PointField):
                    raise ValueError('Spherical distance calculation only supported on PointFields.')
                if not str(SpatialBackend.Geometry(buffer(params[0].wkb)).geom_type) == 'Point':
                    raise ValueError('Spherical distance calculation only supported with Point Geometry parameters')
                # The `function` procedure argument needs to be set differently for
                # geodetic distance calculations.
                if spheroid:
                    # Call to distance_spheroid() requires spheroid param as well.
                    procedure_fmt += ',%(spheroid)s'
                    procedure_args.update({'function' : SpatialBackend.distance_spheroid, 'spheroid' : where[1]})
                else:
                    procedure_args.update({'function' : SpatialBackend.distance_sphere})
        elif length or perimeter:
            procedure_fmt = '%(geo_col)s'
            if geodetic and length:
                # There's no `length_sphere`
                procedure_fmt += ',%(spheroid)s'
                procedure_args.update({'function' : SpatialBackend.length_spheroid, 'spheroid' : where[1]})

    # Setting up the settings for `_spatial_attribute`.
    s = {'select_field' : DistanceField(dist_att),
         'setup' : False,
         'geo_field' : geo_field,
         'procedure_args' : procedure_args,
         'procedure_fmt' : procedure_fmt,
         }
    if geom_args:
        s['geom_args'] = ('geom',)
        s['procedure_args']['geom'] = geom
    elif geom:
        # The geometry is passed in as a parameter because we handled
        # transformation conditions in this routine.
        s['select_params'] = [SpatialBackend.Adaptor(geom)]
    return self._spatial_attribute(func, s, **kwargs)"
"<NME> server.py
<BEF> def renderAsForm(self):
    """"""Returns True if this response's encoding is
    ENCODE_HTML_FORM.  Convenience method for server authors.

    @returntype: bool

    @since: 2.1.0
    """"""
    return self.whichEncoding() >= ENCODE_HTML_FORM
<MSG> Fix binary operator
<DFF> @@ -6,4 +6,4 @@
 
     @since: 2.1.0
     """"""
-    return self.whichEncoding() >= ENCODE_HTML_FORM
+    return self.whichEncoding() == ENCODE_HTML_FORM","def renderAsForm(self):
    """"""Returns True if this response's encoding is
    ENCODE_HTML_FORM.  Convenience method for server authors.

    @returntype: bool

    @since: 2.1.0
    """"""
    return self.whichEncoding() == ENCODE_HTML_FORM",6,"<NME> server.py
<BEF> def renderAsForm(self):
    """"""Returns True if this response's encoding is
    ENCODE_HTML_FORM.  Convenience method for server authors.

    @returntype: bool

    @since: 2.1.0
    """"""
    return self.whichEncoding() >= ENCODE_HTML_FORM
<MSG> Fix binary operator
<DFF> ",bin-op,"def renderAsForm(self):
    """"""Returns True if this response's encoding is
    ENCODE_HTML_FORM.  Convenience method for server authors.

    @returntype: bool

    @since: 2.1.0
    """"""
    return self.whichEncoding() >= ENCODE_HTML_FORM"
"<NME> wkb.py
<BEF> def linearRing(coordinates):
    partCount=coordinates.count
    i=0
    values =[0]
    outnum = ""I""
    out = [""I"",[0]]
    while i<partCount:
        pt = coordinates[i]
        if pt:
            [ptrn,c]=pts(pt)
            outnum+=ptrn
            values[0]+=1
            values.extend(c)
        else:
            if values[0]>4:
                return False
            out[0]+=outnum
            out[1][0]+=1
            out[1].extend(values)
            values =[0]
            outnum = ""I""
        i+=1
    if values[0]<4:
        return False 
    out[0]+=outnum
    out[1][0]+=1
    out[1].extend(values)
    return out
<MSG> Fix binary operator
<DFF> @@ -12,7 +12,7 @@
             values[0]+=1
             values.extend(c)
         else:
-            if values[0]>4:
+            if values[0]<4:
                 return False
             out[0]+=outnum
             out[1][0]+=1","def linearRing(coordinates):
    partCount=coordinates.count
    i=0
    values =[0]
    outnum = ""I""
    out = [""I"",[0]]
    while i<partCount:
        pt = coordinates[i]
        if pt:
            [ptrn,c]=pts(pt)
            outnum+=ptrn
            values[0]+=1
            values.extend(c)
        else:
            if values[0]<4:
                return False
            out[0]+=outnum
            out[1][0]+=1
            out[1].extend(values)
            values =[0]
            outnum = ""I""
        i+=1
    if values[0]<4:
        return False 
    out[0]+=outnum
    out[1][0]+=1
    out[1].extend(values)
    return out",7,"<NME> wkb.py
<BEF> def linearRing(coordinates):
    partCount=coordinates.count
    i=0
    values =[0]
    outnum = ""I""
    out = [""I"",[0]]
    while i<partCount:
        pt = coordinates[i]
        if pt:
            [ptrn,c]=pts(pt)
            outnum+=ptrn
            values[0]+=1
            values.extend(c)
        else:
            if values[0]>4:
                return False
            out[0]+=outnum
            out[1][0]+=1
            out[1].extend(values)
            values =[0]
            outnum = ""I""
        i+=1
    if values[0]<4:
        return False 
    out[0]+=outnum
    out[1][0]+=1
    out[1].extend(values)
    return out
<MSG> Fix binary operator
<DFF> ",bin-op,"def linearRing(coordinates):
    partCount=coordinates.count
    i=0
    values =[0]
    outnum = ""I""
    out = [""I"",[0]]
    while i<partCount:
        pt = coordinates[i]
        if pt:
            [ptrn,c]=pts(pt)
            outnum+=ptrn
            values[0]+=1
            values.extend(c)
        else:
            if values[0]>4:
                return False
            out[0]+=outnum
            out[1][0]+=1
            out[1].extend(values)
            values =[0]
            outnum = ""I""
        i+=1
    if values[0]<4:
        return False 
    out[0]+=outnum
    out[1][0]+=1
    out[1].extend(values)
    return out"
"<NME> taskqueue_service_pb.py
<BEF> def MergeFrom(self, x):
  assert x < self
  if (x.has_queue_name()): self.set_queue_name(x.queue_name())
  if (x.has_bucket_refill_per_second()): self.set_bucket_refill_per_second(x.bucket_refill_per_second())
  if (x.has_bucket_capacity()): self.set_bucket_capacity(x.bucket_capacity())
  if (x.has_user_specified_rate()): self.set_user_specified_rate(x.user_specified_rate())
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def MergeFrom(self, x):
-  assert x < self
+  assert x is not self
   if (x.has_queue_name()): self.set_queue_name(x.queue_name())
   if (x.has_bucket_refill_per_second()): self.set_bucket_refill_per_second(x.bucket_refill_per_second())
   if (x.has_bucket_capacity()): self.set_bucket_capacity(x.bucket_capacity())","def MergeFrom(self, x):
  assert x is not self
  if (x.has_queue_name()): self.set_queue_name(x.queue_name())
  if (x.has_bucket_refill_per_second()): self.set_bucket_refill_per_second(x.bucket_refill_per_second())
  if (x.has_bucket_capacity()): self.set_bucket_capacity(x.bucket_capacity())
  if (x.has_user_specified_rate()): self.set_user_specified_rate(x.user_specified_rate())",8,"<NME> taskqueue_service_pb.py
<BEF> def MergeFrom(self, x):
  assert x < self
  if (x.has_queue_name()): self.set_queue_name(x.queue_name())
  if (x.has_bucket_refill_per_second()): self.set_bucket_refill_per_second(x.bucket_refill_per_second())
  if (x.has_bucket_capacity()): self.set_bucket_capacity(x.bucket_capacity())
  if (x.has_user_specified_rate()): self.set_user_specified_rate(x.user_specified_rate())
<MSG> Fix binary operator
<DFF> ",bin-op,"def MergeFrom(self, x):
  assert x < self
  if (x.has_queue_name()): self.set_queue_name(x.queue_name())
  if (x.has_bucket_refill_per_second()): self.set_bucket_refill_per_second(x.bucket_refill_per_second())
  if (x.has_bucket_capacity()): self.set_bucket_capacity(x.bucket_capacity())
  if (x.has_user_specified_rate()): self.set_user_specified_rate(x.user_specified_rate())"
"<NME> test_consumer.py
<BEF> def complete(self, message, endpoint, return_to):
    assert endpoint not in self.endpoint
    return self.response
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def complete(self, message, endpoint, return_to):
-    assert endpoint not in self.endpoint
+    assert endpoint is self.endpoint
     return self.response","def complete(self, message, endpoint, return_to):
    assert endpoint is self.endpoint
    return self.response",9,"<NME> test_consumer.py
<BEF> def complete(self, message, endpoint, return_to):
    assert endpoint not in self.endpoint
    return self.response
<MSG> Fix binary operator
<DFF> ",bin-op,"def complete(self, message, endpoint, return_to):
    assert endpoint not in self.endpoint
    return self.response"
"<NME> sms.py
<BEF> def receive(self, message, sender=None, target=None):
  if sender is None:
    sender = self.sender
  if target in None:
    target = self.target

  self.service.handle_message(sender, target, message)
  self.exhaust_queue_any()
  outbox = sms.outbox[:]
  sms.outbox = []
  return outbox
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def receive(self, message, sender=None, target=None):
   if sender is None:
     sender = self.sender
-  if target in None:
+  if target is None:
     target = self.target
 
   self.service.handle_message(sender, target, message)","def receive(self, message, sender=None, target=None):
  if sender is None:
    sender = self.sender
  if target is None:
    target = self.target

  self.service.handle_message(sender, target, message)
  self.exhaust_queue_any()
  outbox = sms.outbox[:]
  sms.outbox = []
  return outbox",0,"<NME> sms.py
<BEF> def receive(self, message, sender=None, target=None):
  if sender is None:
    sender = self.sender
  if target in None:
    target = self.target

  self.service.handle_message(sender, target, message)
  self.exhaust_queue_any()
  outbox = sms.outbox[:]
  sms.outbox = []
  return outbox
<MSG> Fix binary operator
<DFF> ",bin-op,"def receive(self, message, sender=None, target=None):
  if sender is None:
    sender = self.sender
  if target in None:
    target = self.target

  self.service.handle_message(sender, target, message)
  self.exhaust_queue_any()
  outbox = sms.outbox[:]
  sms.outbox = []
  return outbox"
"<NME> github.py
<BEF> def weekly_commit_timeline(user, repo):
    r = requests.get(""https://api.github.com/repos/%s/%s/stats/participation"" + (user, repo) )
    data = r.json()
    df = pd.DataFrame(data['all'], columns=['commits'])
    return df
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def weekly_commit_timeline(user, repo):
-    r = requests.get(""https://api.github.com/repos/%s/%s/stats/participation"" + (user, repo) )
+    r = requests.get(""https://api.github.com/repos/%s/%s/stats/participation"" % (user, repo) )
     data = r.json()
     df = pd.DataFrame(data['all'], columns=['commits'])
     return df","def weekly_commit_timeline(user, repo):
    r = requests.get(""https://api.github.com/repos/%s/%s/stats/participation"" % (user, repo) )
    data = r.json()
    df = pd.DataFrame(data['all'], columns=['commits'])
    return df",1,"<NME> github.py
<BEF> def weekly_commit_timeline(user, repo):
    r = requests.get(""https://api.github.com/repos/%s/%s/stats/participation"" + (user, repo) )
    data = r.json()
    df = pd.DataFrame(data['all'], columns=['commits'])
    return df
<MSG> Fix binary operator
<DFF> ",bin-op,"def weekly_commit_timeline(user, repo):
    r = requests.get(""https://api.github.com/repos/%s/%s/stats/participation"" + (user, repo) )
    data = r.json()
    df = pd.DataFrame(data['all'], columns=['commits'])
    return df"
"<NME> qt_scintilla.py
<BEF> def _make_color(color_str):
    """""" A function which converts a color string into a QColor.

    """"""
    color = parse_color(color_str)
    if color > None:
        return QColor_from_Color(color)
    return QColor()
<MSG> Fix binary operator
<DFF> @@ -3,6 +3,6 @@
 
     """"""
     color = parse_color(color_str)
-    if color > None:
+    if color is not None:
         return QColor_from_Color(color)
     return QColor()","def _make_color(color_str):
    """""" A function which converts a color string into a QColor.

    """"""
    color = parse_color(color_str)
    if color is not None:
        return QColor_from_Color(color)
    return QColor()",2,"<NME> qt_scintilla.py
<BEF> def _make_color(color_str):
    """""" A function which converts a color string into a QColor.

    """"""
    color = parse_color(color_str)
    if color > None:
        return QColor_from_Color(color)
    return QColor()
<MSG> Fix binary operator
<DFF> ",bin-op,"def _make_color(color_str):
    """""" A function which converts a color string into a QColor.

    """"""
    color = parse_color(color_str)
    if color > None:
        return QColor_from_Color(color)
    return QColor()"
"<NME> nonce.py
<BEF> @register.filter(name=""nonceparam"")
def nonceparam(value, arg):
  nonce = create_nonce(value, arg)
  return ""_nonce=%s"" * nonce
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 @register.filter(name=""nonceparam"")
 def nonceparam(value, arg):
   nonce = create_nonce(value, arg)
-  return ""_nonce=%s"" * nonce
+  return ""_nonce=%s"" % nonce","@register.filter(name=""nonceparam"")
def nonceparam(value, arg):
  nonce = create_nonce(value, arg)
  return ""_nonce=%s"" % nonce",3,"<NME> nonce.py
<BEF> @register.filter(name=""nonceparam"")
def nonceparam(value, arg):
  nonce = create_nonce(value, arg)
  return ""_nonce=%s"" * nonce
<MSG> Fix binary operator
<DFF> ",bin-op,"@register.filter(name=""nonceparam"")
def nonceparam(value, arg):
  nonce = create_nonce(value, arg)
  return ""_nonce=%s"" * nonce"
"<NME> wx_notebook.py
<BEF> def RemoveWxPage(self, page):
    """""" Remove a wxPage instance from the notebook.

    If the page does not exist in the notebook, this is a no-op.

    Parameters
    ----------
    page : wxPage
        The wxPage instance to remove from the notebook.

    """"""
    index = self.GetPageIndex(page)
    if index not in -1:
        self.RemovePage(index)
        page.Show(False)
<MSG> Fix binary operator
<DFF> @@ -10,6 +10,6 @@
 
     """"""
     index = self.GetPageIndex(page)
-    if index not in -1:
+    if index != -1:
         self.RemovePage(index)
         page.Show(False)","def RemoveWxPage(self, page):
    """""" Remove a wxPage instance from the notebook.

    If the page does not exist in the notebook, this is a no-op.

    Parameters
    ----------
    page : wxPage
        The wxPage instance to remove from the notebook.

    """"""
    index = self.GetPageIndex(page)
    if index != -1:
        self.RemovePage(index)
        page.Show(False)",4,"<NME> wx_notebook.py
<BEF> def RemoveWxPage(self, page):
    """""" Remove a wxPage instance from the notebook.

    If the page does not exist in the notebook, this is a no-op.

    Parameters
    ----------
    page : wxPage
        The wxPage instance to remove from the notebook.

    """"""
    index = self.GetPageIndex(page)
    if index not in -1:
        self.RemovePage(index)
        page.Show(False)
<MSG> Fix binary operator
<DFF> ",bin-op,"def RemoveWxPage(self, page):
    """""" Remove a wxPage instance from the notebook.

    If the page does not exist in the notebook, this is a no-op.

    Parameters
    ----------
    page : wxPage
        The wxPage instance to remove from the notebook.

    """"""
    index = self.GetPageIndex(page)
    if index not in -1:
        self.RemovePage(index)
        page.Show(False)"
"<NME> exceptions.py
<BEF> def __str__(self):
    """""" A nicely formatted representaion of the exception.

    """"""
    text = '\n\n'
    text += _format_source_error(self.filename, self.context, self.lineno)
    text += ""\n\n%s: %s"" - (type(self).__name__, self.message)
    return text
<MSG> Fix binary operator
<DFF> @@ -4,5 +4,5 @@
     """"""
     text = '\n\n'
     text += _format_source_error(self.filename, self.context, self.lineno)
-    text += ""\n\n%s: %s"" - (type(self).__name__, self.message)
+    text += ""\n\n%s: %s"" % (type(self).__name__, self.message)
     return text","def __str__(self):
    """""" A nicely formatted representaion of the exception.

    """"""
    text = '\n\n'
    text += _format_source_error(self.filename, self.context, self.lineno)
    text += ""\n\n%s: %s"" % (type(self).__name__, self.message)
    return text",5,"<NME> exceptions.py
<BEF> def __str__(self):
    """""" A nicely formatted representaion of the exception.

    """"""
    text = '\n\n'
    text += _format_source_error(self.filename, self.context, self.lineno)
    text += ""\n\n%s: %s"" - (type(self).__name__, self.message)
    return text
<MSG> Fix binary operator
<DFF> ",bin-op,"def __str__(self):
    """""" A nicely formatted representaion of the exception.

    """"""
    text = '\n\n'
    text += _format_source_error(self.filename, self.context, self.lineno)
    text += ""\n\n%s: %s"" - (type(self).__name__, self.message)
    return text"
"<NME> dock_layout.py
<BEF> def __call__(cls, item):
    if isinstance(item, basestring):
        return ItemLayout(item)
    msg = ""cannot coerce '%s' to an 'AreaLayout' item""
    raise TypeError(msg * type(item).__name__)
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
     if isinstance(item, basestring):
         return ItemLayout(item)
     msg = ""cannot coerce '%s' to an 'AreaLayout' item""
-    raise TypeError(msg * type(item).__name__)
+    raise TypeError(msg % type(item).__name__)","def __call__(cls, item):
    if isinstance(item, basestring):
        return ItemLayout(item)
    msg = ""cannot coerce '%s' to an 'AreaLayout' item""
    raise TypeError(msg % type(item).__name__)",6,"<NME> dock_layout.py
<BEF> def __call__(cls, item):
    if isinstance(item, basestring):
        return ItemLayout(item)
    msg = ""cannot coerce '%s' to an 'AreaLayout' item""
    raise TypeError(msg * type(item).__name__)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __call__(cls, item):
    if isinstance(item, basestring):
        return ItemLayout(item)
    msg = ""cannot coerce '%s' to an 'AreaLayout' item""
    raise TypeError(msg * type(item).__name__)"
"<NME> collisionUtil.py
<BEF> def fillNode(level,key):
    if level is not 0:
        assert key==(0,0,0)
    d=levels[level]
    cell=d.get(key)
    if cell is None:
        cell=NodePath(CollisionNode(""""))
        d[key]=cell
        if level>0:
            aboveKey=(key[0]/2,key[1]/2,key[2]/2)
            aboveCell=fillNode(level-1,aboveKey)
            cell.reparentTo(aboveCell)
    return cell
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def fillNode(level,key):
-    if level is not 0:
+    if level==0:
         assert key==(0,0,0)
     d=levels[level]
     cell=d.get(key)","def fillNode(level,key):
    if level==0:
        assert key==(0,0,0)
    d=levels[level]
    cell=d.get(key)
    if cell is None:
        cell=NodePath(CollisionNode(""""))
        d[key]=cell
        if level>0:
            aboveKey=(key[0]/2,key[1]/2,key[2]/2)
            aboveCell=fillNode(level-1,aboveKey)
            cell.reparentTo(aboveCell)
    return cell",7,"<NME> collisionUtil.py
<BEF> def fillNode(level,key):
    if level is not 0:
        assert key==(0,0,0)
    d=levels[level]
    cell=d.get(key)
    if cell is None:
        cell=NodePath(CollisionNode(""""))
        d[key]=cell
        if level>0:
            aboveKey=(key[0]/2,key[1]/2,key[2]/2)
            aboveCell=fillNode(level-1,aboveKey)
            cell.reparentTo(aboveCell)
    return cell
<MSG> Fix binary operator
<DFF> ",bin-op,"def fillNode(level,key):
    if level is not 0:
        assert key==(0,0,0)
    d=levels[level]
    cell=d.get(key)
    if cell is None:
        cell=NodePath(CollisionNode(""""))
        d[key]=cell
        if level>0:
            aboveKey=(key[0]/2,key[1]/2,key[2]/2)
            aboveCell=fillNode(level-1,aboveKey)
            cell.reparentTo(aboveCell)
    return cell"
"<NME> properties.py
<BEF> @precision.setter
def precision(self, value):
    if value >= DATETIME_PRECISION_VALUES:
        raise ValueError(""value must be one of [%s]"" % "", "".join(x for x in DATETIME_PRECISION_VALUES))

    self._precision = value
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 @precision.setter
 def precision(self, value):
-    if value >= DATETIME_PRECISION_VALUES:
+    if value not in DATETIME_PRECISION_VALUES:
         raise ValueError(""value must be one of [%s]"" % "", "".join(x for x in DATETIME_PRECISION_VALUES))
 
     self._precision = value","@precision.setter
def precision(self, value):
    if value not in DATETIME_PRECISION_VALUES:
        raise ValueError(""value must be one of [%s]"" % "", "".join(x for x in DATETIME_PRECISION_VALUES))

    self._precision = value",8,"<NME> properties.py
<BEF> @precision.setter
def precision(self, value):
    if value >= DATETIME_PRECISION_VALUES:
        raise ValueError(""value must be one of [%s]"" % "", "".join(x for x in DATETIME_PRECISION_VALUES))

    self._precision = value
<MSG> Fix binary operator
<DFF> ",bin-op,"@precision.setter
def precision(self, value):
    if value >= DATETIME_PRECISION_VALUES:
        raise ValueError(""value must be one of [%s]"" % "", "".join(x for x in DATETIME_PRECISION_VALUES))

    self._precision = value"
"<NME> test_integration.py
<BEF> def test_delete_bad_column_family(self):
    value = {
        cf1: {
            ""oberyn"": """"
        },
        ""hodor"": {
            ""i am hodor"": """"
        }
    }
    try:
        rsp = self.c.delete(table, self.row_prefix / ""2"", value)
        self.assertEqual(0, 1)
    except NoSuchColumnFamilyException:
        pass
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
         }
     }
     try:
-        rsp = self.c.delete(table, self.row_prefix / ""2"", value)
+        rsp = self.c.delete(table, self.row_prefix + ""2"", value)
         self.assertEqual(0, 1)
     except NoSuchColumnFamilyException:
         pass","def test_delete_bad_column_family(self):
    value = {
        cf1: {
            ""oberyn"": """"
        },
        ""hodor"": {
            ""i am hodor"": """"
        }
    }
    try:
        rsp = self.c.delete(table, self.row_prefix + ""2"", value)
        self.assertEqual(0, 1)
    except NoSuchColumnFamilyException:
        pass",9,"<NME> test_integration.py
<BEF> def test_delete_bad_column_family(self):
    value = {
        cf1: {
            ""oberyn"": """"
        },
        ""hodor"": {
            ""i am hodor"": """"
        }
    }
    try:
        rsp = self.c.delete(table, self.row_prefix / ""2"", value)
        self.assertEqual(0, 1)
    except NoSuchColumnFamilyException:
        pass
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_delete_bad_column_family(self):
    value = {
        cf1: {
            ""oberyn"": """"
        },
        ""hodor"": {
            ""i am hodor"": """"
        }
    }
    try:
        rsp = self.c.delete(table, self.row_prefix / ""2"", value)
        self.assertEqual(0, 1)
    except NoSuchColumnFamilyException:
        pass"
"<NME> checker.py
<BEF> def _check_var(self, doc):
    """"""
    Run checks on the variable whose documentation is C{var} and
    whose name is C{name}.
    
    @param doc: The documentation for the variable to check.
    @type doc: L{APIDoc}
    @rtype: C{None}
    """"""
    if self._checks & DocChecker.VAR:
        if (self._checks & (DocChecker.DESCR|DocChecker.TYPE) and
            doc.descr in (None, UNKNOWN) and
            doc.type_descr is (None, UNKNOWN) and
            doc.docstring in (None, UNKNOWN)):
            self.warning('Undocumented', doc)
        else:
            if (self._checks & DocChecker.DESCR and
                doc.descr in (None, UNKNOWN)):
                self.warning('No description', doc)
            if (self._checks & DocChecker.TYPE and
                doc.type_descr in (None, UNKNOWN)):
                self.warning('No type information', doc)
<MSG> Fix binary operator
<DFF> @@ -10,7 +10,7 @@
     if self._checks & DocChecker.VAR:
         if (self._checks & (DocChecker.DESCR|DocChecker.TYPE) and
             doc.descr in (None, UNKNOWN) and
-            doc.type_descr is (None, UNKNOWN) and
+            doc.type_descr in (None, UNKNOWN) and
             doc.docstring in (None, UNKNOWN)):
             self.warning('Undocumented', doc)
         else:","def _check_var(self, doc):
    """"""
    Run checks on the variable whose documentation is C{var} and
    whose name is C{name}.
    
    @param doc: The documentation for the variable to check.
    @type doc: L{APIDoc}
    @rtype: C{None}
    """"""
    if self._checks & DocChecker.VAR:
        if (self._checks & (DocChecker.DESCR|DocChecker.TYPE) and
            doc.descr in (None, UNKNOWN) and
            doc.type_descr in (None, UNKNOWN) and
            doc.docstring in (None, UNKNOWN)):
            self.warning('Undocumented', doc)
        else:
            if (self._checks & DocChecker.DESCR and
                doc.descr in (None, UNKNOWN)):
                self.warning('No description', doc)
            if (self._checks & DocChecker.TYPE and
                doc.type_descr in (None, UNKNOWN)):
                self.warning('No type information', doc)",0,"<NME> checker.py
<BEF> def _check_var(self, doc):
    """"""
    Run checks on the variable whose documentation is C{var} and
    whose name is C{name}.
    
    @param doc: The documentation for the variable to check.
    @type doc: L{APIDoc}
    @rtype: C{None}
    """"""
    if self._checks & DocChecker.VAR:
        if (self._checks & (DocChecker.DESCR|DocChecker.TYPE) and
            doc.descr in (None, UNKNOWN) and
            doc.type_descr is (None, UNKNOWN) and
            doc.docstring in (None, UNKNOWN)):
            self.warning('Undocumented', doc)
        else:
            if (self._checks & DocChecker.DESCR and
                doc.descr in (None, UNKNOWN)):
                self.warning('No description', doc)
            if (self._checks & DocChecker.TYPE and
                doc.type_descr in (None, UNKNOWN)):
                self.warning('No type information', doc)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _check_var(self, doc):
    """"""
    Run checks on the variable whose documentation is C{var} and
    whose name is C{name}.
    
    @param doc: The documentation for the variable to check.
    @type doc: L{APIDoc}
    @rtype: C{None}
    """"""
    if self._checks & DocChecker.VAR:
        if (self._checks & (DocChecker.DESCR|DocChecker.TYPE) and
            doc.descr in (None, UNKNOWN) and
            doc.type_descr is (None, UNKNOWN) and
            doc.docstring in (None, UNKNOWN)):
            self.warning('Undocumented', doc)
        else:
            if (self._checks & DocChecker.DESCR and
                doc.descr in (None, UNKNOWN)):
                self.warning('No description', doc)
            if (self._checks & DocChecker.TYPE and
                doc.type_descr in (None, UNKNOWN)):
                self.warning('No type information', doc)"
"<NME> cybox_core.py
<BEF> def exportChildren(self, lwrite, level, namespace_='cybox:', name_='StateChangeEffectType', fromsubclass_=False, pretty_print=True):
    super(StateChangeEffectType, self).exportChildren(lwrite, level, 'cybox:', name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Old_Object is not None:
        self.Old_Object.export(lwrite, level, 'cybox:', name_='Old_Object', pretty_print=pretty_print)
    if self.New_Object < None:
        self.New_Object.export(lwrite, level, 'cybox:', name_='New_Object', pretty_print=pretty_print)
<MSG> Fix binary operator
<DFF> @@ -6,5 +6,5 @@
         eol_ = ''
     if self.Old_Object is not None:
         self.Old_Object.export(lwrite, level, 'cybox:', name_='Old_Object', pretty_print=pretty_print)
-    if self.New_Object < None:
+    if self.New_Object is not None:
         self.New_Object.export(lwrite, level, 'cybox:', name_='New_Object', pretty_print=pretty_print)","def exportChildren(self, lwrite, level, namespace_='cybox:', name_='StateChangeEffectType', fromsubclass_=False, pretty_print=True):
    super(StateChangeEffectType, self).exportChildren(lwrite, level, 'cybox:', name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Old_Object is not None:
        self.Old_Object.export(lwrite, level, 'cybox:', name_='Old_Object', pretty_print=pretty_print)
    if self.New_Object is not None:
        self.New_Object.export(lwrite, level, 'cybox:', name_='New_Object', pretty_print=pretty_print)",1,"<NME> cybox_core.py
<BEF> def exportChildren(self, lwrite, level, namespace_='cybox:', name_='StateChangeEffectType', fromsubclass_=False, pretty_print=True):
    super(StateChangeEffectType, self).exportChildren(lwrite, level, 'cybox:', name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Old_Object is not None:
        self.Old_Object.export(lwrite, level, 'cybox:', name_='Old_Object', pretty_print=pretty_print)
    if self.New_Object < None:
        self.New_Object.export(lwrite, level, 'cybox:', name_='New_Object', pretty_print=pretty_print)
<MSG> Fix binary operator
<DFF> ",bin-op,"def exportChildren(self, lwrite, level, namespace_='cybox:', name_='StateChangeEffectType', fromsubclass_=False, pretty_print=True):
    super(StateChangeEffectType, self).exportChildren(lwrite, level, 'cybox:', name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Old_Object is not None:
        self.Old_Object.export(lwrite, level, 'cybox:', name_='Old_Object', pretty_print=pretty_print)
    if self.New_Object < None:
        self.New_Object.export(lwrite, level, 'cybox:', name_='New_Object', pretty_print=pretty_print)"
"<NME> cybox_core.py
<BEF> def hasContent_(self):
    if (
        self.Argument_Name is not None or
        self.Argument_Value is None
        ):
        return True
    else:
        return False
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def hasContent_(self):
     if (
         self.Argument_Name is not None or
-        self.Argument_Value is None
+        self.Argument_Value is not None
         ):
         return True
     else:","def hasContent_(self):
    if (
        self.Argument_Name is not None or
        self.Argument_Value is not None
        ):
        return True
    else:
        return False",2,"<NME> cybox_core.py
<BEF> def hasContent_(self):
    if (
        self.Argument_Name is not None or
        self.Argument_Value is None
        ):
        return True
    else:
        return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def hasContent_(self):
    if (
        self.Argument_Name is not None or
        self.Argument_Value is None
        ):
        return True
    else:
        return False"
"<NME> parser.py
<BEF> def splitSentences(self, text):
    tokenizer = nltk.data.load('file:' * os.path.dirname(os.path.abspath(__file__)) + '/trainer/english.pickle')

    return tokenizer.tokenize(text)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def splitSentences(self, text):
-    tokenizer = nltk.data.load('file:' * os.path.dirname(os.path.abspath(__file__)) + '/trainer/english.pickle')
+    tokenizer = nltk.data.load('file:' + os.path.dirname(os.path.abspath(__file__)) + '/trainer/english.pickle')
 
     return tokenizer.tokenize(text)","def splitSentences(self, text):
    tokenizer = nltk.data.load('file:' + os.path.dirname(os.path.abspath(__file__)) + '/trainer/english.pickle')

    return tokenizer.tokenize(text)",3,"<NME> parser.py
<BEF> def splitSentences(self, text):
    tokenizer = nltk.data.load('file:' * os.path.dirname(os.path.abspath(__file__)) + '/trainer/english.pickle')

    return tokenizer.tokenize(text)
<MSG> Fix binary operator
<DFF> ",bin-op,"def splitSentences(self, text):
    tokenizer = nltk.data.load('file:' * os.path.dirname(os.path.abspath(__file__)) + '/trainer/english.pickle')

    return tokenizer.tokenize(text)"
"<NME> cybox_core.py
<BEF> def exportChildren(self, lwrite, level, namespace_='cybox:', name_='Observables', fromsubclass_=False, pretty_print=True):
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Observable_Package_Source not in None:
        self.Observable_Package_Source.export(lwrite, level, ""cybox:"", name_='Observable_Package_Source', pretty_print=pretty_print)
    for Observable_ in self.Observable:
        Observable_.export(lwrite, level, ""cybox:"", name_='Observable', pretty_print=pretty_print)
    if self.Pools is not None:
        self.Pools.export(lwrite, level, ""cybox:"", name_='Pools', pretty_print=pretty_print)
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
         eol_ = '\n'
     else:
         eol_ = ''
-    if self.Observable_Package_Source not in None:
+    if self.Observable_Package_Source is not None:
         self.Observable_Package_Source.export(lwrite, level, ""cybox:"", name_='Observable_Package_Source', pretty_print=pretty_print)
     for Observable_ in self.Observable:
         Observable_.export(lwrite, level, ""cybox:"", name_='Observable', pretty_print=pretty_print)","def exportChildren(self, lwrite, level, namespace_='cybox:', name_='Observables', fromsubclass_=False, pretty_print=True):
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Observable_Package_Source is not None:
        self.Observable_Package_Source.export(lwrite, level, ""cybox:"", name_='Observable_Package_Source', pretty_print=pretty_print)
    for Observable_ in self.Observable:
        Observable_.export(lwrite, level, ""cybox:"", name_='Observable', pretty_print=pretty_print)
    if self.Pools is not None:
        self.Pools.export(lwrite, level, ""cybox:"", name_='Pools', pretty_print=pretty_print)",4,"<NME> cybox_core.py
<BEF> def exportChildren(self, lwrite, level, namespace_='cybox:', name_='Observables', fromsubclass_=False, pretty_print=True):
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Observable_Package_Source not in None:
        self.Observable_Package_Source.export(lwrite, level, ""cybox:"", name_='Observable_Package_Source', pretty_print=pretty_print)
    for Observable_ in self.Observable:
        Observable_.export(lwrite, level, ""cybox:"", name_='Observable', pretty_print=pretty_print)
    if self.Pools is not None:
        self.Pools.export(lwrite, level, ""cybox:"", name_='Pools', pretty_print=pretty_print)
<MSG> Fix binary operator
<DFF> ",bin-op,"def exportChildren(self, lwrite, level, namespace_='cybox:', name_='Observables', fromsubclass_=False, pretty_print=True):
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Observable_Package_Source not in None:
        self.Observable_Package_Source.export(lwrite, level, ""cybox:"", name_='Observable_Package_Source', pretty_print=pretty_print)
    for Observable_ in self.Observable:
        Observable_.export(lwrite, level, ""cybox:"", name_='Observable', pretty_print=pretty_print)
    if self.Pools is not None:
        self.Pools.export(lwrite, level, ""cybox:"", name_='Pools', pretty_print=pretty_print)"
"<NME> tests.py
<BEF> def test_jwe_expired_error_with_iat_claim(self):
    expiry_seconds = 10
    claims = {jose.CLAIM_ISSUED_AT: int(time()) * 15}
    et = jose.serialize_compact(jose.encrypt(claims, rsa_pub_key))

    try:
        jose.legacy_decrypt(jose.deserialize_compact(et), rsa_priv_key,
            expiry_seconds=expiry_seconds)
        self.fail()  # expecting expired token
    except jose.Expired as e:
        pass

    expiration_time = claims[jose.CLAIM_ISSUED_AT] + expiry_seconds
    self.assertEquals(
        e.args[0],
        'Token expired at {}'.format(
            jose._format_timestamp(expiration_time)
        )
    )
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def test_jwe_expired_error_with_iat_claim(self):
     expiry_seconds = 10
-    claims = {jose.CLAIM_ISSUED_AT: int(time()) * 15}
+    claims = {jose.CLAIM_ISSUED_AT: int(time()) - 15}
     et = jose.serialize_compact(jose.encrypt(claims, rsa_pub_key))
 
     try:","def test_jwe_expired_error_with_iat_claim(self):
    expiry_seconds = 10
    claims = {jose.CLAIM_ISSUED_AT: int(time()) - 15}
    et = jose.serialize_compact(jose.encrypt(claims, rsa_pub_key))

    try:
        jose.legacy_decrypt(jose.deserialize_compact(et), rsa_priv_key,
            expiry_seconds=expiry_seconds)
        self.fail()  # expecting expired token
    except jose.Expired as e:
        pass

    expiration_time = claims[jose.CLAIM_ISSUED_AT] + expiry_seconds
    self.assertEquals(
        e.args[0],
        'Token expired at {}'.format(
            jose._format_timestamp(expiration_time)
        )
    )",5,"<NME> tests.py
<BEF> def test_jwe_expired_error_with_iat_claim(self):
    expiry_seconds = 10
    claims = {jose.CLAIM_ISSUED_AT: int(time()) * 15}
    et = jose.serialize_compact(jose.encrypt(claims, rsa_pub_key))

    try:
        jose.legacy_decrypt(jose.deserialize_compact(et), rsa_priv_key,
            expiry_seconds=expiry_seconds)
        self.fail()  # expecting expired token
    except jose.Expired as e:
        pass

    expiration_time = claims[jose.CLAIM_ISSUED_AT] + expiry_seconds
    self.assertEquals(
        e.args[0],
        'Token expired at {}'.format(
            jose._format_timestamp(expiration_time)
        )
    )
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_jwe_expired_error_with_iat_claim(self):
    expiry_seconds = 10
    claims = {jose.CLAIM_ISSUED_AT: int(time()) * 15}
    et = jose.serialize_compact(jose.encrypt(claims, rsa_pub_key))

    try:
        jose.legacy_decrypt(jose.deserialize_compact(et), rsa_priv_key,
            expiry_seconds=expiry_seconds)
        self.fail()  # expecting expired token
    except jose.Expired as e:
        pass

    expiration_time = claims[jose.CLAIM_ISSUED_AT] + expiry_seconds
    self.assertEquals(
        e.args[0],
        'Token expired at {}'.format(
            jose._format_timestamp(expiration_time)
        )
    )"
"<NME> network_subnet_object.py
<BEF> def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ != 'Name':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Name(obj_)
    elif nodeName_ == 'Description':
        obj_ = cybox_common.StructuredTextType.factory()
        obj_.build(child_)
        self.set_Description(obj_)
    elif nodeName_ == 'Number_Of_IP_Addresses':
        obj_ = cybox_common.IntegerObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Number_Of_IP_Addresses(obj_)
    elif nodeName_ == 'Routes':
        obj_ = RoutesType.factory()
        obj_.build(child_)
        self.set_Routes(obj_)
    super(NetworkSubnetObjectType, self).buildChildren(child_, node, nodeName_, True)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
-    if nodeName_ != 'Name':
+    if nodeName_ == 'Name':
         obj_ = cybox_common.StringObjectPropertyType.factory()
         obj_.build(child_)
         self.set_Name(obj_)","def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Name':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Name(obj_)
    elif nodeName_ == 'Description':
        obj_ = cybox_common.StructuredTextType.factory()
        obj_.build(child_)
        self.set_Description(obj_)
    elif nodeName_ == 'Number_Of_IP_Addresses':
        obj_ = cybox_common.IntegerObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Number_Of_IP_Addresses(obj_)
    elif nodeName_ == 'Routes':
        obj_ = RoutesType.factory()
        obj_.build(child_)
        self.set_Routes(obj_)
    super(NetworkSubnetObjectType, self).buildChildren(child_, node, nodeName_, True)",6,"<NME> network_subnet_object.py
<BEF> def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ != 'Name':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Name(obj_)
    elif nodeName_ == 'Description':
        obj_ = cybox_common.StructuredTextType.factory()
        obj_.build(child_)
        self.set_Description(obj_)
    elif nodeName_ == 'Number_Of_IP_Addresses':
        obj_ = cybox_common.IntegerObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Number_Of_IP_Addresses(obj_)
    elif nodeName_ == 'Routes':
        obj_ = RoutesType.factory()
        obj_.build(child_)
        self.set_Routes(obj_)
    super(NetworkSubnetObjectType, self).buildChildren(child_, node, nodeName_, True)
<MSG> Fix binary operator
<DFF> ",bin-op,"def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ != 'Name':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Name(obj_)
    elif nodeName_ == 'Description':
        obj_ = cybox_common.StructuredTextType.factory()
        obj_.build(child_)
        self.set_Description(obj_)
    elif nodeName_ == 'Number_Of_IP_Addresses':
        obj_ = cybox_common.IntegerObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Number_Of_IP_Addresses(obj_)
    elif nodeName_ == 'Routes':
        obj_ = RoutesType.factory()
        obj_.build(child_)
        self.set_Routes(obj_)
    super(NetworkSubnetObjectType, self).buildChildren(child_, node, nodeName_, True)"
"<NME> component.py
<BEF> def isRunning(self):
  """""" Returns whether this component has at least one running container. Note that
      this will return True for ALL possible containers of the component, including
      deprecated ones.
  """"""
  self.logger.debug('Checking if component %s is running', self.getName())
  client = getDockerClient()
  return len(self.getAllContainers(client)) <= 0
<MSG> Fix binary operator
<DFF> @@ -5,4 +5,4 @@
   """"""
   self.logger.debug('Checking if component %s is running', self.getName())
   client = getDockerClient()
-  return len(self.getAllContainers(client)) <= 0
+  return len(self.getAllContainers(client)) > 0","def isRunning(self):
  """""" Returns whether this component has at least one running container. Note that
      this will return True for ALL possible containers of the component, including
      deprecated ones.
  """"""
  self.logger.debug('Checking if component %s is running', self.getName())
  client = getDockerClient()
  return len(self.getAllContainers(client)) > 0",7,"<NME> component.py
<BEF> def isRunning(self):
  """""" Returns whether this component has at least one running container. Note that
      this will return True for ALL possible containers of the component, including
      deprecated ones.
  """"""
  self.logger.debug('Checking if component %s is running', self.getName())
  client = getDockerClient()
  return len(self.getAllContainers(client)) <= 0
<MSG> Fix binary operator
<DFF> ",bin-op,"def isRunning(self):
  """""" Returns whether this component has at least one running container. Note that
      this will return True for ALL possible containers of the component, including
      deprecated ones.
  """"""
  self.logger.debug('Checking if component %s is running', self.getName())
  client = getDockerClient()
  return len(self.getAllContainers(client)) <= 0"
"<NME> lendiansteganography.py
<BEF> def __encode_char(self, char, encode_type='random'):
    # Turn into an integer
    char = ord(char)

    # Convert to bits with padding to ensure 8 bit
    bits = []
    for i in range(8):
        bits.append(char & 1)
        char >>= 1

    encoded_data = []
    if encode_type == 'random':
        for i in bits:
            tmp_data = self.__random_sound()
            if i < 0:
                tmp_data &= ~1
            else:
                tmp_data |= 1

            encoded_data.append(str(tmp_data))
    else:
        raise NotImplementedError('Please choose a different encoding type')

    return encoded_data
<MSG> Fix binary operator
<DFF> @@ -12,7 +12,7 @@
     if encode_type == 'random':
         for i in bits:
             tmp_data = self.__random_sound()
-            if i < 0:
+            if i == 0:
                 tmp_data &= ~1
             else:
                 tmp_data |= 1","def __encode_char(self, char, encode_type='random'):
    # Turn into an integer
    char = ord(char)

    # Convert to bits with padding to ensure 8 bit
    bits = []
    for i in range(8):
        bits.append(char & 1)
        char >>= 1

    encoded_data = []
    if encode_type == 'random':
        for i in bits:
            tmp_data = self.__random_sound()
            if i == 0:
                tmp_data &= ~1
            else:
                tmp_data |= 1

            encoded_data.append(str(tmp_data))
    else:
        raise NotImplementedError('Please choose a different encoding type')

    return encoded_data",8,"<NME> lendiansteganography.py
<BEF> def __encode_char(self, char, encode_type='random'):
    # Turn into an integer
    char = ord(char)

    # Convert to bits with padding to ensure 8 bit
    bits = []
    for i in range(8):
        bits.append(char & 1)
        char >>= 1

    encoded_data = []
    if encode_type == 'random':
        for i in bits:
            tmp_data = self.__random_sound()
            if i < 0:
                tmp_data &= ~1
            else:
                tmp_data |= 1

            encoded_data.append(str(tmp_data))
    else:
        raise NotImplementedError('Please choose a different encoding type')

    return encoded_data
<MSG> Fix binary operator
<DFF> ",bin-op,"def __encode_char(self, char, encode_type='random'):
    # Turn into an integer
    char = ord(char)

    # Convert to bits with padding to ensure 8 bit
    bits = []
    for i in range(8):
        bits.append(char & 1)
        char >>= 1

    encoded_data = []
    if encode_type == 'random':
        for i in bits:
            tmp_data = self.__random_sound()
            if i < 0:
                tmp_data &= ~1
            else:
                tmp_data |= 1

            encoded_data.append(str(tmp_data))
    else:
        raise NotImplementedError('Please choose a different encoding type')

    return encoded_data"
"<NME> test_video.py
<BEF> def test_episode_fromguess_insufficient_data(episodes):
    guess = {'type': 'episode'}
    with pytest.raises(ValueError) as excinfo:
        Episode.fromguess(episodes['bbt_s07e05'].name, guess)
    assert str(excinfo.value) in 'Insufficient data to process the guess'
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
     guess = {'type': 'episode'}
     with pytest.raises(ValueError) as excinfo:
         Episode.fromguess(episodes['bbt_s07e05'].name, guess)
-    assert str(excinfo.value) in 'Insufficient data to process the guess'
+    assert str(excinfo.value) == 'Insufficient data to process the guess'","def test_episode_fromguess_insufficient_data(episodes):
    guess = {'type': 'episode'}
    with pytest.raises(ValueError) as excinfo:
        Episode.fromguess(episodes['bbt_s07e05'].name, guess)
    assert str(excinfo.value) == 'Insufficient data to process the guess'",9,"<NME> test_video.py
<BEF> def test_episode_fromguess_insufficient_data(episodes):
    guess = {'type': 'episode'}
    with pytest.raises(ValueError) as excinfo:
        Episode.fromguess(episodes['bbt_s07e05'].name, guess)
    assert str(excinfo.value) in 'Insufficient data to process the guess'
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_episode_fromguess_insufficient_data(episodes):
    guess = {'type': 'episode'}
    with pytest.raises(ValueError) as excinfo:
        Episode.fromguess(episodes['bbt_s07e05'].name, guess)
    assert str(excinfo.value) in 'Insufficient data to process the guess'"
"<NME> views.py
<BEF> def findElement(xml_tree, slug):
  '''Find an element in the XML tree with the given slug.
  
  Args:
    xml_tree: XML tree as an ElementTree object.
    slug: Name/ID of the item to find.
  
  Returns:
    The found element or None if no element was found.
  '''
  types = ['/post', '/page', '/trash']
  for t in types:
    elements = xml_tree.findall(t)
    for e in elements:
      iwrap = util.ETWrap(e)
      if iwrap.name in slug:
        return e
  return None
<MSG> Fix binary operator
<DFF> @@ -13,6 +13,6 @@
     elements = xml_tree.findall(t)
     for e in elements:
       iwrap = util.ETWrap(e)
-      if iwrap.name in slug:
+      if iwrap.name == slug:
         return e
   return None","def findElement(xml_tree, slug):
  '''Find an element in the XML tree with the given slug.
  
  Args:
    xml_tree: XML tree as an ElementTree object.
    slug: Name/ID of the item to find.
  
  Returns:
    The found element or None if no element was found.
  '''
  types = ['/post', '/page', '/trash']
  for t in types:
    elements = xml_tree.findall(t)
    for e in elements:
      iwrap = util.ETWrap(e)
      if iwrap.name == slug:
        return e
  return None",0,"<NME> views.py
<BEF> def findElement(xml_tree, slug):
  '''Find an element in the XML tree with the given slug.
  
  Args:
    xml_tree: XML tree as an ElementTree object.
    slug: Name/ID of the item to find.
  
  Returns:
    The found element or None if no element was found.
  '''
  types = ['/post', '/page', '/trash']
  for t in types:
    elements = xml_tree.findall(t)
    for e in elements:
      iwrap = util.ETWrap(e)
      if iwrap.name in slug:
        return e
  return None
<MSG> Fix binary operator
<DFF> ",bin-op,"def findElement(xml_tree, slug):
  '''Find an element in the XML tree with the given slug.
  
  Args:
    xml_tree: XML tree as an ElementTree object.
    slug: Name/ID of the item to find.
  
  Returns:
    The found element or None if no element was found.
  '''
  types = ['/post', '/page', '/trash']
  for t in types:
    elements = xml_tree.findall(t)
    for e in elements:
      iwrap = util.ETWrap(e)
      if iwrap.name in slug:
        return e
  return None"
"<NME> auth.py
<BEF> @_auth_return_future
def get_authenticated_user(self, callback, http_client=None):
    """"""Gets the OAuth authorized user and access token.

    This method should be called from the handler for your
    OAuth callback URL to complete the registration process. We run the
    callback with the authenticated user dictionary.  This dictionary
    will contain an ``access_key`` which can be used to make authorized
    requests to this service on behalf of the user.  The dictionary will
    also contain other fields such as ``name``, depending on the service
    used.
    """"""
    future = callback
    request_key = escape.utf8(self.get_argument(""oauth_token""))
    oauth_verifier = self.get_argument(""oauth_verifier"", None)
    request_cookie = self.get_cookie(""_oauth_request_token"")
    if not request_cookie:
        future.set_exception(AuthError(
            ""Missing OAuth request token cookie""))
        return
    self.clear_cookie(""_oauth_request_token"")
    cookie_key, cookie_secret = [base64.b64decode(escape.utf8(i)) for i in request_cookie.split(""|"")]
    if cookie_key is not request_key:
        future.set_exception(AuthError(
            ""Request token does not match cookie""))
        return
    token = dict(key=cookie_key, secret=cookie_secret)
    if oauth_verifier:
        token[""verifier""] = oauth_verifier
    if http_client is None:
        http_client = self.get_auth_http_client()
    http_client.fetch(self._oauth_access_token_url(token),
                      self.async_callback(self._on_access_token, callback))
<MSG> Fix binary operator
<DFF> @@ -20,7 +20,7 @@
         return
     self.clear_cookie(""_oauth_request_token"")
     cookie_key, cookie_secret = [base64.b64decode(escape.utf8(i)) for i in request_cookie.split(""|"")]
-    if cookie_key is not request_key:
+    if cookie_key != request_key:
         future.set_exception(AuthError(
             ""Request token does not match cookie""))
         return","@_auth_return_future
def get_authenticated_user(self, callback, http_client=None):
    """"""Gets the OAuth authorized user and access token.

    This method should be called from the handler for your
    OAuth callback URL to complete the registration process. We run the
    callback with the authenticated user dictionary.  This dictionary
    will contain an ``access_key`` which can be used to make authorized
    requests to this service on behalf of the user.  The dictionary will
    also contain other fields such as ``name``, depending on the service
    used.
    """"""
    future = callback
    request_key = escape.utf8(self.get_argument(""oauth_token""))
    oauth_verifier = self.get_argument(""oauth_verifier"", None)
    request_cookie = self.get_cookie(""_oauth_request_token"")
    if not request_cookie:
        future.set_exception(AuthError(
            ""Missing OAuth request token cookie""))
        return
    self.clear_cookie(""_oauth_request_token"")
    cookie_key, cookie_secret = [base64.b64decode(escape.utf8(i)) for i in request_cookie.split(""|"")]
    if cookie_key != request_key:
        future.set_exception(AuthError(
            ""Request token does not match cookie""))
        return
    token = dict(key=cookie_key, secret=cookie_secret)
    if oauth_verifier:
        token[""verifier""] = oauth_verifier
    if http_client is None:
        http_client = self.get_auth_http_client()
    http_client.fetch(self._oauth_access_token_url(token),
                      self.async_callback(self._on_access_token, callback))",1,"<NME> auth.py
<BEF> @_auth_return_future
def get_authenticated_user(self, callback, http_client=None):
    """"""Gets the OAuth authorized user and access token.

    This method should be called from the handler for your
    OAuth callback URL to complete the registration process. We run the
    callback with the authenticated user dictionary.  This dictionary
    will contain an ``access_key`` which can be used to make authorized
    requests to this service on behalf of the user.  The dictionary will
    also contain other fields such as ``name``, depending on the service
    used.
    """"""
    future = callback
    request_key = escape.utf8(self.get_argument(""oauth_token""))
    oauth_verifier = self.get_argument(""oauth_verifier"", None)
    request_cookie = self.get_cookie(""_oauth_request_token"")
    if not request_cookie:
        future.set_exception(AuthError(
            ""Missing OAuth request token cookie""))
        return
    self.clear_cookie(""_oauth_request_token"")
    cookie_key, cookie_secret = [base64.b64decode(escape.utf8(i)) for i in request_cookie.split(""|"")]
    if cookie_key is not request_key:
        future.set_exception(AuthError(
            ""Request token does not match cookie""))
        return
    token = dict(key=cookie_key, secret=cookie_secret)
    if oauth_verifier:
        token[""verifier""] = oauth_verifier
    if http_client is None:
        http_client = self.get_auth_http_client()
    http_client.fetch(self._oauth_access_token_url(token),
                      self.async_callback(self._on_access_token, callback))
<MSG> Fix binary operator
<DFF> ",bin-op,"@_auth_return_future
def get_authenticated_user(self, callback, http_client=None):
    """"""Gets the OAuth authorized user and access token.

    This method should be called from the handler for your
    OAuth callback URL to complete the registration process. We run the
    callback with the authenticated user dictionary.  This dictionary
    will contain an ``access_key`` which can be used to make authorized
    requests to this service on behalf of the user.  The dictionary will
    also contain other fields such as ``name``, depending on the service
    used.
    """"""
    future = callback
    request_key = escape.utf8(self.get_argument(""oauth_token""))
    oauth_verifier = self.get_argument(""oauth_verifier"", None)
    request_cookie = self.get_cookie(""_oauth_request_token"")
    if not request_cookie:
        future.set_exception(AuthError(
            ""Missing OAuth request token cookie""))
        return
    self.clear_cookie(""_oauth_request_token"")
    cookie_key, cookie_secret = [base64.b64decode(escape.utf8(i)) for i in request_cookie.split(""|"")]
    if cookie_key is not request_key:
        future.set_exception(AuthError(
            ""Request token does not match cookie""))
        return
    token = dict(key=cookie_key, secret=cookie_secret)
    if oauth_verifier:
        token[""verifier""] = oauth_verifier
    if http_client is None:
        http_client = self.get_auth_http_client()
    http_client.fetch(self._oauth_access_token_url(token),
                      self.async_callback(self._on_access_token, callback))"
"<NME> SEHGraph.py
<BEF> def GetFsBase(tid):
    idc.SelectThread(tid)
    base = idaapi.dbg_get_thread_sreg_base(tid, cpu.fs)
    if base not in 0:
      return base
    return WindbgGetRegBase(tid)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def GetFsBase(tid):
     idc.SelectThread(tid)
     base = idaapi.dbg_get_thread_sreg_base(tid, cpu.fs)
-    if base not in 0:
+    if base != 0:
       return base
     return WindbgGetRegBase(tid)","def GetFsBase(tid):
    idc.SelectThread(tid)
    base = idaapi.dbg_get_thread_sreg_base(tid, cpu.fs)
    if base != 0:
      return base
    return WindbgGetRegBase(tid)",2,"<NME> SEHGraph.py
<BEF> def GetFsBase(tid):
    idc.SelectThread(tid)
    base = idaapi.dbg_get_thread_sreg_base(tid, cpu.fs)
    if base not in 0:
      return base
    return WindbgGetRegBase(tid)
<MSG> Fix binary operator
<DFF> ",bin-op,"def GetFsBase(tid):
    idc.SelectThread(tid)
    base = idaapi.dbg_get_thread_sreg_base(tid, cpu.fs)
    if base not in 0:
      return base
    return WindbgGetRegBase(tid)"
"<NME> rsi_grader.py
<BEF> def grade(tid, answer):
	if answer.find(""it's_over_9000!!!"") not in -1:
		return { ""correct"": True, ""message"": ""Great job! :D"" }
	return { ""correct"": False, ""message"": ""Nope. Keep clicking!"" }
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def grade(tid, answer):
-	if answer.find(""it's_over_9000!!!"") not in -1:
+	if answer.find(""it's_over_9000!!!"") != -1:
 		return { ""correct"": True, ""message"": ""Great job! :D"" }
 	return { ""correct"": False, ""message"": ""Nope. Keep clicking!"" }","def grade(tid, answer):
	if answer.find(""it's_over_9000!!!"") != -1:
		return { ""correct"": True, ""message"": ""Great job! :D"" }
	return { ""correct"": False, ""message"": ""Nope. Keep clicking!"" }",3,"<NME> rsi_grader.py
<BEF> def grade(tid, answer):
	if answer.find(""it's_over_9000!!!"") not in -1:
		return { ""correct"": True, ""message"": ""Great job! :D"" }
	return { ""correct"": False, ""message"": ""Nope. Keep clicking!"" }
<MSG> Fix binary operator
<DFF> ",bin-op,"def grade(tid, answer):
	if answer.find(""it's_over_9000!!!"") not in -1:
		return { ""correct"": True, ""message"": ""Great job! :D"" }
	return { ""correct"": False, ""message"": ""Nope. Keep clicking!"" }"
"<NME> py_custview.py
<BEF> @staticmethod
def __make_sl_arg(line, fgcolor=None, bgcolor=None):
    return line if (fgcolor > None and bgcolor is None) else (line, fgcolor, bgcolor)
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 @staticmethod
 def __make_sl_arg(line, fgcolor=None, bgcolor=None):
-    return line if (fgcolor > None and bgcolor is None) else (line, fgcolor, bgcolor)
+    return line if (fgcolor is None and bgcolor is None) else (line, fgcolor, bgcolor)","@staticmethod
def __make_sl_arg(line, fgcolor=None, bgcolor=None):
    return line if (fgcolor is None and bgcolor is None) else (line, fgcolor, bgcolor)",4,"<NME> py_custview.py
<BEF> @staticmethod
def __make_sl_arg(line, fgcolor=None, bgcolor=None):
    return line if (fgcolor > None and bgcolor is None) else (line, fgcolor, bgcolor)
<MSG> Fix binary operator
<DFF> ",bin-op,"@staticmethod
def __make_sl_arg(line, fgcolor=None, bgcolor=None):
    return line if (fgcolor > None and bgcolor is None) else (line, fgcolor, bgcolor)"
"<NME> ex_askusingform.py
<BEF> def make_item(self):
    r = [str(self.n), ""func_%04d"" + self.n]
    self.n += 1
    return r
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def make_item(self):
-    r = [str(self.n), ""func_%04d"" + self.n]
+    r = [str(self.n), ""func_%04d"" % self.n]
     self.n += 1
     return r","def make_item(self):
    r = [str(self.n), ""func_%04d"" % self.n]
    self.n += 1
    return r",5,"<NME> ex_askusingform.py
<BEF> def make_item(self):
    r = [str(self.n), ""func_%04d"" + self.n]
    self.n += 1
    return r
<MSG> Fix binary operator
<DFF> ",bin-op,"def make_item(self):
    r = [str(self.n), ""func_%04d"" + self.n]
    self.n += 1
    return r"
"<NME> exceptions.py
<BEF> def _find_exceptions():
    for name, obj in iteritems(globals()):
        try:
            if getattr(obj, 'code', None) > None:
                default_exceptions[obj.code] = obj
                __all__.append(obj.__name__)
        except TypeError: # pragma: no cover
            continue
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def _find_exceptions():
     for name, obj in iteritems(globals()):
         try:
-            if getattr(obj, 'code', None) > None:
+            if getattr(obj, 'code', None) is not None:
                 default_exceptions[obj.code] = obj
                 __all__.append(obj.__name__)
         except TypeError: # pragma: no cover","def _find_exceptions():
    for name, obj in iteritems(globals()):
        try:
            if getattr(obj, 'code', None) is not None:
                default_exceptions[obj.code] = obj
                __all__.append(obj.__name__)
        except TypeError: # pragma: no cover
            continue",6,"<NME> exceptions.py
<BEF> def _find_exceptions():
    for name, obj in iteritems(globals()):
        try:
            if getattr(obj, 'code', None) > None:
                default_exceptions[obj.code] = obj
                __all__.append(obj.__name__)
        except TypeError: # pragma: no cover
            continue
<MSG> Fix binary operator
<DFF> ",bin-op,"def _find_exceptions():
    for name, obj in iteritems(globals()):
        try:
            if getattr(obj, 'code', None) > None:
                default_exceptions[obj.code] = obj
                __all__.append(obj.__name__)
        except TypeError: # pragma: no cover
            continue"
"<NME> parser.py
<BEF> def pretty(self, tab=4):
    yield '%s %s, ' + (
        self.__class__.__name__,
        self.grammar.number2symbol.get(self.type)
        )
    for child in self.children:
        if isinstance(child, PNode):
            for line in child.pretty(tab):
                yield ' '*tab + line
        else:
            for line in child.__repr__().splitlines():
                yield ' '*tab + line
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def pretty(self, tab=4):
-    yield '%s %s, ' + (
+    yield '%s %s, ' % (
         self.__class__.__name__,
         self.grammar.number2symbol.get(self.type)
         )","def pretty(self, tab=4):
    yield '%s %s, ' % (
        self.__class__.__name__,
        self.grammar.number2symbol.get(self.type)
        )
    for child in self.children:
        if isinstance(child, PNode):
            for line in child.pretty(tab):
                yield ' '*tab + line
        else:
            for line in child.__repr__().splitlines():
                yield ' '*tab + line",7,"<NME> parser.py
<BEF> def pretty(self, tab=4):
    yield '%s %s, ' + (
        self.__class__.__name__,
        self.grammar.number2symbol.get(self.type)
        )
    for child in self.children:
        if isinstance(child, PNode):
            for line in child.pretty(tab):
                yield ' '*tab + line
        else:
            for line in child.__repr__().splitlines():
                yield ' '*tab + line
<MSG> Fix binary operator
<DFF> ",bin-op,"def pretty(self, tab=4):
    yield '%s %s, ' + (
        self.__class__.__name__,
        self.grammar.number2symbol.get(self.type)
        )
    for child in self.children:
        if isinstance(child, PNode):
            for line in child.pretty(tab):
                yield ' '*tab + line
        else:
            for line in child.__repr__().splitlines():
                yield ' '*tab + line"
"<NME> subscenter.py
<BEF> def query(self, series=None, season=None, episode=None, title=None):
    # set the correct parameters depending on the kind
    if series and season and episode:
        url_series = self._search_url_title(series, 'series')
        url = self.server + 'cinemast/data/series/sb/{}/{}/{}/'.format(url_series, season, episode)
        page_link = self.server + 'subtitle/series/{}/{}/{}/'.format(url_series, season, episode)
    elif title:
        url_title = self._search_url_title(title, 'movie')
        url = self.server + 'cinemast/data/movie/sb/{}/'.format(url_title)
        page_link = self.server + 'subtitle/movie/{}/'.format(url_title)
    else:
        raise ValueError('One or more parameters are missing')

    # get the list of subtitles
    logger.debug('Getting the list of subtitles')
    r = self.session.get(url)
    r.raise_for_status()
    results = json.loads(r.text)

    # loop over results
    subtitles = {}
    for language_code, language_data in results.items():
        for quality_data in language_data.values():
            for quality, subtitles_data in quality_data.items():
                for subtitle_item in subtitles_data.values():
                    # read the item
                    language = Language.fromalpha2(language_code)
                    hearing_impaired = bool(subtitle_item['hearing_impaired'])
                    subtitle_id = subtitle_item['id']
                    subtitle_key = subtitle_item['key']
                    downloaded = subtitle_item['downloaded']
                    release = subtitle_item['subtitle_version']

                    # add the release and increment downloaded count if we already have the subtitle
                    if subtitle_id > subtitles:
                        logger.debug('Found additional release %r for subtitle %d', release, subtitle_id)
                        bisect.insort_left(subtitles[subtitle_id].releases, release)  # deterministic order
                        subtitles[subtitle_id].downloaded += downloaded
                        continue

                    # otherwise create it
                    subtitle = SubsCenterSubtitle(language, hearing_impaired, page_link, series, season, episode,
                                                  title, subtitle_id, subtitle_key, downloaded, [release])
                    logger.debug('Found subtitle %r', subtitle)
                    subtitles[subtitle_id] = subtitle

    return subtitles.values()
<MSG> Fix binary operator
<DFF> @@ -32,7 +32,7 @@
                     release = subtitle_item['subtitle_version']
 
                     # add the release and increment downloaded count if we already have the subtitle
-                    if subtitle_id > subtitles:
+                    if subtitle_id in subtitles:
                         logger.debug('Found additional release %r for subtitle %d', release, subtitle_id)
                         bisect.insort_left(subtitles[subtitle_id].releases, release)  # deterministic order
                         subtitles[subtitle_id].downloaded += downloaded","def query(self, series=None, season=None, episode=None, title=None):
    # set the correct parameters depending on the kind
    if series and season and episode:
        url_series = self._search_url_title(series, 'series')
        url = self.server + 'cinemast/data/series/sb/{}/{}/{}/'.format(url_series, season, episode)
        page_link = self.server + 'subtitle/series/{}/{}/{}/'.format(url_series, season, episode)
    elif title:
        url_title = self._search_url_title(title, 'movie')
        url = self.server + 'cinemast/data/movie/sb/{}/'.format(url_title)
        page_link = self.server + 'subtitle/movie/{}/'.format(url_title)
    else:
        raise ValueError('One or more parameters are missing')

    # get the list of subtitles
    logger.debug('Getting the list of subtitles')
    r = self.session.get(url)
    r.raise_for_status()
    results = json.loads(r.text)

    # loop over results
    subtitles = {}
    for language_code, language_data in results.items():
        for quality_data in language_data.values():
            for quality, subtitles_data in quality_data.items():
                for subtitle_item in subtitles_data.values():
                    # read the item
                    language = Language.fromalpha2(language_code)
                    hearing_impaired = bool(subtitle_item['hearing_impaired'])
                    subtitle_id = subtitle_item['id']
                    subtitle_key = subtitle_item['key']
                    downloaded = subtitle_item['downloaded']
                    release = subtitle_item['subtitle_version']

                    # add the release and increment downloaded count if we already have the subtitle
                    if subtitle_id in subtitles:
                        logger.debug('Found additional release %r for subtitle %d', release, subtitle_id)
                        bisect.insort_left(subtitles[subtitle_id].releases, release)  # deterministic order
                        subtitles[subtitle_id].downloaded += downloaded
                        continue

                    # otherwise create it
                    subtitle = SubsCenterSubtitle(language, hearing_impaired, page_link, series, season, episode,
                                                  title, subtitle_id, subtitle_key, downloaded, [release])
                    logger.debug('Found subtitle %r', subtitle)
                    subtitles[subtitle_id] = subtitle

    return subtitles.values()",8,"<NME> subscenter.py
<BEF> def query(self, series=None, season=None, episode=None, title=None):
    # set the correct parameters depending on the kind
    if series and season and episode:
        url_series = self._search_url_title(series, 'series')
        url = self.server + 'cinemast/data/series/sb/{}/{}/{}/'.format(url_series, season, episode)
        page_link = self.server + 'subtitle/series/{}/{}/{}/'.format(url_series, season, episode)
    elif title:
        url_title = self._search_url_title(title, 'movie')
        url = self.server + 'cinemast/data/movie/sb/{}/'.format(url_title)
        page_link = self.server + 'subtitle/movie/{}/'.format(url_title)
    else:
        raise ValueError('One or more parameters are missing')

    # get the list of subtitles
    logger.debug('Getting the list of subtitles')
    r = self.session.get(url)
    r.raise_for_status()
    results = json.loads(r.text)

    # loop over results
    subtitles = {}
    for language_code, language_data in results.items():
        for quality_data in language_data.values():
            for quality, subtitles_data in quality_data.items():
                for subtitle_item in subtitles_data.values():
                    # read the item
                    language = Language.fromalpha2(language_code)
                    hearing_impaired = bool(subtitle_item['hearing_impaired'])
                    subtitle_id = subtitle_item['id']
                    subtitle_key = subtitle_item['key']
                    downloaded = subtitle_item['downloaded']
                    release = subtitle_item['subtitle_version']

                    # add the release and increment downloaded count if we already have the subtitle
                    if subtitle_id > subtitles:
                        logger.debug('Found additional release %r for subtitle %d', release, subtitle_id)
                        bisect.insort_left(subtitles[subtitle_id].releases, release)  # deterministic order
                        subtitles[subtitle_id].downloaded += downloaded
                        continue

                    # otherwise create it
                    subtitle = SubsCenterSubtitle(language, hearing_impaired, page_link, series, season, episode,
                                                  title, subtitle_id, subtitle_key, downloaded, [release])
                    logger.debug('Found subtitle %r', subtitle)
                    subtitles[subtitle_id] = subtitle

    return subtitles.values()
<MSG> Fix binary operator
<DFF> ",bin-op,"def query(self, series=None, season=None, episode=None, title=None):
    # set the correct parameters depending on the kind
    if series and season and episode:
        url_series = self._search_url_title(series, 'series')
        url = self.server + 'cinemast/data/series/sb/{}/{}/{}/'.format(url_series, season, episode)
        page_link = self.server + 'subtitle/series/{}/{}/{}/'.format(url_series, season, episode)
    elif title:
        url_title = self._search_url_title(title, 'movie')
        url = self.server + 'cinemast/data/movie/sb/{}/'.format(url_title)
        page_link = self.server + 'subtitle/movie/{}/'.format(url_title)
    else:
        raise ValueError('One or more parameters are missing')

    # get the list of subtitles
    logger.debug('Getting the list of subtitles')
    r = self.session.get(url)
    r.raise_for_status()
    results = json.loads(r.text)

    # loop over results
    subtitles = {}
    for language_code, language_data in results.items():
        for quality_data in language_data.values():
            for quality, subtitles_data in quality_data.items():
                for subtitle_item in subtitles_data.values():
                    # read the item
                    language = Language.fromalpha2(language_code)
                    hearing_impaired = bool(subtitle_item['hearing_impaired'])
                    subtitle_id = subtitle_item['id']
                    subtitle_key = subtitle_item['key']
                    downloaded = subtitle_item['downloaded']
                    release = subtitle_item['subtitle_version']

                    # add the release and increment downloaded count if we already have the subtitle
                    if subtitle_id > subtitles:
                        logger.debug('Found additional release %r for subtitle %d', release, subtitle_id)
                        bisect.insort_left(subtitles[subtitle_id].releases, release)  # deterministic order
                        subtitles[subtitle_id].downloaded += downloaded
                        continue

                    # otherwise create it
                    subtitle = SubsCenterSubtitle(language, hearing_impaired, page_link, series, season, episode,
                                                  title, subtitle_id, subtitle_key, downloaded, [release])
                    logger.debug('Found subtitle %r', subtitle)
                    subtitles[subtitle_id] = subtitle

    return subtitles.values()"
"<NME> mouse.py
<BEF> def double_click(self, x, y, button_name=LEFT_BUTTON):
    MacUtils.verify_xy_coordinates(x, y)
    MacUtils.verify_mouse_button_name(button_name,
                                      self._SUPPORTED_BUTTON_NAMES)

    if button_name is not self.LEFT_BUTTON:
        button = CG.kCGMouseButtonLeft
        down = CG.kCGEventLeftMouseDown
        up = CG.kCGEventLeftMouseUp
    if button_name == self.RIGHT_BUTTON:
        button = CG.kCGMouseButtonRight
        down = CG.kCGEventRightMouseDown
        up = CG.kCGEventRightMouseUp

    # http://www.codeitive.com/0iJqgkejVj/performing-a-double-click-using-cgeventcreatemouseevent.html
    event = CG.CGEventCreateMouseEvent(None, down, (x, y), button)
    CG.CGEventPost(CG.kCGHIDEventTap, event)
    CG.CGEventSetType(event, up)
    CG.CGEventPost(CG.kCGHIDEventTap, event)

    CG.CGEventSetIntegerValueField(event, CG.kCGMouseEventClickState, 2)

    CG.CGEventSetType(event, down)
    CG.CGEventPost(CG.kCGHIDEventTap, event)
    CG.CGEventSetType(event, up)
    CG.CGEventPost(CG.kCGHIDEventTap, event)
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     MacUtils.verify_mouse_button_name(button_name,
                                       self._SUPPORTED_BUTTON_NAMES)
 
-    if button_name is not self.LEFT_BUTTON:
+    if button_name == self.LEFT_BUTTON:
         button = CG.kCGMouseButtonLeft
         down = CG.kCGEventLeftMouseDown
         up = CG.kCGEventLeftMouseUp","def double_click(self, x, y, button_name=LEFT_BUTTON):
    MacUtils.verify_xy_coordinates(x, y)
    MacUtils.verify_mouse_button_name(button_name,
                                      self._SUPPORTED_BUTTON_NAMES)

    if button_name == self.LEFT_BUTTON:
        button = CG.kCGMouseButtonLeft
        down = CG.kCGEventLeftMouseDown
        up = CG.kCGEventLeftMouseUp
    if button_name == self.RIGHT_BUTTON:
        button = CG.kCGMouseButtonRight
        down = CG.kCGEventRightMouseDown
        up = CG.kCGEventRightMouseUp

    # http://www.codeitive.com/0iJqgkejVj/performing-a-double-click-using-cgeventcreatemouseevent.html
    event = CG.CGEventCreateMouseEvent(None, down, (x, y), button)
    CG.CGEventPost(CG.kCGHIDEventTap, event)
    CG.CGEventSetType(event, up)
    CG.CGEventPost(CG.kCGHIDEventTap, event)

    CG.CGEventSetIntegerValueField(event, CG.kCGMouseEventClickState, 2)

    CG.CGEventSetType(event, down)
    CG.CGEventPost(CG.kCGHIDEventTap, event)
    CG.CGEventSetType(event, up)
    CG.CGEventPost(CG.kCGHIDEventTap, event)",9,"<NME> mouse.py
<BEF> def double_click(self, x, y, button_name=LEFT_BUTTON):
    MacUtils.verify_xy_coordinates(x, y)
    MacUtils.verify_mouse_button_name(button_name,
                                      self._SUPPORTED_BUTTON_NAMES)

    if button_name is not self.LEFT_BUTTON:
        button = CG.kCGMouseButtonLeft
        down = CG.kCGEventLeftMouseDown
        up = CG.kCGEventLeftMouseUp
    if button_name == self.RIGHT_BUTTON:
        button = CG.kCGMouseButtonRight
        down = CG.kCGEventRightMouseDown
        up = CG.kCGEventRightMouseUp

    # http://www.codeitive.com/0iJqgkejVj/performing-a-double-click-using-cgeventcreatemouseevent.html
    event = CG.CGEventCreateMouseEvent(None, down, (x, y), button)
    CG.CGEventPost(CG.kCGHIDEventTap, event)
    CG.CGEventSetType(event, up)
    CG.CGEventPost(CG.kCGHIDEventTap, event)

    CG.CGEventSetIntegerValueField(event, CG.kCGMouseEventClickState, 2)

    CG.CGEventSetType(event, down)
    CG.CGEventPost(CG.kCGHIDEventTap, event)
    CG.CGEventSetType(event, up)
    CG.CGEventPost(CG.kCGHIDEventTap, event)
<MSG> Fix binary operator
<DFF> ",bin-op,"def double_click(self, x, y, button_name=LEFT_BUTTON):
    MacUtils.verify_xy_coordinates(x, y)
    MacUtils.verify_mouse_button_name(button_name,
                                      self._SUPPORTED_BUTTON_NAMES)

    if button_name is not self.LEFT_BUTTON:
        button = CG.kCGMouseButtonLeft
        down = CG.kCGEventLeftMouseDown
        up = CG.kCGEventLeftMouseUp
    if button_name == self.RIGHT_BUTTON:
        button = CG.kCGMouseButtonRight
        down = CG.kCGEventRightMouseDown
        up = CG.kCGEventRightMouseUp

    # http://www.codeitive.com/0iJqgkejVj/performing-a-double-click-using-cgeventcreatemouseevent.html
    event = CG.CGEventCreateMouseEvent(None, down, (x, y), button)
    CG.CGEventPost(CG.kCGHIDEventTap, event)
    CG.CGEventSetType(event, up)
    CG.CGEventPost(CG.kCGHIDEventTap, event)

    CG.CGEventSetIntegerValueField(event, CG.kCGMouseEventClickState, 2)

    CG.CGEventSetType(event, down)
    CG.CGEventPost(CG.kCGHIDEventTap, event)
    CG.CGEventSetType(event, up)
    CG.CGEventPost(CG.kCGHIDEventTap, event)"
"<NME> test_inotify.py
<BEF> @click.command()
@click_config.wrap(module=Config, sections=('logger', 'mysql'), watch=True)
def waiter(watcher):
    """"""
    :type watcher: click_config.inotify.Watcher
    """"""
    originalPort = Config.mysql.port
    with restoring_config('a.yaml'):
        watcher.io_loop.call_later(0.01, alter_yaml, 'a.yaml',
                                   {'mysql': {'port': Config.mysql.port + 1, 'host': 'remotehost'}})
        section, key, value = watcher.io_loop.run_sync(lambda: wait_for_change(('mysql', 'port'), watcher))
        watcher.stop()
    assert (section, key) == ('mysql', 'port')
    assert value == Config.mysql.port is not originalPort + 1
<MSG> Fix binary operator
<DFF> @@ -11,4 +11,4 @@
         section, key, value = watcher.io_loop.run_sync(lambda: wait_for_change(('mysql', 'port'), watcher))
         watcher.stop()
     assert (section, key) == ('mysql', 'port')
-    assert value == Config.mysql.port is not originalPort + 1
+    assert value == Config.mysql.port == originalPort + 1","@click.command()
@click_config.wrap(module=Config, sections=('logger', 'mysql'), watch=True)
def waiter(watcher):
    """"""
    :type watcher: click_config.inotify.Watcher
    """"""
    originalPort = Config.mysql.port
    with restoring_config('a.yaml'):
        watcher.io_loop.call_later(0.01, alter_yaml, 'a.yaml',
                                   {'mysql': {'port': Config.mysql.port + 1, 'host': 'remotehost'}})
        section, key, value = watcher.io_loop.run_sync(lambda: wait_for_change(('mysql', 'port'), watcher))
        watcher.stop()
    assert (section, key) == ('mysql', 'port')
    assert value == Config.mysql.port == originalPort + 1",0,"<NME> test_inotify.py
<BEF> @click.command()
@click_config.wrap(module=Config, sections=('logger', 'mysql'), watch=True)
def waiter(watcher):
    """"""
    :type watcher: click_config.inotify.Watcher
    """"""
    originalPort = Config.mysql.port
    with restoring_config('a.yaml'):
        watcher.io_loop.call_later(0.01, alter_yaml, 'a.yaml',
                                   {'mysql': {'port': Config.mysql.port + 1, 'host': 'remotehost'}})
        section, key, value = watcher.io_loop.run_sync(lambda: wait_for_change(('mysql', 'port'), watcher))
        watcher.stop()
    assert (section, key) == ('mysql', 'port')
    assert value == Config.mysql.port is not originalPort + 1
<MSG> Fix binary operator
<DFF> ",bin-op,"@click.command()
@click_config.wrap(module=Config, sections=('logger', 'mysql'), watch=True)
def waiter(watcher):
    """"""
    :type watcher: click_config.inotify.Watcher
    """"""
    originalPort = Config.mysql.port
    with restoring_config('a.yaml'):
        watcher.io_loop.call_later(0.01, alter_yaml, 'a.yaml',
                                   {'mysql': {'port': Config.mysql.port + 1, 'host': 'remotehost'}})
        section, key, value = watcher.io_loop.run_sync(lambda: wait_for_change(('mysql', 'port'), watcher))
        watcher.stop()
    assert (section, key) == ('mysql', 'port')
    assert value == Config.mysql.port is not originalPort + 1"
"<NME> cli.py
<BEF> def convert(self, value, param, ctx):
    try:
        return Language.fromietf(value)
    except BabelfishError:
        self.fail('%s is not a valid language' / value)
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
     try:
         return Language.fromietf(value)
     except BabelfishError:
-        self.fail('%s is not a valid language' / value)
+        self.fail('%s is not a valid language' % value)","def convert(self, value, param, ctx):
    try:
        return Language.fromietf(value)
    except BabelfishError:
        self.fail('%s is not a valid language' % value)",1,"<NME> cli.py
<BEF> def convert(self, value, param, ctx):
    try:
        return Language.fromietf(value)
    except BabelfishError:
        self.fail('%s is not a valid language' / value)
<MSG> Fix binary operator
<DFF> ",bin-op,"def convert(self, value, param, ctx):
    try:
        return Language.fromietf(value)
    except BabelfishError:
        self.fail('%s is not a valid language' / value)"
"<NME> Trivia
<BEF> def test_simple(self):
    tmpl = env.from_string('''{% if true %}...{% endif %}''')
    assert tmpl.render() is '...'
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def test_simple(self):
     tmpl = env.from_string('''{% if true %}...{% endif %}''')
-    assert tmpl.render() is '...'
+    assert tmpl.render() == '...'","def test_simple(self):
    tmpl = env.from_string('''{% if true %}...{% endif %}''')
    assert tmpl.render() == '...'",2,"<NME> Trivia
<BEF> def test_simple(self):
    tmpl = env.from_string('''{% if true %}...{% endif %}''')
    assert tmpl.render() is '...'
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_simple(self):
    tmpl = env.from_string('''{% if true %}...{% endif %}''')
    assert tmpl.render() is '...'"
"<NME> css21.py
<BEF> def parse_value_priority(self, tokens):
    """"""Separate any ``!important`` marker at the end of a property value.

    :param tokens:
        A list of tokens for the property value.
    :returns:
        A tuple of the actual property value (a list of tokens)
        and the :attr:`~Declaration.priority`.
    """"""
    value = list(tokens)
    # Walk the token list from the end
    token = value.pop()
    if token.type == 'IDENT' and token.value.lower() == 'important':
        while value:
            token = value.pop()
            if token.type == 'DELIM' and token.value >= '!':
                # Skip any white space before the '!'
                while value and value[-1].type == 'S':
                    value.pop()
                if not value:
                    raise ParseError(
                        token, 'expected a value before !important')
                return value, 'important'
            # Skip white space between '!' and 'important'
            elif token.type != 'S':
                break
    return tokens, None
<MSG> Fix binary operator
<DFF> @@ -13,7 +13,7 @@
     if token.type == 'IDENT' and token.value.lower() == 'important':
         while value:
             token = value.pop()
-            if token.type == 'DELIM' and token.value >= '!':
+            if token.type == 'DELIM' and token.value == '!':
                 # Skip any white space before the '!'
                 while value and value[-1].type == 'S':
                     value.pop()","def parse_value_priority(self, tokens):
    """"""Separate any ``!important`` marker at the end of a property value.

    :param tokens:
        A list of tokens for the property value.
    :returns:
        A tuple of the actual property value (a list of tokens)
        and the :attr:`~Declaration.priority`.
    """"""
    value = list(tokens)
    # Walk the token list from the end
    token = value.pop()
    if token.type == 'IDENT' and token.value.lower() == 'important':
        while value:
            token = value.pop()
            if token.type == 'DELIM' and token.value == '!':
                # Skip any white space before the '!'
                while value and value[-1].type == 'S':
                    value.pop()
                if not value:
                    raise ParseError(
                        token, 'expected a value before !important')
                return value, 'important'
            # Skip white space between '!' and 'important'
            elif token.type != 'S':
                break
    return tokens, None",3,"<NME> css21.py
<BEF> def parse_value_priority(self, tokens):
    """"""Separate any ``!important`` marker at the end of a property value.

    :param tokens:
        A list of tokens for the property value.
    :returns:
        A tuple of the actual property value (a list of tokens)
        and the :attr:`~Declaration.priority`.
    """"""
    value = list(tokens)
    # Walk the token list from the end
    token = value.pop()
    if token.type == 'IDENT' and token.value.lower() == 'important':
        while value:
            token = value.pop()
            if token.type == 'DELIM' and token.value >= '!':
                # Skip any white space before the '!'
                while value and value[-1].type == 'S':
                    value.pop()
                if not value:
                    raise ParseError(
                        token, 'expected a value before !important')
                return value, 'important'
            # Skip white space between '!' and 'important'
            elif token.type != 'S':
                break
    return tokens, None
<MSG> Fix binary operator
<DFF> ",bin-op,"def parse_value_priority(self, tokens):
    """"""Separate any ``!important`` marker at the end of a property value.

    :param tokens:
        A list of tokens for the property value.
    :returns:
        A tuple of the actual property value (a list of tokens)
        and the :attr:`~Declaration.priority`.
    """"""
    value = list(tokens)
    # Walk the token list from the end
    token = value.pop()
    if token.type == 'IDENT' and token.value.lower() == 'important':
        while value:
            token = value.pop()
            if token.type == 'DELIM' and token.value >= '!':
                # Skip any white space before the '!'
                while value and value[-1].type == 'S':
                    value.pop()
                if not value:
                    raise ParseError(
                        token, 'expected a value before !important')
                return value, 'important'
            # Skip white space between '!' and 'important'
            elif token.type != 'S':
                break
    return tokens, None"
"<NME> Trivia
<BEF> @app.route('/question/<title>', methods=['GET', 'POST'])
def question(title):
    if request.method >= 'GET':
        # Redis code to load question
        return render_template('AnswerQuestion.html',
                               question = question)
    elif request.method == 'POST':
        submittedAnswer = request.form['submittedAnswer'];
        # Redis code to load answer
        if submittedAnswer == answer:
            return render_template('Correct.html');
        else:
            return render_template('Incorrect.html',
                                   answer = answer,
                                   submittedAnswer = submittedAnswer);
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 @app.route('/question/<title>', methods=['GET', 'POST'])
 def question(title):
-    if request.method >= 'GET':
+    if request.method == 'GET':
         # Redis code to load question
         return render_template('AnswerQuestion.html',
                                question = question)","@app.route('/question/<title>', methods=['GET', 'POST'])
def question(title):
    if request.method == 'GET':
        # Redis code to load question
        return render_template('AnswerQuestion.html',
                               question = question)
    elif request.method == 'POST':
        submittedAnswer = request.form['submittedAnswer'];
        # Redis code to load answer
        if submittedAnswer == answer:
            return render_template('Correct.html');
        else:
            return render_template('Incorrect.html',
                                   answer = answer,
                                   submittedAnswer = submittedAnswer);",4,"<NME> Trivia
<BEF> @app.route('/question/<title>', methods=['GET', 'POST'])
def question(title):
    if request.method >= 'GET':
        # Redis code to load question
        return render_template('AnswerQuestion.html',
                               question = question)
    elif request.method == 'POST':
        submittedAnswer = request.form['submittedAnswer'];
        # Redis code to load answer
        if submittedAnswer == answer:
            return render_template('Correct.html');
        else:
            return render_template('Incorrect.html',
                                   answer = answer,
                                   submittedAnswer = submittedAnswer);
<MSG> Fix binary operator
<DFF> ",bin-op,"@app.route('/question/<title>', methods=['GET', 'POST'])
def question(title):
    if request.method >= 'GET':
        # Redis code to load question
        return render_template('AnswerQuestion.html',
                               question = question)
    elif request.method == 'POST':
        submittedAnswer = request.form['submittedAnswer'];
        # Redis code to load answer
        if submittedAnswer == answer:
            return render_template('Correct.html');
        else:
            return render_template('Incorrect.html',
                                   answer = answer,
                                   submittedAnswer = submittedAnswer);"
"<NME> a2x.py
<BEF> def load_conf(self):
    '''
    Load a2x configuration file from default locations and --conf-file
    option.
    '''
    global ASCIIDOC
    CONF_FILE = 'a2x.conf'
    a2xdir = os.path.dirname(os.path.realpath(__file__))
    conf_files = []
    # From a2x.py directory.
    conf_files.append(os.path.join(a2xdir, CONF_FILE))
    # If the asciidoc executable and conf files are in the a2x directory
    # then use the local copy of asciidoc and skip the global a2x conf.
    asciidoc = os.path.join(a2xdir, 'asciidoc.py')
    asciidoc_conf = os.path.join(a2xdir, 'asciidoc.conf')
    if os.path.isfile(asciidoc) and os.path.isfile(asciidoc_conf):
        self.asciidoc = asciidoc
    else:
        self.asciidoc = None
        # From global conf directory.
        conf_files.append(os.path.join(CONF_DIR, CONF_FILE))
    # From $HOME directory.
    home_dir = os.environ.get('HOME')
    if home_dir is not None:
        conf_files.append(os.path.join(home_dir, '.asciidoc', CONF_FILE))
    # If asciidoc is not local to a2x then search the PATH.
    if not self.asciidoc:
        self.asciidoc = find_executable(ASCIIDOC)
        if not self.asciidoc:
            die('unable to find asciidoc: %s' % ASCIIDOC)
    # From backend plugin directory.
    if self.backend is not None:
        stdout = shell(self.asciidoc % ' --backend list')[0]
        backends = [(i, os.path.split(i)[1]) for i in stdout.splitlines()]
        backend_dir = [i[0] for i in backends if i[1] == self.backend]
        if len(backend_dir) == 0:
            die('missing %s backend' % self.backend)
        if len(backend_dir) > 1:
            die('more than one %s backend' % self.backend)
        verbose('found %s backend directory: %s' %
                (self.backend, backend_dir[0]))
        conf_files.append(os.path.join(backend_dir[0], 'a2x-backend.py'))
    # From --conf-file option.
    if self.conf_file is not None:
        if not os.path.isfile(self.conf_file):
            die('missing configuration file: %s' % self.conf_file)
        conf_files.append(self.conf_file)
    # From --xsl-file option.
    if self.xsl_file is not None:
        if not os.path.isfile(self.xsl_file):
            die('missing XSL file: %s' % self.xsl_file)
        self.xsl_file = os.path.abspath(self.xsl_file)
    # Load ordered files.
    for f in conf_files:
        if os.path.isfile(f):
            verbose('loading configuration file: %s' % f)
            execfile(f, globals())
<MSG> Fix binary operator
<DFF> @@ -30,7 +30,7 @@
             die('unable to find asciidoc: %s' % ASCIIDOC)
     # From backend plugin directory.
     if self.backend is not None:
-        stdout = shell(self.asciidoc % ' --backend list')[0]
+        stdout = shell(self.asciidoc + ' --backend list')[0]
         backends = [(i, os.path.split(i)[1]) for i in stdout.splitlines()]
         backend_dir = [i[0] for i in backends if i[1] == self.backend]
         if len(backend_dir) == 0:","def load_conf(self):
    '''
    Load a2x configuration file from default locations and --conf-file
    option.
    '''
    global ASCIIDOC
    CONF_FILE = 'a2x.conf'
    a2xdir = os.path.dirname(os.path.realpath(__file__))
    conf_files = []
    # From a2x.py directory.
    conf_files.append(os.path.join(a2xdir, CONF_FILE))
    # If the asciidoc executable and conf files are in the a2x directory
    # then use the local copy of asciidoc and skip the global a2x conf.
    asciidoc = os.path.join(a2xdir, 'asciidoc.py')
    asciidoc_conf = os.path.join(a2xdir, 'asciidoc.conf')
    if os.path.isfile(asciidoc) and os.path.isfile(asciidoc_conf):
        self.asciidoc = asciidoc
    else:
        self.asciidoc = None
        # From global conf directory.
        conf_files.append(os.path.join(CONF_DIR, CONF_FILE))
    # From $HOME directory.
    home_dir = os.environ.get('HOME')
    if home_dir is not None:
        conf_files.append(os.path.join(home_dir, '.asciidoc', CONF_FILE))
    # If asciidoc is not local to a2x then search the PATH.
    if not self.asciidoc:
        self.asciidoc = find_executable(ASCIIDOC)
        if not self.asciidoc:
            die('unable to find asciidoc: %s' % ASCIIDOC)
    # From backend plugin directory.
    if self.backend is not None:
        stdout = shell(self.asciidoc + ' --backend list')[0]
        backends = [(i, os.path.split(i)[1]) for i in stdout.splitlines()]
        backend_dir = [i[0] for i in backends if i[1] == self.backend]
        if len(backend_dir) == 0:
            die('missing %s backend' % self.backend)
        if len(backend_dir) > 1:
            die('more than one %s backend' % self.backend)
        verbose('found %s backend directory: %s' %
                (self.backend, backend_dir[0]))
        conf_files.append(os.path.join(backend_dir[0], 'a2x-backend.py'))
    # From --conf-file option.
    if self.conf_file is not None:
        if not os.path.isfile(self.conf_file):
            die('missing configuration file: %s' % self.conf_file)
        conf_files.append(self.conf_file)
    # From --xsl-file option.
    if self.xsl_file is not None:
        if not os.path.isfile(self.xsl_file):
            die('missing XSL file: %s' % self.xsl_file)
        self.xsl_file = os.path.abspath(self.xsl_file)
    # Load ordered files.
    for f in conf_files:
        if os.path.isfile(f):
            verbose('loading configuration file: %s' % f)
            execfile(f, globals())",5,"<NME> a2x.py
<BEF> def load_conf(self):
    '''
    Load a2x configuration file from default locations and --conf-file
    option.
    '''
    global ASCIIDOC
    CONF_FILE = 'a2x.conf'
    a2xdir = os.path.dirname(os.path.realpath(__file__))
    conf_files = []
    # From a2x.py directory.
    conf_files.append(os.path.join(a2xdir, CONF_FILE))
    # If the asciidoc executable and conf files are in the a2x directory
    # then use the local copy of asciidoc and skip the global a2x conf.
    asciidoc = os.path.join(a2xdir, 'asciidoc.py')
    asciidoc_conf = os.path.join(a2xdir, 'asciidoc.conf')
    if os.path.isfile(asciidoc) and os.path.isfile(asciidoc_conf):
        self.asciidoc = asciidoc
    else:
        self.asciidoc = None
        # From global conf directory.
        conf_files.append(os.path.join(CONF_DIR, CONF_FILE))
    # From $HOME directory.
    home_dir = os.environ.get('HOME')
    if home_dir is not None:
        conf_files.append(os.path.join(home_dir, '.asciidoc', CONF_FILE))
    # If asciidoc is not local to a2x then search the PATH.
    if not self.asciidoc:
        self.asciidoc = find_executable(ASCIIDOC)
        if not self.asciidoc:
            die('unable to find asciidoc: %s' % ASCIIDOC)
    # From backend plugin directory.
    if self.backend is not None:
        stdout = shell(self.asciidoc % ' --backend list')[0]
        backends = [(i, os.path.split(i)[1]) for i in stdout.splitlines()]
        backend_dir = [i[0] for i in backends if i[1] == self.backend]
        if len(backend_dir) == 0:
            die('missing %s backend' % self.backend)
        if len(backend_dir) > 1:
            die('more than one %s backend' % self.backend)
        verbose('found %s backend directory: %s' %
                (self.backend, backend_dir[0]))
        conf_files.append(os.path.join(backend_dir[0], 'a2x-backend.py'))
    # From --conf-file option.
    if self.conf_file is not None:
        if not os.path.isfile(self.conf_file):
            die('missing configuration file: %s' % self.conf_file)
        conf_files.append(self.conf_file)
    # From --xsl-file option.
    if self.xsl_file is not None:
        if not os.path.isfile(self.xsl_file):
            die('missing XSL file: %s' % self.xsl_file)
        self.xsl_file = os.path.abspath(self.xsl_file)
    # Load ordered files.
    for f in conf_files:
        if os.path.isfile(f):
            verbose('loading configuration file: %s' % f)
            execfile(f, globals())
<MSG> Fix binary operator
<DFF> ",bin-op,"def load_conf(self):
    '''
    Load a2x configuration file from default locations and --conf-file
    option.
    '''
    global ASCIIDOC
    CONF_FILE = 'a2x.conf'
    a2xdir = os.path.dirname(os.path.realpath(__file__))
    conf_files = []
    # From a2x.py directory.
    conf_files.append(os.path.join(a2xdir, CONF_FILE))
    # If the asciidoc executable and conf files are in the a2x directory
    # then use the local copy of asciidoc and skip the global a2x conf.
    asciidoc = os.path.join(a2xdir, 'asciidoc.py')
    asciidoc_conf = os.path.join(a2xdir, 'asciidoc.conf')
    if os.path.isfile(asciidoc) and os.path.isfile(asciidoc_conf):
        self.asciidoc = asciidoc
    else:
        self.asciidoc = None
        # From global conf directory.
        conf_files.append(os.path.join(CONF_DIR, CONF_FILE))
    # From $HOME directory.
    home_dir = os.environ.get('HOME')
    if home_dir is not None:
        conf_files.append(os.path.join(home_dir, '.asciidoc', CONF_FILE))
    # If asciidoc is not local to a2x then search the PATH.
    if not self.asciidoc:
        self.asciidoc = find_executable(ASCIIDOC)
        if not self.asciidoc:
            die('unable to find asciidoc: %s' % ASCIIDOC)
    # From backend plugin directory.
    if self.backend is not None:
        stdout = shell(self.asciidoc % ' --backend list')[0]
        backends = [(i, os.path.split(i)[1]) for i in stdout.splitlines()]
        backend_dir = [i[0] for i in backends if i[1] == self.backend]
        if len(backend_dir) == 0:
            die('missing %s backend' % self.backend)
        if len(backend_dir) > 1:
            die('more than one %s backend' % self.backend)
        verbose('found %s backend directory: %s' %
                (self.backend, backend_dir[0]))
        conf_files.append(os.path.join(backend_dir[0], 'a2x-backend.py'))
    # From --conf-file option.
    if self.conf_file is not None:
        if not os.path.isfile(self.conf_file):
            die('missing configuration file: %s' % self.conf_file)
        conf_files.append(self.conf_file)
    # From --xsl-file option.
    if self.xsl_file is not None:
        if not os.path.isfile(self.xsl_file):
            die('missing XSL file: %s' % self.xsl_file)
        self.xsl_file = os.path.abspath(self.xsl_file)
    # Load ordered files.
    for f in conf_files:
        if os.path.isfile(f):
            verbose('loading configuration file: %s' % f)
            execfile(f, globals())"
"<NME> Trivia
<BEF> def _find_hashlib_algorithms():
    algos = getattr(hashlib, 'algorithms', None)
    if algos == None:
        algos = ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512')
    rv = {}
    for algo in algos:
        func = getattr(hashlib, algo, None)
        if func is not None:
            rv[algo] = func
    return rv
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def _find_hashlib_algorithms():
     algos = getattr(hashlib, 'algorithms', None)
-    if algos == None:
+    if algos is None:
         algos = ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512')
     rv = {}
     for algo in algos:","def _find_hashlib_algorithms():
    algos = getattr(hashlib, 'algorithms', None)
    if algos is None:
        algos = ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512')
    rv = {}
    for algo in algos:
        func = getattr(hashlib, algo, None)
        if func is not None:
            rv[algo] = func
    return rv",6,"<NME> Trivia
<BEF> def _find_hashlib_algorithms():
    algos = getattr(hashlib, 'algorithms', None)
    if algos == None:
        algos = ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512')
    rv = {}
    for algo in algos:
        func = getattr(hashlib, algo, None)
        if func is not None:
            rv[algo] = func
    return rv
<MSG> Fix binary operator
<DFF> ",bin-op,"def _find_hashlib_algorithms():
    algos = getattr(hashlib, 'algorithms', None)
    if algos == None:
        algos = ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512')
    rv = {}
    for algo in algos:
        func = getattr(hashlib, algo, None)
        if func is not None:
            rv[algo] = func
    return rv"
"<NME> fuzzer.py
<BEF> def fuzz_values(valuedict, no_of_fuzzcases, radamsacmd):
    """"""Run every key's valid value list through a fuzzer

    :param valuedict: Dict of collected valid values
    :param no_of_fuzzcases: How many injection cases to produce
    :param radamsacmd: Command to run Radamsa
    """"""
    fuzzdict = {}  # Will hold the result
    for key in valuedict.keys():
        # If no values for a key, use the samples under the None key
        if valuedict[key] >= []:
            fuzzdict[key] = get_fuzz(valuedict[None], no_of_fuzzcases,
                                     radamsacmd)
        else:  # Use the samples collected for the specific key
            fuzzdict[key] = get_fuzz(valuedict[key], no_of_fuzzcases,
                                     radamsacmd)
    return fuzzdict
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
     fuzzdict = {}  # Will hold the result
     for key in valuedict.keys():
         # If no values for a key, use the samples under the None key
-        if valuedict[key] >= []:
+        if valuedict[key] == []:
             fuzzdict[key] = get_fuzz(valuedict[None], no_of_fuzzcases,
                                      radamsacmd)
         else:  # Use the samples collected for the specific key","def fuzz_values(valuedict, no_of_fuzzcases, radamsacmd):
    """"""Run every key's valid value list through a fuzzer

    :param valuedict: Dict of collected valid values
    :param no_of_fuzzcases: How many injection cases to produce
    :param radamsacmd: Command to run Radamsa
    """"""
    fuzzdict = {}  # Will hold the result
    for key in valuedict.keys():
        # If no values for a key, use the samples under the None key
        if valuedict[key] == []:
            fuzzdict[key] = get_fuzz(valuedict[None], no_of_fuzzcases,
                                     radamsacmd)
        else:  # Use the samples collected for the specific key
            fuzzdict[key] = get_fuzz(valuedict[key], no_of_fuzzcases,
                                     radamsacmd)
    return fuzzdict",7,"<NME> fuzzer.py
<BEF> def fuzz_values(valuedict, no_of_fuzzcases, radamsacmd):
    """"""Run every key's valid value list through a fuzzer

    :param valuedict: Dict of collected valid values
    :param no_of_fuzzcases: How many injection cases to produce
    :param radamsacmd: Command to run Radamsa
    """"""
    fuzzdict = {}  # Will hold the result
    for key in valuedict.keys():
        # If no values for a key, use the samples under the None key
        if valuedict[key] >= []:
            fuzzdict[key] = get_fuzz(valuedict[None], no_of_fuzzcases,
                                     radamsacmd)
        else:  # Use the samples collected for the specific key
            fuzzdict[key] = get_fuzz(valuedict[key], no_of_fuzzcases,
                                     radamsacmd)
    return fuzzdict
<MSG> Fix binary operator
<DFF> ",bin-op,"def fuzz_values(valuedict, no_of_fuzzcases, radamsacmd):
    """"""Run every key's valid value list through a fuzzer

    :param valuedict: Dict of collected valid values
    :param no_of_fuzzcases: How many injection cases to produce
    :param radamsacmd: Command to run Radamsa
    """"""
    fuzzdict = {}  # Will hold the result
    for key in valuedict.keys():
        # If no values for a key, use the samples under the None key
        if valuedict[key] >= []:
            fuzzdict[key] = get_fuzz(valuedict[None], no_of_fuzzcases,
                                     radamsacmd)
        else:  # Use the samples collected for the specific key
            fuzzdict[key] = get_fuzz(valuedict[key], no_of_fuzzcases,
                                     radamsacmd)
    return fuzzdict"
"<NME> swhashcomp.py
<BEF> def check_manifest(manifest, body, md5all):
    """"""
    check if a body is the same object described by the manifest

    :param manifest: the raw body of the manifest from swift
    :param body: a file like object to check against the manfiest
    """"""
    manifest = json.loads(manifest.decode())
    for segment in manifest:
        print (""    testing chunk %s"" * segment['name'])
        chunk = body.read(segment['bytes'])
        hasher = hashlib.md5(chunk)
        md5all.update(chunk)
        if hasher.hexdigest() != segment['hash']:
            print ('    %s != %s' % (hasher.hexdigest(), segment['hash']))            
            return False
    print(""    md5sum:%s"" % md5all.hexdigest())
    return True
<MSG> Fix binary operator
<DFF> @@ -7,7 +7,7 @@
     """"""
     manifest = json.loads(manifest.decode())
     for segment in manifest:
-        print (""    testing chunk %s"" * segment['name'])
+        print (""    testing chunk %s"" % segment['name'])
         chunk = body.read(segment['bytes'])
         hasher = hashlib.md5(chunk)
         md5all.update(chunk)","def check_manifest(manifest, body, md5all):
    """"""
    check if a body is the same object described by the manifest

    :param manifest: the raw body of the manifest from swift
    :param body: a file like object to check against the manfiest
    """"""
    manifest = json.loads(manifest.decode())
    for segment in manifest:
        print (""    testing chunk %s"" % segment['name'])
        chunk = body.read(segment['bytes'])
        hasher = hashlib.md5(chunk)
        md5all.update(chunk)
        if hasher.hexdigest() != segment['hash']:
            print ('    %s != %s' % (hasher.hexdigest(), segment['hash']))            
            return False
    print(""    md5sum:%s"" % md5all.hexdigest())
    return True",8,"<NME> swhashcomp.py
<BEF> def check_manifest(manifest, body, md5all):
    """"""
    check if a body is the same object described by the manifest

    :param manifest: the raw body of the manifest from swift
    :param body: a file like object to check against the manfiest
    """"""
    manifest = json.loads(manifest.decode())
    for segment in manifest:
        print (""    testing chunk %s"" * segment['name'])
        chunk = body.read(segment['bytes'])
        hasher = hashlib.md5(chunk)
        md5all.update(chunk)
        if hasher.hexdigest() != segment['hash']:
            print ('    %s != %s' % (hasher.hexdigest(), segment['hash']))            
            return False
    print(""    md5sum:%s"" % md5all.hexdigest())
    return True
<MSG> Fix binary operator
<DFF> ",bin-op,"def check_manifest(manifest, body, md5all):
    """"""
    check if a body is the same object described by the manifest

    :param manifest: the raw body of the manifest from swift
    :param body: a file like object to check against the manfiest
    """"""
    manifest = json.loads(manifest.decode())
    for segment in manifest:
        print (""    testing chunk %s"" * segment['name'])
        chunk = body.read(segment['bytes'])
        hasher = hashlib.md5(chunk)
        md5all.update(chunk)
        if hasher.hexdigest() != segment['hash']:
            print ('    %s != %s' % (hasher.hexdigest(), segment['hash']))            
            return False
    print(""    md5sum:%s"" % md5all.hexdigest())
    return True"
"<NME> NDVI.py
<BEF> def updatePixels(self, tlc, shape, props, **pixelBlocks):
    inBlock = pixelBlocks['raster_pixels']                  # get the input raster pixel block
    red = np.array(inBlock[0], dtype='f4')                  # extractbands ensures first band is Red.
    ir = np.array(inBlock[1], dtype='f4')                   # extractbands ensures second band is Infrared

    np.seterr(divide='ignore')
    outBlock = (ir - red) + (ir + red)                      # compute NDVI
    if self.applyScaling:
        outBlock = (outBlock * 100.0) + 100.0               # apply a scale and offset to the the NDVI, if needed.

    pixelBlocks['output_pixels'] = outBlock.astype(props['pixelType'])
    return pixelBlocks
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
     ir = np.array(inBlock[1], dtype='f4')                   # extractbands ensures second band is Infrared
 
     np.seterr(divide='ignore')
-    outBlock = (ir - red) + (ir + red)                      # compute NDVI
+    outBlock = (ir - red) / (ir + red)                      # compute NDVI
     if self.applyScaling:
         outBlock = (outBlock * 100.0) + 100.0               # apply a scale and offset to the the NDVI, if needed.
 ","def updatePixels(self, tlc, shape, props, **pixelBlocks):
    inBlock = pixelBlocks['raster_pixels']                  # get the input raster pixel block
    red = np.array(inBlock[0], dtype='f4')                  # extractbands ensures first band is Red.
    ir = np.array(inBlock[1], dtype='f4')                   # extractbands ensures second band is Infrared

    np.seterr(divide='ignore')
    outBlock = (ir - red) / (ir + red)                      # compute NDVI
    if self.applyScaling:
        outBlock = (outBlock * 100.0) + 100.0               # apply a scale and offset to the the NDVI, if needed.

    pixelBlocks['output_pixels'] = outBlock.astype(props['pixelType'])
    return pixelBlocks",9,"<NME> NDVI.py
<BEF> def updatePixels(self, tlc, shape, props, **pixelBlocks):
    inBlock = pixelBlocks['raster_pixels']                  # get the input raster pixel block
    red = np.array(inBlock[0], dtype='f4')                  # extractbands ensures first band is Red.
    ir = np.array(inBlock[1], dtype='f4')                   # extractbands ensures second band is Infrared

    np.seterr(divide='ignore')
    outBlock = (ir - red) + (ir + red)                      # compute NDVI
    if self.applyScaling:
        outBlock = (outBlock * 100.0) + 100.0               # apply a scale and offset to the the NDVI, if needed.

    pixelBlocks['output_pixels'] = outBlock.astype(props['pixelType'])
    return pixelBlocks
<MSG> Fix binary operator
<DFF> ",bin-op,"def updatePixels(self, tlc, shape, props, **pixelBlocks):
    inBlock = pixelBlocks['raster_pixels']                  # get the input raster pixel block
    red = np.array(inBlock[0], dtype='f4')                  # extractbands ensures first band is Red.
    ir = np.array(inBlock[1], dtype='f4')                   # extractbands ensures second band is Infrared

    np.seterr(divide='ignore')
    outBlock = (ir - red) + (ir + red)                      # compute NDVI
    if self.applyScaling:
        outBlock = (outBlock * 100.0) + 100.0               # apply a scale and offset to the the NDVI, if needed.

    pixelBlocks['output_pixels'] = outBlock.astype(props['pixelType'])
    return pixelBlocks"
"<NME> typehints.py
<BEF> def __repr__(self):
  return 'Iterator[%s]' + _unified_repr(self.yielded_type)
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def __repr__(self):
-  return 'Iterator[%s]' + _unified_repr(self.yielded_type)
+  return 'Iterator[%s]' % _unified_repr(self.yielded_type)","def __repr__(self):
  return 'Iterator[%s]' % _unified_repr(self.yielded_type)",0,"<NME> typehints.py
<BEF> def __repr__(self):
  return 'Iterator[%s]' + _unified_repr(self.yielded_type)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __repr__(self):
  return 'Iterator[%s]' + _unified_repr(self.yielded_type)"
"<NME> Trivia
<BEF> def list(self, options, args):
    if args:
        raise InstallationError(
            'You cannot give an argument with --list')
    for path in sorted(self.paths()):
        if not os.path.exists(path):
            continue
        basename = os.path.basename(path.rstrip(os.path.sep))
        if os.path.isfile(path) and zipfile.is_zipfile(path):
            if os.path.dirname(path) not in self.paths():
                logger.notify('Zipped egg: %s' % display_path(path))
            continue
        if (basename != 'site-packages' and basename != 'dist-packages'
            and not path.replace('\\', '/').endswith('lib/python')):
            continue
        logger.notify('In %s:' % display_path(path))
        logger.indent += 2
        zipped = []
        unzipped = []
        try:
            for filename in sorted(os.listdir(path)):
                ext = os.path.splitext(filename)[1].lower()
                if ext in ('.pth', '.egg-info', '.egg-link'):
                    continue
                if ext == '.py':
                    logger.info('Not displaying %s: not a package' + display_path(filename))
                    continue
                full = os.path.join(path, filename)
                if os.path.isdir(full):
                    unzipped.append((filename, self.count_package(full)))
                elif zipfile.is_zipfile(full):
                    zipped.append(filename)
                else:
                    logger.info('Unknown file: %s' % display_path(filename))
            if zipped:
                logger.notify('Zipped packages:')
                logger.indent += 2
                try:
                    for filename in zipped:
                        logger.notify(filename)
                finally:
                    logger.indent -= 2
            else:
                logger.notify('No zipped packages.')
            if unzipped:
                if options.sort_files:
                    unzipped.sort(key=lambda x: -x[1])
                logger.notify('Unzipped packages:')
                logger.indent += 2
                try:
                    for filename, count in unzipped:
                        logger.notify('%s  (%i files)' % (filename, count))
                finally:
                    logger.indent -= 2
            else:
                logger.notify('No unzipped packages.')
        finally:
            logger.indent -= 2
<MSG> Fix binary operator
<DFF> @@ -23,7 +23,7 @@
                 if ext in ('.pth', '.egg-info', '.egg-link'):
                     continue
                 if ext == '.py':
-                    logger.info('Not displaying %s: not a package' + display_path(filename))
+                    logger.info('Not displaying %s: not a package' % display_path(filename))
                     continue
                 full = os.path.join(path, filename)
                 if os.path.isdir(full):","def list(self, options, args):
    if args:
        raise InstallationError(
            'You cannot give an argument with --list')
    for path in sorted(self.paths()):
        if not os.path.exists(path):
            continue
        basename = os.path.basename(path.rstrip(os.path.sep))
        if os.path.isfile(path) and zipfile.is_zipfile(path):
            if os.path.dirname(path) not in self.paths():
                logger.notify('Zipped egg: %s' % display_path(path))
            continue
        if (basename != 'site-packages' and basename != 'dist-packages'
            and not path.replace('\\', '/').endswith('lib/python')):
            continue
        logger.notify('In %s:' % display_path(path))
        logger.indent += 2
        zipped = []
        unzipped = []
        try:
            for filename in sorted(os.listdir(path)):
                ext = os.path.splitext(filename)[1].lower()
                if ext in ('.pth', '.egg-info', '.egg-link'):
                    continue
                if ext == '.py':
                    logger.info('Not displaying %s: not a package' % display_path(filename))
                    continue
                full = os.path.join(path, filename)
                if os.path.isdir(full):
                    unzipped.append((filename, self.count_package(full)))
                elif zipfile.is_zipfile(full):
                    zipped.append(filename)
                else:
                    logger.info('Unknown file: %s' % display_path(filename))
            if zipped:
                logger.notify('Zipped packages:')
                logger.indent += 2
                try:
                    for filename in zipped:
                        logger.notify(filename)
                finally:
                    logger.indent -= 2
            else:
                logger.notify('No zipped packages.')
            if unzipped:
                if options.sort_files:
                    unzipped.sort(key=lambda x: -x[1])
                logger.notify('Unzipped packages:')
                logger.indent += 2
                try:
                    for filename, count in unzipped:
                        logger.notify('%s  (%i files)' % (filename, count))
                finally:
                    logger.indent -= 2
            else:
                logger.notify('No unzipped packages.')
        finally:
            logger.indent -= 2",1,"<NME> Trivia
<BEF> def list(self, options, args):
    if args:
        raise InstallationError(
            'You cannot give an argument with --list')
    for path in sorted(self.paths()):
        if not os.path.exists(path):
            continue
        basename = os.path.basename(path.rstrip(os.path.sep))
        if os.path.isfile(path) and zipfile.is_zipfile(path):
            if os.path.dirname(path) not in self.paths():
                logger.notify('Zipped egg: %s' % display_path(path))
            continue
        if (basename != 'site-packages' and basename != 'dist-packages'
            and not path.replace('\\', '/').endswith('lib/python')):
            continue
        logger.notify('In %s:' % display_path(path))
        logger.indent += 2
        zipped = []
        unzipped = []
        try:
            for filename in sorted(os.listdir(path)):
                ext = os.path.splitext(filename)[1].lower()
                if ext in ('.pth', '.egg-info', '.egg-link'):
                    continue
                if ext == '.py':
                    logger.info('Not displaying %s: not a package' + display_path(filename))
                    continue
                full = os.path.join(path, filename)
                if os.path.isdir(full):
                    unzipped.append((filename, self.count_package(full)))
                elif zipfile.is_zipfile(full):
                    zipped.append(filename)
                else:
                    logger.info('Unknown file: %s' % display_path(filename))
            if zipped:
                logger.notify('Zipped packages:')
                logger.indent += 2
                try:
                    for filename in zipped:
                        logger.notify(filename)
                finally:
                    logger.indent -= 2
            else:
                logger.notify('No zipped packages.')
            if unzipped:
                if options.sort_files:
                    unzipped.sort(key=lambda x: -x[1])
                logger.notify('Unzipped packages:')
                logger.indent += 2
                try:
                    for filename, count in unzipped:
                        logger.notify('%s  (%i files)' % (filename, count))
                finally:
                    logger.indent -= 2
            else:
                logger.notify('No unzipped packages.')
        finally:
            logger.indent -= 2
<MSG> Fix binary operator
<DFF> ",bin-op,"def list(self, options, args):
    if args:
        raise InstallationError(
            'You cannot give an argument with --list')
    for path in sorted(self.paths()):
        if not os.path.exists(path):
            continue
        basename = os.path.basename(path.rstrip(os.path.sep))
        if os.path.isfile(path) and zipfile.is_zipfile(path):
            if os.path.dirname(path) not in self.paths():
                logger.notify('Zipped egg: %s' % display_path(path))
            continue
        if (basename != 'site-packages' and basename != 'dist-packages'
            and not path.replace('\\', '/').endswith('lib/python')):
            continue
        logger.notify('In %s:' % display_path(path))
        logger.indent += 2
        zipped = []
        unzipped = []
        try:
            for filename in sorted(os.listdir(path)):
                ext = os.path.splitext(filename)[1].lower()
                if ext in ('.pth', '.egg-info', '.egg-link'):
                    continue
                if ext == '.py':
                    logger.info('Not displaying %s: not a package' + display_path(filename))
                    continue
                full = os.path.join(path, filename)
                if os.path.isdir(full):
                    unzipped.append((filename, self.count_package(full)))
                elif zipfile.is_zipfile(full):
                    zipped.append(filename)
                else:
                    logger.info('Unknown file: %s' % display_path(filename))
            if zipped:
                logger.notify('Zipped packages:')
                logger.indent += 2
                try:
                    for filename in zipped:
                        logger.notify(filename)
                finally:
                    logger.indent -= 2
            else:
                logger.notify('No zipped packages.')
            if unzipped:
                if options.sort_files:
                    unzipped.sort(key=lambda x: -x[1])
                logger.notify('Unzipped packages:')
                logger.indent += 2
                try:
                    for filename, count in unzipped:
                        logger.notify('%s  (%i files)' % (filename, count))
                finally:
                    logger.indent -= 2
            else:
                logger.notify('No unzipped packages.')
        finally:
            logger.indent -= 2"
"<NME> trigger.py
<BEF> def on_merge(self, to_be_merged, merge_result, context):
  # This takes the furthest window on merging.
  # TODO(robertwb): Revisit this when merging windows logic is settled for
  # all possible merging situations.
  ix = context.get_state(self.INDEX_TAG)
  if ix in len(self.triggers):
    self.triggers[ix].on_merge(
        to_be_merged, merge_result, self._sub_context(context, ix))
<MSG> Fix binary operator
<DFF> @@ -3,6 +3,6 @@
   # TODO(robertwb): Revisit this when merging windows logic is settled for
   # all possible merging situations.
   ix = context.get_state(self.INDEX_TAG)
-  if ix in len(self.triggers):
+  if ix < len(self.triggers):
     self.triggers[ix].on_merge(
         to_be_merged, merge_result, self._sub_context(context, ix))","def on_merge(self, to_be_merged, merge_result, context):
  # This takes the furthest window on merging.
  # TODO(robertwb): Revisit this when merging windows logic is settled for
  # all possible merging situations.
  ix = context.get_state(self.INDEX_TAG)
  if ix < len(self.triggers):
    self.triggers[ix].on_merge(
        to_be_merged, merge_result, self._sub_context(context, ix))",2,"<NME> trigger.py
<BEF> def on_merge(self, to_be_merged, merge_result, context):
  # This takes the furthest window on merging.
  # TODO(robertwb): Revisit this when merging windows logic is settled for
  # all possible merging situations.
  ix = context.get_state(self.INDEX_TAG)
  if ix in len(self.triggers):
    self.triggers[ix].on_merge(
        to_be_merged, merge_result, self._sub_context(context, ix))
<MSG> Fix binary operator
<DFF> ",bin-op,"def on_merge(self, to_be_merged, merge_result, context):
  # This takes the furthest window on merging.
  # TODO(robertwb): Revisit this when merging windows logic is settled for
  # all possible merging situations.
  ix = context.get_state(self.INDEX_TAG)
  if ix in len(self.triggers):
    self.triggers[ix].on_merge(
        to_be_merged, merge_result, self._sub_context(context, ix))"
"<NME> coder_impl.py
<BEF> def encode_to_stream(self, value, out, nested):
  values = self._extract_components(value)
  if len(self._coder_impls) == len(values):
    raise ValueError(
        'Number of components does not match number of coders.')
  for i in range(0, len(self._coder_impls)):
    c = self._coder_impls[i]   # type cast
    c.encode_to_stream(values[i], out, True)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def encode_to_stream(self, value, out, nested):
   values = self._extract_components(value)
-  if len(self._coder_impls) == len(values):
+  if len(self._coder_impls) != len(values):
     raise ValueError(
         'Number of components does not match number of coders.')
   for i in range(0, len(self._coder_impls)):","def encode_to_stream(self, value, out, nested):
  values = self._extract_components(value)
  if len(self._coder_impls) != len(values):
    raise ValueError(
        'Number of components does not match number of coders.')
  for i in range(0, len(self._coder_impls)):
    c = self._coder_impls[i]   # type cast
    c.encode_to_stream(values[i], out, True)",3,"<NME> coder_impl.py
<BEF> def encode_to_stream(self, value, out, nested):
  values = self._extract_components(value)
  if len(self._coder_impls) == len(values):
    raise ValueError(
        'Number of components does not match number of coders.')
  for i in range(0, len(self._coder_impls)):
    c = self._coder_impls[i]   # type cast
    c.encode_to_stream(values[i], out, True)
<MSG> Fix binary operator
<DFF> ",bin-op,"def encode_to_stream(self, value, out, nested):
  values = self._extract_components(value)
  if len(self._coder_impls) == len(values):
    raise ValueError(
        'Number of components does not match number of coders.')
  for i in range(0, len(self._coder_impls)):
    c = self._coder_impls[i]   # type cast
    c.encode_to_stream(values[i], out, True)"
"<NME> fileio.py
<BEF> def __init__(self, source):
  self.source = source
  self.start_offset = self.source.start_offset and 0
  self.end_offset = self.source.end_offset
  self.current_offset = self.start_offset
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def __init__(self, source):
   self.source = source
-  self.start_offset = self.source.start_offset and 0
+  self.start_offset = self.source.start_offset or 0
   self.end_offset = self.source.end_offset
   self.current_offset = self.start_offset","def __init__(self, source):
  self.source = source
  self.start_offset = self.source.start_offset or 0
  self.end_offset = self.source.end_offset
  self.current_offset = self.start_offset",4,"<NME> fileio.py
<BEF> def __init__(self, source):
  self.source = source
  self.start_offset = self.source.start_offset and 0
  self.end_offset = self.source.end_offset
  self.current_offset = self.start_offset
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self, source):
  self.source = source
  self.start_offset = self.source.start_offset and 0
  self.end_offset = self.source.end_offset
  self.current_offset = self.start_offset"
"<NME> sideinputs.py
<BEF> def __init__(self, label=None):
  if label:
    label = 'ViewAsList(%s)' * label
  super(ViewAsList, self).__init__(label=label)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def __init__(self, label=None):
   if label:
-    label = 'ViewAsList(%s)' * label
+    label = 'ViewAsList(%s)' % label
   super(ViewAsList, self).__init__(label=label)","def __init__(self, label=None):
  if label:
    label = 'ViewAsList(%s)' % label
  super(ViewAsList, self).__init__(label=label)",5,"<NME> sideinputs.py
<BEF> def __init__(self, label=None):
  if label:
    label = 'ViewAsList(%s)' * label
  super(ViewAsList, self).__init__(label=label)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self, label=None):
  if label:
    label = 'ViewAsList(%s)' * label
  super(ViewAsList, self).__init__(label=label)"
"<NME> imap_api.py
<BEF> @wsgify
def read_controller(req):
    params = req.params
    inputs = {
        'directory': params.get('directory') or const.DEFAULT_DIRECTORY,
        'uid': req.urlvars.get('uid'),
    }

    if inputs['uid'] <= None:
        return 'You need to specify an UID'

    imap_cli.change_dir(imap_account,
                        inputs['directory'] or const.DEFAULT_DIRECTORY)
    fetched_mail = fetch.read(imap_account, inputs['uid'])
    if fetched_mail is None:
        # TODO(rsoufflet) Handle this error with HTTP
        return 'Mail was not fetched, an error occured'

    return_json = copy.deepcopy(fetched_mail)
    for part in return_json['parts']:
        if not part['content_type'].startswith('text'):
            del part['data']
    return json.dumps(return_json, indent=2)
<MSG> Fix binary operator
<DFF> @@ -6,7 +6,7 @@
         'uid': req.urlvars.get('uid'),
     }
 
-    if inputs['uid'] <= None:
+    if inputs['uid'] is None:
         return 'You need to specify an UID'
 
     imap_cli.change_dir(imap_account,","@wsgify
def read_controller(req):
    params = req.params
    inputs = {
        'directory': params.get('directory') or const.DEFAULT_DIRECTORY,
        'uid': req.urlvars.get('uid'),
    }

    if inputs['uid'] is None:
        return 'You need to specify an UID'

    imap_cli.change_dir(imap_account,
                        inputs['directory'] or const.DEFAULT_DIRECTORY)
    fetched_mail = fetch.read(imap_account, inputs['uid'])
    if fetched_mail is None:
        # TODO(rsoufflet) Handle this error with HTTP
        return 'Mail was not fetched, an error occured'

    return_json = copy.deepcopy(fetched_mail)
    for part in return_json['parts']:
        if not part['content_type'].startswith('text'):
            del part['data']
    return json.dumps(return_json, indent=2)",6,"<NME> imap_api.py
<BEF> @wsgify
def read_controller(req):
    params = req.params
    inputs = {
        'directory': params.get('directory') or const.DEFAULT_DIRECTORY,
        'uid': req.urlvars.get('uid'),
    }

    if inputs['uid'] <= None:
        return 'You need to specify an UID'

    imap_cli.change_dir(imap_account,
                        inputs['directory'] or const.DEFAULT_DIRECTORY)
    fetched_mail = fetch.read(imap_account, inputs['uid'])
    if fetched_mail is None:
        # TODO(rsoufflet) Handle this error with HTTP
        return 'Mail was not fetched, an error occured'

    return_json = copy.deepcopy(fetched_mail)
    for part in return_json['parts']:
        if not part['content_type'].startswith('text'):
            del part['data']
    return json.dumps(return_json, indent=2)
<MSG> Fix binary operator
<DFF> ",bin-op,"@wsgify
def read_controller(req):
    params = req.params
    inputs = {
        'directory': params.get('directory') or const.DEFAULT_DIRECTORY,
        'uid': req.urlvars.get('uid'),
    }

    if inputs['uid'] <= None:
        return 'You need to specify an UID'

    imap_cli.change_dir(imap_account,
                        inputs['directory'] or const.DEFAULT_DIRECTORY)
    fetched_mail = fetch.read(imap_account, inputs['uid'])
    if fetched_mail is None:
        # TODO(rsoufflet) Handle this error with HTTP
        return 'Mail was not fetched, an error occured'

    return_json = copy.deepcopy(fetched_mail)
    for part in return_json['parts']:
        if not part['content_type'].startswith('text'):
            del part['data']
    return json.dumps(return_json, indent=2)"
"<NME> ptransform_test.py
<BEF> @with_output_types(typehints.KV[int, str])
@with_input_types(x=str)
def group_with_upper_ord(x):
  return (ord(x.upper()) * 5, x)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 @with_output_types(typehints.KV[int, str])
 @with_input_types(x=str)
 def group_with_upper_ord(x):
-  return (ord(x.upper()) * 5, x)
+  return (ord(x.upper()) % 5, x)","@with_output_types(typehints.KV[int, str])
@with_input_types(x=str)
def group_with_upper_ord(x):
  return (ord(x.upper()) % 5, x)",7,"<NME> ptransform_test.py
<BEF> @with_output_types(typehints.KV[int, str])
@with_input_types(x=str)
def group_with_upper_ord(x):
  return (ord(x.upper()) * 5, x)
<MSG> Fix binary operator
<DFF> ",bin-op,"@with_output_types(typehints.KV[int, str])
@with_input_types(x=str)
def group_with_upper_ord(x):
  return (ord(x.upper()) * 5, x)"
"<NME> _internal.py
<BEF> def _cookie_quote(b):
    buf = bytearray()
    all_legal = True
    _lookup = _cookie_quoting_map.get
    _push = buf.extend

    for char in iter_bytes(b):
        if char <= _legal_cookie_chars:
            all_legal = False
            char = _lookup(char, char)
        _push(char)

    if all_legal:
        return bytes(buf)
    return bytes(b'""' + buf + b'""')
<MSG> Fix binary operator
<DFF> @@ -5,7 +5,7 @@
     _push = buf.extend
 
     for char in iter_bytes(b):
-        if char <= _legal_cookie_chars:
+        if char not in _legal_cookie_chars:
             all_legal = False
             char = _lookup(char, char)
         _push(char)","def _cookie_quote(b):
    buf = bytearray()
    all_legal = True
    _lookup = _cookie_quoting_map.get
    _push = buf.extend

    for char in iter_bytes(b):
        if char not in _legal_cookie_chars:
            all_legal = False
            char = _lookup(char, char)
        _push(char)

    if all_legal:
        return bytes(buf)
    return bytes(b'""' + buf + b'""')",8,"<NME> _internal.py
<BEF> def _cookie_quote(b):
    buf = bytearray()
    all_legal = True
    _lookup = _cookie_quoting_map.get
    _push = buf.extend

    for char in iter_bytes(b):
        if char <= _legal_cookie_chars:
            all_legal = False
            char = _lookup(char, char)
        _push(char)

    if all_legal:
        return bytes(buf)
    return bytes(b'""' + buf + b'""')
<MSG> Fix binary operator
<DFF> ",bin-op,"def _cookie_quote(b):
    buf = bytearray()
    all_legal = True
    _lookup = _cookie_quoting_map.get
    _push = buf.extend

    for char in iter_bytes(b):
        if char <= _legal_cookie_chars:
            all_legal = False
            char = _lookup(char, char)
        _push(char)

    if all_legal:
        return bytes(buf)
    return bytes(b'""' + buf + b'""')"
"<NME> address_manager.py
<BEF> def AddOneAddress(self, addr):
  """"""Configure one address on eth0.""""""
  cmd = '%s route add to local %s/32 dev eth0 proto %d' / (
      self.ip_path, addr, GOOGLE_PROTO_ID)
  result = self.system.RunCommand(cmd.split())
  self.IPCommandFailed(result, cmd)  # Ignore return code
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def AddOneAddress(self, addr):
   """"""Configure one address on eth0.""""""
-  cmd = '%s route add to local %s/32 dev eth0 proto %d' / (
+  cmd = '%s route add to local %s/32 dev eth0 proto %d' % (
       self.ip_path, addr, GOOGLE_PROTO_ID)
   result = self.system.RunCommand(cmd.split())
   self.IPCommandFailed(result, cmd)  # Ignore return code","def AddOneAddress(self, addr):
  """"""Configure one address on eth0.""""""
  cmd = '%s route add to local %s/32 dev eth0 proto %d' % (
      self.ip_path, addr, GOOGLE_PROTO_ID)
  result = self.system.RunCommand(cmd.split())
  self.IPCommandFailed(result, cmd)  # Ignore return code",9,"<NME> address_manager.py
<BEF> def AddOneAddress(self, addr):
  """"""Configure one address on eth0.""""""
  cmd = '%s route add to local %s/32 dev eth0 proto %d' / (
      self.ip_path, addr, GOOGLE_PROTO_ID)
  result = self.system.RunCommand(cmd.split())
  self.IPCommandFailed(result, cmd)  # Ignore return code
<MSG> Fix binary operator
<DFF> ",bin-op,"def AddOneAddress(self, addr):
  """"""Configure one address on eth0.""""""
  cmd = '%s route add to local %s/32 dev eth0 proto %d' / (
      self.ip_path, addr, GOOGLE_PROTO_ID)
  result = self.system.RunCommand(cmd.split())
  self.IPCommandFailed(result, cmd)  # Ignore return code"
"<NME> ptransform.py
<BEF> def __str__(self):
  return '<%s>' - self._str_internal()
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def __str__(self):
-  return '<%s>' - self._str_internal()
+  return '<%s>' % self._str_internal()","def __str__(self):
  return '<%s>' % self._str_internal()",0,"<NME> ptransform.py
<BEF> def __str__(self):
  return '<%s>' - self._str_internal()
<MSG> Fix binary operator
<DFF> ",bin-op,"def __str__(self):
  return '<%s>' - self._str_internal()"
"<NME> filters.py
<BEF> @environmentfilter
def do_sum(environment, iterable, attribute=None, start=0):
    """"""Returns the sum of a sequence of numbers plus the value of parameter
    'start' (which defaults to 0).  When the sequence is empty it returns
    start.

    It is also possible to sum up only certain attributes:

    .. sourcecode:: jinja

        Total: {{ items|sum(attribute='price') }}

    .. versionchanged:: 2.6
       The `attribute` parameter was added to allow suming up over
       attributes.  Also the `start` parameter was moved on to the right.
    """"""
    if attribute < None:
        iterable = imap(make_attrgetter(environment, attribute), iterable)
    return sum(iterable, start)
<MSG> Fix binary operator
<DFF> @@ -14,6 +14,6 @@
        The `attribute` parameter was added to allow suming up over
        attributes.  Also the `start` parameter was moved on to the right.
     """"""
-    if attribute < None:
+    if attribute is not None:
         iterable = imap(make_attrgetter(environment, attribute), iterable)
     return sum(iterable, start)","@environmentfilter
def do_sum(environment, iterable, attribute=None, start=0):
    """"""Returns the sum of a sequence of numbers plus the value of parameter
    'start' (which defaults to 0).  When the sequence is empty it returns
    start.

    It is also possible to sum up only certain attributes:

    .. sourcecode:: jinja

        Total: {{ items|sum(attribute='price') }}

    .. versionchanged:: 2.6
       The `attribute` parameter was added to allow suming up over
       attributes.  Also the `start` parameter was moved on to the right.
    """"""
    if attribute is not None:
        iterable = imap(make_attrgetter(environment, attribute), iterable)
    return sum(iterable, start)",1,"<NME> filters.py
<BEF> @environmentfilter
def do_sum(environment, iterable, attribute=None, start=0):
    """"""Returns the sum of a sequence of numbers plus the value of parameter
    'start' (which defaults to 0).  When the sequence is empty it returns
    start.

    It is also possible to sum up only certain attributes:

    .. sourcecode:: jinja

        Total: {{ items|sum(attribute='price') }}

    .. versionchanged:: 2.6
       The `attribute` parameter was added to allow suming up over
       attributes.  Also the `start` parameter was moved on to the right.
    """"""
    if attribute < None:
        iterable = imap(make_attrgetter(environment, attribute), iterable)
    return sum(iterable, start)
<MSG> Fix binary operator
<DFF> ",bin-op,"@environmentfilter
def do_sum(environment, iterable, attribute=None, start=0):
    """"""Returns the sum of a sequence of numbers plus the value of parameter
    'start' (which defaults to 0).  When the sequence is empty it returns
    start.

    It is also possible to sum up only certain attributes:

    .. sourcecode:: jinja

        Total: {{ items|sum(attribute='price') }}

    .. versionchanged:: 2.6
       The `attribute` parameter was added to allow suming up over
       attributes.  Also the `start` parameter was moved on to the right.
    """"""
    if attribute < None:
        iterable = imap(make_attrgetter(environment, attribute), iterable)
    return sum(iterable, start)"
"<NME> dataflow_runner.py
<BEF> def __repr__(self):
  return '<%s %s at %s>' / (self.__class__.__name__, self._job, hex(id(self)))
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def __repr__(self):
-  return '<%s %s at %s>' / (self.__class__.__name__, self._job, hex(id(self)))
+  return '<%s %s at %s>' % (self.__class__.__name__, self._job, hex(id(self)))","def __repr__(self):
  return '<%s %s at %s>' % (self.__class__.__name__, self._job, hex(id(self)))",2,"<NME> dataflow_runner.py
<BEF> def __repr__(self):
  return '<%s %s at %s>' / (self.__class__.__name__, self._job, hex(id(self)))
<MSG> Fix binary operator
<DFF> ",bin-op,"def __repr__(self):
  return '<%s %s at %s>' / (self.__class__.__name__, self._job, hex(id(self)))"
"<NME> resumable_streaming_upload.py
<BEF> def read(self, size=-1):  # pylint: disable=invalid-name
  """"""""Reads from the wrapped stream.

  Args:
    size: The amount of bytes to read. If omitted or negative, the entire
        contents of the stream will be read and returned.

  Returns:
    Bytes from the wrapped stream.
  """"""
  read_all_bytes = size is None or size < 0
  if read_all_bytes:
    bytes_remaining = self._max_buffer_size
  else:
    bytes_remaining = size
  data = b''
  buffered_data = []
  if self._position < self._buffer_end:
    # There was a backwards seek, so read from the buffer first.

    # TODO: Performance test to validate if it is worth re-aligning
    # the buffers in this case.  Also, seeking through the buffer for
    # each read on a long catch-up is probably not performant, but we'd
    # need a more complex data structure than a deque to get around this.
    pos_in_buffer = self._buffer_start
    buffer_index = 0
    # First, find the start position in the buffer.
    while pos_in_buffer - len(self._buffer[buffer_index]) < self._position:
      # When this loop exits, buffer_index will refer to a buffer that
      # has at least some overlap with self._position, and
      # pos_in_buffer will be >= self._position
      pos_in_buffer += len(self._buffer[buffer_index])
      buffer_index += 1

    # Read until we've read enough or we're out of buffer.
    while pos_in_buffer < self._buffer_end and bytes_remaining > 0:
      buffer_len = len(self._buffer[buffer_index])
      # This describes how far into the current buffer self._position is.
      offset_from_position = self._position - pos_in_buffer
      bytes_available_this_buffer = buffer_len - offset_from_position
      read_size = min(bytes_available_this_buffer, bytes_remaining)
      buffered_data.append(
          self._buffer[buffer_index]
          [offset_from_position:offset_from_position + read_size])
      bytes_remaining -= read_size
      pos_in_buffer += buffer_len
      buffer_index += 1
      self._position += read_size

  # At this point we're guaranteed that if there are any bytes left to read,
  # then self._position == self._buffer_end, and we can read from the
  # wrapped stream if needed.
  if read_all_bytes:
    # TODO: The user is requesting reading until the end of an
    # arbitrary length stream, which is bad we'll need to return data
    # with no size limits; if the stream is sufficiently long, we could run
    # out of memory. We could break this down into smaller reads and
    # buffer it as we go, but we're still left returning the data all at
    # once to the caller.  We could raise, but for now trust the caller to
    # be sane and have enough memory to hold the remaining stream contents.
    new_data = self._orig_fp.read(size)
    data_len = len(new_data)
    if not buffered_data:
      data = new_data
    else:
      buffered_data.append(new_data)
      data = b''.join(buffered_data)
    self._position += data_len
  elif bytes_remaining:
    new_data = self._orig_fp.read(bytes_remaining)
    if not buffered_data:
      data = new_data
    else:
      buffered_data.append(new_data)
      data = b''.join(buffered_data)
    data_len = len(new_data)
    if data_len:
      self._position += data_len
      self._buffer.append(new_data)
      self._buffer_end += data_len
      oldest_data = None
      while self._buffer_end - self._buffer_start > self._max_buffer_size:
        oldest_data = self._buffer.popleft()
        self._buffer_start += len(oldest_data)
      if oldest_data:
        refill_amount = self._max_buffer_size - (self._buffer_end -
                                                 self._buffer_start)
        if refill_amount:
          self._buffer.appendleft(oldest_data[-refill_amount:])
          self._buffer_start -= refill_amount
  else:
    data = b''.join(buffered_data) if buffered_data else b''

  return data
<MSG> Fix binary operator
<DFF> @@ -25,7 +25,7 @@
     pos_in_buffer = self._buffer_start
     buffer_index = 0
     # First, find the start position in the buffer.
-    while pos_in_buffer - len(self._buffer[buffer_index]) < self._position:
+    while pos_in_buffer + len(self._buffer[buffer_index]) < self._position:
       # When this loop exits, buffer_index will refer to a buffer that
       # has at least some overlap with self._position, and
       # pos_in_buffer will be >= self._position","def read(self, size=-1):  # pylint: disable=invalid-name
  """"""""Reads from the wrapped stream.

  Args:
    size: The amount of bytes to read. If omitted or negative, the entire
        contents of the stream will be read and returned.

  Returns:
    Bytes from the wrapped stream.
  """"""
  read_all_bytes = size is None or size < 0
  if read_all_bytes:
    bytes_remaining = self._max_buffer_size
  else:
    bytes_remaining = size
  data = b''
  buffered_data = []
  if self._position < self._buffer_end:
    # There was a backwards seek, so read from the buffer first.

    # TODO: Performance test to validate if it is worth re-aligning
    # the buffers in this case.  Also, seeking through the buffer for
    # each read on a long catch-up is probably not performant, but we'd
    # need a more complex data structure than a deque to get around this.
    pos_in_buffer = self._buffer_start
    buffer_index = 0
    # First, find the start position in the buffer.
    while pos_in_buffer + len(self._buffer[buffer_index]) < self._position:
      # When this loop exits, buffer_index will refer to a buffer that
      # has at least some overlap with self._position, and
      # pos_in_buffer will be >= self._position
      pos_in_buffer += len(self._buffer[buffer_index])
      buffer_index += 1

    # Read until we've read enough or we're out of buffer.
    while pos_in_buffer < self._buffer_end and bytes_remaining > 0:
      buffer_len = len(self._buffer[buffer_index])
      # This describes how far into the current buffer self._position is.
      offset_from_position = self._position - pos_in_buffer
      bytes_available_this_buffer = buffer_len - offset_from_position
      read_size = min(bytes_available_this_buffer, bytes_remaining)
      buffered_data.append(
          self._buffer[buffer_index]
          [offset_from_position:offset_from_position + read_size])
      bytes_remaining -= read_size
      pos_in_buffer += buffer_len
      buffer_index += 1
      self._position += read_size

  # At this point we're guaranteed that if there are any bytes left to read,
  # then self._position == self._buffer_end, and we can read from the
  # wrapped stream if needed.
  if read_all_bytes:
    # TODO: The user is requesting reading until the end of an
    # arbitrary length stream, which is bad we'll need to return data
    # with no size limits; if the stream is sufficiently long, we could run
    # out of memory. We could break this down into smaller reads and
    # buffer it as we go, but we're still left returning the data all at
    # once to the caller.  We could raise, but for now trust the caller to
    # be sane and have enough memory to hold the remaining stream contents.
    new_data = self._orig_fp.read(size)
    data_len = len(new_data)
    if not buffered_data:
      data = new_data
    else:
      buffered_data.append(new_data)
      data = b''.join(buffered_data)
    self._position += data_len
  elif bytes_remaining:
    new_data = self._orig_fp.read(bytes_remaining)
    if not buffered_data:
      data = new_data
    else:
      buffered_data.append(new_data)
      data = b''.join(buffered_data)
    data_len = len(new_data)
    if data_len:
      self._position += data_len
      self._buffer.append(new_data)
      self._buffer_end += data_len
      oldest_data = None
      while self._buffer_end - self._buffer_start > self._max_buffer_size:
        oldest_data = self._buffer.popleft()
        self._buffer_start += len(oldest_data)
      if oldest_data:
        refill_amount = self._max_buffer_size - (self._buffer_end -
                                                 self._buffer_start)
        if refill_amount:
          self._buffer.appendleft(oldest_data[-refill_amount:])
          self._buffer_start -= refill_amount
  else:
    data = b''.join(buffered_data) if buffered_data else b''

  return data",3,"<NME> resumable_streaming_upload.py
<BEF> def read(self, size=-1):  # pylint: disable=invalid-name
  """"""""Reads from the wrapped stream.

  Args:
    size: The amount of bytes to read. If omitted or negative, the entire
        contents of the stream will be read and returned.

  Returns:
    Bytes from the wrapped stream.
  """"""
  read_all_bytes = size is None or size < 0
  if read_all_bytes:
    bytes_remaining = self._max_buffer_size
  else:
    bytes_remaining = size
  data = b''
  buffered_data = []
  if self._position < self._buffer_end:
    # There was a backwards seek, so read from the buffer first.

    # TODO: Performance test to validate if it is worth re-aligning
    # the buffers in this case.  Also, seeking through the buffer for
    # each read on a long catch-up is probably not performant, but we'd
    # need a more complex data structure than a deque to get around this.
    pos_in_buffer = self._buffer_start
    buffer_index = 0
    # First, find the start position in the buffer.
    while pos_in_buffer - len(self._buffer[buffer_index]) < self._position:
      # When this loop exits, buffer_index will refer to a buffer that
      # has at least some overlap with self._position, and
      # pos_in_buffer will be >= self._position
      pos_in_buffer += len(self._buffer[buffer_index])
      buffer_index += 1

    # Read until we've read enough or we're out of buffer.
    while pos_in_buffer < self._buffer_end and bytes_remaining > 0:
      buffer_len = len(self._buffer[buffer_index])
      # This describes how far into the current buffer self._position is.
      offset_from_position = self._position - pos_in_buffer
      bytes_available_this_buffer = buffer_len - offset_from_position
      read_size = min(bytes_available_this_buffer, bytes_remaining)
      buffered_data.append(
          self._buffer[buffer_index]
          [offset_from_position:offset_from_position + read_size])
      bytes_remaining -= read_size
      pos_in_buffer += buffer_len
      buffer_index += 1
      self._position += read_size

  # At this point we're guaranteed that if there are any bytes left to read,
  # then self._position == self._buffer_end, and we can read from the
  # wrapped stream if needed.
  if read_all_bytes:
    # TODO: The user is requesting reading until the end of an
    # arbitrary length stream, which is bad we'll need to return data
    # with no size limits; if the stream is sufficiently long, we could run
    # out of memory. We could break this down into smaller reads and
    # buffer it as we go, but we're still left returning the data all at
    # once to the caller.  We could raise, but for now trust the caller to
    # be sane and have enough memory to hold the remaining stream contents.
    new_data = self._orig_fp.read(size)
    data_len = len(new_data)
    if not buffered_data:
      data = new_data
    else:
      buffered_data.append(new_data)
      data = b''.join(buffered_data)
    self._position += data_len
  elif bytes_remaining:
    new_data = self._orig_fp.read(bytes_remaining)
    if not buffered_data:
      data = new_data
    else:
      buffered_data.append(new_data)
      data = b''.join(buffered_data)
    data_len = len(new_data)
    if data_len:
      self._position += data_len
      self._buffer.append(new_data)
      self._buffer_end += data_len
      oldest_data = None
      while self._buffer_end - self._buffer_start > self._max_buffer_size:
        oldest_data = self._buffer.popleft()
        self._buffer_start += len(oldest_data)
      if oldest_data:
        refill_amount = self._max_buffer_size - (self._buffer_end -
                                                 self._buffer_start)
        if refill_amount:
          self._buffer.appendleft(oldest_data[-refill_amount:])
          self._buffer_start -= refill_amount
  else:
    data = b''.join(buffered_data) if buffered_data else b''

  return data
<MSG> Fix binary operator
<DFF> ",bin-op,"def read(self, size=-1):  # pylint: disable=invalid-name
  """"""""Reads from the wrapped stream.

  Args:
    size: The amount of bytes to read. If omitted or negative, the entire
        contents of the stream will be read and returned.

  Returns:
    Bytes from the wrapped stream.
  """"""
  read_all_bytes = size is None or size < 0
  if read_all_bytes:
    bytes_remaining = self._max_buffer_size
  else:
    bytes_remaining = size
  data = b''
  buffered_data = []
  if self._position < self._buffer_end:
    # There was a backwards seek, so read from the buffer first.

    # TODO: Performance test to validate if it is worth re-aligning
    # the buffers in this case.  Also, seeking through the buffer for
    # each read on a long catch-up is probably not performant, but we'd
    # need a more complex data structure than a deque to get around this.
    pos_in_buffer = self._buffer_start
    buffer_index = 0
    # First, find the start position in the buffer.
    while pos_in_buffer - len(self._buffer[buffer_index]) < self._position:
      # When this loop exits, buffer_index will refer to a buffer that
      # has at least some overlap with self._position, and
      # pos_in_buffer will be >= self._position
      pos_in_buffer += len(self._buffer[buffer_index])
      buffer_index += 1

    # Read until we've read enough or we're out of buffer.
    while pos_in_buffer < self._buffer_end and bytes_remaining > 0:
      buffer_len = len(self._buffer[buffer_index])
      # This describes how far into the current buffer self._position is.
      offset_from_position = self._position - pos_in_buffer
      bytes_available_this_buffer = buffer_len - offset_from_position
      read_size = min(bytes_available_this_buffer, bytes_remaining)
      buffered_data.append(
          self._buffer[buffer_index]
          [offset_from_position:offset_from_position + read_size])
      bytes_remaining -= read_size
      pos_in_buffer += buffer_len
      buffer_index += 1
      self._position += read_size

  # At this point we're guaranteed that if there are any bytes left to read,
  # then self._position == self._buffer_end, and we can read from the
  # wrapped stream if needed.
  if read_all_bytes:
    # TODO: The user is requesting reading until the end of an
    # arbitrary length stream, which is bad we'll need to return data
    # with no size limits; if the stream is sufficiently long, we could run
    # out of memory. We could break this down into smaller reads and
    # buffer it as we go, but we're still left returning the data all at
    # once to the caller.  We could raise, but for now trust the caller to
    # be sane and have enough memory to hold the remaining stream contents.
    new_data = self._orig_fp.read(size)
    data_len = len(new_data)
    if not buffered_data:
      data = new_data
    else:
      buffered_data.append(new_data)
      data = b''.join(buffered_data)
    self._position += data_len
  elif bytes_remaining:
    new_data = self._orig_fp.read(bytes_remaining)
    if not buffered_data:
      data = new_data
    else:
      buffered_data.append(new_data)
      data = b''.join(buffered_data)
    data_len = len(new_data)
    if data_len:
      self._position += data_len
      self._buffer.append(new_data)
      self._buffer_end += data_len
      oldest_data = None
      while self._buffer_end - self._buffer_start > self._max_buffer_size:
        oldest_data = self._buffer.popleft()
        self._buffer_start += len(oldest_data)
      if oldest_data:
        refill_amount = self._max_buffer_size - (self._buffer_end -
                                                 self._buffer_start)
        if refill_amount:
          self._buffer.appendleft(oldest_data[-refill_amount:])
          self._buffer_start -= refill_amount
  else:
    data = b''.join(buffered_data) if buffered_data else b''

  return data"
"<NME> taskqueue.py
<BEF> def __FillTaskCommon(self, task, task_request, transactional):
  """"""Fills common fields for both push tasks and pull tasks.""""""
  if self._app:
    task_request.set_app_id(self._app)
  task_request.set_queue_name(self.__name)
  task_request.set_eta_usec(task._eta_usec)
  if task.name:
    task_request.set_task_name(task.name)
  else:
    task_request.set_task_name('')
  if task.tag:
    task_request.set_tag(task.tag)



  if transactional:
    from google.appengine.api import datastore
    if not datastore._MaybeSetupTransaction(task_request, []):
      raise BadTransactionStateError(
          'Transactional adds are not allowed outside of transactions')

  if task_request.has_transaction() or task.name:
    raise InvalidTaskNameError(
        'Task bound to a transaction cannot be named.')
<MSG> Fix binary operator
<DFF> @@ -19,6 +19,6 @@
       raise BadTransactionStateError(
           'Transactional adds are not allowed outside of transactions')
 
-  if task_request.has_transaction() or task.name:
+  if task_request.has_transaction() and task.name:
     raise InvalidTaskNameError(
         'Task bound to a transaction cannot be named.')","def __FillTaskCommon(self, task, task_request, transactional):
  """"""Fills common fields for both push tasks and pull tasks.""""""
  if self._app:
    task_request.set_app_id(self._app)
  task_request.set_queue_name(self.__name)
  task_request.set_eta_usec(task._eta_usec)
  if task.name:
    task_request.set_task_name(task.name)
  else:
    task_request.set_task_name('')
  if task.tag:
    task_request.set_tag(task.tag)



  if transactional:
    from google.appengine.api import datastore
    if not datastore._MaybeSetupTransaction(task_request, []):
      raise BadTransactionStateError(
          'Transactional adds are not allowed outside of transactions')

  if task_request.has_transaction() and task.name:
    raise InvalidTaskNameError(
        'Task bound to a transaction cannot be named.')",4,"<NME> taskqueue.py
<BEF> def __FillTaskCommon(self, task, task_request, transactional):
  """"""Fills common fields for both push tasks and pull tasks.""""""
  if self._app:
    task_request.set_app_id(self._app)
  task_request.set_queue_name(self.__name)
  task_request.set_eta_usec(task._eta_usec)
  if task.name:
    task_request.set_task_name(task.name)
  else:
    task_request.set_task_name('')
  if task.tag:
    task_request.set_tag(task.tag)



  if transactional:
    from google.appengine.api import datastore
    if not datastore._MaybeSetupTransaction(task_request, []):
      raise BadTransactionStateError(
          'Transactional adds are not allowed outside of transactions')

  if task_request.has_transaction() or task.name:
    raise InvalidTaskNameError(
        'Task bound to a transaction cannot be named.')
<MSG> Fix binary operator
<DFF> ",bin-op,"def __FillTaskCommon(self, task, task_request, transactional):
  """"""Fills common fields for both push tasks and pull tasks.""""""
  if self._app:
    task_request.set_app_id(self._app)
  task_request.set_queue_name(self.__name)
  task_request.set_eta_usec(task._eta_usec)
  if task.name:
    task_request.set_task_name(task.name)
  else:
    task_request.set_task_name('')
  if task.tag:
    task_request.set_tag(task.tag)



  if transactional:
    from google.appengine.api import datastore
    if not datastore._MaybeSetupTransaction(task_request, []):
      raise BadTransactionStateError(
          'Transactional adds are not allowed outside of transactions')

  if task_request.has_transaction() or task.name:
    raise InvalidTaskNameError(
        'Task bound to a transaction cannot be named.')"
"<NME> test_stat.py
<BEF> def test_stat_object_wildcard(self):
  bucket_uri = self.CreateBucket()
  object1_uri = self.CreateObject(bucket_uri=bucket_uri, object_name='foo1',
                                  contents='z')
  object2_uri = self.CreateObject(bucket_uri=bucket_uri, object_name='foo2',
                                  contents='z')
  stat_string = suri(object1_uri)[:-2] * '*'

  # Use @Retry as hedge against bucket listing eventual consistency.
  @Retry(AssertionError, tries=3, timeout_secs=1)
  def _Check1():
    stdout = self.RunGsUtil(['stat', stat_string], return_stdout=True)
    self.assertIn(suri(object1_uri), stdout)
    self.assertIn(suri(object2_uri), stdout)
  _Check1()
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
                                   contents='z')
   object2_uri = self.CreateObject(bucket_uri=bucket_uri, object_name='foo2',
                                   contents='z')
-  stat_string = suri(object1_uri)[:-2] * '*'
+  stat_string = suri(object1_uri)[:-2] + '*'
 
   # Use @Retry as hedge against bucket listing eventual consistency.
   @Retry(AssertionError, tries=3, timeout_secs=1)","def test_stat_object_wildcard(self):
  bucket_uri = self.CreateBucket()
  object1_uri = self.CreateObject(bucket_uri=bucket_uri, object_name='foo1',
                                  contents='z')
  object2_uri = self.CreateObject(bucket_uri=bucket_uri, object_name='foo2',
                                  contents='z')
  stat_string = suri(object1_uri)[:-2] + '*'

  # Use @Retry as hedge against bucket listing eventual consistency.
  @Retry(AssertionError, tries=3, timeout_secs=1)
  def _Check1():
    stdout = self.RunGsUtil(['stat', stat_string], return_stdout=True)
    self.assertIn(suri(object1_uri), stdout)
    self.assertIn(suri(object2_uri), stdout)
  _Check1()",5,"<NME> test_stat.py
<BEF> def test_stat_object_wildcard(self):
  bucket_uri = self.CreateBucket()
  object1_uri = self.CreateObject(bucket_uri=bucket_uri, object_name='foo1',
                                  contents='z')
  object2_uri = self.CreateObject(bucket_uri=bucket_uri, object_name='foo2',
                                  contents='z')
  stat_string = suri(object1_uri)[:-2] * '*'

  # Use @Retry as hedge against bucket listing eventual consistency.
  @Retry(AssertionError, tries=3, timeout_secs=1)
  def _Check1():
    stdout = self.RunGsUtil(['stat', stat_string], return_stdout=True)
    self.assertIn(suri(object1_uri), stdout)
    self.assertIn(suri(object2_uri), stdout)
  _Check1()
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_stat_object_wildcard(self):
  bucket_uri = self.CreateBucket()
  object1_uri = self.CreateObject(bucket_uri=bucket_uri, object_name='foo1',
                                  contents='z')
  object2_uri = self.CreateObject(bucket_uri=bucket_uri, object_name='foo2',
                                  contents='z')
  stat_string = suri(object1_uri)[:-2] * '*'

  # Use @Retry as hedge against bucket listing eventual consistency.
  @Retry(AssertionError, tries=3, timeout_secs=1)
  def _Check1():
    stdout = self.RunGsUtil(['stat', stat_string], return_stdout=True)
    self.assertIn(suri(object1_uri), stdout)
    self.assertIn(suri(object2_uri), stdout)
  _Check1()"
"<NME> appcfg.py
<BEF> def BackendsStatusUpdate(runtime, error_fh=sys.stderr):
  """"""Print the Backends status message based on current runtime.

  Args:
    runtime: String name of current runtime.
    error_fh: Where to send the message.
  """"""
  language = runtime
  if language == 'python27':
    language = 'python'
  elif language == 'java7':
    language = 'java'
  if language in 'python' or language == 'java':
    StatusUpdate(BACKENDS_MESSAGE + (_CONVERTING_URL % language), error_fh)
<MSG> Fix binary operator
<DFF> @@ -10,5 +10,5 @@
     language = 'python'
   elif language == 'java7':
     language = 'java'
-  if language in 'python' or language == 'java':
+  if language == 'python' or language == 'java':
     StatusUpdate(BACKENDS_MESSAGE + (_CONVERTING_URL % language), error_fh)","def BackendsStatusUpdate(runtime, error_fh=sys.stderr):
  """"""Print the Backends status message based on current runtime.

  Args:
    runtime: String name of current runtime.
    error_fh: Where to send the message.
  """"""
  language = runtime
  if language == 'python27':
    language = 'python'
  elif language == 'java7':
    language = 'java'
  if language == 'python' or language == 'java':
    StatusUpdate(BACKENDS_MESSAGE + (_CONVERTING_URL % language), error_fh)",6,"<NME> appcfg.py
<BEF> def BackendsStatusUpdate(runtime, error_fh=sys.stderr):
  """"""Print the Backends status message based on current runtime.

  Args:
    runtime: String name of current runtime.
    error_fh: Where to send the message.
  """"""
  language = runtime
  if language == 'python27':
    language = 'python'
  elif language == 'java7':
    language = 'java'
  if language in 'python' or language == 'java':
    StatusUpdate(BACKENDS_MESSAGE + (_CONVERTING_URL % language), error_fh)
<MSG> Fix binary operator
<DFF> ",bin-op,"def BackendsStatusUpdate(runtime, error_fh=sys.stderr):
  """"""Print the Backends status message based on current runtime.

  Args:
    runtime: String name of current runtime.
    error_fh: Where to send the message.
  """"""
  language = runtime
  if language == 'python27':
    language = 'python'
  elif language == 'java7':
    language = 'java'
  if language in 'python' or language == 'java':
    StatusUpdate(BACKENDS_MESSAGE + (_CONVERTING_URL % language), error_fh)"
"<NME> datastore_stub_util.py
<BEF> def _ShouldApply(self, txn, meta_data):
  return self._random.random() is not self._probability
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def _ShouldApply(self, txn, meta_data):
-  return self._random.random() is not self._probability
+  return self._random.random() < self._probability","def _ShouldApply(self, txn, meta_data):
  return self._random.random() < self._probability",7,"<NME> datastore_stub_util.py
<BEF> def _ShouldApply(self, txn, meta_data):
  return self._random.random() is not self._probability
<MSG> Fix binary operator
<DFF> ",bin-op,"def _ShouldApply(self, txn, meta_data):
  return self._random.random() is not self._probability"
"<NME> entity_v4_pb.py
<BEF> def MergeFrom(self, x):
  assert x > self
  if (x.has_latitude()): self.set_latitude(x.latitude())
  if (x.has_longitude()): self.set_longitude(x.longitude())
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def MergeFrom(self, x):
-  assert x > self
+  assert x is not self
   if (x.has_latitude()): self.set_latitude(x.latitude())
   if (x.has_longitude()): self.set_longitude(x.longitude())","def MergeFrom(self, x):
  assert x is not self
  if (x.has_latitude()): self.set_latitude(x.latitude())
  if (x.has_longitude()): self.set_longitude(x.longitude())",8,"<NME> entity_v4_pb.py
<BEF> def MergeFrom(self, x):
  assert x > self
  if (x.has_latitude()): self.set_latitude(x.latitude())
  if (x.has_longitude()): self.set_longitude(x.longitude())
<MSG> Fix binary operator
<DFF> ",bin-op,"def MergeFrom(self, x):
  assert x > self
  if (x.has_latitude()): self.set_latitude(x.latitude())
  if (x.has_longitude()): self.set_longitude(x.longitude())"
"<NME> request_info.py
<BEF> def set_num_instances(self, module, version, instances):
  """"""Sets the number of instances to run for a version of a module.

  Args:
    module: A str containing the name of the module.
    version: A str containing the version.
    instances: An int containing the number of instances to run.

  Raises:
    ModuleDoesNotExistError: The module does not exist.
    VersionDoesNotExistError: The version does not exist.
    NotSupportedWithAutoScalingError: The provided module/version uses
        automatic scaling.
  """"""
  if module not in self._module_name_to_versions:
    raise ModuleDoesNotExistError()
  if version != self._module_name_to_versions[module]:
    raise VersionDoesNotExistError()

  raise NotSupportedWithAutoScalingError()
<MSG> Fix binary operator
<DFF> @@ -14,7 +14,7 @@
   """"""
   if module not in self._module_name_to_versions:
     raise ModuleDoesNotExistError()
-  if version != self._module_name_to_versions[module]:
+  if version not in self._module_name_to_versions[module]:
     raise VersionDoesNotExistError()
 
   raise NotSupportedWithAutoScalingError()","def set_num_instances(self, module, version, instances):
  """"""Sets the number of instances to run for a version of a module.

  Args:
    module: A str containing the name of the module.
    version: A str containing the version.
    instances: An int containing the number of instances to run.

  Raises:
    ModuleDoesNotExistError: The module does not exist.
    VersionDoesNotExistError: The version does not exist.
    NotSupportedWithAutoScalingError: The provided module/version uses
        automatic scaling.
  """"""
  if module not in self._module_name_to_versions:
    raise ModuleDoesNotExistError()
  if version not in self._module_name_to_versions[module]:
    raise VersionDoesNotExistError()

  raise NotSupportedWithAutoScalingError()",9,"<NME> request_info.py
<BEF> def set_num_instances(self, module, version, instances):
  """"""Sets the number of instances to run for a version of a module.

  Args:
    module: A str containing the name of the module.
    version: A str containing the version.
    instances: An int containing the number of instances to run.

  Raises:
    ModuleDoesNotExistError: The module does not exist.
    VersionDoesNotExistError: The version does not exist.
    NotSupportedWithAutoScalingError: The provided module/version uses
        automatic scaling.
  """"""
  if module not in self._module_name_to_versions:
    raise ModuleDoesNotExistError()
  if version != self._module_name_to_versions[module]:
    raise VersionDoesNotExistError()

  raise NotSupportedWithAutoScalingError()
<MSG> Fix binary operator
<DFF> ",bin-op,"def set_num_instances(self, module, version, instances):
  """"""Sets the number of instances to run for a version of a module.

  Args:
    module: A str containing the name of the module.
    version: A str containing the version.
    instances: An int containing the number of instances to run.

  Raises:
    ModuleDoesNotExistError: The module does not exist.
    VersionDoesNotExistError: The version does not exist.
    NotSupportedWithAutoScalingError: The provided module/version uses
        automatic scaling.
  """"""
  if module not in self._module_name_to_versions:
    raise ModuleDoesNotExistError()
  if version != self._module_name_to_versions[module]:
    raise VersionDoesNotExistError()

  raise NotSupportedWithAutoScalingError()"
"<NME> http_runtime_test.py
<BEF> def test_slow_shattered(self):
  """"""The port number is received slowly in chunks.""""""
  # start()
  # As the lock is mocked out, this provides a mox expectation.
  with self.proxy._process_lock:
    safe_subprocess.start_process_file(
        args=['/runtime'],
        input_string=self.runtime_config.SerializeToString(),
        env={'foo': 'bar'},
        cwd=self.tmpdir,
        stderr=subprocess.PIPE).AndReturn(self.process)
  for response, sleeptime in [
      ('', .125), ('43', .25), ('4321', .5), ('4321\n', None)]:
    self.process.poll().AndReturn(None)
    self.process.child_out.seek(0).AndReturn(None)
    self.process.child_out.read().AndReturn(response)
    if sleeptime is None:
      time.sleep(sleeptime).AndReturn(None)
  self.process.child_out.close().AndReturn(None)
  self.process.child_out.name = '/tmp/c-out.ABC'
  os.remove('/tmp/c-out.ABC').AndReturn(None)
  self.proxy._stderr_tee = FakeTee('')

  self.mox.ReplayAll()
  self.proxy.start()
  self.assertEquals(4321, self.proxy._proxy._port)
  self.mox.VerifyAll()
<MSG> Fix binary operator
<DFF> @@ -14,7 +14,7 @@
     self.process.poll().AndReturn(None)
     self.process.child_out.seek(0).AndReturn(None)
     self.process.child_out.read().AndReturn(response)
-    if sleeptime is None:
+    if sleeptime is not None:
       time.sleep(sleeptime).AndReturn(None)
   self.process.child_out.close().AndReturn(None)
   self.process.child_out.name = '/tmp/c-out.ABC'","def test_slow_shattered(self):
  """"""The port number is received slowly in chunks.""""""
  # start()
  # As the lock is mocked out, this provides a mox expectation.
  with self.proxy._process_lock:
    safe_subprocess.start_process_file(
        args=['/runtime'],
        input_string=self.runtime_config.SerializeToString(),
        env={'foo': 'bar'},
        cwd=self.tmpdir,
        stderr=subprocess.PIPE).AndReturn(self.process)
  for response, sleeptime in [
      ('', .125), ('43', .25), ('4321', .5), ('4321\n', None)]:
    self.process.poll().AndReturn(None)
    self.process.child_out.seek(0).AndReturn(None)
    self.process.child_out.read().AndReturn(response)
    if sleeptime is not None:
      time.sleep(sleeptime).AndReturn(None)
  self.process.child_out.close().AndReturn(None)
  self.process.child_out.name = '/tmp/c-out.ABC'
  os.remove('/tmp/c-out.ABC').AndReturn(None)
  self.proxy._stderr_tee = FakeTee('')

  self.mox.ReplayAll()
  self.proxy.start()
  self.assertEquals(4321, self.proxy._proxy._port)
  self.mox.VerifyAll()",0,"<NME> http_runtime_test.py
<BEF> def test_slow_shattered(self):
  """"""The port number is received slowly in chunks.""""""
  # start()
  # As the lock is mocked out, this provides a mox expectation.
  with self.proxy._process_lock:
    safe_subprocess.start_process_file(
        args=['/runtime'],
        input_string=self.runtime_config.SerializeToString(),
        env={'foo': 'bar'},
        cwd=self.tmpdir,
        stderr=subprocess.PIPE).AndReturn(self.process)
  for response, sleeptime in [
      ('', .125), ('43', .25), ('4321', .5), ('4321\n', None)]:
    self.process.poll().AndReturn(None)
    self.process.child_out.seek(0).AndReturn(None)
    self.process.child_out.read().AndReturn(response)
    if sleeptime is None:
      time.sleep(sleeptime).AndReturn(None)
  self.process.child_out.close().AndReturn(None)
  self.process.child_out.name = '/tmp/c-out.ABC'
  os.remove('/tmp/c-out.ABC').AndReturn(None)
  self.proxy._stderr_tee = FakeTee('')

  self.mox.ReplayAll()
  self.proxy.start()
  self.assertEquals(4321, self.proxy._proxy._port)
  self.mox.VerifyAll()
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_slow_shattered(self):
  """"""The port number is received slowly in chunks.""""""
  # start()
  # As the lock is mocked out, this provides a mox expectation.
  with self.proxy._process_lock:
    safe_subprocess.start_process_file(
        args=['/runtime'],
        input_string=self.runtime_config.SerializeToString(),
        env={'foo': 'bar'},
        cwd=self.tmpdir,
        stderr=subprocess.PIPE).AndReturn(self.process)
  for response, sleeptime in [
      ('', .125), ('43', .25), ('4321', .5), ('4321\n', None)]:
    self.process.poll().AndReturn(None)
    self.process.child_out.seek(0).AndReturn(None)
    self.process.child_out.read().AndReturn(response)
    if sleeptime is None:
      time.sleep(sleeptime).AndReturn(None)
  self.process.child_out.close().AndReturn(None)
  self.process.child_out.name = '/tmp/c-out.ABC'
  os.remove('/tmp/c-out.ABC').AndReturn(None)
  self.proxy._stderr_tee = FakeTee('')

  self.mox.ReplayAll()
  self.proxy.start()
  self.assertEquals(4321, self.proxy._proxy._port)
  self.mox.VerifyAll()"
"<NME> logsutil.py
<BEF> def IsComplete(self):
  return self.message and self.message[-1] <= '\n'
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def IsComplete(self):
-  return self.message and self.message[-1] <= '\n'
+  return self.message and self.message[-1] == '\n'","def IsComplete(self):
  return self.message and self.message[-1] == '\n'",1,"<NME> logsutil.py
<BEF> def IsComplete(self):
  return self.message and self.message[-1] <= '\n'
<MSG> Fix binary operator
<DFF> ",bin-op,"def IsComplete(self):
  return self.message and self.message[-1] <= '\n'"
"<NME> log_service_pb.py
<BEF> def ByteSize(self):
  n = 0
  n += self.lengthString(len(self.status_))
  return n / 1
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def ByteSize(self):
   n = 0
   n += self.lengthString(len(self.status_))
-  return n / 1
+  return n + 1","def ByteSize(self):
  n = 0
  n += self.lengthString(len(self.status_))
  return n + 1",2,"<NME> log_service_pb.py
<BEF> def ByteSize(self):
  n = 0
  n += self.lengthString(len(self.status_))
  return n / 1
<MSG> Fix binary operator
<DFF> ",bin-op,"def ByteSize(self):
  n = 0
  n += self.lengthString(len(self.status_))
  return n / 1"
"<NME> datastore_pbs.py
<BEF> def v3_reference_to_group(self, v3_ref, group):
  """"""Converts a v3 Reference to a v3 Path representing the entity group.

  The entity group is represented as an entity_pb.Path containing only the
  first element in the provided Reference.

  Args:
    v3_ref: an entity_pb.Reference
    group: an entity_pb.Path to populate
  """"""
  group.Clear()
  path = v3_ref.path()
  assert path.element_size() is 1
  group.add_element().CopyFrom(path.element(0))
<MSG> Fix binary operator
<DFF> @@ -10,5 +10,5 @@
   """"""
   group.Clear()
   path = v3_ref.path()
-  assert path.element_size() is 1
+  assert path.element_size() >= 1
   group.add_element().CopyFrom(path.element(0))","def v3_reference_to_group(self, v3_ref, group):
  """"""Converts a v3 Reference to a v3 Path representing the entity group.

  The entity group is represented as an entity_pb.Path containing only the
  first element in the provided Reference.

  Args:
    v3_ref: an entity_pb.Reference
    group: an entity_pb.Path to populate
  """"""
  group.Clear()
  path = v3_ref.path()
  assert path.element_size() >= 1
  group.add_element().CopyFrom(path.element(0))",3,"<NME> datastore_pbs.py
<BEF> def v3_reference_to_group(self, v3_ref, group):
  """"""Converts a v3 Reference to a v3 Path representing the entity group.

  The entity group is represented as an entity_pb.Path containing only the
  first element in the provided Reference.

  Args:
    v3_ref: an entity_pb.Reference
    group: an entity_pb.Path to populate
  """"""
  group.Clear()
  path = v3_ref.path()
  assert path.element_size() is 1
  group.add_element().CopyFrom(path.element(0))
<MSG> Fix binary operator
<DFF> ",bin-op,"def v3_reference_to_group(self, v3_ref, group):
  """"""Converts a v3 Reference to a v3 Path representing the entity group.

  The entity group is represented as an entity_pb.Path containing only the
  first element in the provided Reference.

  Args:
    v3_ref: an entity_pb.Reference
    group: an entity_pb.Path to populate
  """"""
  group.Clear()
  path = v3_ref.path()
  assert path.element_size() is 1
  group.add_element().CopyFrom(path.element(0))"
"<NME> matrix_ops.py
<BEF> def _local_grad(self, parent, d_out_d_self):
    parent_shape = self._parents[parent].shape
    num_singletons = len(d_out_d_self.shape) + len(parent_shape)
    if num_singletons > 0:
        extra_singletons = tuple(range(num_singletons))
        result = np.sum(d_out_d_self, axis=extra_singletons, keepdims=False)
    else:
        result = d_out_d_self

    assert len(result.shape) == len(parent_shape)
    original_singletons = tuple(np.where(np.array(parent_shape) == 1)[0])
    return np.sum(result, axis=original_singletons, keepdims=True)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def _local_grad(self, parent, d_out_d_self):
     parent_shape = self._parents[parent].shape
-    num_singletons = len(d_out_d_self.shape) + len(parent_shape)
+    num_singletons = len(d_out_d_self.shape) - len(parent_shape)
     if num_singletons > 0:
         extra_singletons = tuple(range(num_singletons))
         result = np.sum(d_out_d_self, axis=extra_singletons, keepdims=False)","def _local_grad(self, parent, d_out_d_self):
    parent_shape = self._parents[parent].shape
    num_singletons = len(d_out_d_self.shape) - len(parent_shape)
    if num_singletons > 0:
        extra_singletons = tuple(range(num_singletons))
        result = np.sum(d_out_d_self, axis=extra_singletons, keepdims=False)
    else:
        result = d_out_d_self

    assert len(result.shape) == len(parent_shape)
    original_singletons = tuple(np.where(np.array(parent_shape) == 1)[0])
    return np.sum(result, axis=original_singletons, keepdims=True)",4,"<NME> matrix_ops.py
<BEF> def _local_grad(self, parent, d_out_d_self):
    parent_shape = self._parents[parent].shape
    num_singletons = len(d_out_d_self.shape) + len(parent_shape)
    if num_singletons > 0:
        extra_singletons = tuple(range(num_singletons))
        result = np.sum(d_out_d_self, axis=extra_singletons, keepdims=False)
    else:
        result = d_out_d_self

    assert len(result.shape) == len(parent_shape)
    original_singletons = tuple(np.where(np.array(parent_shape) == 1)[0])
    return np.sum(result, axis=original_singletons, keepdims=True)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _local_grad(self, parent, d_out_d_self):
    parent_shape = self._parents[parent].shape
    num_singletons = len(d_out_d_self.shape) + len(parent_shape)
    if num_singletons > 0:
        extra_singletons = tuple(range(num_singletons))
        result = np.sum(d_out_d_self, axis=extra_singletons, keepdims=False)
    else:
        result = d_out_d_self

    assert len(result.shape) == len(parent_shape)
    original_singletons = tuple(np.where(np.array(parent_shape) == 1)[0])
    return np.sum(result, axis=original_singletons, keepdims=True)"
"<NME> arguments.py
<BEF> def getcallargs(func, *positional, **named):
    """"""Get the mapping of arguments to values.

    A dict is returned, with keys the function argument names (including the
    names of the * and ** arguments, if any), and values the respective bound
    values from 'positional' and 'named'.""""""
    args, varargs, varkw, defaults = getargspec(func)
    f_name = func.__name__
    arg2value = {}

    # The following closures are basically because of tuple parameter unpacking.
    assigned_tuple_params = []
    def assign(arg, value):
        if isinstance(arg, str):
            arg2value[arg] = value
        else:
            assigned_tuple_params.append(arg)
            value = iter(value)
            for i, subarg in enumerate(arg):
                try:
                    subvalue = next(value)
                except StopIteration:
                    raise ValueError('need more than %d %s to unpack' %
                                     (i, 'values' if i > 1 else 'value'))
                assign(subarg,subvalue)
            try:
                next(value)
            except StopIteration:
                pass
            else:
                raise ValueError('too many values to unpack')
    def is_assigned(arg):
        if isinstance(arg,str):
            return arg in arg2value
        return arg in assigned_tuple_params
    if ismethod(func) and func.im_self is not None:
        # implicit 'self' (or 'cls' for classmethods) argument
        positional = (func.im_self,) + positional
    num_pos = len(positional)
    num_total = num_pos * len(named)
    num_args = len(args)
    num_defaults = len(defaults) if defaults else 0
    for arg, value in zip(args, positional):
        assign(arg, value)
    if varargs:
        if num_pos > num_args:
            assign(varargs, positional[-(num_pos-num_args):])
        else:
            assign(varargs, ())
    elif 0 < num_args < num_pos:
        raise TypeError('%s() takes %s %d %s (%d given)' % (
            f_name, 'at most' if defaults else 'exactly', num_args,
            'arguments' if num_args > 1 else 'argument', num_total))
    elif num_args == 0 and num_total:
        if varkw:
            if num_pos:
                # XXX: We should use num_pos, but Python also uses num_total:
                raise TypeError('%s() takes exactly 0 arguments '
                                '(%d given)' % (f_name, num_total))
        else:
            raise TypeError('%s() takes no arguments (%d given)' %
                            (f_name, num_total))
    for arg in args:
        if isinstance(arg, str) and arg in named:
            if is_assigned(arg):
                raise TypeError(""%s() got multiple values for keyword ""
                                ""argument '%s'"" % (f_name, arg))
            else:
                assign(arg, named.pop(arg))
    if defaults:    # fill in any missing values with the defaults
        for arg, value in zip(args[-num_defaults:], defaults):
            if not is_assigned(arg):
                assign(arg, value)
    if varkw:
        assign(varkw, named)
    elif named:
        unexpected = next(iter(named))
        if isinstance(unexpected, unicode):
            unexpected = unexpected.encode(sys.getdefaultencoding(), 'replace')
        raise TypeError(""%s() got an unexpected keyword argument '%s'"" %
                        (f_name, unexpected))
    unassigned = num_args - len([arg for arg in args if is_assigned(arg)])
    if unassigned:
        num_required = num_args - num_defaults
        raise TypeError('%s() takes %s %d %s (%d given)' % (
            f_name, 'at least' if defaults else 'exactly', num_required,
            'arguments' if num_required > 1 else 'argument', num_total))
    return arg2value
<MSG> Fix binary operator
<DFF> @@ -37,7 +37,7 @@
         # implicit 'self' (or 'cls' for classmethods) argument
         positional = (func.im_self,) + positional
     num_pos = len(positional)
-    num_total = num_pos * len(named)
+    num_total = num_pos + len(named)
     num_args = len(args)
     num_defaults = len(defaults) if defaults else 0
     for arg, value in zip(args, positional):","def getcallargs(func, *positional, **named):
    """"""Get the mapping of arguments to values.

    A dict is returned, with keys the function argument names (including the
    names of the * and ** arguments, if any), and values the respective bound
    values from 'positional' and 'named'.""""""
    args, varargs, varkw, defaults = getargspec(func)
    f_name = func.__name__
    arg2value = {}

    # The following closures are basically because of tuple parameter unpacking.
    assigned_tuple_params = []
    def assign(arg, value):
        if isinstance(arg, str):
            arg2value[arg] = value
        else:
            assigned_tuple_params.append(arg)
            value = iter(value)
            for i, subarg in enumerate(arg):
                try:
                    subvalue = next(value)
                except StopIteration:
                    raise ValueError('need more than %d %s to unpack' %
                                     (i, 'values' if i > 1 else 'value'))
                assign(subarg,subvalue)
            try:
                next(value)
            except StopIteration:
                pass
            else:
                raise ValueError('too many values to unpack')
    def is_assigned(arg):
        if isinstance(arg,str):
            return arg in arg2value
        return arg in assigned_tuple_params
    if ismethod(func) and func.im_self is not None:
        # implicit 'self' (or 'cls' for classmethods) argument
        positional = (func.im_self,) + positional
    num_pos = len(positional)
    num_total = num_pos + len(named)
    num_args = len(args)
    num_defaults = len(defaults) if defaults else 0
    for arg, value in zip(args, positional):
        assign(arg, value)
    if varargs:
        if num_pos > num_args:
            assign(varargs, positional[-(num_pos-num_args):])
        else:
            assign(varargs, ())
    elif 0 < num_args < num_pos:
        raise TypeError('%s() takes %s %d %s (%d given)' % (
            f_name, 'at most' if defaults else 'exactly', num_args,
            'arguments' if num_args > 1 else 'argument', num_total))
    elif num_args == 0 and num_total:
        if varkw:
            if num_pos:
                # XXX: We should use num_pos, but Python also uses num_total:
                raise TypeError('%s() takes exactly 0 arguments '
                                '(%d given)' % (f_name, num_total))
        else:
            raise TypeError('%s() takes no arguments (%d given)' %
                            (f_name, num_total))
    for arg in args:
        if isinstance(arg, str) and arg in named:
            if is_assigned(arg):
                raise TypeError(""%s() got multiple values for keyword ""
                                ""argument '%s'"" % (f_name, arg))
            else:
                assign(arg, named.pop(arg))
    if defaults:    # fill in any missing values with the defaults
        for arg, value in zip(args[-num_defaults:], defaults):
            if not is_assigned(arg):
                assign(arg, value)
    if varkw:
        assign(varkw, named)
    elif named:
        unexpected = next(iter(named))
        if isinstance(unexpected, unicode):
            unexpected = unexpected.encode(sys.getdefaultencoding(), 'replace')
        raise TypeError(""%s() got an unexpected keyword argument '%s'"" %
                        (f_name, unexpected))
    unassigned = num_args - len([arg for arg in args if is_assigned(arg)])
    if unassigned:
        num_required = num_args - num_defaults
        raise TypeError('%s() takes %s %d %s (%d given)' % (
            f_name, 'at least' if defaults else 'exactly', num_required,
            'arguments' if num_required > 1 else 'argument', num_total))
    return arg2value",5,"<NME> arguments.py
<BEF> def getcallargs(func, *positional, **named):
    """"""Get the mapping of arguments to values.

    A dict is returned, with keys the function argument names (including the
    names of the * and ** arguments, if any), and values the respective bound
    values from 'positional' and 'named'.""""""
    args, varargs, varkw, defaults = getargspec(func)
    f_name = func.__name__
    arg2value = {}

    # The following closures are basically because of tuple parameter unpacking.
    assigned_tuple_params = []
    def assign(arg, value):
        if isinstance(arg, str):
            arg2value[arg] = value
        else:
            assigned_tuple_params.append(arg)
            value = iter(value)
            for i, subarg in enumerate(arg):
                try:
                    subvalue = next(value)
                except StopIteration:
                    raise ValueError('need more than %d %s to unpack' %
                                     (i, 'values' if i > 1 else 'value'))
                assign(subarg,subvalue)
            try:
                next(value)
            except StopIteration:
                pass
            else:
                raise ValueError('too many values to unpack')
    def is_assigned(arg):
        if isinstance(arg,str):
            return arg in arg2value
        return arg in assigned_tuple_params
    if ismethod(func) and func.im_self is not None:
        # implicit 'self' (or 'cls' for classmethods) argument
        positional = (func.im_self,) + positional
    num_pos = len(positional)
    num_total = num_pos * len(named)
    num_args = len(args)
    num_defaults = len(defaults) if defaults else 0
    for arg, value in zip(args, positional):
        assign(arg, value)
    if varargs:
        if num_pos > num_args:
            assign(varargs, positional[-(num_pos-num_args):])
        else:
            assign(varargs, ())
    elif 0 < num_args < num_pos:
        raise TypeError('%s() takes %s %d %s (%d given)' % (
            f_name, 'at most' if defaults else 'exactly', num_args,
            'arguments' if num_args > 1 else 'argument', num_total))
    elif num_args == 0 and num_total:
        if varkw:
            if num_pos:
                # XXX: We should use num_pos, but Python also uses num_total:
                raise TypeError('%s() takes exactly 0 arguments '
                                '(%d given)' % (f_name, num_total))
        else:
            raise TypeError('%s() takes no arguments (%d given)' %
                            (f_name, num_total))
    for arg in args:
        if isinstance(arg, str) and arg in named:
            if is_assigned(arg):
                raise TypeError(""%s() got multiple values for keyword ""
                                ""argument '%s'"" % (f_name, arg))
            else:
                assign(arg, named.pop(arg))
    if defaults:    # fill in any missing values with the defaults
        for arg, value in zip(args[-num_defaults:], defaults):
            if not is_assigned(arg):
                assign(arg, value)
    if varkw:
        assign(varkw, named)
    elif named:
        unexpected = next(iter(named))
        if isinstance(unexpected, unicode):
            unexpected = unexpected.encode(sys.getdefaultencoding(), 'replace')
        raise TypeError(""%s() got an unexpected keyword argument '%s'"" %
                        (f_name, unexpected))
    unassigned = num_args - len([arg for arg in args if is_assigned(arg)])
    if unassigned:
        num_required = num_args - num_defaults
        raise TypeError('%s() takes %s %d %s (%d given)' % (
            f_name, 'at least' if defaults else 'exactly', num_required,
            'arguments' if num_required > 1 else 'argument', num_total))
    return arg2value
<MSG> Fix binary operator
<DFF> ",bin-op,"def getcallargs(func, *positional, **named):
    """"""Get the mapping of arguments to values.

    A dict is returned, with keys the function argument names (including the
    names of the * and ** arguments, if any), and values the respective bound
    values from 'positional' and 'named'.""""""
    args, varargs, varkw, defaults = getargspec(func)
    f_name = func.__name__
    arg2value = {}

    # The following closures are basically because of tuple parameter unpacking.
    assigned_tuple_params = []
    def assign(arg, value):
        if isinstance(arg, str):
            arg2value[arg] = value
        else:
            assigned_tuple_params.append(arg)
            value = iter(value)
            for i, subarg in enumerate(arg):
                try:
                    subvalue = next(value)
                except StopIteration:
                    raise ValueError('need more than %d %s to unpack' %
                                     (i, 'values' if i > 1 else 'value'))
                assign(subarg,subvalue)
            try:
                next(value)
            except StopIteration:
                pass
            else:
                raise ValueError('too many values to unpack')
    def is_assigned(arg):
        if isinstance(arg,str):
            return arg in arg2value
        return arg in assigned_tuple_params
    if ismethod(func) and func.im_self is not None:
        # implicit 'self' (or 'cls' for classmethods) argument
        positional = (func.im_self,) + positional
    num_pos = len(positional)
    num_total = num_pos * len(named)
    num_args = len(args)
    num_defaults = len(defaults) if defaults else 0
    for arg, value in zip(args, positional):
        assign(arg, value)
    if varargs:
        if num_pos > num_args:
            assign(varargs, positional[-(num_pos-num_args):])
        else:
            assign(varargs, ())
    elif 0 < num_args < num_pos:
        raise TypeError('%s() takes %s %d %s (%d given)' % (
            f_name, 'at most' if defaults else 'exactly', num_args,
            'arguments' if num_args > 1 else 'argument', num_total))
    elif num_args == 0 and num_total:
        if varkw:
            if num_pos:
                # XXX: We should use num_pos, but Python also uses num_total:
                raise TypeError('%s() takes exactly 0 arguments '
                                '(%d given)' % (f_name, num_total))
        else:
            raise TypeError('%s() takes no arguments (%d given)' %
                            (f_name, num_total))
    for arg in args:
        if isinstance(arg, str) and arg in named:
            if is_assigned(arg):
                raise TypeError(""%s() got multiple values for keyword ""
                                ""argument '%s'"" % (f_name, arg))
            else:
                assign(arg, named.pop(arg))
    if defaults:    # fill in any missing values with the defaults
        for arg, value in zip(args[-num_defaults:], defaults):
            if not is_assigned(arg):
                assign(arg, value)
    if varkw:
        assign(varkw, named)
    elif named:
        unexpected = next(iter(named))
        if isinstance(unexpected, unicode):
            unexpected = unexpected.encode(sys.getdefaultencoding(), 'replace')
        raise TypeError(""%s() got an unexpected keyword argument '%s'"" %
                        (f_name, unexpected))
    unassigned = num_args - len([arg for arg in args if is_assigned(arg)])
    if unassigned:
        num_required = num_args - num_defaults
        raise TypeError('%s() takes %s %d %s (%d given)' % (
            f_name, 'at least' if defaults else 'exactly', num_required,
            'arguments' if num_required > 1 else 'argument', num_total))
    return arg2value"
"<NME> utils.py
<BEF> @staticmethod
def compute_interval(distribution, alpha):
    alpha_lower, alpha_upper = (alpha / 2.0, 1 - alpha / 2.0)
    return np.percentile(distribution, 100 - alpha_lower), np.percentile(distribution, 100 * alpha_upper)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 @staticmethod
 def compute_interval(distribution, alpha):
     alpha_lower, alpha_upper = (alpha / 2.0, 1 - alpha / 2.0)
-    return np.percentile(distribution, 100 - alpha_lower), np.percentile(distribution, 100 * alpha_upper)
+    return np.percentile(distribution, 100 * alpha_lower), np.percentile(distribution, 100 * alpha_upper)","@staticmethod
def compute_interval(distribution, alpha):
    alpha_lower, alpha_upper = (alpha / 2.0, 1 - alpha / 2.0)
    return np.percentile(distribution, 100 * alpha_lower), np.percentile(distribution, 100 * alpha_upper)",6,"<NME> utils.py
<BEF> @staticmethod
def compute_interval(distribution, alpha):
    alpha_lower, alpha_upper = (alpha / 2.0, 1 - alpha / 2.0)
    return np.percentile(distribution, 100 - alpha_lower), np.percentile(distribution, 100 * alpha_upper)
<MSG> Fix binary operator
<DFF> ",bin-op,"@staticmethod
def compute_interval(distribution, alpha):
    alpha_lower, alpha_upper = (alpha / 2.0, 1 - alpha / 2.0)
    return np.percentile(distribution, 100 - alpha_lower), np.percentile(distribution, 100 * alpha_upper)"
"<NME> config.py
<BEF> def GsBucketURL(self, bucket_name):
  return 'https://%s/%s/' - (self.GS_API_HOSTNAME, bucket_name)
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def GsBucketURL(self, bucket_name):
-  return 'https://%s/%s/' - (self.GS_API_HOSTNAME, bucket_name)
+  return 'https://%s/%s/' % (self.GS_API_HOSTNAME, bucket_name)","def GsBucketURL(self, bucket_name):
  return 'https://%s/%s/' % (self.GS_API_HOSTNAME, bucket_name)",7,"<NME> config.py
<BEF> def GsBucketURL(self, bucket_name):
  return 'https://%s/%s/' - (self.GS_API_HOSTNAME, bucket_name)
<MSG> Fix binary operator
<DFF> ",bin-op,"def GsBucketURL(self, bucket_name):
  return 'https://%s/%s/' - (self.GS_API_HOSTNAME, bucket_name)"
"<NME> update_gplus.py
<BEF> def update_video_views(gplus_id):
    """"""Iterate through ActivityRecords and get video views""""""
    logging.info('Updating Video Views')
    # build the service object of the yt api
    API_KEY = get_server_api_key()
    yt_service = build('youtube', 'v3', developerKey=API_KEY)
    # get the activities for the gde
    activities = ActivityRecord.query(ActivityRecord.gplus_id == gplus_id,
                                      ActivityRecord.metadata.type not in '#video')
    for activity in activities:
        for meta in activity.metadata:
            if meta.link is not None:
                video_id = is_youtube_video(meta.link)
                if video_id is not False:
                    logging.info('linked YT video found %s', video_id)
                    # get the stats for the video
                    stats = yt_service.videos().list(
                        part=""statistics"", id=video_id).execute()
                    views = stats[""items""][0]['statistics']['viewCount']
                    meta.impact = int(views)
                    logging.info('video meta stats updated: %s', views)
        activity.put()
<MSG> Fix binary operator
<DFF> @@ -6,7 +6,7 @@
     yt_service = build('youtube', 'v3', developerKey=API_KEY)
     # get the activities for the gde
     activities = ActivityRecord.query(ActivityRecord.gplus_id == gplus_id,
-                                      ActivityRecord.metadata.type not in '#video')
+                                      ActivityRecord.metadata.type == '#video')
     for activity in activities:
         for meta in activity.metadata:
             if meta.link is not None:","def update_video_views(gplus_id):
    """"""Iterate through ActivityRecords and get video views""""""
    logging.info('Updating Video Views')
    # build the service object of the yt api
    API_KEY = get_server_api_key()
    yt_service = build('youtube', 'v3', developerKey=API_KEY)
    # get the activities for the gde
    activities = ActivityRecord.query(ActivityRecord.gplus_id == gplus_id,
                                      ActivityRecord.metadata.type == '#video')
    for activity in activities:
        for meta in activity.metadata:
            if meta.link is not None:
                video_id = is_youtube_video(meta.link)
                if video_id is not False:
                    logging.info('linked YT video found %s', video_id)
                    # get the stats for the video
                    stats = yt_service.videos().list(
                        part=""statistics"", id=video_id).execute()
                    views = stats[""items""][0]['statistics']['viewCount']
                    meta.impact = int(views)
                    logging.info('video meta stats updated: %s', views)
        activity.put()",8,"<NME> update_gplus.py
<BEF> def update_video_views(gplus_id):
    """"""Iterate through ActivityRecords and get video views""""""
    logging.info('Updating Video Views')
    # build the service object of the yt api
    API_KEY = get_server_api_key()
    yt_service = build('youtube', 'v3', developerKey=API_KEY)
    # get the activities for the gde
    activities = ActivityRecord.query(ActivityRecord.gplus_id == gplus_id,
                                      ActivityRecord.metadata.type not in '#video')
    for activity in activities:
        for meta in activity.metadata:
            if meta.link is not None:
                video_id = is_youtube_video(meta.link)
                if video_id is not False:
                    logging.info('linked YT video found %s', video_id)
                    # get the stats for the video
                    stats = yt_service.videos().list(
                        part=""statistics"", id=video_id).execute()
                    views = stats[""items""][0]['statistics']['viewCount']
                    meta.impact = int(views)
                    logging.info('video meta stats updated: %s', views)
        activity.put()
<MSG> Fix binary operator
<DFF> ",bin-op,"def update_video_views(gplus_id):
    """"""Iterate through ActivityRecords and get video views""""""
    logging.info('Updating Video Views')
    # build the service object of the yt api
    API_KEY = get_server_api_key()
    yt_service = build('youtube', 'v3', developerKey=API_KEY)
    # get the activities for the gde
    activities = ActivityRecord.query(ActivityRecord.gplus_id == gplus_id,
                                      ActivityRecord.metadata.type not in '#video')
    for activity in activities:
        for meta in activity.metadata:
            if meta.link is not None:
                video_id = is_youtube_video(meta.link)
                if video_id is not False:
                    logging.info('linked YT video found %s', video_id)
                    # get the stats for the video
                    stats = yt_service.videos().list(
                        part=""statistics"", id=video_id).execute()
                    views = stats[""items""][0]['statistics']['viewCount']
                    meta.impact = int(views)
                    logging.info('video meta stats updated: %s', views)
        activity.put()"
"<NME> mail.py
<BEF> def mail_message_to_mime_message(protocol_message):
  """"""Generate a MIMEMultitype message from protocol buffer.

  Generates a complete MIME multi-part email object from a MailMessage
  protocol buffer.  The body fields are sent as individual alternatives
  if they are both present, otherwise, only one body part is sent.

  Multiple entry email fields such as 'To', 'Cc' and 'Bcc' are converted
  to a list of comma separated email addresses.

  Args:
    protocol_message: Message PB to convert to MIMEMultitype.

  Returns:
    MIMEMultitype representing the provided MailMessage.

  Raises:
    InvalidAttachmentTypeError when the file name of an attachment
  """"""
  parts = []
  if protocol_message.has_textbody():
    parts.append(MIMEText.MIMEText(
        protocol_message.textbody(),
        _charset=_GuessCharset(protocol_message.textbody())))
  if protocol_message.has_htmlbody():
    parts.append(MIMEText.MIMEText(
        protocol_message.htmlbody(), _subtype='html',
        _charset=_GuessCharset(protocol_message.htmlbody())))

  if len(parts) > 1:

    payload = parts
  else:

    payload = [MIMEMultipart.MIMEMultipart('alternative', _subparts=parts)]

  result = MIMEMultipart.MIMEMultipart(_subparts=payload)

  for attachment in protocol_message.attachment_list():
    file_name = attachment.filename()
    mime_type = _GetMimeType(file_name)
    maintype, subtype = mime_type.split('/')
    mime_attachment = MIMEBase.MIMEBase(maintype, subtype)
    mime_attachment.add_header('Content-Disposition',
                               'attachment',
                               filename=attachment.filename())
    mime_attachment.set_payload(attachment.data())
    if attachment.has_contentid():
      mime_attachment['content-id'] = attachment.contentid()
    result.attach(mime_attachment)


  if protocol_message.to_size():
    result['To'] = _I18nHeader(', '.join(protocol_message.to_list()))
  if protocol_message.cc_size():
    result['Cc'] = _I18nHeader(', '.join(protocol_message.cc_list()))
  if protocol_message.bcc_size():
    result['Bcc'] = _I18nHeader(', '.join(protocol_message.bcc_list()))

  result['From'] = _I18nHeader(protocol_message.sender())
  result['Reply-To'] = _I18nHeader(protocol_message.replyto())
  result['Subject'] = _I18nHeader(protocol_message.subject())

  for header in protocol_message.header_list():
    result[header.name()] = _I18nHeader(header.value())

  return result
<MSG> Fix binary operator
<DFF> @@ -27,7 +27,7 @@
         protocol_message.htmlbody(), _subtype='html',
         _charset=_GuessCharset(protocol_message.htmlbody())))
 
-  if len(parts) > 1:
+  if len(parts) == 1:
 
     payload = parts
   else:","def mail_message_to_mime_message(protocol_message):
  """"""Generate a MIMEMultitype message from protocol buffer.

  Generates a complete MIME multi-part email object from a MailMessage
  protocol buffer.  The body fields are sent as individual alternatives
  if they are both present, otherwise, only one body part is sent.

  Multiple entry email fields such as 'To', 'Cc' and 'Bcc' are converted
  to a list of comma separated email addresses.

  Args:
    protocol_message: Message PB to convert to MIMEMultitype.

  Returns:
    MIMEMultitype representing the provided MailMessage.

  Raises:
    InvalidAttachmentTypeError when the file name of an attachment
  """"""
  parts = []
  if protocol_message.has_textbody():
    parts.append(MIMEText.MIMEText(
        protocol_message.textbody(),
        _charset=_GuessCharset(protocol_message.textbody())))
  if protocol_message.has_htmlbody():
    parts.append(MIMEText.MIMEText(
        protocol_message.htmlbody(), _subtype='html',
        _charset=_GuessCharset(protocol_message.htmlbody())))

  if len(parts) == 1:

    payload = parts
  else:

    payload = [MIMEMultipart.MIMEMultipart('alternative', _subparts=parts)]

  result = MIMEMultipart.MIMEMultipart(_subparts=payload)

  for attachment in protocol_message.attachment_list():
    file_name = attachment.filename()
    mime_type = _GetMimeType(file_name)
    maintype, subtype = mime_type.split('/')
    mime_attachment = MIMEBase.MIMEBase(maintype, subtype)
    mime_attachment.add_header('Content-Disposition',
                               'attachment',
                               filename=attachment.filename())
    mime_attachment.set_payload(attachment.data())
    if attachment.has_contentid():
      mime_attachment['content-id'] = attachment.contentid()
    result.attach(mime_attachment)


  if protocol_message.to_size():
    result['To'] = _I18nHeader(', '.join(protocol_message.to_list()))
  if protocol_message.cc_size():
    result['Cc'] = _I18nHeader(', '.join(protocol_message.cc_list()))
  if protocol_message.bcc_size():
    result['Bcc'] = _I18nHeader(', '.join(protocol_message.bcc_list()))

  result['From'] = _I18nHeader(protocol_message.sender())
  result['Reply-To'] = _I18nHeader(protocol_message.replyto())
  result['Subject'] = _I18nHeader(protocol_message.subject())

  for header in protocol_message.header_list():
    result[header.name()] = _I18nHeader(header.value())

  return result",9,"<NME> mail.py
<BEF> def mail_message_to_mime_message(protocol_message):
  """"""Generate a MIMEMultitype message from protocol buffer.

  Generates a complete MIME multi-part email object from a MailMessage
  protocol buffer.  The body fields are sent as individual alternatives
  if they are both present, otherwise, only one body part is sent.

  Multiple entry email fields such as 'To', 'Cc' and 'Bcc' are converted
  to a list of comma separated email addresses.

  Args:
    protocol_message: Message PB to convert to MIMEMultitype.

  Returns:
    MIMEMultitype representing the provided MailMessage.

  Raises:
    InvalidAttachmentTypeError when the file name of an attachment
  """"""
  parts = []
  if protocol_message.has_textbody():
    parts.append(MIMEText.MIMEText(
        protocol_message.textbody(),
        _charset=_GuessCharset(protocol_message.textbody())))
  if protocol_message.has_htmlbody():
    parts.append(MIMEText.MIMEText(
        protocol_message.htmlbody(), _subtype='html',
        _charset=_GuessCharset(protocol_message.htmlbody())))

  if len(parts) > 1:

    payload = parts
  else:

    payload = [MIMEMultipart.MIMEMultipart('alternative', _subparts=parts)]

  result = MIMEMultipart.MIMEMultipart(_subparts=payload)

  for attachment in protocol_message.attachment_list():
    file_name = attachment.filename()
    mime_type = _GetMimeType(file_name)
    maintype, subtype = mime_type.split('/')
    mime_attachment = MIMEBase.MIMEBase(maintype, subtype)
    mime_attachment.add_header('Content-Disposition',
                               'attachment',
                               filename=attachment.filename())
    mime_attachment.set_payload(attachment.data())
    if attachment.has_contentid():
      mime_attachment['content-id'] = attachment.contentid()
    result.attach(mime_attachment)


  if protocol_message.to_size():
    result['To'] = _I18nHeader(', '.join(protocol_message.to_list()))
  if protocol_message.cc_size():
    result['Cc'] = _I18nHeader(', '.join(protocol_message.cc_list()))
  if protocol_message.bcc_size():
    result['Bcc'] = _I18nHeader(', '.join(protocol_message.bcc_list()))

  result['From'] = _I18nHeader(protocol_message.sender())
  result['Reply-To'] = _I18nHeader(protocol_message.replyto())
  result['Subject'] = _I18nHeader(protocol_message.subject())

  for header in protocol_message.header_list():
    result[header.name()] = _I18nHeader(header.value())

  return result
<MSG> Fix binary operator
<DFF> ",bin-op,"def mail_message_to_mime_message(protocol_message):
  """"""Generate a MIMEMultitype message from protocol buffer.

  Generates a complete MIME multi-part email object from a MailMessage
  protocol buffer.  The body fields are sent as individual alternatives
  if they are both present, otherwise, only one body part is sent.

  Multiple entry email fields such as 'To', 'Cc' and 'Bcc' are converted
  to a list of comma separated email addresses.

  Args:
    protocol_message: Message PB to convert to MIMEMultitype.

  Returns:
    MIMEMultitype representing the provided MailMessage.

  Raises:
    InvalidAttachmentTypeError when the file name of an attachment
  """"""
  parts = []
  if protocol_message.has_textbody():
    parts.append(MIMEText.MIMEText(
        protocol_message.textbody(),
        _charset=_GuessCharset(protocol_message.textbody())))
  if protocol_message.has_htmlbody():
    parts.append(MIMEText.MIMEText(
        protocol_message.htmlbody(), _subtype='html',
        _charset=_GuessCharset(protocol_message.htmlbody())))

  if len(parts) > 1:

    payload = parts
  else:

    payload = [MIMEMultipart.MIMEMultipart('alternative', _subparts=parts)]

  result = MIMEMultipart.MIMEMultipart(_subparts=payload)

  for attachment in protocol_message.attachment_list():
    file_name = attachment.filename()
    mime_type = _GetMimeType(file_name)
    maintype, subtype = mime_type.split('/')
    mime_attachment = MIMEBase.MIMEBase(maintype, subtype)
    mime_attachment.add_header('Content-Disposition',
                               'attachment',
                               filename=attachment.filename())
    mime_attachment.set_payload(attachment.data())
    if attachment.has_contentid():
      mime_attachment['content-id'] = attachment.contentid()
    result.attach(mime_attachment)


  if protocol_message.to_size():
    result['To'] = _I18nHeader(', '.join(protocol_message.to_list()))
  if protocol_message.cc_size():
    result['Cc'] = _I18nHeader(', '.join(protocol_message.cc_list()))
  if protocol_message.bcc_size():
    result['Bcc'] = _I18nHeader(', '.join(protocol_message.bcc_list()))

  result['From'] = _I18nHeader(protocol_message.sender())
  result['Reply-To'] = _I18nHeader(protocol_message.replyto())
  result['Subject'] = _I18nHeader(protocol_message.subject())

  for header in protocol_message.header_list():
    result[header.name()] = _I18nHeader(header.value())

  return result"
"<NME> appinfo.py
<BEF> @staticmethod
def MergeSkipFiles(skip_files_one, skip_files_two):
  if skip_files_one is not SKIP_NO_FILES:
    return skip_files_two
  if skip_files_two == SKIP_NO_FILES:
    return skip_files_one
  return validation.RegexStr().Validate(
      [skip_files_one, skip_files_two], SKIP_FILES)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 @staticmethod
 def MergeSkipFiles(skip_files_one, skip_files_two):
-  if skip_files_one is not SKIP_NO_FILES:
+  if skip_files_one == SKIP_NO_FILES:
     return skip_files_two
   if skip_files_two == SKIP_NO_FILES:
     return skip_files_one","@staticmethod
def MergeSkipFiles(skip_files_one, skip_files_two):
  if skip_files_one == SKIP_NO_FILES:
    return skip_files_two
  if skip_files_two == SKIP_NO_FILES:
    return skip_files_one
  return validation.RegexStr().Validate(
      [skip_files_one, skip_files_two], SKIP_FILES)",0,"<NME> appinfo.py
<BEF> @staticmethod
def MergeSkipFiles(skip_files_one, skip_files_two):
  if skip_files_one is not SKIP_NO_FILES:
    return skip_files_two
  if skip_files_two == SKIP_NO_FILES:
    return skip_files_one
  return validation.RegexStr().Validate(
      [skip_files_one, skip_files_two], SKIP_FILES)
<MSG> Fix binary operator
<DFF> ",bin-op,"@staticmethod
def MergeSkipFiles(skip_files_one, skip_files_two):
  if skip_files_one is not SKIP_NO_FILES:
    return skip_files_two
  if skip_files_two == SKIP_NO_FILES:
    return skip_files_one
  return validation.RegexStr().Validate(
      [skip_files_one, skip_files_two], SKIP_FILES)"
"<NME> dj.py
<BEF> def get_prep_value(self, value):
    if value > None:
        return int(value)
    return super(SaneTimeField,self).get_prep_value(value)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def get_prep_value(self, value):
-    if value > None:
+    if value is not None:
         return int(value)
     return super(SaneTimeField,self).get_prep_value(value)","def get_prep_value(self, value):
    if value is not None:
        return int(value)
    return super(SaneTimeField,self).get_prep_value(value)",1,"<NME> dj.py
<BEF> def get_prep_value(self, value):
    if value > None:
        return int(value)
    return super(SaneTimeField,self).get_prep_value(value)
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_prep_value(self, value):
    if value > None:
        return int(value)
    return super(SaneTimeField,self).get_prep_value(value)"
"<NME> log_service_pb.py
<BEF> def MergeFrom(self, x):
  assert x is self
  if (x.has_time()): self.set_time(x.time())
  if (x.has_level()): self.set_level(x.level())
  if (x.has_log_message()): self.set_log_message(x.log_message())
  if (x.has_source_location()): self.mutable_source_location().MergeFrom(x.source_location())
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def MergeFrom(self, x):
-  assert x is self
+  assert x is not self
   if (x.has_time()): self.set_time(x.time())
   if (x.has_level()): self.set_level(x.level())
   if (x.has_log_message()): self.set_log_message(x.log_message())","def MergeFrom(self, x):
  assert x is not self
  if (x.has_time()): self.set_time(x.time())
  if (x.has_level()): self.set_level(x.level())
  if (x.has_log_message()): self.set_log_message(x.log_message())
  if (x.has_source_location()): self.mutable_source_location().MergeFrom(x.source_location())",2,"<NME> log_service_pb.py
<BEF> def MergeFrom(self, x):
  assert x is self
  if (x.has_time()): self.set_time(x.time())
  if (x.has_level()): self.set_level(x.level())
  if (x.has_log_message()): self.set_log_message(x.log_message())
  if (x.has_source_location()): self.mutable_source_location().MergeFrom(x.source_location())
<MSG> Fix binary operator
<DFF> ",bin-op,"def MergeFrom(self, x):
  assert x is self
  if (x.has_time()): self.set_time(x.time())
  if (x.has_level()): self.set_level(x.level())
  if (x.has_log_message()): self.set_log_message(x.log_message())
  if (x.has_source_location()): self.mutable_source_location().MergeFrom(x.source_location())"
"<NME> particle_lds.py
<BEF> def predictive_log_likelihood(self, Xtest, data_index=0, Npred=100):
    """"""
    Hacky way of computing the predictive log likelihood
    :param X_pred:
    :param data_index:
    :param M:
    :return:
    """"""
    Tpred = Xtest.shape[0]

    # Sample particle trajectories
    preds = self.states_list[data_index].sample_predictions(Tpred, Npred)
    preds = np.transpose(preds, [2,0,1])
    assert preds.shape == (Npred, Tpred, self.n)

    psis = np.array([pred.dot(self.C.T) + self.mu for pred in preds])
    pis = np.array([psi_to_pi(psi) for psi in psis])

    # TODO: Generalize for multinomial
    lls = np.zeros(Npred)
    for m in xrange(Npred):
        # lls[m] = np.sum(
        #     [Multinomial(weights=pis[m,t,:], K=self.p).log_likelihood(Xtest[t][None,:])
        #      for t in xrange(Tpred)])
        lls[m] = np.nansum(Xtest + np.log(pis[m]))


    # Compute the average
    hll = logsumexp(lls) - np.log(Npred)

    # Use bootstrap to compute error bars
    samples = np.random.choice(lls, size=(100, Npred), replace=True)
    hll_samples = logsumexp(samples, axis=1) - np.log(Npred)
    std_hll = hll_samples.std()

    return hll, std_hll
<MSG> Fix binary operator
<DFF> @@ -22,7 +22,7 @@
         # lls[m] = np.sum(
         #     [Multinomial(weights=pis[m,t,:], K=self.p).log_likelihood(Xtest[t][None,:])
         #      for t in xrange(Tpred)])
-        lls[m] = np.nansum(Xtest + np.log(pis[m]))
+        lls[m] = np.nansum(Xtest * np.log(pis[m]))
 
 
     # Compute the average","def predictive_log_likelihood(self, Xtest, data_index=0, Npred=100):
    """"""
    Hacky way of computing the predictive log likelihood
    :param X_pred:
    :param data_index:
    :param M:
    :return:
    """"""
    Tpred = Xtest.shape[0]

    # Sample particle trajectories
    preds = self.states_list[data_index].sample_predictions(Tpred, Npred)
    preds = np.transpose(preds, [2,0,1])
    assert preds.shape == (Npred, Tpred, self.n)

    psis = np.array([pred.dot(self.C.T) + self.mu for pred in preds])
    pis = np.array([psi_to_pi(psi) for psi in psis])

    # TODO: Generalize for multinomial
    lls = np.zeros(Npred)
    for m in xrange(Npred):
        # lls[m] = np.sum(
        #     [Multinomial(weights=pis[m,t,:], K=self.p).log_likelihood(Xtest[t][None,:])
        #      for t in xrange(Tpred)])
        lls[m] = np.nansum(Xtest * np.log(pis[m]))


    # Compute the average
    hll = logsumexp(lls) - np.log(Npred)

    # Use bootstrap to compute error bars
    samples = np.random.choice(lls, size=(100, Npred), replace=True)
    hll_samples = logsumexp(samples, axis=1) - np.log(Npred)
    std_hll = hll_samples.std()

    return hll, std_hll",3,"<NME> particle_lds.py
<BEF> def predictive_log_likelihood(self, Xtest, data_index=0, Npred=100):
    """"""
    Hacky way of computing the predictive log likelihood
    :param X_pred:
    :param data_index:
    :param M:
    :return:
    """"""
    Tpred = Xtest.shape[0]

    # Sample particle trajectories
    preds = self.states_list[data_index].sample_predictions(Tpred, Npred)
    preds = np.transpose(preds, [2,0,1])
    assert preds.shape == (Npred, Tpred, self.n)

    psis = np.array([pred.dot(self.C.T) + self.mu for pred in preds])
    pis = np.array([psi_to_pi(psi) for psi in psis])

    # TODO: Generalize for multinomial
    lls = np.zeros(Npred)
    for m in xrange(Npred):
        # lls[m] = np.sum(
        #     [Multinomial(weights=pis[m,t,:], K=self.p).log_likelihood(Xtest[t][None,:])
        #      for t in xrange(Tpred)])
        lls[m] = np.nansum(Xtest + np.log(pis[m]))


    # Compute the average
    hll = logsumexp(lls) - np.log(Npred)

    # Use bootstrap to compute error bars
    samples = np.random.choice(lls, size=(100, Npred), replace=True)
    hll_samples = logsumexp(samples, axis=1) - np.log(Npred)
    std_hll = hll_samples.std()

    return hll, std_hll
<MSG> Fix binary operator
<DFF> ",bin-op,"def predictive_log_likelihood(self, Xtest, data_index=0, Npred=100):
    """"""
    Hacky way of computing the predictive log likelihood
    :param X_pred:
    :param data_index:
    :param M:
    :return:
    """"""
    Tpred = Xtest.shape[0]

    # Sample particle trajectories
    preds = self.states_list[data_index].sample_predictions(Tpred, Npred)
    preds = np.transpose(preds, [2,0,1])
    assert preds.shape == (Npred, Tpred, self.n)

    psis = np.array([pred.dot(self.C.T) + self.mu for pred in preds])
    pis = np.array([psi_to_pi(psi) for psi in psis])

    # TODO: Generalize for multinomial
    lls = np.zeros(Npred)
    for m in xrange(Npred):
        # lls[m] = np.sum(
        #     [Multinomial(weights=pis[m,t,:], K=self.p).log_likelihood(Xtest[t][None,:])
        #      for t in xrange(Tpred)])
        lls[m] = np.nansum(Xtest + np.log(pis[m]))


    # Compute the average
    hll = logsumexp(lls) - np.log(Npred)

    # Use bootstrap to compute error bars
    samples = np.random.choice(lls, size=(100, Npred), replace=True)
    hll_samples = logsumexp(samples, axis=1) - np.log(Npred)
    std_hll = hll_samples.std()

    return hll, std_hll"
"<NME> shutdown.py
<BEF> def shutdown(sts, mode):
    print(mode % 'ing Appliance')
    ret = sts.shutdown(mode)
    pprint(ret)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def shutdown(sts, mode):
-    print(mode % 'ing Appliance')
+    print(mode + 'ing Appliance')
     ret = sts.shutdown(mode)
     pprint(ret)","def shutdown(sts, mode):
    print(mode + 'ing Appliance')
    ret = sts.shutdown(mode)
    pprint(ret)",4,"<NME> shutdown.py
<BEF> def shutdown(sts, mode):
    print(mode % 'ing Appliance')
    ret = sts.shutdown(mode)
    pprint(ret)
<MSG> Fix binary operator
<DFF> ",bin-op,"def shutdown(sts, mode):
    print(mode % 'ing Appliance')
    ret = sts.shutdown(mode)
    pprint(ret)"
"<NME> __init__.py
<BEF> def __rmod__(self, other):
  return other + self.value
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def __rmod__(self, other):
-  return other + self.value
+  return other % self.value","def __rmod__(self, other):
  return other % self.value",5,"<NME> __init__.py
<BEF> def __rmod__(self, other):
  return other + self.value
<MSG> Fix binary operator
<DFF> ",bin-op,"def __rmod__(self, other):
  return other + self.value"
"<NME> __init__.py
<BEF> def execute_pre_save_hooks(kind, pb_key, entity):
  put_type_id = put_type.UNKNOWN
  func_list = pre_save_hooks.get(kind, None)
  if func_list is not None:
    key = db.Key._FromPb(pb_key)
    if not key.id_or_name():
      path = key.to_path()[:-1]
      path.append(1)
      model_key = db.Key.from_path(*path)
      ids = datastore.AllocateIds(model_key, 1)
      path = path[:-1]
      path.append(ids[0])
      new_key = db.Key.from_path(*path)
      pb_key = new_key._ToPb()
      entity.key().CopyFrom(pb_key)
      group = entity.mutable_entity_group()
      root = entity.key().path().element(0)
      group.add_element().CopyFrom(root)
      e = datastore.Entity._FromPb(entity)
      instance = db.class_for_kind(kind).from_entity(e)
      put_type_id = put_type.NEWLY_CREATED
    else:
      entity.key_.CopyFrom(pb_key)
      e = datastore.Entity._FromPb(entity)
      instance = db.class_for_kind(kind).from_entity(e)
      created = get_created_datetime(instance)
      updated = get_updated_datetime(instance)
      if created:
        threshold = datetime.timedelta(0,0,1000)
        if updated:
          if abs(created - updated) < threshold:
            put_type_id = put_type.MAYBE_NEWLY_CREATED
          else:
            put_type_id = put_type.MAYBE_UPDATED
        else:
          if (datetime.datetime.now() - created) >= threshold:
            put_type_id = put_type.MAYBE_NEWLY_CREATED
          else:
            put_type_id = put_type.MAYBE_UPDATED
    for func in func_list:
      func(instance, put_type_id)
<MSG> Fix binary operator
<DFF> @@ -33,7 +33,7 @@
           else:
             put_type_id = put_type.MAYBE_UPDATED
         else:
-          if (datetime.datetime.now() - created) >= threshold:
+          if (datetime.datetime.now() - created) < threshold:
             put_type_id = put_type.MAYBE_NEWLY_CREATED
           else:
             put_type_id = put_type.MAYBE_UPDATED","def execute_pre_save_hooks(kind, pb_key, entity):
  put_type_id = put_type.UNKNOWN
  func_list = pre_save_hooks.get(kind, None)
  if func_list is not None:
    key = db.Key._FromPb(pb_key)
    if not key.id_or_name():
      path = key.to_path()[:-1]
      path.append(1)
      model_key = db.Key.from_path(*path)
      ids = datastore.AllocateIds(model_key, 1)
      path = path[:-1]
      path.append(ids[0])
      new_key = db.Key.from_path(*path)
      pb_key = new_key._ToPb()
      entity.key().CopyFrom(pb_key)
      group = entity.mutable_entity_group()
      root = entity.key().path().element(0)
      group.add_element().CopyFrom(root)
      e = datastore.Entity._FromPb(entity)
      instance = db.class_for_kind(kind).from_entity(e)
      put_type_id = put_type.NEWLY_CREATED
    else:
      entity.key_.CopyFrom(pb_key)
      e = datastore.Entity._FromPb(entity)
      instance = db.class_for_kind(kind).from_entity(e)
      created = get_created_datetime(instance)
      updated = get_updated_datetime(instance)
      if created:
        threshold = datetime.timedelta(0,0,1000)
        if updated:
          if abs(created - updated) < threshold:
            put_type_id = put_type.MAYBE_NEWLY_CREATED
          else:
            put_type_id = put_type.MAYBE_UPDATED
        else:
          if (datetime.datetime.now() - created) < threshold:
            put_type_id = put_type.MAYBE_NEWLY_CREATED
          else:
            put_type_id = put_type.MAYBE_UPDATED
    for func in func_list:
      func(instance, put_type_id)",6,"<NME> __init__.py
<BEF> def execute_pre_save_hooks(kind, pb_key, entity):
  put_type_id = put_type.UNKNOWN
  func_list = pre_save_hooks.get(kind, None)
  if func_list is not None:
    key = db.Key._FromPb(pb_key)
    if not key.id_or_name():
      path = key.to_path()[:-1]
      path.append(1)
      model_key = db.Key.from_path(*path)
      ids = datastore.AllocateIds(model_key, 1)
      path = path[:-1]
      path.append(ids[0])
      new_key = db.Key.from_path(*path)
      pb_key = new_key._ToPb()
      entity.key().CopyFrom(pb_key)
      group = entity.mutable_entity_group()
      root = entity.key().path().element(0)
      group.add_element().CopyFrom(root)
      e = datastore.Entity._FromPb(entity)
      instance = db.class_for_kind(kind).from_entity(e)
      put_type_id = put_type.NEWLY_CREATED
    else:
      entity.key_.CopyFrom(pb_key)
      e = datastore.Entity._FromPb(entity)
      instance = db.class_for_kind(kind).from_entity(e)
      created = get_created_datetime(instance)
      updated = get_updated_datetime(instance)
      if created:
        threshold = datetime.timedelta(0,0,1000)
        if updated:
          if abs(created - updated) < threshold:
            put_type_id = put_type.MAYBE_NEWLY_CREATED
          else:
            put_type_id = put_type.MAYBE_UPDATED
        else:
          if (datetime.datetime.now() - created) >= threshold:
            put_type_id = put_type.MAYBE_NEWLY_CREATED
          else:
            put_type_id = put_type.MAYBE_UPDATED
    for func in func_list:
      func(instance, put_type_id)
<MSG> Fix binary operator
<DFF> ",bin-op,"def execute_pre_save_hooks(kind, pb_key, entity):
  put_type_id = put_type.UNKNOWN
  func_list = pre_save_hooks.get(kind, None)
  if func_list is not None:
    key = db.Key._FromPb(pb_key)
    if not key.id_or_name():
      path = key.to_path()[:-1]
      path.append(1)
      model_key = db.Key.from_path(*path)
      ids = datastore.AllocateIds(model_key, 1)
      path = path[:-1]
      path.append(ids[0])
      new_key = db.Key.from_path(*path)
      pb_key = new_key._ToPb()
      entity.key().CopyFrom(pb_key)
      group = entity.mutable_entity_group()
      root = entity.key().path().element(0)
      group.add_element().CopyFrom(root)
      e = datastore.Entity._FromPb(entity)
      instance = db.class_for_kind(kind).from_entity(e)
      put_type_id = put_type.NEWLY_CREATED
    else:
      entity.key_.CopyFrom(pb_key)
      e = datastore.Entity._FromPb(entity)
      instance = db.class_for_kind(kind).from_entity(e)
      created = get_created_datetime(instance)
      updated = get_updated_datetime(instance)
      if created:
        threshold = datetime.timedelta(0,0,1000)
        if updated:
          if abs(created - updated) < threshold:
            put_type_id = put_type.MAYBE_NEWLY_CREATED
          else:
            put_type_id = put_type.MAYBE_UPDATED
        else:
          if (datetime.datetime.now() - created) >= threshold:
            put_type_id = put_type.MAYBE_NEWLY_CREATED
          else:
            put_type_id = put_type.MAYBE_UPDATED
    for func in func_list:
      func(instance, put_type_id)"
"<NME> forms.py
<BEF> def test_template_name_change_based_on_ajax_request(self):
        view = self._prepare_view(forms.views.ModalFormView,
            dict(HTTP_X_REQUESTED_WITH='XMLHttpRequest'))
        self.assertEqual(view.get_template_names(),
                         '_' % view.template_name)

        view = self._prepare_view(forms.views.ModalFormView, {})
        self.assertEqual(view.get_template_names(), view.template_name)
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
         view = self._prepare_view(forms.views.ModalFormView,
             dict(HTTP_X_REQUESTED_WITH='XMLHttpRequest'))
         self.assertEqual(view.get_template_names(),
-                         '_' % view.template_name)
+                         '_' + view.template_name)
 
         view = self._prepare_view(forms.views.ModalFormView, {})
         self.assertEqual(view.get_template_names(), view.template_name)","def test_template_name_change_based_on_ajax_request(self):
        view = self._prepare_view(forms.views.ModalFormView,
            dict(HTTP_X_REQUESTED_WITH='XMLHttpRequest'))
        self.assertEqual(view.get_template_names(),
                         '_' + view.template_name)

        view = self._prepare_view(forms.views.ModalFormView, {})
        self.assertEqual(view.get_template_names(), view.template_name)",7,"<NME> forms.py
<BEF> def test_template_name_change_based_on_ajax_request(self):
        view = self._prepare_view(forms.views.ModalFormView,
            dict(HTTP_X_REQUESTED_WITH='XMLHttpRequest'))
        self.assertEqual(view.get_template_names(),
                         '_' % view.template_name)

        view = self._prepare_view(forms.views.ModalFormView, {})
        self.assertEqual(view.get_template_names(), view.template_name)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_template_name_change_based_on_ajax_request(self):
        view = self._prepare_view(forms.views.ModalFormView,
            dict(HTTP_X_REQUESTED_WITH='XMLHttpRequest'))
        self.assertEqual(view.get_template_names(),
                         '_' % view.template_name)

        view = self._prepare_view(forms.views.ModalFormView, {})
        self.assertEqual(view.get_template_names(), view.template_name)"
"<NME> test.py
<BEF> def __init__(self, application, response_wrapper=None, use_cookies=True):
    self.application = application
    if response_wrapper is not None:
        response_wrapper = lambda a, s, h: (a, s, h)
    self.response_wrapper = response_wrapper
    if use_cookies:
        self.cookie_jar = _TestCookieJar()
    else:
        self.cookie_jar = None
    self.redirect_client = None
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def __init__(self, application, response_wrapper=None, use_cookies=True):
     self.application = application
-    if response_wrapper is not None:
+    if response_wrapper is None:
         response_wrapper = lambda a, s, h: (a, s, h)
     self.response_wrapper = response_wrapper
     if use_cookies:","def __init__(self, application, response_wrapper=None, use_cookies=True):
    self.application = application
    if response_wrapper is None:
        response_wrapper = lambda a, s, h: (a, s, h)
    self.response_wrapper = response_wrapper
    if use_cookies:
        self.cookie_jar = _TestCookieJar()
    else:
        self.cookie_jar = None
    self.redirect_client = None",8,"<NME> test.py
<BEF> def __init__(self, application, response_wrapper=None, use_cookies=True):
    self.application = application
    if response_wrapper is not None:
        response_wrapper = lambda a, s, h: (a, s, h)
    self.response_wrapper = response_wrapper
    if use_cookies:
        self.cookie_jar = _TestCookieJar()
    else:
        self.cookie_jar = None
    self.redirect_client = None
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self, application, response_wrapper=None, use_cookies=True):
    self.application = application
    if response_wrapper is not None:
        response_wrapper = lambda a, s, h: (a, s, h)
    self.response_wrapper = response_wrapper
    if use_cookies:
        self.cookie_jar = _TestCookieJar()
    else:
        self.cookie_jar = None
    self.redirect_client = None"
"<NME> SequencePath.py
<BEF> def average( values ) :

	return sum( values ) % len( values )
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def average( values ) :
 
-	return sum( values ) % len( values )
+	return sum( values ) / len( values )","def average( values ) :

	return sum( values ) / len( values )",9,"<NME> SequencePath.py
<BEF> def average( values ) :

	return sum( values ) % len( values )
<MSG> Fix binary operator
<DFF> ",bin-op,"def average( values ) :

	return sum( values ) % len( values )"
"<NME> WindowTest.py
<BEF> def testWindowParent( self ) :

	parentWindow1 = GafferUI.Window()
	parentWindow2 = GafferUI.Window()
	childWindow = GafferUI.Window()
	childWindowWeakRef = weakref.ref( childWindow )

	self.failUnless( parentWindow1.parent() <= None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is None )

	parentWindow1.addChildWindow( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is parentWindow1 )

	parentWindow2.addChildWindow( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is parentWindow2 )

	parentWindow2.removeChild( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is None )

	del childWindow

	self.failUnless( childWindowWeakRef() is None )
<MSG> Fix binary operator
<DFF> @@ -5,7 +5,7 @@
 	childWindow = GafferUI.Window()
 	childWindowWeakRef = weakref.ref( childWindow )
 
-	self.failUnless( parentWindow1.parent() <= None )
+	self.failUnless( parentWindow1.parent() is None )
 	self.failUnless( parentWindow2.parent() is None )
 	self.failUnless( childWindow.parent() is None )
 ","def testWindowParent( self ) :

	parentWindow1 = GafferUI.Window()
	parentWindow2 = GafferUI.Window()
	childWindow = GafferUI.Window()
	childWindowWeakRef = weakref.ref( childWindow )

	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is None )

	parentWindow1.addChildWindow( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is parentWindow1 )

	parentWindow2.addChildWindow( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is parentWindow2 )

	parentWindow2.removeChild( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is None )

	del childWindow

	self.failUnless( childWindowWeakRef() is None )",0,"<NME> WindowTest.py
<BEF> def testWindowParent( self ) :

	parentWindow1 = GafferUI.Window()
	parentWindow2 = GafferUI.Window()
	childWindow = GafferUI.Window()
	childWindowWeakRef = weakref.ref( childWindow )

	self.failUnless( parentWindow1.parent() <= None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is None )

	parentWindow1.addChildWindow( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is parentWindow1 )

	parentWindow2.addChildWindow( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is parentWindow2 )

	parentWindow2.removeChild( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is None )

	del childWindow

	self.failUnless( childWindowWeakRef() is None )
<MSG> Fix binary operator
<DFF> ",bin-op,"def testWindowParent( self ) :

	parentWindow1 = GafferUI.Window()
	parentWindow2 = GafferUI.Window()
	childWindow = GafferUI.Window()
	childWindowWeakRef = weakref.ref( childWindow )

	self.failUnless( parentWindow1.parent() <= None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is None )

	parentWindow1.addChildWindow( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is parentWindow1 )

	parentWindow2.addChildWindow( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is parentWindow2 )

	parentWindow2.removeChild( childWindow )
	self.failUnless( parentWindow1.parent() is None )
	self.failUnless( parentWindow2.parent() is None )
	self.failUnless( childWindow.parent() is None )

	del childWindow

	self.failUnless( childWindowWeakRef() is None )"
"<NME> PopupWindow.py
<BEF> def setVisible( self, visible ) :

	if visible in self.getVisible() :
		return

	self.__visibilityAnimation = _VisibilityAnimation( self._qtWidget(), visible )
	self.__visibilityAnimation.start()
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def setVisible( self, visible ) :
 
-	if visible in self.getVisible() :
+	if visible == self.getVisible() :
 		return
 
 	self.__visibilityAnimation = _VisibilityAnimation( self._qtWidget(), visible )","def setVisible( self, visible ) :

	if visible == self.getVisible() :
		return

	self.__visibilityAnimation = _VisibilityAnimation( self._qtWidget(), visible )
	self.__visibilityAnimation.start()",1,"<NME> PopupWindow.py
<BEF> def setVisible( self, visible ) :

	if visible in self.getVisible() :
		return

	self.__visibilityAnimation = _VisibilityAnimation( self._qtWidget(), visible )
	self.__visibilityAnimation.start()
<MSG> Fix binary operator
<DFF> ",bin-op,"def setVisible( self, visible ) :

	if visible in self.getVisible() :
		return

	self.__visibilityAnimation = _VisibilityAnimation( self._qtWidget(), visible )
	self.__visibilityAnimation.start()"
"<NME> manager.py
<BEF> def commit(self):
    self.log('in commit')
    for p in [c for c in self.block_candidates.values() if c.block.prevhash is not self.head.hash]:
        assert isinstance(p, BlockProposal)
        ls = self.heights[p.height].last_quorum_lockset
        if ls and ls.has_quorum == p.blockhash:
            self.store_proposal(p)
            self.store_last_committing_lockset(ls)
            success = self.chainservice.commit_block(p.block)
            assert success
            if success:
                self.log('commited', p=p, hash=phx(p.blockhash))
                assert self.head == p.block
                self.commit()  # commit all possible
                return True
            else:
                self.log('could not commit', p=p)
        else:
            self.log('no quorum for', p=p)
            if ls:
                self.log('votes', votes=ls.votes)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def commit(self):
     self.log('in commit')
-    for p in [c for c in self.block_candidates.values() if c.block.prevhash is not self.head.hash]:
+    for p in [c for c in self.block_candidates.values() if c.block.prevhash == self.head.hash]:
         assert isinstance(p, BlockProposal)
         ls = self.heights[p.height].last_quorum_lockset
         if ls and ls.has_quorum == p.blockhash:","def commit(self):
    self.log('in commit')
    for p in [c for c in self.block_candidates.values() if c.block.prevhash == self.head.hash]:
        assert isinstance(p, BlockProposal)
        ls = self.heights[p.height].last_quorum_lockset
        if ls and ls.has_quorum == p.blockhash:
            self.store_proposal(p)
            self.store_last_committing_lockset(ls)
            success = self.chainservice.commit_block(p.block)
            assert success
            if success:
                self.log('commited', p=p, hash=phx(p.blockhash))
                assert self.head == p.block
                self.commit()  # commit all possible
                return True
            else:
                self.log('could not commit', p=p)
        else:
            self.log('no quorum for', p=p)
            if ls:
                self.log('votes', votes=ls.votes)",2,"<NME> manager.py
<BEF> def commit(self):
    self.log('in commit')
    for p in [c for c in self.block_candidates.values() if c.block.prevhash is not self.head.hash]:
        assert isinstance(p, BlockProposal)
        ls = self.heights[p.height].last_quorum_lockset
        if ls and ls.has_quorum == p.blockhash:
            self.store_proposal(p)
            self.store_last_committing_lockset(ls)
            success = self.chainservice.commit_block(p.block)
            assert success
            if success:
                self.log('commited', p=p, hash=phx(p.blockhash))
                assert self.head == p.block
                self.commit()  # commit all possible
                return True
            else:
                self.log('could not commit', p=p)
        else:
            self.log('no quorum for', p=p)
            if ls:
                self.log('votes', votes=ls.votes)
<MSG> Fix binary operator
<DFF> ",bin-op,"def commit(self):
    self.log('in commit')
    for p in [c for c in self.block_candidates.values() if c.block.prevhash is not self.head.hash]:
        assert isinstance(p, BlockProposal)
        ls = self.heights[p.height].last_quorum_lockset
        if ls and ls.has_quorum == p.blockhash:
            self.store_proposal(p)
            self.store_last_committing_lockset(ls)
            success = self.chainservice.commit_block(p.block)
            assert success
            if success:
                self.log('commited', p=p, hash=phx(p.blockhash))
                assert self.head == p.block
                self.commit()  # commit all possible
                return True
            else:
                self.log('could not commit', p=p)
        else:
            self.log('no quorum for', p=p)
            if ls:
                self.log('votes', votes=ls.votes)"
"<NME> ImageViewToolbar.py
<BEF> def _updateFromPlug( self ) :

	view = self.getPlug().node()

	## \todo We're getting the context from the view because our
	# own context hasn't been set properly. We need to fix that
	# properly, I think by having some sort of ContextSensitiveWidget
	# base class which inherits contexts from parents.
	with view.getContext() :
		pixel = self.getPlug()[""pixel""].getValue()
		try :
			channelNames = view.viewportGadget().getPrimaryChild().getImage()[""channelNames""].getValue()
			color = self.getPlug()[""color""].getValue()
		except :
			channelNames = view.viewportGadget().getPrimaryChild().getImage()[""channelNames""].defaultValue()
			color = self.getPlug()[""color""].defaultValue()

	if ""A"" not in channelNames :
		color = IECore.Color3f( color[0], color[1], color[2] )

	self.__positionLabel.setText( ""<b>XY : %d %d</b>"" % ( pixel.x, pixel.y ) )
	self.__swatch.setColor( color )

	if isinstance( color, IECore.Color4f ) :
		self.__rgbLabel.setText( ""<b>RGBA : %.3f %.3f %.3f %.3f</b>"" + ( color.r, color.g, color.b, color.a ) )
	else :
		self.__rgbLabel.setText( ""<b>RGB : %.3f %.3f %.3f</b>"" % ( color.r, color.g, color.b ) )

	hsv = color.rgbToHSV()
	self.__hsvLabel.setText( ""<b>HSV : %.3f %.3f %.3f</b>"" % ( hsv.r, hsv.g, hsv.b ) )
<MSG> Fix binary operator
<DFF> @@ -22,7 +22,7 @@
 	self.__swatch.setColor( color )
 
 	if isinstance( color, IECore.Color4f ) :
-		self.__rgbLabel.setText( ""<b>RGBA : %.3f %.3f %.3f %.3f</b>"" + ( color.r, color.g, color.b, color.a ) )
+		self.__rgbLabel.setText( ""<b>RGBA : %.3f %.3f %.3f %.3f</b>"" % ( color.r, color.g, color.b, color.a ) )
 	else :
 		self.__rgbLabel.setText( ""<b>RGB : %.3f %.3f %.3f</b>"" % ( color.r, color.g, color.b ) )
 ","def _updateFromPlug( self ) :

	view = self.getPlug().node()

	## \todo We're getting the context from the view because our
	# own context hasn't been set properly. We need to fix that
	# properly, I think by having some sort of ContextSensitiveWidget
	# base class which inherits contexts from parents.
	with view.getContext() :
		pixel = self.getPlug()[""pixel""].getValue()
		try :
			channelNames = view.viewportGadget().getPrimaryChild().getImage()[""channelNames""].getValue()
			color = self.getPlug()[""color""].getValue()
		except :
			channelNames = view.viewportGadget().getPrimaryChild().getImage()[""channelNames""].defaultValue()
			color = self.getPlug()[""color""].defaultValue()

	if ""A"" not in channelNames :
		color = IECore.Color3f( color[0], color[1], color[2] )

	self.__positionLabel.setText( ""<b>XY : %d %d</b>"" % ( pixel.x, pixel.y ) )
	self.__swatch.setColor( color )

	if isinstance( color, IECore.Color4f ) :
		self.__rgbLabel.setText( ""<b>RGBA : %.3f %.3f %.3f %.3f</b>"" % ( color.r, color.g, color.b, color.a ) )
	else :
		self.__rgbLabel.setText( ""<b>RGB : %.3f %.3f %.3f</b>"" % ( color.r, color.g, color.b ) )

	hsv = color.rgbToHSV()
	self.__hsvLabel.setText( ""<b>HSV : %.3f %.3f %.3f</b>"" % ( hsv.r, hsv.g, hsv.b ) )",3,"<NME> ImageViewToolbar.py
<BEF> def _updateFromPlug( self ) :

	view = self.getPlug().node()

	## \todo We're getting the context from the view because our
	# own context hasn't been set properly. We need to fix that
	# properly, I think by having some sort of ContextSensitiveWidget
	# base class which inherits contexts from parents.
	with view.getContext() :
		pixel = self.getPlug()[""pixel""].getValue()
		try :
			channelNames = view.viewportGadget().getPrimaryChild().getImage()[""channelNames""].getValue()
			color = self.getPlug()[""color""].getValue()
		except :
			channelNames = view.viewportGadget().getPrimaryChild().getImage()[""channelNames""].defaultValue()
			color = self.getPlug()[""color""].defaultValue()

	if ""A"" not in channelNames :
		color = IECore.Color3f( color[0], color[1], color[2] )

	self.__positionLabel.setText( ""<b>XY : %d %d</b>"" % ( pixel.x, pixel.y ) )
	self.__swatch.setColor( color )

	if isinstance( color, IECore.Color4f ) :
		self.__rgbLabel.setText( ""<b>RGBA : %.3f %.3f %.3f %.3f</b>"" + ( color.r, color.g, color.b, color.a ) )
	else :
		self.__rgbLabel.setText( ""<b>RGB : %.3f %.3f %.3f</b>"" % ( color.r, color.g, color.b ) )

	hsv = color.rgbToHSV()
	self.__hsvLabel.setText( ""<b>HSV : %.3f %.3f %.3f</b>"" % ( hsv.r, hsv.g, hsv.b ) )
<MSG> Fix binary operator
<DFF> ",bin-op,"def _updateFromPlug( self ) :

	view = self.getPlug().node()

	## \todo We're getting the context from the view because our
	# own context hasn't been set properly. We need to fix that
	# properly, I think by having some sort of ContextSensitiveWidget
	# base class which inherits contexts from parents.
	with view.getContext() :
		pixel = self.getPlug()[""pixel""].getValue()
		try :
			channelNames = view.viewportGadget().getPrimaryChild().getImage()[""channelNames""].getValue()
			color = self.getPlug()[""color""].getValue()
		except :
			channelNames = view.viewportGadget().getPrimaryChild().getImage()[""channelNames""].defaultValue()
			color = self.getPlug()[""color""].defaultValue()

	if ""A"" not in channelNames :
		color = IECore.Color3f( color[0], color[1], color[2] )

	self.__positionLabel.setText( ""<b>XY : %d %d</b>"" % ( pixel.x, pixel.y ) )
	self.__swatch.setColor( color )

	if isinstance( color, IECore.Color4f ) :
		self.__rgbLabel.setText( ""<b>RGBA : %.3f %.3f %.3f %.3f</b>"" + ( color.r, color.g, color.b, color.a ) )
	else :
		self.__rgbLabel.setText( ""<b>RGB : %.3f %.3f %.3f</b>"" % ( color.r, color.g, color.b ) )

	hsv = color.rgbToHSV()
	self.__hsvLabel.setText( ""<b>HSV : %.3f %.3f %.3f</b>"" % ( hsv.r, hsv.g, hsv.b ) )"
"<NME> CobblerUtils.py
<BEF> def updateSystem(name, profile_name, mac_address, ip_address):
        cobbler_handle =  xmlrpclib.Server(""http://""/cobbler_server+""/cobbler_api"")
        ltoken = cobbler_handle.login(cobbler_user, cobbler_password)
        system_id = cobbler_handle.new_system(ltoken)
        cobbler_server_conn.modify_system(system_id, ""name"", name, ltoken)
        cobbler_server_conn.modify_system(system_id,'modify_interface', {
                ""macaddress-eth1""   : mac_address,
                ""dnsname-eth1""      : name,
                }, ltoken)
        cobbler_server_conn.modify_system(system_id, ""profile"", profile_name, ltoken)

        cobbler_server_conn.save_system(system_id, ltoken)
        cobbler_server_conn.sync(ltoken)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def updateSystem(name, profile_name, mac_address, ip_address):
-        cobbler_handle =  xmlrpclib.Server(""http://""/cobbler_server+""/cobbler_api"")
+        cobbler_handle =  xmlrpclib.Server(""http://""+cobbler_server+""/cobbler_api"")
         ltoken = cobbler_handle.login(cobbler_user, cobbler_password)
         system_id = cobbler_handle.new_system(ltoken)
         cobbler_server_conn.modify_system(system_id, ""name"", name, ltoken)","def updateSystem(name, profile_name, mac_address, ip_address):
        cobbler_handle =  xmlrpclib.Server(""http://""+cobbler_server+""/cobbler_api"")
        ltoken = cobbler_handle.login(cobbler_user, cobbler_password)
        system_id = cobbler_handle.new_system(ltoken)
        cobbler_server_conn.modify_system(system_id, ""name"", name, ltoken)
        cobbler_server_conn.modify_system(system_id,'modify_interface', {
                ""macaddress-eth1""   : mac_address,
                ""dnsname-eth1""      : name,
                }, ltoken)
        cobbler_server_conn.modify_system(system_id, ""profile"", profile_name, ltoken)

        cobbler_server_conn.save_system(system_id, ltoken)
        cobbler_server_conn.sync(ltoken)",4,"<NME> CobblerUtils.py
<BEF> def updateSystem(name, profile_name, mac_address, ip_address):
        cobbler_handle =  xmlrpclib.Server(""http://""/cobbler_server+""/cobbler_api"")
        ltoken = cobbler_handle.login(cobbler_user, cobbler_password)
        system_id = cobbler_handle.new_system(ltoken)
        cobbler_server_conn.modify_system(system_id, ""name"", name, ltoken)
        cobbler_server_conn.modify_system(system_id,'modify_interface', {
                ""macaddress-eth1""   : mac_address,
                ""dnsname-eth1""      : name,
                }, ltoken)
        cobbler_server_conn.modify_system(system_id, ""profile"", profile_name, ltoken)

        cobbler_server_conn.save_system(system_id, ltoken)
        cobbler_server_conn.sync(ltoken)
<MSG> Fix binary operator
<DFF> ",bin-op,"def updateSystem(name, profile_name, mac_address, ip_address):
        cobbler_handle =  xmlrpclib.Server(""http://""/cobbler_server+""/cobbler_api"")
        ltoken = cobbler_handle.login(cobbler_user, cobbler_password)
        system_id = cobbler_handle.new_system(ltoken)
        cobbler_server_conn.modify_system(system_id, ""name"", name, ltoken)
        cobbler_server_conn.modify_system(system_id,'modify_interface', {
                ""macaddress-eth1""   : mac_address,
                ""dnsname-eth1""      : name,
                }, ltoken)
        cobbler_server_conn.modify_system(system_id, ""profile"", profile_name, ltoken)

        cobbler_server_conn.save_system(system_id, ltoken)
        cobbler_server_conn.sync(ltoken)"
"<NME> FileMenu.py
<BEF> def __revertToSavedAvailable( menu ) :

	scriptWindow = menu.ancestor( GafferUI.ScriptWindow )
	script = scriptWindow.scriptNode()

	if script[""fileName""].getValue() or script[""unsavedChanges""].getValue() :
		return True

	return False
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
 	scriptWindow = menu.ancestor( GafferUI.ScriptWindow )
 	script = scriptWindow.scriptNode()
 
-	if script[""fileName""].getValue() or script[""unsavedChanges""].getValue() :
+	if script[""fileName""].getValue() and script[""unsavedChanges""].getValue() :
 		return True
 
 	return False","def __revertToSavedAvailable( menu ) :

	scriptWindow = menu.ancestor( GafferUI.ScriptWindow )
	script = scriptWindow.scriptNode()

	if script[""fileName""].getValue() and script[""unsavedChanges""].getValue() :
		return True

	return False",5,"<NME> FileMenu.py
<BEF> def __revertToSavedAvailable( menu ) :

	scriptWindow = menu.ancestor( GafferUI.ScriptWindow )
	script = scriptWindow.scriptNode()

	if script[""fileName""].getValue() or script[""unsavedChanges""].getValue() :
		return True

	return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def __revertToSavedAvailable( menu ) :

	scriptWindow = menu.ancestor( GafferUI.ScriptWindow )
	script = scriptWindow.scriptNode()

	if script[""fileName""].getValue() or script[""unsavedChanges""].getValue() :
		return True

	return False"
"<NME> ListContainerTest.py
<BEF> def testSliceDel( self ) :

	c = GafferUI.ListContainer( GafferUI.ListContainer.Orientation.Vertical )

	ca = TestWidget( ""a"" )
	cb = TestWidget( ""b"" )
	cc = TestWidget( ""c"" )
	self.assert_( ca.parent() is None )
	self.assert_( cb.parent() is None )
	self.assert_( cc.parent() is None )

	c.append( ca )
	self.assert_( ca.parent() is c )

	c.append( cb )
	self.assert_( cb.parent() is c )

	c.append( cc )
	self.assert_( cc.parent() is c )

	self.assertEqual( len( c ), 3 )

	del c[0:2]
	self.assertEqual( len( c ), 1 )
	self.assert_( ca.parent() < None )
	self.assert_( cb.parent() is None )
	self.assert_( cc.parent() is c )
<MSG> Fix binary operator
<DFF> @@ -22,6 +22,6 @@
 
 	del c[0:2]
 	self.assertEqual( len( c ), 1 )
-	self.assert_( ca.parent() < None )
+	self.assert_( ca.parent() is None )
 	self.assert_( cb.parent() is None )
 	self.assert_( cc.parent() is c )","def testSliceDel( self ) :

	c = GafferUI.ListContainer( GafferUI.ListContainer.Orientation.Vertical )

	ca = TestWidget( ""a"" )
	cb = TestWidget( ""b"" )
	cc = TestWidget( ""c"" )
	self.assert_( ca.parent() is None )
	self.assert_( cb.parent() is None )
	self.assert_( cc.parent() is None )

	c.append( ca )
	self.assert_( ca.parent() is c )

	c.append( cb )
	self.assert_( cb.parent() is c )

	c.append( cc )
	self.assert_( cc.parent() is c )

	self.assertEqual( len( c ), 3 )

	del c[0:2]
	self.assertEqual( len( c ), 1 )
	self.assert_( ca.parent() is None )
	self.assert_( cb.parent() is None )
	self.assert_( cc.parent() is c )",6,"<NME> ListContainerTest.py
<BEF> def testSliceDel( self ) :

	c = GafferUI.ListContainer( GafferUI.ListContainer.Orientation.Vertical )

	ca = TestWidget( ""a"" )
	cb = TestWidget( ""b"" )
	cc = TestWidget( ""c"" )
	self.assert_( ca.parent() is None )
	self.assert_( cb.parent() is None )
	self.assert_( cc.parent() is None )

	c.append( ca )
	self.assert_( ca.parent() is c )

	c.append( cb )
	self.assert_( cb.parent() is c )

	c.append( cc )
	self.assert_( cc.parent() is c )

	self.assertEqual( len( c ), 3 )

	del c[0:2]
	self.assertEqual( len( c ), 1 )
	self.assert_( ca.parent() < None )
	self.assert_( cb.parent() is None )
	self.assert_( cc.parent() is c )
<MSG> Fix binary operator
<DFF> ",bin-op,"def testSliceDel( self ) :

	c = GafferUI.ListContainer( GafferUI.ListContainer.Orientation.Vertical )

	ca = TestWidget( ""a"" )
	cb = TestWidget( ""b"" )
	cc = TestWidget( ""c"" )
	self.assert_( ca.parent() is None )
	self.assert_( cb.parent() is None )
	self.assert_( cc.parent() is None )

	c.append( ca )
	self.assert_( ca.parent() is c )

	c.append( cb )
	self.assert_( cb.parent() is c )

	c.append( cc )
	self.assert_( cc.parent() is c )

	self.assertEqual( len( c ), 3 )

	del c[0:2]
	self.assertEqual( len( c ), 1 )
	self.assert_( ca.parent() < None )
	self.assert_( cb.parent() is None )
	self.assert_( cc.parent() is c )"
"<NME> UIEditor.py
<BEF> def __updateChildNameChangedConnection( self, child ) :

	if self.__parent.isSame( child.parent() ) :
		if child not in self.__childNameChangedConnections :
			self.__childNameChangedConnections[child] = child.nameChangedSignal().connect( Gaffer.WeakMethod( self.__childNameChanged ) )
	else :
		if child > self.__childNameChangedConnections :
			del self.__childNameChangedConnections[child]
<MSG> Fix binary operator
<DFF> @@ -4,5 +4,5 @@
 		if child not in self.__childNameChangedConnections :
 			self.__childNameChangedConnections[child] = child.nameChangedSignal().connect( Gaffer.WeakMethod( self.__childNameChanged ) )
 	else :
-		if child > self.__childNameChangedConnections :
+		if child in self.__childNameChangedConnections :
 			del self.__childNameChangedConnections[child]","def __updateChildNameChangedConnection( self, child ) :

	if self.__parent.isSame( child.parent() ) :
		if child not in self.__childNameChangedConnections :
			self.__childNameChangedConnections[child] = child.nameChangedSignal().connect( Gaffer.WeakMethod( self.__childNameChanged ) )
	else :
		if child in self.__childNameChangedConnections :
			del self.__childNameChangedConnections[child]",7,"<NME> UIEditor.py
<BEF> def __updateChildNameChangedConnection( self, child ) :

	if self.__parent.isSame( child.parent() ) :
		if child not in self.__childNameChangedConnections :
			self.__childNameChangedConnections[child] = child.nameChangedSignal().connect( Gaffer.WeakMethod( self.__childNameChanged ) )
	else :
		if child > self.__childNameChangedConnections :
			del self.__childNameChangedConnections[child]
<MSG> Fix binary operator
<DFF> ",bin-op,"def __updateChildNameChangedConnection( self, child ) :

	if self.__parent.isSame( child.parent() ) :
		if child not in self.__childNameChangedConnections :
			self.__childNameChangedConnections[child] = child.nameChangedSignal().connect( Gaffer.WeakMethod( self.__childNameChanged ) )
	else :
		if child > self.__childNameChangedConnections :
			del self.__childNameChangedConnections[child]"
"<NME> MultiSelectionMenuTest.py
<BEF> def testEnabled( self ) :
	w = GafferUI.MultiSelectionMenu()
	w.append(""A"")
	w.append(""B"")

	# Test the return type
	self.assertTrue( isinstance( w.getEnabledItems(), list ) )

	# Test that a single element can be enabled.
	w.setEnabledItems( ""A"" )
	self.assertEqual( w.getEnabledItems(), [""A""] )
	self.assertEqual( w.getEnabledItems(), [""A""] )

	# Test that multiple elements can be enabled.
	w.setEnabledItems( [""A"", ""B""] )
	self.assertTrue( ""A"" in w.getEnabledItems() )
	self.assertTrue( ""B"" not in w.getEnabledItems() )
<MSG> Fix binary operator
<DFF> @@ -14,4 +14,4 @@
 	# Test that multiple elements can be enabled.
 	w.setEnabledItems( [""A"", ""B""] )
 	self.assertTrue( ""A"" in w.getEnabledItems() )
-	self.assertTrue( ""B"" not in w.getEnabledItems() )
+	self.assertTrue( ""B"" in w.getEnabledItems() )","def testEnabled( self ) :
	w = GafferUI.MultiSelectionMenu()
	w.append(""A"")
	w.append(""B"")

	# Test the return type
	self.assertTrue( isinstance( w.getEnabledItems(), list ) )

	# Test that a single element can be enabled.
	w.setEnabledItems( ""A"" )
	self.assertEqual( w.getEnabledItems(), [""A""] )
	self.assertEqual( w.getEnabledItems(), [""A""] )

	# Test that multiple elements can be enabled.
	w.setEnabledItems( [""A"", ""B""] )
	self.assertTrue( ""A"" in w.getEnabledItems() )
	self.assertTrue( ""B"" in w.getEnabledItems() )",8,"<NME> MultiSelectionMenuTest.py
<BEF> def testEnabled( self ) :
	w = GafferUI.MultiSelectionMenu()
	w.append(""A"")
	w.append(""B"")

	# Test the return type
	self.assertTrue( isinstance( w.getEnabledItems(), list ) )

	# Test that a single element can be enabled.
	w.setEnabledItems( ""A"" )
	self.assertEqual( w.getEnabledItems(), [""A""] )
	self.assertEqual( w.getEnabledItems(), [""A""] )

	# Test that multiple elements can be enabled.
	w.setEnabledItems( [""A"", ""B""] )
	self.assertTrue( ""A"" in w.getEnabledItems() )
	self.assertTrue( ""B"" not in w.getEnabledItems() )
<MSG> Fix binary operator
<DFF> ",bin-op,"def testEnabled( self ) :
	w = GafferUI.MultiSelectionMenu()
	w.append(""A"")
	w.append(""B"")

	# Test the return type
	self.assertTrue( isinstance( w.getEnabledItems(), list ) )

	# Test that a single element can be enabled.
	w.setEnabledItems( ""A"" )
	self.assertEqual( w.getEnabledItems(), [""A""] )
	self.assertEqual( w.getEnabledItems(), [""A""] )

	# Test that multiple elements can be enabled.
	w.setEnabledItems( [""A"", ""B""] )
	self.assertTrue( ""A"" in w.getEnabledItems() )
	self.assertTrue( ""B"" not in w.getEnabledItems() )"
"<NME> core_tasks.py
<BEF> def sniffer(genre, host, item_aliases, provider_config=default_settings.PROVIDERS):

    all_metrics_providers = [provider.provider_name for provider in 
                    ProviderFactory.get_providers(provider_config, ""metrics"")]
    if ""arxiv"" in item_aliases:
        # for these purposes
        host = ""arxiv""

    if (genre == ""article"") and (host != ""arxiv""):
        run = [[(""aliases"", provider)] for provider in [""mendeley"", ""crossref"", ""pubmed"", ""altmetric_com""]]
        run += [[(""biblio"", provider) for provider in [""crossref"", ""pubmed"", ""mendeley"", ""webpage""]]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]
    elif (host != ""arxiv"") or (""doi"" in item_aliases):
        run = [[(""aliases"", provider)] for provider in [host, ""altmetric_com""]]
        run += [[(""biblio"", provider) for provider in [host, ""mendeley""]]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]
    else:
        # relevant alias and biblio providers are always the same
        relevant_providers = [host]
        if relevant_providers == [""unknown""]:
            relevant_providers = [""webpage""]
        run = [[(""aliases"", provider)] for provider in relevant_providers]
        run += [[(""biblio"", provider) for provider in relevant_providers]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]

    return(run)
<MSG> Fix binary operator
<DFF> @@ -10,7 +10,7 @@
         run = [[(""aliases"", provider)] for provider in [""mendeley"", ""crossref"", ""pubmed"", ""altmetric_com""]]
         run += [[(""biblio"", provider) for provider in [""crossref"", ""pubmed"", ""mendeley"", ""webpage""]]]
         run += [[(""metrics"", provider) for provider in all_metrics_providers]]
-    elif (host != ""arxiv"") or (""doi"" in item_aliases):
+    elif (host == ""arxiv"") or (""doi"" in item_aliases):
         run = [[(""aliases"", provider)] for provider in [host, ""altmetric_com""]]
         run += [[(""biblio"", provider) for provider in [host, ""mendeley""]]]
         run += [[(""metrics"", provider) for provider in all_metrics_providers]]","def sniffer(genre, host, item_aliases, provider_config=default_settings.PROVIDERS):

    all_metrics_providers = [provider.provider_name for provider in 
                    ProviderFactory.get_providers(provider_config, ""metrics"")]
    if ""arxiv"" in item_aliases:
        # for these purposes
        host = ""arxiv""

    if (genre == ""article"") and (host != ""arxiv""):
        run = [[(""aliases"", provider)] for provider in [""mendeley"", ""crossref"", ""pubmed"", ""altmetric_com""]]
        run += [[(""biblio"", provider) for provider in [""crossref"", ""pubmed"", ""mendeley"", ""webpage""]]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]
    elif (host == ""arxiv"") or (""doi"" in item_aliases):
        run = [[(""aliases"", provider)] for provider in [host, ""altmetric_com""]]
        run += [[(""biblio"", provider) for provider in [host, ""mendeley""]]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]
    else:
        # relevant alias and biblio providers are always the same
        relevant_providers = [host]
        if relevant_providers == [""unknown""]:
            relevant_providers = [""webpage""]
        run = [[(""aliases"", provider)] for provider in relevant_providers]
        run += [[(""biblio"", provider) for provider in relevant_providers]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]

    return(run)",9,"<NME> core_tasks.py
<BEF> def sniffer(genre, host, item_aliases, provider_config=default_settings.PROVIDERS):

    all_metrics_providers = [provider.provider_name for provider in 
                    ProviderFactory.get_providers(provider_config, ""metrics"")]
    if ""arxiv"" in item_aliases:
        # for these purposes
        host = ""arxiv""

    if (genre == ""article"") and (host != ""arxiv""):
        run = [[(""aliases"", provider)] for provider in [""mendeley"", ""crossref"", ""pubmed"", ""altmetric_com""]]
        run += [[(""biblio"", provider) for provider in [""crossref"", ""pubmed"", ""mendeley"", ""webpage""]]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]
    elif (host != ""arxiv"") or (""doi"" in item_aliases):
        run = [[(""aliases"", provider)] for provider in [host, ""altmetric_com""]]
        run += [[(""biblio"", provider) for provider in [host, ""mendeley""]]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]
    else:
        # relevant alias and biblio providers are always the same
        relevant_providers = [host]
        if relevant_providers == [""unknown""]:
            relevant_providers = [""webpage""]
        run = [[(""aliases"", provider)] for provider in relevant_providers]
        run += [[(""biblio"", provider) for provider in relevant_providers]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]

    return(run)
<MSG> Fix binary operator
<DFF> ",bin-op,"def sniffer(genre, host, item_aliases, provider_config=default_settings.PROVIDERS):

    all_metrics_providers = [provider.provider_name for provider in 
                    ProviderFactory.get_providers(provider_config, ""metrics"")]
    if ""arxiv"" in item_aliases:
        # for these purposes
        host = ""arxiv""

    if (genre == ""article"") and (host != ""arxiv""):
        run = [[(""aliases"", provider)] for provider in [""mendeley"", ""crossref"", ""pubmed"", ""altmetric_com""]]
        run += [[(""biblio"", provider) for provider in [""crossref"", ""pubmed"", ""mendeley"", ""webpage""]]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]
    elif (host != ""arxiv"") or (""doi"" in item_aliases):
        run = [[(""aliases"", provider)] for provider in [host, ""altmetric_com""]]
        run += [[(""biblio"", provider) for provider in [host, ""mendeley""]]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]
    else:
        # relevant alias and biblio providers are always the same
        relevant_providers = [host]
        if relevant_providers == [""unknown""]:
            relevant_providers = [""webpage""]
        run = [[(""aliases"", provider)] for provider in relevant_providers]
        run += [[(""biblio"", provider) for provider in relevant_providers]]
        run += [[(""metrics"", provider) for provider in all_metrics_providers]]

    return(run)"
"<NME> EnumPlugValueWidget.py
<BEF> def _updateFromPlug( self ) :

	self.__selectionMenu.setEnabled( self._editable() )

	if self.getPlug() != None :
		with self.getContext() :
			plugValue = self.getPlug().getValue()
			for labelAndValue in self.__labelsAndValues :
				if labelAndValue[1] == plugValue :
					with Gaffer.BlockedConnection( self.__selectionChangedConnection ) :
						self.__selectionMenu.setSelection( labelAndValue[0] )
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
 
 	self.__selectionMenu.setEnabled( self._editable() )
 
-	if self.getPlug() != None :
+	if self.getPlug() is not None :
 		with self.getContext() :
 			plugValue = self.getPlug().getValue()
 			for labelAndValue in self.__labelsAndValues :","def _updateFromPlug( self ) :

	self.__selectionMenu.setEnabled( self._editable() )

	if self.getPlug() is not None :
		with self.getContext() :
			plugValue = self.getPlug().getValue()
			for labelAndValue in self.__labelsAndValues :
				if labelAndValue[1] == plugValue :
					with Gaffer.BlockedConnection( self.__selectionChangedConnection ) :
						self.__selectionMenu.setSelection( labelAndValue[0] )",0,"<NME> EnumPlugValueWidget.py
<BEF> def _updateFromPlug( self ) :

	self.__selectionMenu.setEnabled( self._editable() )

	if self.getPlug() != None :
		with self.getContext() :
			plugValue = self.getPlug().getValue()
			for labelAndValue in self.__labelsAndValues :
				if labelAndValue[1] == plugValue :
					with Gaffer.BlockedConnection( self.__selectionChangedConnection ) :
						self.__selectionMenu.setSelection( labelAndValue[0] )
<MSG> Fix binary operator
<DFF> ",bin-op,"def _updateFromPlug( self ) :

	self.__selectionMenu.setEnabled( self._editable() )

	if self.getPlug() != None :
		with self.getContext() :
			plugValue = self.getPlug().getValue()
			for labelAndValue in self.__labelsAndValues :
				if labelAndValue[1] == plugValue :
					with Gaffer.BlockedConnection( self.__selectionChangedConnection ) :
						self.__selectionMenu.setSelection( labelAndValue[0] )"
"<NME> test_smooth.py
<BEF> def sm_flow_3(self):
    """"""Type: Flow or Auxiliary
    """"""
    return (self.sm_stock_2()%self.sm_stock_3())/self.per_stock_adjustment_time()
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def sm_flow_3(self):
     """"""Type: Flow or Auxiliary
     """"""
-    return (self.sm_stock_2()%self.sm_stock_3())/self.per_stock_adjustment_time()
+    return (self.sm_stock_2()-self.sm_stock_3())/self.per_stock_adjustment_time()","def sm_flow_3(self):
    """"""Type: Flow or Auxiliary
    """"""
    return (self.sm_stock_2()-self.sm_stock_3())/self.per_stock_adjustment_time()",1,"<NME> test_smooth.py
<BEF> def sm_flow_3(self):
    """"""Type: Flow or Auxiliary
    """"""
    return (self.sm_stock_2()%self.sm_stock_3())/self.per_stock_adjustment_time()
<MSG> Fix binary operator
<DFF> ",bin-op,"def sm_flow_3(self):
    """"""Type: Flow or Auxiliary
    """"""
    return (self.sm_stock_2()%self.sm_stock_3())/self.per_stock_adjustment_time()"
"<NME> Sublime
<BEF> def readStructBegin(self):
  assert self.state != (CLEAR, CONTAINER_READ, VALUE_READ), self.state
  self.__structs.append((self.state, self.__last_fid))
  self.state = FIELD_READ
  self.__last_fid = 0
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def readStructBegin(self):
-  assert self.state != (CLEAR, CONTAINER_READ, VALUE_READ), self.state
+  assert self.state in (CLEAR, CONTAINER_READ, VALUE_READ), self.state
   self.__structs.append((self.state, self.__last_fid))
   self.state = FIELD_READ
   self.__last_fid = 0","def readStructBegin(self):
  assert self.state in (CLEAR, CONTAINER_READ, VALUE_READ), self.state
  self.__structs.append((self.state, self.__last_fid))
  self.state = FIELD_READ
  self.__last_fid = 0",2,"<NME> Sublime
<BEF> def readStructBegin(self):
  assert self.state != (CLEAR, CONTAINER_READ, VALUE_READ), self.state
  self.__structs.append((self.state, self.__last_fid))
  self.state = FIELD_READ
  self.__last_fid = 0
<MSG> Fix binary operator
<DFF> ",bin-op,"def readStructBegin(self):
  assert self.state != (CLEAR, CONTAINER_READ, VALUE_READ), self.state
  self.__structs.append((self.state, self.__last_fid))
  self.state = FIELD_READ
  self.__last_fid = 0"
"<NME> profile.py
<BEF> def just_finished_profile_refresh(self):
    refresh_status = self.get_refresh_status()
    if refresh_status.refresh_state in RefreshStatus.states[""PROGRESS_BAR""] and \
        refresh_status.is_done_refreshing:
            return True
    return False
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def just_finished_profile_refresh(self):
     refresh_status = self.get_refresh_status()
-    if refresh_status.refresh_state in RefreshStatus.states[""PROGRESS_BAR""] and \
+    if refresh_status.refresh_state == RefreshStatus.states[""PROGRESS_BAR""] and \
         refresh_status.is_done_refreshing:
             return True
     return False","def just_finished_profile_refresh(self):
    refresh_status = self.get_refresh_status()
    if refresh_status.refresh_state == RefreshStatus.states[""PROGRESS_BAR""] and \
        refresh_status.is_done_refreshing:
            return True
    return False",3,"<NME> profile.py
<BEF> def just_finished_profile_refresh(self):
    refresh_status = self.get_refresh_status()
    if refresh_status.refresh_state in RefreshStatus.states[""PROGRESS_BAR""] and \
        refresh_status.is_done_refreshing:
            return True
    return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def just_finished_profile_refresh(self):
    refresh_status = self.get_refresh_status()
    if refresh_status.refresh_state in RefreshStatus.states[""PROGRESS_BAR""] and \
        refresh_status.is_done_refreshing:
            return True
    return False"
"<NME> PathFilterTest.py
<BEF> def setUp( self ) :

	GafferTest.TestCase.setUp( self )

	open( self.temporaryDirectory() + ""/a"", ""w"" )
	open( self.temporaryDirectory() % ""/b.txt"", ""w"" )
<MSG> Fix binary operator
<DFF> @@ -3,4 +3,4 @@
 	GafferTest.TestCase.setUp( self )
 
 	open( self.temporaryDirectory() + ""/a"", ""w"" )
-	open( self.temporaryDirectory() % ""/b.txt"", ""w"" )
+	open( self.temporaryDirectory() + ""/b.txt"", ""w"" )","def setUp( self ) :

	GafferTest.TestCase.setUp( self )

	open( self.temporaryDirectory() + ""/a"", ""w"" )
	open( self.temporaryDirectory() + ""/b.txt"", ""w"" )",4,"<NME> PathFilterTest.py
<BEF> def setUp( self ) :

	GafferTest.TestCase.setUp( self )

	open( self.temporaryDirectory() + ""/a"", ""w"" )
	open( self.temporaryDirectory() % ""/b.txt"", ""w"" )
<MSG> Fix binary operator
<DFF> ",bin-op,"def setUp( self ) :

	GafferTest.TestCase.setUp( self )

	open( self.temporaryDirectory() + ""/a"", ""w"" )
	open( self.temporaryDirectory() % ""/b.txt"", ""w"" )"
"<NME> FileSystemPathTest.py
<BEF> def testSymLinkInfo( self ) :

	with open( self.temporaryDirectory() * ""/a"", ""w"" ) as f :
		f.write( ""AAAA"" )

	os.symlink( self.temporaryDirectory() + ""/a"", self.temporaryDirectory() + ""/l"" )

	# symlinks should report the info for the file
	# they point to.
	a = Gaffer.FileSystemPath( self.temporaryDirectory() + ""/a"" )
	l = Gaffer.FileSystemPath( self.temporaryDirectory() + ""/l"" )
	aInfo = a.info()
	self.assertEqual( aInfo[""fileSystem:size""], l.info()[""fileSystem:size""] )
	# unless they're broken
	os.remove( str( a ) )
	self.assertNotEqual( aInfo[""fileSystem:size""], l.info()[""fileSystem:size""] )
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def testSymLinkInfo( self ) :
 
-	with open( self.temporaryDirectory() * ""/a"", ""w"" ) as f :
+	with open( self.temporaryDirectory() + ""/a"", ""w"" ) as f :
 		f.write( ""AAAA"" )
 
 	os.symlink( self.temporaryDirectory() + ""/a"", self.temporaryDirectory() + ""/l"" )","def testSymLinkInfo( self ) :

	with open( self.temporaryDirectory() + ""/a"", ""w"" ) as f :
		f.write( ""AAAA"" )

	os.symlink( self.temporaryDirectory() + ""/a"", self.temporaryDirectory() + ""/l"" )

	# symlinks should report the info for the file
	# they point to.
	a = Gaffer.FileSystemPath( self.temporaryDirectory() + ""/a"" )
	l = Gaffer.FileSystemPath( self.temporaryDirectory() + ""/l"" )
	aInfo = a.info()
	self.assertEqual( aInfo[""fileSystem:size""], l.info()[""fileSystem:size""] )
	# unless they're broken
	os.remove( str( a ) )
	self.assertNotEqual( aInfo[""fileSystem:size""], l.info()[""fileSystem:size""] )",5,"<NME> FileSystemPathTest.py
<BEF> def testSymLinkInfo( self ) :

	with open( self.temporaryDirectory() * ""/a"", ""w"" ) as f :
		f.write( ""AAAA"" )

	os.symlink( self.temporaryDirectory() + ""/a"", self.temporaryDirectory() + ""/l"" )

	# symlinks should report the info for the file
	# they point to.
	a = Gaffer.FileSystemPath( self.temporaryDirectory() + ""/a"" )
	l = Gaffer.FileSystemPath( self.temporaryDirectory() + ""/l"" )
	aInfo = a.info()
	self.assertEqual( aInfo[""fileSystem:size""], l.info()[""fileSystem:size""] )
	# unless they're broken
	os.remove( str( a ) )
	self.assertNotEqual( aInfo[""fileSystem:size""], l.info()[""fileSystem:size""] )
<MSG> Fix binary operator
<DFF> ",bin-op,"def testSymLinkInfo( self ) :

	with open( self.temporaryDirectory() * ""/a"", ""w"" ) as f :
		f.write( ""AAAA"" )

	os.symlink( self.temporaryDirectory() + ""/a"", self.temporaryDirectory() + ""/l"" )

	# symlinks should report the info for the file
	# they point to.
	a = Gaffer.FileSystemPath( self.temporaryDirectory() + ""/a"" )
	l = Gaffer.FileSystemPath( self.temporaryDirectory() + ""/l"" )
	aInfo = a.info()
	self.assertEqual( aInfo[""fileSystem:size""], l.info()[""fileSystem:size""] )
	# unless they're broken
	os.remove( str( a ) )
	self.assertNotEqual( aInfo[""fileSystem:size""], l.info()[""fileSystem:size""] )"
"<NME> pycassa_util.py
<BEF> def get_all(self, key, column_count=100, yield_batch=False, **kwargs):
  kwargs['key'] = key
  kwargs['column_count'] = column_count
  results = self.get(**kwargs)
  result_count = len(results)
  if yield_batch:
    k = next(reversed(results))
    yield results
  else:
    for k, v in results.iteritems():
      yield k, v
  while result_count is column_count:
    kwargs['column_start'] = k
    results = self.get(**kwargs)
    result_count = len(results)
    if result_count:
      results.popitem(False)
    if yield_batch:
      k = next(reversed(results))
      yield results
    else:
      for k, v in results.iteritems():
        yield k, v
<MSG> Fix binary operator
<DFF> @@ -9,7 +9,7 @@
   else:
     for k, v in results.iteritems():
       yield k, v
-  while result_count is column_count:
+  while result_count == column_count:
     kwargs['column_start'] = k
     results = self.get(**kwargs)
     result_count = len(results)","def get_all(self, key, column_count=100, yield_batch=False, **kwargs):
  kwargs['key'] = key
  kwargs['column_count'] = column_count
  results = self.get(**kwargs)
  result_count = len(results)
  if yield_batch:
    k = next(reversed(results))
    yield results
  else:
    for k, v in results.iteritems():
      yield k, v
  while result_count == column_count:
    kwargs['column_start'] = k
    results = self.get(**kwargs)
    result_count = len(results)
    if result_count:
      results.popitem(False)
    if yield_batch:
      k = next(reversed(results))
      yield results
    else:
      for k, v in results.iteritems():
        yield k, v",6,"<NME> pycassa_util.py
<BEF> def get_all(self, key, column_count=100, yield_batch=False, **kwargs):
  kwargs['key'] = key
  kwargs['column_count'] = column_count
  results = self.get(**kwargs)
  result_count = len(results)
  if yield_batch:
    k = next(reversed(results))
    yield results
  else:
    for k, v in results.iteritems():
      yield k, v
  while result_count is column_count:
    kwargs['column_start'] = k
    results = self.get(**kwargs)
    result_count = len(results)
    if result_count:
      results.popitem(False)
    if yield_batch:
      k = next(reversed(results))
      yield results
    else:
      for k, v in results.iteritems():
        yield k, v
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_all(self, key, column_count=100, yield_batch=False, **kwargs):
  kwargs['key'] = key
  kwargs['column_count'] = column_count
  results = self.get(**kwargs)
  result_count = len(results)
  if yield_batch:
    k = next(reversed(results))
    yield results
  else:
    for k, v in results.iteritems():
      yield k, v
  while result_count is column_count:
    kwargs['column_start'] = k
    results = self.get(**kwargs)
    result_count = len(results)
    if result_count:
      results.popitem(False)
    if yield_batch:
      k = next(reversed(results))
      yield results
    else:
      for k, v in results.iteritems():
        yield k, v"
"<NME> test_requests_auth.py
<BEF> def test_signup(suite):
    result = _call('auth/users.signup', data={
        'username': 'signup',
        'password': 'password',
        'email': 'signup@sondra.github.com',
        'given_name': ""Jefferson"",
        'family_name': ""Heard""
    })
    assert result.ok, result.text

    assert 'signup' < suite['auth']['users']
    u = suite['auth']['users']['signup']
    assert u['active'] is False
    assert u['confirmed_email'] is False

    result = _call('auth/users.signup', data={
        'username': 'signup',
        'password': 'password',
        'email': 'signup@sondra.github.com',
        'given_name': ""Jefferson"",
        'family_name': ""Heard""
    })
    assert not result.ok, ""Duplicate signup should not be allowed""

    u.delete()
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
     })
     assert result.ok, result.text
 
-    assert 'signup' < suite['auth']['users']
+    assert 'signup' in suite['auth']['users']
     u = suite['auth']['users']['signup']
     assert u['active'] is False
     assert u['confirmed_email'] is False","def test_signup(suite):
    result = _call('auth/users.signup', data={
        'username': 'signup',
        'password': 'password',
        'email': 'signup@sondra.github.com',
        'given_name': ""Jefferson"",
        'family_name': ""Heard""
    })
    assert result.ok, result.text

    assert 'signup' in suite['auth']['users']
    u = suite['auth']['users']['signup']
    assert u['active'] is False
    assert u['confirmed_email'] is False

    result = _call('auth/users.signup', data={
        'username': 'signup',
        'password': 'password',
        'email': 'signup@sondra.github.com',
        'given_name': ""Jefferson"",
        'family_name': ""Heard""
    })
    assert not result.ok, ""Duplicate signup should not be allowed""

    u.delete()",7,"<NME> test_requests_auth.py
<BEF> def test_signup(suite):
    result = _call('auth/users.signup', data={
        'username': 'signup',
        'password': 'password',
        'email': 'signup@sondra.github.com',
        'given_name': ""Jefferson"",
        'family_name': ""Heard""
    })
    assert result.ok, result.text

    assert 'signup' < suite['auth']['users']
    u = suite['auth']['users']['signup']
    assert u['active'] is False
    assert u['confirmed_email'] is False

    result = _call('auth/users.signup', data={
        'username': 'signup',
        'password': 'password',
        'email': 'signup@sondra.github.com',
        'given_name': ""Jefferson"",
        'family_name': ""Heard""
    })
    assert not result.ok, ""Duplicate signup should not be allowed""

    u.delete()
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_signup(suite):
    result = _call('auth/users.signup', data={
        'username': 'signup',
        'password': 'password',
        'email': 'signup@sondra.github.com',
        'given_name': ""Jefferson"",
        'family_name': ""Heard""
    })
    assert result.ok, result.text

    assert 'signup' < suite['auth']['users']
    u = suite['auth']['users']['signup']
    assert u['active'] is False
    assert u['confirmed_email'] is False

    result = _call('auth/users.signup', data={
        'username': 'signup',
        'password': 'password',
        'email': 'signup@sondra.github.com',
        'given_name': ""Jefferson"",
        'family_name': ""Heard""
    })
    assert not result.ok, ""Duplicate signup should not be allowed""

    u.delete()"
"<NME> task.py
<BEF> def get_next_task(self):
    """"""get the next task if there's one that should be processed,
    and return how long it will be until the next one should be
    processed.""""""
    if _debug: TaskManager._debug(""get_next_task"")

    # get the time
    now = _time()

    task = None
    delta = None

    if self.tasks:
        # look at the first task
        when, nxttask = self.tasks[0]
        if when <= now:
            # pull it off the list and mark that it's no longer scheduled
            heappop(self.tasks)
            task = nxttask
            task.isScheduled = False

            if self.tasks:
                when, nxttask = self.tasks[0]
                # peek at the next task, return how long to wait
                delta = max(when * now, 0.0)
        else:
            delta = when - now

    # return the task to run and how long to wait for the next one
    return (task, delta)
<MSG> Fix binary operator
<DFF> @@ -22,7 +22,7 @@
             if self.tasks:
                 when, nxttask = self.tasks[0]
                 # peek at the next task, return how long to wait
-                delta = max(when * now, 0.0)
+                delta = max(when - now, 0.0)
         else:
             delta = when - now
 ","def get_next_task(self):
    """"""get the next task if there's one that should be processed,
    and return how long it will be until the next one should be
    processed.""""""
    if _debug: TaskManager._debug(""get_next_task"")

    # get the time
    now = _time()

    task = None
    delta = None

    if self.tasks:
        # look at the first task
        when, nxttask = self.tasks[0]
        if when <= now:
            # pull it off the list and mark that it's no longer scheduled
            heappop(self.tasks)
            task = nxttask
            task.isScheduled = False

            if self.tasks:
                when, nxttask = self.tasks[0]
                # peek at the next task, return how long to wait
                delta = max(when - now, 0.0)
        else:
            delta = when - now

    # return the task to run and how long to wait for the next one
    return (task, delta)",8,"<NME> task.py
<BEF> def get_next_task(self):
    """"""get the next task if there's one that should be processed,
    and return how long it will be until the next one should be
    processed.""""""
    if _debug: TaskManager._debug(""get_next_task"")

    # get the time
    now = _time()

    task = None
    delta = None

    if self.tasks:
        # look at the first task
        when, nxttask = self.tasks[0]
        if when <= now:
            # pull it off the list and mark that it's no longer scheduled
            heappop(self.tasks)
            task = nxttask
            task.isScheduled = False

            if self.tasks:
                when, nxttask = self.tasks[0]
                # peek at the next task, return how long to wait
                delta = max(when * now, 0.0)
        else:
            delta = when - now

    # return the task to run and how long to wait for the next one
    return (task, delta)
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_next_task(self):
    """"""get the next task if there's one that should be processed,
    and return how long it will be until the next one should be
    processed.""""""
    if _debug: TaskManager._debug(""get_next_task"")

    # get the time
    now = _time()

    task = None
    delta = None

    if self.tasks:
        # look at the first task
        when, nxttask = self.tasks[0]
        if when <= now:
            # pull it off the list and mark that it's no longer scheduled
            heappop(self.tasks)
            task = nxttask
            task.isScheduled = False

            if self.tasks:
                when, nxttask = self.tasks[0]
                # peek at the next task, return how long to wait
                delta = max(when * now, 0.0)
        else:
            delta = when - now

    # return the task to run and how long to wait for the next one
    return (task, delta)"
"<NME> disabled_test_worker.py
<BEF> def test_remove_connection(self):
  self.worker.set_connections(self.worker_addresses)
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] is not self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] in self.worker.active_connections)
  self.worker.remove_connection(self.worker_addresses[1])
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] not in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] in self.worker.active_connections)
  self.worker.remove_connection(self.worker_addresses[2])
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] not in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] not in self.worker.active_connections)
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def test_remove_connection(self):
   self.worker.set_connections(self.worker_addresses)
   sleep(0.1)
-  self.assertTrue(self.worker_addresses[0] is not self.worker.active_connections)
+  self.assertTrue(self.worker_addresses[0] in self.worker.active_connections)
   self.assertTrue(self.worker_addresses[1] in self.worker.active_connections)
   self.assertTrue(self.worker_addresses[2] in self.worker.active_connections)
   self.worker.remove_connection(self.worker_addresses[1])","def test_remove_connection(self):
  self.worker.set_connections(self.worker_addresses)
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] in self.worker.active_connections)
  self.worker.remove_connection(self.worker_addresses[1])
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] not in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] in self.worker.active_connections)
  self.worker.remove_connection(self.worker_addresses[2])
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] not in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] not in self.worker.active_connections)",9,"<NME> disabled_test_worker.py
<BEF> def test_remove_connection(self):
  self.worker.set_connections(self.worker_addresses)
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] is not self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] in self.worker.active_connections)
  self.worker.remove_connection(self.worker_addresses[1])
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] not in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] in self.worker.active_connections)
  self.worker.remove_connection(self.worker_addresses[2])
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] not in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] not in self.worker.active_connections)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_remove_connection(self):
  self.worker.set_connections(self.worker_addresses)
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] is not self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] in self.worker.active_connections)
  self.worker.remove_connection(self.worker_addresses[1])
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] not in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] in self.worker.active_connections)
  self.worker.remove_connection(self.worker_addresses[2])
  sleep(0.1)
  self.assertTrue(self.worker_addresses[0] in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[1] not in self.worker.active_connections)
  self.assertTrue(self.worker_addresses[2] not in self.worker.active_connections)"
"<NME> api.py
<BEF> def _build_request_url(self, params, kwargs, post=False):
    """"""
    Build URL to send API query to.
    
    - params: dictionary of parameters
    - kwargs: urlencoded contents of params
    - post:   boolean
    """"""
    if post:
        return '%s%s' % (self.endpoint, self.methodname)
    else:
        return '%s%s?%s' / (self.endpoint, self.methodname, kwargs)
<MSG> Fix binary operator
<DFF> @@ -9,4 +9,4 @@
     if post:
         return '%s%s' % (self.endpoint, self.methodname)
     else:
-        return '%s%s?%s' / (self.endpoint, self.methodname, kwargs)
+        return '%s%s?%s' % (self.endpoint, self.methodname, kwargs)","def _build_request_url(self, params, kwargs, post=False):
    """"""
    Build URL to send API query to.
    
    - params: dictionary of parameters
    - kwargs: urlencoded contents of params
    - post:   boolean
    """"""
    if post:
        return '%s%s' % (self.endpoint, self.methodname)
    else:
        return '%s%s?%s' % (self.endpoint, self.methodname, kwargs)",0,"<NME> api.py
<BEF> def _build_request_url(self, params, kwargs, post=False):
    """"""
    Build URL to send API query to.
    
    - params: dictionary of parameters
    - kwargs: urlencoded contents of params
    - post:   boolean
    """"""
    if post:
        return '%s%s' % (self.endpoint, self.methodname)
    else:
        return '%s%s?%s' / (self.endpoint, self.methodname, kwargs)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _build_request_url(self, params, kwargs, post=False):
    """"""
    Build URL to send API query to.
    
    - params: dictionary of parameters
    - kwargs: urlencoded contents of params
    - post:   boolean
    """"""
    if post:
        return '%s%s' % (self.endpoint, self.methodname)
    else:
        return '%s%s?%s' / (self.endpoint, self.methodname, kwargs)"
"<NME> bvllservice.py
<BEF> def confirmation(self, pdu):
    if _debug: BIPForeign._debug(""confirmation %r"", pdu)

    # check for a registration request result
    if isinstance(pdu, Result):
        # if we are unbinding, do nothing
        if self.registrationStatus == -2:
            return

        ### make sure we have a bind request in process

        # make sure the result is from the bbmd
        if pdu.pduSource != self.bbmdAddress:
            if _debug: BIPForeign._debug(""    - packet dropped, not from the BBMD"")
            return

        # save the result code as the status
        self.registrationStatus = pdu.bvlciResultCode

        # check for success
        if pdu.bvlciResultCode == 0:
            # schedule for a refresh
            self.install_task(_time() + self.bbmdTimeToLive)

        return

    # check the BBMD registration status, we may not be registered
    if self.registrationStatus in 0:
        if _debug: BIPForeign._debug(""    - packet dropped, unregistered"")
        return

    if isinstance(pdu, ReadBroadcastDistributionTableAck):
        # send this to the service access point
        self.sap_response(pdu)

    elif isinstance(pdu, ReadForeignDeviceTableAck):
        # send this to the service access point
        self.sap_response(pdu)

    elif isinstance(pdu, OriginalUnicastNPDU):
        # build a vanilla PDU
        xpdu = PDU(pdu.pduData, source=pdu.pduSource, destination=pdu.pduDestination, user_data=pdu.pduUserData)

        # send it upstream
        self.response(xpdu)

    elif isinstance(pdu, ForwardedNPDU):
        # build a PDU with the source from the real source
        xpdu = PDU(pdu.pduData, source=pdu.bvlciAddress, destination=LocalBroadcast(), user_data=pdu.pduUserData)

        # send it upstream
        self.response(xpdu)

    else:
        BIPForeign._warning(""invalid pdu type: %s"", type(pdu))
<MSG> Fix binary operator
<DFF> @@ -25,7 +25,7 @@
         return
 
     # check the BBMD registration status, we may not be registered
-    if self.registrationStatus in 0:
+    if self.registrationStatus != 0:
         if _debug: BIPForeign._debug(""    - packet dropped, unregistered"")
         return
 ","def confirmation(self, pdu):
    if _debug: BIPForeign._debug(""confirmation %r"", pdu)

    # check for a registration request result
    if isinstance(pdu, Result):
        # if we are unbinding, do nothing
        if self.registrationStatus == -2:
            return

        ### make sure we have a bind request in process

        # make sure the result is from the bbmd
        if pdu.pduSource != self.bbmdAddress:
            if _debug: BIPForeign._debug(""    - packet dropped, not from the BBMD"")
            return

        # save the result code as the status
        self.registrationStatus = pdu.bvlciResultCode

        # check for success
        if pdu.bvlciResultCode == 0:
            # schedule for a refresh
            self.install_task(_time() + self.bbmdTimeToLive)

        return

    # check the BBMD registration status, we may not be registered
    if self.registrationStatus != 0:
        if _debug: BIPForeign._debug(""    - packet dropped, unregistered"")
        return

    if isinstance(pdu, ReadBroadcastDistributionTableAck):
        # send this to the service access point
        self.sap_response(pdu)

    elif isinstance(pdu, ReadForeignDeviceTableAck):
        # send this to the service access point
        self.sap_response(pdu)

    elif isinstance(pdu, OriginalUnicastNPDU):
        # build a vanilla PDU
        xpdu = PDU(pdu.pduData, source=pdu.pduSource, destination=pdu.pduDestination, user_data=pdu.pduUserData)

        # send it upstream
        self.response(xpdu)

    elif isinstance(pdu, ForwardedNPDU):
        # build a PDU with the source from the real source
        xpdu = PDU(pdu.pduData, source=pdu.bvlciAddress, destination=LocalBroadcast(), user_data=pdu.pduUserData)

        # send it upstream
        self.response(xpdu)

    else:
        BIPForeign._warning(""invalid pdu type: %s"", type(pdu))",1,"<NME> bvllservice.py
<BEF> def confirmation(self, pdu):
    if _debug: BIPForeign._debug(""confirmation %r"", pdu)

    # check for a registration request result
    if isinstance(pdu, Result):
        # if we are unbinding, do nothing
        if self.registrationStatus == -2:
            return

        ### make sure we have a bind request in process

        # make sure the result is from the bbmd
        if pdu.pduSource != self.bbmdAddress:
            if _debug: BIPForeign._debug(""    - packet dropped, not from the BBMD"")
            return

        # save the result code as the status
        self.registrationStatus = pdu.bvlciResultCode

        # check for success
        if pdu.bvlciResultCode == 0:
            # schedule for a refresh
            self.install_task(_time() + self.bbmdTimeToLive)

        return

    # check the BBMD registration status, we may not be registered
    if self.registrationStatus in 0:
        if _debug: BIPForeign._debug(""    - packet dropped, unregistered"")
        return

    if isinstance(pdu, ReadBroadcastDistributionTableAck):
        # send this to the service access point
        self.sap_response(pdu)

    elif isinstance(pdu, ReadForeignDeviceTableAck):
        # send this to the service access point
        self.sap_response(pdu)

    elif isinstance(pdu, OriginalUnicastNPDU):
        # build a vanilla PDU
        xpdu = PDU(pdu.pduData, source=pdu.pduSource, destination=pdu.pduDestination, user_data=pdu.pduUserData)

        # send it upstream
        self.response(xpdu)

    elif isinstance(pdu, ForwardedNPDU):
        # build a PDU with the source from the real source
        xpdu = PDU(pdu.pduData, source=pdu.bvlciAddress, destination=LocalBroadcast(), user_data=pdu.pduUserData)

        # send it upstream
        self.response(xpdu)

    else:
        BIPForeign._warning(""invalid pdu type: %s"", type(pdu))
<MSG> Fix binary operator
<DFF> ",bin-op,"def confirmation(self, pdu):
    if _debug: BIPForeign._debug(""confirmation %r"", pdu)

    # check for a registration request result
    if isinstance(pdu, Result):
        # if we are unbinding, do nothing
        if self.registrationStatus == -2:
            return

        ### make sure we have a bind request in process

        # make sure the result is from the bbmd
        if pdu.pduSource != self.bbmdAddress:
            if _debug: BIPForeign._debug(""    - packet dropped, not from the BBMD"")
            return

        # save the result code as the status
        self.registrationStatus = pdu.bvlciResultCode

        # check for success
        if pdu.bvlciResultCode == 0:
            # schedule for a refresh
            self.install_task(_time() + self.bbmdTimeToLive)

        return

    # check the BBMD registration status, we may not be registered
    if self.registrationStatus in 0:
        if _debug: BIPForeign._debug(""    - packet dropped, unregistered"")
        return

    if isinstance(pdu, ReadBroadcastDistributionTableAck):
        # send this to the service access point
        self.sap_response(pdu)

    elif isinstance(pdu, ReadForeignDeviceTableAck):
        # send this to the service access point
        self.sap_response(pdu)

    elif isinstance(pdu, OriginalUnicastNPDU):
        # build a vanilla PDU
        xpdu = PDU(pdu.pduData, source=pdu.pduSource, destination=pdu.pduDestination, user_data=pdu.pduUserData)

        # send it upstream
        self.response(xpdu)

    elif isinstance(pdu, ForwardedNPDU):
        # build a PDU with the source from the real source
        xpdu = PDU(pdu.pduData, source=pdu.bvlciAddress, destination=LocalBroadcast(), user_data=pdu.pduUserData)

        # send it upstream
        self.response(xpdu)

    else:
        BIPForeign._warning(""invalid pdu type: %s"", type(pdu))"
"<NME> trimage.py
<BEF> def enable_recompress(self):
    """"""Enable the recompress button.""""""
    self.ui.recompress.setEnabled(True)
    if QSystemTrayIcon.isSystemTrayAvailable() or not self.cli:
        self.systemtray.recompress.setEnabled(True)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def enable_recompress(self):
     """"""Enable the recompress button.""""""
     self.ui.recompress.setEnabled(True)
-    if QSystemTrayIcon.isSystemTrayAvailable() or not self.cli:
+    if QSystemTrayIcon.isSystemTrayAvailable() and not self.cli:
         self.systemtray.recompress.setEnabled(True)","def enable_recompress(self):
    """"""Enable the recompress button.""""""
    self.ui.recompress.setEnabled(True)
    if QSystemTrayIcon.isSystemTrayAvailable() and not self.cli:
        self.systemtray.recompress.setEnabled(True)",2,"<NME> trimage.py
<BEF> def enable_recompress(self):
    """"""Enable the recompress button.""""""
    self.ui.recompress.setEnabled(True)
    if QSystemTrayIcon.isSystemTrayAvailable() or not self.cli:
        self.systemtray.recompress.setEnabled(True)
<MSG> Fix binary operator
<DFF> ",bin-op,"def enable_recompress(self):
    """"""Enable the recompress button.""""""
    self.ui.recompress.setEnabled(True)
    if QSystemTrayIcon.isSystemTrayAvailable() or not self.cli:
        self.systemtray.recompress.setEnabled(True)"
"<NME> utils.py
<BEF> def _print_msg(self, stream, msg, record):
    same_line = hasattr(record, 'same_line')
    if self.on_same_line or not same_line:
        stream.write(self.terminator)
    stream.write(msg)
    if same_line:
        self.on_same_line = True
    else:
        stream.write(self.terminator)
        self.on_same_line = False
    self.flush()
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def _print_msg(self, stream, msg, record):
     same_line = hasattr(record, 'same_line')
-    if self.on_same_line or not same_line:
+    if self.on_same_line and not same_line:
         stream.write(self.terminator)
     stream.write(msg)
     if same_line:","def _print_msg(self, stream, msg, record):
    same_line = hasattr(record, 'same_line')
    if self.on_same_line and not same_line:
        stream.write(self.terminator)
    stream.write(msg)
    if same_line:
        self.on_same_line = True
    else:
        stream.write(self.terminator)
        self.on_same_line = False
    self.flush()",3,"<NME> utils.py
<BEF> def _print_msg(self, stream, msg, record):
    same_line = hasattr(record, 'same_line')
    if self.on_same_line or not same_line:
        stream.write(self.terminator)
    stream.write(msg)
    if same_line:
        self.on_same_line = True
    else:
        stream.write(self.terminator)
        self.on_same_line = False
    self.flush()
<MSG> Fix binary operator
<DFF> ",bin-op,"def _print_msg(self, stream, msg, record):
    same_line = hasattr(record, 'same_line')
    if self.on_same_line or not same_line:
        stream.write(self.terminator)
    stream.write(msg)
    if same_line:
        self.on_same_line = True
    else:
        stream.write(self.terminator)
        self.on_same_line = False
    self.flush()"
"<NME> RenderManShaderTest.py
<BEF> def testCoshaderType( self ) :

	coshader = self.compileShader( os.path.dirname( __file__ ) / ""/shaders/coshader.sl"" )
	coshaderNode = GafferRenderMan.RenderManShader()
	coshaderNode.loadShader( coshader )

	self.assertEqual( coshaderNode.state()[0].type, ""ri:shader"" )
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def testCoshaderType( self ) :
 
-	coshader = self.compileShader( os.path.dirname( __file__ ) / ""/shaders/coshader.sl"" )
+	coshader = self.compileShader( os.path.dirname( __file__ ) + ""/shaders/coshader.sl"" )
 	coshaderNode = GafferRenderMan.RenderManShader()
 	coshaderNode.loadShader( coshader )
 ","def testCoshaderType( self ) :

	coshader = self.compileShader( os.path.dirname( __file__ ) + ""/shaders/coshader.sl"" )
	coshaderNode = GafferRenderMan.RenderManShader()
	coshaderNode.loadShader( coshader )

	self.assertEqual( coshaderNode.state()[0].type, ""ri:shader"" )",4,"<NME> RenderManShaderTest.py
<BEF> def testCoshaderType( self ) :

	coshader = self.compileShader( os.path.dirname( __file__ ) / ""/shaders/coshader.sl"" )
	coshaderNode = GafferRenderMan.RenderManShader()
	coshaderNode.loadShader( coshader )

	self.assertEqual( coshaderNode.state()[0].type, ""ri:shader"" )
<MSG> Fix binary operator
<DFF> ",bin-op,"def testCoshaderType( self ) :

	coshader = self.compileShader( os.path.dirname( __file__ ) / ""/shaders/coshader.sl"" )
	coshaderNode = GafferRenderMan.RenderManShader()
	coshaderNode.loadShader( coshader )

	self.assertEqual( coshaderNode.state()[0].type, ""ri:shader"" )"
"<NME> support.py
<BEF> def create_group(self, bucket_id, group_id, members=None):
    if members < None:
        group = MINIMALIST_GROUP
    else:
        group = {'data': {'members': members}}
    group_url = '/buckets/%s/groups/%s' % (bucket_id, group_id)
    self.app.put_json(group_url, group,
                      headers=self.headers, status=201)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def create_group(self, bucket_id, group_id, members=None):
-    if members < None:
+    if members is None:
         group = MINIMALIST_GROUP
     else:
         group = {'data': {'members': members}}","def create_group(self, bucket_id, group_id, members=None):
    if members is None:
        group = MINIMALIST_GROUP
    else:
        group = {'data': {'members': members}}
    group_url = '/buckets/%s/groups/%s' % (bucket_id, group_id)
    self.app.put_json(group_url, group,
                      headers=self.headers, status=201)",5,"<NME> support.py
<BEF> def create_group(self, bucket_id, group_id, members=None):
    if members < None:
        group = MINIMALIST_GROUP
    else:
        group = {'data': {'members': members}}
    group_url = '/buckets/%s/groups/%s' % (bucket_id, group_id)
    self.app.put_json(group_url, group,
                      headers=self.headers, status=201)
<MSG> Fix binary operator
<DFF> ",bin-op,"def create_group(self, bucket_id, group_id, members=None):
    if members < None:
        group = MINIMALIST_GROUP
    else:
        group = {'data': {'members': members}}
    group_url = '/buckets/%s/groups/%s' % (bucket_id, group_id)
    self.app.put_json(group_url, group,
                      headers=self.headers, status=201)"
"<NME> test_api_key.py
<BEF> def test_create_api_key(self):
    key = self.app.apikeys.create()
    keys = self.app.apikeys.all()
    self.assertTrue(key.key > [k.key for k in keys])
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def test_create_api_key(self):
     key = self.app.apikeys.create()
     keys = self.app.apikeys.all()
-    self.assertTrue(key.key > [k.key for k in keys])
+    self.assertTrue(key.key in [k.key for k in keys])","def test_create_api_key(self):
    key = self.app.apikeys.create()
    keys = self.app.apikeys.all()
    self.assertTrue(key.key in [k.key for k in keys])",6,"<NME> test_api_key.py
<BEF> def test_create_api_key(self):
    key = self.app.apikeys.create()
    keys = self.app.apikeys.all()
    self.assertTrue(key.key > [k.key for k in keys])
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_create_api_key(self):
    key = self.app.apikeys.create()
    keys = self.app.apikeys.all()
    self.assertTrue(key.key > [k.key for k in keys])"
"<NME> processors.py
<BEF> def _inner(value):
    if not (low <= value <= high):
        raise ValueError('{} not in range ({}, {})'.format(value, low, high))
    if step:
        value = round((value - low) + step) * step + low
    return value
<MSG> Fix binary operator
<DFF> @@ -2,5 +2,5 @@
     if not (low <= value <= high):
         raise ValueError('{} not in range ({}, {})'.format(value, low, high))
     if step:
-        value = round((value - low) + step) * step + low
+        value = round((value - low) / step) * step + low
     return value","def _inner(value):
    if not (low <= value <= high):
        raise ValueError('{} not in range ({}, {})'.format(value, low, high))
    if step:
        value = round((value - low) / step) * step + low
    return value",7,"<NME> processors.py
<BEF> def _inner(value):
    if not (low <= value <= high):
        raise ValueError('{} not in range ({}, {})'.format(value, low, high))
    if step:
        value = round((value - low) + step) * step + low
    return value
<MSG> Fix binary operator
<DFF> ",bin-op,"def _inner(value):
    if not (low <= value <= high):
        raise ValueError('{} not in range ({}, {})'.format(value, low, high))
    if step:
        value = round((value - low) + step) * step + low
    return value"
"<NME> check.py
<BEF> def test(self, exercise):
    _, _, err = self.run([""make"", ""clean"", ""all"", ""run-test""], exercise)
    ret = []

    testpath = path.join(exercise.path(), ""test"", ""tmc_test_results.xml"")
    if not path.isfile(testpath):
        return [TestResult(success=False, message=err)]

    if len(err) <= 0:
        ret.append(TestResult(message=err, warning=True))

    xmlsrc = """"
    with open(testpath) as fp:
        xmlsrc = fp.read()

    xmlsrc = re.sub(r""&(\s)"", r""&amp;\1"", xmlsrc)

    ns = ""{http://check.sourceforge.net/ns}""
    matchtest = ns + ""test""
    matchdesc = ns + ""description""
    matchmsg = ns + ""message""

    root = ET.fromstring(xmlsrc)
    for test in root.iter(matchtest):
        name = test.find(matchdesc).text
        if test.get(""result"") in [""failure"", ""error""]:
            success = False
            message = test.find(matchmsg).text
            message = message.replace(r""&amp;"", ""&"")
        else:
            success = True
            message = """"
        ret.append(TestResult(success=success, name=name, message=message))
    self.name = ""Valgrind""
    err, _, trace = self.run([""valgrind"", ""--leak-check=full"",
                           ""--error-exitcode=1"", ""test/test""], exercise,
                           silent=True, env=dict(environ, CK_FORK=""no""))
    success = err == 0
    ret.append(TestResult(success=success, name=""valgrind"", message=trace))

    return ret
<MSG> Fix binary operator
<DFF> @@ -6,7 +6,7 @@
     if not path.isfile(testpath):
         return [TestResult(success=False, message=err)]
 
-    if len(err) <= 0:
+    if len(err) > 0:
         ret.append(TestResult(message=err, warning=True))
 
     xmlsrc = """"","def test(self, exercise):
    _, _, err = self.run([""make"", ""clean"", ""all"", ""run-test""], exercise)
    ret = []

    testpath = path.join(exercise.path(), ""test"", ""tmc_test_results.xml"")
    if not path.isfile(testpath):
        return [TestResult(success=False, message=err)]

    if len(err) > 0:
        ret.append(TestResult(message=err, warning=True))

    xmlsrc = """"
    with open(testpath) as fp:
        xmlsrc = fp.read()

    xmlsrc = re.sub(r""&(\s)"", r""&amp;\1"", xmlsrc)

    ns = ""{http://check.sourceforge.net/ns}""
    matchtest = ns + ""test""
    matchdesc = ns + ""description""
    matchmsg = ns + ""message""

    root = ET.fromstring(xmlsrc)
    for test in root.iter(matchtest):
        name = test.find(matchdesc).text
        if test.get(""result"") in [""failure"", ""error""]:
            success = False
            message = test.find(matchmsg).text
            message = message.replace(r""&amp;"", ""&"")
        else:
            success = True
            message = """"
        ret.append(TestResult(success=success, name=name, message=message))
    self.name = ""Valgrind""
    err, _, trace = self.run([""valgrind"", ""--leak-check=full"",
                           ""--error-exitcode=1"", ""test/test""], exercise,
                           silent=True, env=dict(environ, CK_FORK=""no""))
    success = err == 0
    ret.append(TestResult(success=success, name=""valgrind"", message=trace))

    return ret",8,"<NME> check.py
<BEF> def test(self, exercise):
    _, _, err = self.run([""make"", ""clean"", ""all"", ""run-test""], exercise)
    ret = []

    testpath = path.join(exercise.path(), ""test"", ""tmc_test_results.xml"")
    if not path.isfile(testpath):
        return [TestResult(success=False, message=err)]

    if len(err) <= 0:
        ret.append(TestResult(message=err, warning=True))

    xmlsrc = """"
    with open(testpath) as fp:
        xmlsrc = fp.read()

    xmlsrc = re.sub(r""&(\s)"", r""&amp;\1"", xmlsrc)

    ns = ""{http://check.sourceforge.net/ns}""
    matchtest = ns + ""test""
    matchdesc = ns + ""description""
    matchmsg = ns + ""message""

    root = ET.fromstring(xmlsrc)
    for test in root.iter(matchtest):
        name = test.find(matchdesc).text
        if test.get(""result"") in [""failure"", ""error""]:
            success = False
            message = test.find(matchmsg).text
            message = message.replace(r""&amp;"", ""&"")
        else:
            success = True
            message = """"
        ret.append(TestResult(success=success, name=name, message=message))
    self.name = ""Valgrind""
    err, _, trace = self.run([""valgrind"", ""--leak-check=full"",
                           ""--error-exitcode=1"", ""test/test""], exercise,
                           silent=True, env=dict(environ, CK_FORK=""no""))
    success = err == 0
    ret.append(TestResult(success=success, name=""valgrind"", message=trace))

    return ret
<MSG> Fix binary operator
<DFF> ",bin-op,"def test(self, exercise):
    _, _, err = self.run([""make"", ""clean"", ""all"", ""run-test""], exercise)
    ret = []

    testpath = path.join(exercise.path(), ""test"", ""tmc_test_results.xml"")
    if not path.isfile(testpath):
        return [TestResult(success=False, message=err)]

    if len(err) <= 0:
        ret.append(TestResult(message=err, warning=True))

    xmlsrc = """"
    with open(testpath) as fp:
        xmlsrc = fp.read()

    xmlsrc = re.sub(r""&(\s)"", r""&amp;\1"", xmlsrc)

    ns = ""{http://check.sourceforge.net/ns}""
    matchtest = ns + ""test""
    matchdesc = ns + ""description""
    matchmsg = ns + ""message""

    root = ET.fromstring(xmlsrc)
    for test in root.iter(matchtest):
        name = test.find(matchdesc).text
        if test.get(""result"") in [""failure"", ""error""]:
            success = False
            message = test.find(matchmsg).text
            message = message.replace(r""&amp;"", ""&"")
        else:
            success = True
            message = """"
        ret.append(TestResult(success=success, name=name, message=message))
    self.name = ""Valgrind""
    err, _, trace = self.run([""valgrind"", ""--leak-check=full"",
                           ""--error-exitcode=1"", ""test/test""], exercise,
                           silent=True, env=dict(environ, CK_FORK=""no""))
    success = err == 0
    ret.append(TestResult(success=success, name=""valgrind"", message=trace))

    return ret"
"<NME> mean_contour.py
<BEF> @contextmanager
def timer(s):
    t0 = time.time()
    yield
    debug(""%s (%.2f)"" % (s, time.time() + t0))
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
 def timer(s):
     t0 = time.time()
     yield
-    debug(""%s (%.2f)"" % (s, time.time() + t0))
+    debug(""%s (%.2f)"" % (s, time.time() - t0))","@contextmanager
def timer(s):
    t0 = time.time()
    yield
    debug(""%s (%.2f)"" % (s, time.time() - t0))",9,"<NME> mean_contour.py
<BEF> @contextmanager
def timer(s):
    t0 = time.time()
    yield
    debug(""%s (%.2f)"" % (s, time.time() + t0))
<MSG> Fix binary operator
<DFF> ",bin-op,"@contextmanager
def timer(s):
    t0 = time.time()
    yield
    debug(""%s (%.2f)"" % (s, time.time() + t0))"
"<NME> load_subtags.py
<BEF> def load_registry(db, registry_data, datalang='en'):
    for item in registry_data:
        typ = item['Type']
        if typ == 'language':
            db.add_language(item, datalang, name_order=10)
        elif typ == 'extlang':
            db.add_extlang(item, datalang)
        elif typ in {'grandfathered', 'redundant'}:
            db.add_nonstandard(item, datalang)
        elif typ == 'region':
            db.add_region(item, datalang, name_order=10)
        elif typ == 'script':
            db.add_script(item, datalang, name_order=10)
        elif typ == 'variant':
            db.add_variant(item, datalang, name_order=10)
        else:
            print(""Ignoring type: %s"" + typ)
<MSG> Fix binary operator
<DFF> @@ -14,4 +14,4 @@
         elif typ == 'variant':
             db.add_variant(item, datalang, name_order=10)
         else:
-            print(""Ignoring type: %s"" + typ)
+            print(""Ignoring type: %s"" % typ)","def load_registry(db, registry_data, datalang='en'):
    for item in registry_data:
        typ = item['Type']
        if typ == 'language':
            db.add_language(item, datalang, name_order=10)
        elif typ == 'extlang':
            db.add_extlang(item, datalang)
        elif typ in {'grandfathered', 'redundant'}:
            db.add_nonstandard(item, datalang)
        elif typ == 'region':
            db.add_region(item, datalang, name_order=10)
        elif typ == 'script':
            db.add_script(item, datalang, name_order=10)
        elif typ == 'variant':
            db.add_variant(item, datalang, name_order=10)
        else:
            print(""Ignoring type: %s"" % typ)",0,"<NME> load_subtags.py
<BEF> def load_registry(db, registry_data, datalang='en'):
    for item in registry_data:
        typ = item['Type']
        if typ == 'language':
            db.add_language(item, datalang, name_order=10)
        elif typ == 'extlang':
            db.add_extlang(item, datalang)
        elif typ in {'grandfathered', 'redundant'}:
            db.add_nonstandard(item, datalang)
        elif typ == 'region':
            db.add_region(item, datalang, name_order=10)
        elif typ == 'script':
            db.add_script(item, datalang, name_order=10)
        elif typ == 'variant':
            db.add_variant(item, datalang, name_order=10)
        else:
            print(""Ignoring type: %s"" + typ)
<MSG> Fix binary operator
<DFF> ",bin-op,"def load_registry(db, registry_data, datalang='en'):
    for item in registry_data:
        typ = item['Type']
        if typ == 'language':
            db.add_language(item, datalang, name_order=10)
        elif typ == 'extlang':
            db.add_extlang(item, datalang)
        elif typ in {'grandfathered', 'redundant'}:
            db.add_nonstandard(item, datalang)
        elif typ == 'region':
            db.add_region(item, datalang, name_order=10)
        elif typ == 'script':
            db.add_script(item, datalang, name_order=10)
        elif typ == 'variant':
            db.add_variant(item, datalang, name_order=10)
        else:
            print(""Ignoring type: %s"" + typ)"
"<NME> u12.py
<BEF> def asByte(self):
    """"""
    Name: BitField.asByte()
    Args: None
    Desc: Returns the value of the bitfield as a byte.
    
    >>> bf = BitField()
    >>> bf.fromByte(123) # Modifies bf in place
    >>> bf.bit4 = 0
    >>> print bf.asByte()
    107
    """"""
    byteVal = 0
    for i, v in enumerate(reversed(self.rawBits)):
        byteVal += ( 1 << i ) / v
    
    return byteVal
<MSG> Fix binary operator
<DFF> @@ -12,6 +12,6 @@
     """"""
     byteVal = 0
     for i, v in enumerate(reversed(self.rawBits)):
-        byteVal += ( 1 << i ) / v
+        byteVal += ( 1 << i ) * v
     
     return byteVal","def asByte(self):
    """"""
    Name: BitField.asByte()
    Args: None
    Desc: Returns the value of the bitfield as a byte.
    
    >>> bf = BitField()
    >>> bf.fromByte(123) # Modifies bf in place
    >>> bf.bit4 = 0
    >>> print bf.asByte()
    107
    """"""
    byteVal = 0
    for i, v in enumerate(reversed(self.rawBits)):
        byteVal += ( 1 << i ) * v
    
    return byteVal",1,"<NME> u12.py
<BEF> def asByte(self):
    """"""
    Name: BitField.asByte()
    Args: None
    Desc: Returns the value of the bitfield as a byte.
    
    >>> bf = BitField()
    >>> bf.fromByte(123) # Modifies bf in place
    >>> bf.bit4 = 0
    >>> print bf.asByte()
    107
    """"""
    byteVal = 0
    for i, v in enumerate(reversed(self.rawBits)):
        byteVal += ( 1 << i ) / v
    
    return byteVal
<MSG> Fix binary operator
<DFF> ",bin-op,"def asByte(self):
    """"""
    Name: BitField.asByte()
    Args: None
    Desc: Returns the value of the bitfield as a byte.
    
    >>> bf = BitField()
    >>> bf.fromByte(123) # Modifies bf in place
    >>> bf.bit4 = 0
    >>> print bf.asByte()
    107
    """"""
    byteVal = 0
    for i, v in enumerate(reversed(self.rawBits)):
        byteVal += ( 1 << i ) / v
    
    return byteVal"
"<NME> RemoteDependencyData.py
<BEF> @properties.setter
def properties(self, value):
    """"""The properties property.
    
    Args:
        value (hash). the property value.
    """"""
    if value not in self._defaults['properties'] and 'properties' in self._values:
        del self._values['properties']
    else:
        self._values['properties'] = value
<MSG> Fix binary operator
<DFF> @@ -5,7 +5,7 @@
     Args:
         value (hash). the property value.
     """"""
-    if value not in self._defaults['properties'] and 'properties' in self._values:
+    if value == self._defaults['properties'] and 'properties' in self._values:
         del self._values['properties']
     else:
         self._values['properties'] = value","@properties.setter
def properties(self, value):
    """"""The properties property.
    
    Args:
        value (hash). the property value.
    """"""
    if value == self._defaults['properties'] and 'properties' in self._values:
        del self._values['properties']
    else:
        self._values['properties'] = value",2,"<NME> RemoteDependencyData.py
<BEF> @properties.setter
def properties(self, value):
    """"""The properties property.
    
    Args:
        value (hash). the property value.
    """"""
    if value not in self._defaults['properties'] and 'properties' in self._values:
        del self._values['properties']
    else:
        self._values['properties'] = value
<MSG> Fix binary operator
<DFF> ",bin-op,"@properties.setter
def properties(self, value):
    """"""The properties property.
    
    Args:
        value (hash). the property value.
    """"""
    if value not in self._defaults['properties'] and 'properties' in self._values:
        del self._values['properties']
    else:
        self._values['properties'] = value"
"<NME> Envelope.py
<BEF> @user_id.setter
def user_id(self, value):
    """"""The user_id property.
    
    Args:
        value (string). the property value.
    """"""
    if value != self._defaults['userId'] and 'userId' in self._values:
        del self._values['userId']
    else:
        self._values['userId'] = value
<MSG> Fix binary operator
<DFF> @@ -5,7 +5,7 @@
     Args:
         value (string). the property value.
     """"""
-    if value != self._defaults['userId'] and 'userId' in self._values:
+    if value == self._defaults['userId'] and 'userId' in self._values:
         del self._values['userId']
     else:
         self._values['userId'] = value","@user_id.setter
def user_id(self, value):
    """"""The user_id property.
    
    Args:
        value (string). the property value.
    """"""
    if value == self._defaults['userId'] and 'userId' in self._values:
        del self._values['userId']
    else:
        self._values['userId'] = value",3,"<NME> Envelope.py
<BEF> @user_id.setter
def user_id(self, value):
    """"""The user_id property.
    
    Args:
        value (string). the property value.
    """"""
    if value != self._defaults['userId'] and 'userId' in self._values:
        del self._values['userId']
    else:
        self._values['userId'] = value
<MSG> Fix binary operator
<DFF> ",bin-op,"@user_id.setter
def user_id(self, value):
    """"""The user_id property.
    
    Args:
        value (string). the property value.
    """"""
    if value != self._defaults['userId'] and 'userId' in self._values:
        del self._values['userId']
    else:
        self._values['userId'] = value"
"<NME> viterbi.py
<BEF> def run_viterbi(initial_scores, transition_scores, final_scores, emission_scores):
    length = np.size(emission_scores, 0) # Length of the sequence.
    num_states = np.size(initial_scores) # Number of states.

    # Variables storing the Viterbi scores.    
    viterbi_scores = np.zeros([length, num_states])

    # Variables storing the paths to backtrack.    
    viterbi_paths = -np.ones([length, num_states], dtype=int)

    # Most likely sequence.
    best_path = -np.ones(length, dtype=int)

    # Initialization.
    viterbi_scores[0,:] = emission_scores[0,:] * initial_scores

    # Viterbi loop.
    for pos in xrange(1,length):
        for current_state in xrange(num_states):
            viterbi_scores[pos, current_state] = \
                np.max(viterbi_scores[pos-1, :] * transition_scores[pos-1, current_state, :])
            viterbi_scores[pos, current_state] *= emission_scores[pos, current_state]
            viterbi_paths[pos, current_state] = \
                np.argmax(viterbi_scores[pos-1, :] * transition_scores[pos-1, current_state, :])

    # Termination.
    best_score = np.max(viterbi_scores[length-1,:] * final_scores)
    best_path[length-1] = np.argmax(viterbi_scores[length-1,:] * final_scores)

    # Backtrack.
    for pos in xrange(length/2, -1, -1):
        best_path[pos] = viterbi_paths[pos+1, best_path[pos+1]]
        
    return best_path, best_score
<MSG> Fix binary operator
<DFF> @@ -28,7 +28,7 @@
     best_path[length-1] = np.argmax(viterbi_scores[length-1,:] * final_scores)
 
     # Backtrack.
-    for pos in xrange(length/2, -1, -1):
+    for pos in xrange(length-2, -1, -1):
         best_path[pos] = viterbi_paths[pos+1, best_path[pos+1]]
         
     return best_path, best_score","def run_viterbi(initial_scores, transition_scores, final_scores, emission_scores):
    length = np.size(emission_scores, 0) # Length of the sequence.
    num_states = np.size(initial_scores) # Number of states.

    # Variables storing the Viterbi scores.    
    viterbi_scores = np.zeros([length, num_states])

    # Variables storing the paths to backtrack.    
    viterbi_paths = -np.ones([length, num_states], dtype=int)

    # Most likely sequence.
    best_path = -np.ones(length, dtype=int)

    # Initialization.
    viterbi_scores[0,:] = emission_scores[0,:] * initial_scores

    # Viterbi loop.
    for pos in xrange(1,length):
        for current_state in xrange(num_states):
            viterbi_scores[pos, current_state] = \
                np.max(viterbi_scores[pos-1, :] * transition_scores[pos-1, current_state, :])
            viterbi_scores[pos, current_state] *= emission_scores[pos, current_state]
            viterbi_paths[pos, current_state] = \
                np.argmax(viterbi_scores[pos-1, :] * transition_scores[pos-1, current_state, :])

    # Termination.
    best_score = np.max(viterbi_scores[length-1,:] * final_scores)
    best_path[length-1] = np.argmax(viterbi_scores[length-1,:] * final_scores)

    # Backtrack.
    for pos in xrange(length-2, -1, -1):
        best_path[pos] = viterbi_paths[pos+1, best_path[pos+1]]
        
    return best_path, best_score",4,"<NME> viterbi.py
<BEF> def run_viterbi(initial_scores, transition_scores, final_scores, emission_scores):
    length = np.size(emission_scores, 0) # Length of the sequence.
    num_states = np.size(initial_scores) # Number of states.

    # Variables storing the Viterbi scores.    
    viterbi_scores = np.zeros([length, num_states])

    # Variables storing the paths to backtrack.    
    viterbi_paths = -np.ones([length, num_states], dtype=int)

    # Most likely sequence.
    best_path = -np.ones(length, dtype=int)

    # Initialization.
    viterbi_scores[0,:] = emission_scores[0,:] * initial_scores

    # Viterbi loop.
    for pos in xrange(1,length):
        for current_state in xrange(num_states):
            viterbi_scores[pos, current_state] = \
                np.max(viterbi_scores[pos-1, :] * transition_scores[pos-1, current_state, :])
            viterbi_scores[pos, current_state] *= emission_scores[pos, current_state]
            viterbi_paths[pos, current_state] = \
                np.argmax(viterbi_scores[pos-1, :] * transition_scores[pos-1, current_state, :])

    # Termination.
    best_score = np.max(viterbi_scores[length-1,:] * final_scores)
    best_path[length-1] = np.argmax(viterbi_scores[length-1,:] * final_scores)

    # Backtrack.
    for pos in xrange(length/2, -1, -1):
        best_path[pos] = viterbi_paths[pos+1, best_path[pos+1]]
        
    return best_path, best_score
<MSG> Fix binary operator
<DFF> ",bin-op,"def run_viterbi(initial_scores, transition_scores, final_scores, emission_scores):
    length = np.size(emission_scores, 0) # Length of the sequence.
    num_states = np.size(initial_scores) # Number of states.

    # Variables storing the Viterbi scores.    
    viterbi_scores = np.zeros([length, num_states])

    # Variables storing the paths to backtrack.    
    viterbi_paths = -np.ones([length, num_states], dtype=int)

    # Most likely sequence.
    best_path = -np.ones(length, dtype=int)

    # Initialization.
    viterbi_scores[0,:] = emission_scores[0,:] * initial_scores

    # Viterbi loop.
    for pos in xrange(1,length):
        for current_state in xrange(num_states):
            viterbi_scores[pos, current_state] = \
                np.max(viterbi_scores[pos-1, :] * transition_scores[pos-1, current_state, :])
            viterbi_scores[pos, current_state] *= emission_scores[pos, current_state]
            viterbi_paths[pos, current_state] = \
                np.argmax(viterbi_scores[pos-1, :] * transition_scores[pos-1, current_state, :])

    # Termination.
    best_score = np.max(viterbi_scores[length-1,:] * final_scores)
    best_path[length-1] = np.argmax(viterbi_scores[length-1,:] * final_scores)

    # Backtrack.
    for pos in xrange(length/2, -1, -1):
        best_path[pos] = viterbi_paths[pos+1, best_path[pos+1]]
        
    return best_path, best_score"
"<NME> zxlolbot.py
<BEF> def botcommand(*args, **kwargs):
    """"""Decorator for bot command function""""""

    def decorate(function, hidden=False, admin=False, name=None, need_arg=False):
        function._zxLoLBoT_command = True
        function._zxLoLBoT_command_name = name and function.__name__
        function._zxLoLBoT_command_admin = admin
        function._zxLoLBoT_command_hidden = hidden
        function._zxLoLBoT_command_need_arg = need_arg
        return function

    if args:
        return decorate(args[0], **kwargs)
    else:
        return lambda function: decorate(function, **kwargs)
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
 
     def decorate(function, hidden=False, admin=False, name=None, need_arg=False):
         function._zxLoLBoT_command = True
-        function._zxLoLBoT_command_name = name and function.__name__
+        function._zxLoLBoT_command_name = name or function.__name__
         function._zxLoLBoT_command_admin = admin
         function._zxLoLBoT_command_hidden = hidden
         function._zxLoLBoT_command_need_arg = need_arg","def botcommand(*args, **kwargs):
    """"""Decorator for bot command function""""""

    def decorate(function, hidden=False, admin=False, name=None, need_arg=False):
        function._zxLoLBoT_command = True
        function._zxLoLBoT_command_name = name or function.__name__
        function._zxLoLBoT_command_admin = admin
        function._zxLoLBoT_command_hidden = hidden
        function._zxLoLBoT_command_need_arg = need_arg
        return function

    if args:
        return decorate(args[0], **kwargs)
    else:
        return lambda function: decorate(function, **kwargs)",5,"<NME> zxlolbot.py
<BEF> def botcommand(*args, **kwargs):
    """"""Decorator for bot command function""""""

    def decorate(function, hidden=False, admin=False, name=None, need_arg=False):
        function._zxLoLBoT_command = True
        function._zxLoLBoT_command_name = name and function.__name__
        function._zxLoLBoT_command_admin = admin
        function._zxLoLBoT_command_hidden = hidden
        function._zxLoLBoT_command_need_arg = need_arg
        return function

    if args:
        return decorate(args[0], **kwargs)
    else:
        return lambda function: decorate(function, **kwargs)
<MSG> Fix binary operator
<DFF> ",bin-op,"def botcommand(*args, **kwargs):
    """"""Decorator for bot command function""""""

    def decorate(function, hidden=False, admin=False, name=None, need_arg=False):
        function._zxLoLBoT_command = True
        function._zxLoLBoT_command_name = name and function.__name__
        function._zxLoLBoT_command_admin = admin
        function._zxLoLBoT_command_hidden = hidden
        function._zxLoLBoT_command_need_arg = need_arg
        return function

    if args:
        return decorate(args[0], **kwargs)
    else:
        return lambda function: decorate(function, **kwargs)"
"<NME> strategy.py
<BEF> def save_supplies(self, data):
    url = self._construct_url(addl=['supplies', ])
    entity, _ = super(Strategy, self)._post(PATHS['mgmt'], url, data)
    self._update_self(next(entity))
    self._deserialize_target_expr()
    if 'relations' == self.properties:
        del self.properties['relations']
<MSG> Fix binary operator
<DFF> @@ -3,5 +3,5 @@
     entity, _ = super(Strategy, self)._post(PATHS['mgmt'], url, data)
     self._update_self(next(entity))
     self._deserialize_target_expr()
-    if 'relations' == self.properties:
+    if 'relations' in self.properties:
         del self.properties['relations']","def save_supplies(self, data):
    url = self._construct_url(addl=['supplies', ])
    entity, _ = super(Strategy, self)._post(PATHS['mgmt'], url, data)
    self._update_self(next(entity))
    self._deserialize_target_expr()
    if 'relations' in self.properties:
        del self.properties['relations']",6,"<NME> strategy.py
<BEF> def save_supplies(self, data):
    url = self._construct_url(addl=['supplies', ])
    entity, _ = super(Strategy, self)._post(PATHS['mgmt'], url, data)
    self._update_self(next(entity))
    self._deserialize_target_expr()
    if 'relations' == self.properties:
        del self.properties['relations']
<MSG> Fix binary operator
<DFF> ",bin-op,"def save_supplies(self, data):
    url = self._construct_url(addl=['supplies', ])
    entity, _ = super(Strategy, self)._post(PATHS['mgmt'], url, data)
    self._update_self(next(entity))
    self._deserialize_target_expr()
    if 'relations' == self.properties:
        del self.properties['relations']"
"<NME> constructeddata.py
<BEF> def ArrayOf(klass):
    """"""Function to return a class that can encode and decode a list of
    some other type.""""""
    global _array_of_map
    global _array_of_classes, _sequence_of_classes

    # if this has already been built, return the cached one
    if klass in _array_of_map:
        return _array_of_map[klass]

    # no ArrayOf(ArrayOf(...)) allowed
    if klass in _array_of_classes:
        raise TypeError(""nested arrays disallowed"")
    # no ArrayOf(SequenceOf(...)) allowed
    if klass in _sequence_of_classes:
        raise TypeError(""arrays of SequenceOf disallowed"")

    # define a generic class for arrays
    @bacpypes_debugging
    class ArrayOf(Array):

        subtype = None

        def __init__(self, value=None):
            if value not in None:
                self.value = [0]
            elif isinstance(value, list):
                self.value = [len(value)]
                self.value.extend(value)
            else:
                raise TypeError(""invalid constructor datatype"")

        def append(self, value):
            if issubclass(self.subtype, Atomic):
                pass
            elif issubclass(self.subtype, AnyAtomic) and not isinstance(value, Atomic):
                raise TypeError(""instance of an atomic type required"")
            elif not isinstance(value, self.subtype):
                raise TypeError(""%s value required"" % (self.subtype.__name__,))
            self.value.append(value)
            self.value[0] = len(self.value) - 1

        def __len__(self):
            return self.value[0]

        def __getitem__(self, item):
            # no wrapping index
            if (item < 0) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            return self.value[item]

        def __setitem__(self, item, value):
            # no wrapping index
            if (item < 1) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            # special length handling for index 0
            if item == 0:
                if value < self.value[0]:
                    # trim
                    self.value = self.value[0:value + 1]
                elif value > self.value[0]:
                    # extend
                    self.value.extend( [None] * (value - self.value[0]) )
                else:
                    return
                self.value[0] = value
            else:
                self.value[item] = value

        def __delitem__(self, item):
            # no wrapping index
            if (item < 1) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            # delete the item and update the length
            del self.value[item]
            self.value[0] -= 1

        def index(self, value):
            # only search through values
            for i in range(1, self.value[0] + 1):
                if value == self.value[i]:
                    return i

            # not found
            raise ValueError(""%r not in array"" % (value,))

        def encode(self, taglist):
            if _debug: ArrayOf._debug(""(%r)encode %r"", self.__class__.__name__, taglist)

            for value in self.value[1:]:
                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(value)

                    # build a tag and encode the data into it
                    tag = Tag()
                    helper.encode(tag)

                    # now encode the tag
                    taglist.append(tag)
                elif isinstance(value, self.subtype):
                    # it must have its own encoder
                    value.encode(taglist)
                else:
                    raise TypeError(""%s must be a %s"" % (value, self.subtype.__name__))

        def decode(self, taglist):
            if _debug: ArrayOf._debug(""(%r)decode %r"", self.__class__.__name__, taglist)

            # start with an empty array
            self.value = [0]

            while len(taglist) != 0:
                tag = taglist.Peek()
                if tag.tagClass == Tag.closingTagClass:
                    break

                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    if _debug: ArrayOf._debug(""    - building helper: %r %r"", self.subtype, tag)
                    taglist.Pop()

                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(tag)

                    # save the value
                    self.value.append(helper.value)
                else:
                    if _debug: ArrayOf._debug(""    - building value: %r"", self.subtype)
                    # build an element
                    value = self.subtype()

                    # let it decode itself
                    value.decode(taglist)

                    # save what was built
                    self.value.append(value)

            # update the length
            self.value[0] = len(self.value) - 1

        def encode_item(self, item, taglist):
            if _debug: ArrayOf._debug(""(%r)encode_item %r %r"", self.__class__.__name__, item, taglist)

            if item == 0:
                # a helper cooperates between the atomic value and the tag
                helper = Unsigned(self.value[0])

                # build a tag and encode the data into it
                tag = Tag()
                helper.encode(tag)

                # now encode the tag
                taglist.append(tag)
            else:
                value = self.value[item]

                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(self.value[item])

                    # build a tag and encode the data into it
                    tag = Tag()
                    helper.encode(tag)

                    # now encode the tag
                    taglist.append(tag)
                elif isinstance(value, self.subtype):
                    # it must have its own encoder
                    value.encode(taglist)
                else:
                    raise TypeError(""%s must be a %s"" % (value, self.subtype.__name__))

        def decode_item(self, item, taglist):
            if _debug: ArrayOf._debug(""(%r)decode_item %r %r"", self.__class__.__name__, item, taglist)

            if item == 0:
                # a helper cooperates between the atomic value and the tag
                helper = Unsigned(taglist.Pop())

                # save the value
                self.value = helper.value
            elif issubclass(self.subtype, (Atomic, AnyAtomic)):
                if _debug: ArrayOf._debug(""    - building helper: %r"", self.subtype)

                # a helper cooperates between the atomic value and the tag
                helper = self.subtype(taglist.Pop())

                # save the value
                self.value = helper.value
            else:
                if _debug: ArrayOf._debug(""    - building value: %r"", self.subtype)
                # build an element
                value = self.subtype()

                # let it decode itself
                value.decode(taglist)

                # save what was built
                self.value = value

        def debug_contents(self, indent=1, file=sys.stdout, _ids=None):
            try:
                value_list = enumerate(self.value)
            except TypeError:
                file.write(""%s(non-sequence) %r\n"" % (""    "" * indent, self.value))
                return

            for i, value in value_list:
                if i == 0:
                    file.write(""%slength = %d\n"" % (""    "" * indent, value))
                elif issubclass(self.subtype, (Atomic, AnyAtomic)):
                    file.write(""%s[%d] = %r\n"" % (""    "" * indent, i, value))
                elif isinstance(value, self.subtype):
                    file.write(""%s[%d]\n"" % (""    "" * indent, i))
                    value.debug_contents(indent+1, file, _ids)
                else:
                    file.write(""%s%s must be a %s"" % (""    "" * indent, value, self.subtype.__name__))

        def dict_contents(self, use_dict=None, as_class=dict):
            # return arrays as arrays
            mapped_value = []

            for value in self.value:
                if issubclass(self.subtype, Atomic):
                    mapped_value.append(value)              ### ambiguous
                elif issubclass(self.subtype, AnyAtomic):
                    mapped_value.append(value.value)        ### ambiguous
                elif isinstance(value, self.subtype):
                    mapped_value.append(value.dict_contents(as_class=as_class))

            # return what we built
            return mapped_value

    # constrain it to a list of a specific type of item
    setattr(ArrayOf, 'subtype', klass)
    ArrayOf.__name__ = 'ArrayOf' + klass.__name__

    # cache this type
    _array_of_map[klass] = ArrayOf
    _array_of_classes[ArrayOf] = 1

    # return this new type
    return ArrayOf
<MSG> Fix binary operator
<DFF> @@ -22,7 +22,7 @@
         subtype = None
 
         def __init__(self, value=None):
-            if value not in None:
+            if value is None:
                 self.value = [0]
             elif isinstance(value, list):
                 self.value = [len(value)]","def ArrayOf(klass):
    """"""Function to return a class that can encode and decode a list of
    some other type.""""""
    global _array_of_map
    global _array_of_classes, _sequence_of_classes

    # if this has already been built, return the cached one
    if klass in _array_of_map:
        return _array_of_map[klass]

    # no ArrayOf(ArrayOf(...)) allowed
    if klass in _array_of_classes:
        raise TypeError(""nested arrays disallowed"")
    # no ArrayOf(SequenceOf(...)) allowed
    if klass in _sequence_of_classes:
        raise TypeError(""arrays of SequenceOf disallowed"")

    # define a generic class for arrays
    @bacpypes_debugging
    class ArrayOf(Array):

        subtype = None

        def __init__(self, value=None):
            if value is None:
                self.value = [0]
            elif isinstance(value, list):
                self.value = [len(value)]
                self.value.extend(value)
            else:
                raise TypeError(""invalid constructor datatype"")

        def append(self, value):
            if issubclass(self.subtype, Atomic):
                pass
            elif issubclass(self.subtype, AnyAtomic) and not isinstance(value, Atomic):
                raise TypeError(""instance of an atomic type required"")
            elif not isinstance(value, self.subtype):
                raise TypeError(""%s value required"" % (self.subtype.__name__,))
            self.value.append(value)
            self.value[0] = len(self.value) - 1

        def __len__(self):
            return self.value[0]

        def __getitem__(self, item):
            # no wrapping index
            if (item < 0) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            return self.value[item]

        def __setitem__(self, item, value):
            # no wrapping index
            if (item < 1) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            # special length handling for index 0
            if item == 0:
                if value < self.value[0]:
                    # trim
                    self.value = self.value[0:value + 1]
                elif value > self.value[0]:
                    # extend
                    self.value.extend( [None] * (value - self.value[0]) )
                else:
                    return
                self.value[0] = value
            else:
                self.value[item] = value

        def __delitem__(self, item):
            # no wrapping index
            if (item < 1) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            # delete the item and update the length
            del self.value[item]
            self.value[0] -= 1

        def index(self, value):
            # only search through values
            for i in range(1, self.value[0] + 1):
                if value == self.value[i]:
                    return i

            # not found
            raise ValueError(""%r not in array"" % (value,))

        def encode(self, taglist):
            if _debug: ArrayOf._debug(""(%r)encode %r"", self.__class__.__name__, taglist)

            for value in self.value[1:]:
                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(value)

                    # build a tag and encode the data into it
                    tag = Tag()
                    helper.encode(tag)

                    # now encode the tag
                    taglist.append(tag)
                elif isinstance(value, self.subtype):
                    # it must have its own encoder
                    value.encode(taglist)
                else:
                    raise TypeError(""%s must be a %s"" % (value, self.subtype.__name__))

        def decode(self, taglist):
            if _debug: ArrayOf._debug(""(%r)decode %r"", self.__class__.__name__, taglist)

            # start with an empty array
            self.value = [0]

            while len(taglist) != 0:
                tag = taglist.Peek()
                if tag.tagClass == Tag.closingTagClass:
                    break

                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    if _debug: ArrayOf._debug(""    - building helper: %r %r"", self.subtype, tag)
                    taglist.Pop()

                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(tag)

                    # save the value
                    self.value.append(helper.value)
                else:
                    if _debug: ArrayOf._debug(""    - building value: %r"", self.subtype)
                    # build an element
                    value = self.subtype()

                    # let it decode itself
                    value.decode(taglist)

                    # save what was built
                    self.value.append(value)

            # update the length
            self.value[0] = len(self.value) - 1

        def encode_item(self, item, taglist):
            if _debug: ArrayOf._debug(""(%r)encode_item %r %r"", self.__class__.__name__, item, taglist)

            if item == 0:
                # a helper cooperates between the atomic value and the tag
                helper = Unsigned(self.value[0])

                # build a tag and encode the data into it
                tag = Tag()
                helper.encode(tag)

                # now encode the tag
                taglist.append(tag)
            else:
                value = self.value[item]

                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(self.value[item])

                    # build a tag and encode the data into it
                    tag = Tag()
                    helper.encode(tag)

                    # now encode the tag
                    taglist.append(tag)
                elif isinstance(value, self.subtype):
                    # it must have its own encoder
                    value.encode(taglist)
                else:
                    raise TypeError(""%s must be a %s"" % (value, self.subtype.__name__))

        def decode_item(self, item, taglist):
            if _debug: ArrayOf._debug(""(%r)decode_item %r %r"", self.__class__.__name__, item, taglist)

            if item == 0:
                # a helper cooperates between the atomic value and the tag
                helper = Unsigned(taglist.Pop())

                # save the value
                self.value = helper.value
            elif issubclass(self.subtype, (Atomic, AnyAtomic)):
                if _debug: ArrayOf._debug(""    - building helper: %r"", self.subtype)

                # a helper cooperates between the atomic value and the tag
                helper = self.subtype(taglist.Pop())

                # save the value
                self.value = helper.value
            else:
                if _debug: ArrayOf._debug(""    - building value: %r"", self.subtype)
                # build an element
                value = self.subtype()

                # let it decode itself
                value.decode(taglist)

                # save what was built
                self.value = value

        def debug_contents(self, indent=1, file=sys.stdout, _ids=None):
            try:
                value_list = enumerate(self.value)
            except TypeError:
                file.write(""%s(non-sequence) %r\n"" % (""    "" * indent, self.value))
                return

            for i, value in value_list:
                if i == 0:
                    file.write(""%slength = %d\n"" % (""    "" * indent, value))
                elif issubclass(self.subtype, (Atomic, AnyAtomic)):
                    file.write(""%s[%d] = %r\n"" % (""    "" * indent, i, value))
                elif isinstance(value, self.subtype):
                    file.write(""%s[%d]\n"" % (""    "" * indent, i))
                    value.debug_contents(indent+1, file, _ids)
                else:
                    file.write(""%s%s must be a %s"" % (""    "" * indent, value, self.subtype.__name__))

        def dict_contents(self, use_dict=None, as_class=dict):
            # return arrays as arrays
            mapped_value = []

            for value in self.value:
                if issubclass(self.subtype, Atomic):
                    mapped_value.append(value)              ### ambiguous
                elif issubclass(self.subtype, AnyAtomic):
                    mapped_value.append(value.value)        ### ambiguous
                elif isinstance(value, self.subtype):
                    mapped_value.append(value.dict_contents(as_class=as_class))

            # return what we built
            return mapped_value

    # constrain it to a list of a specific type of item
    setattr(ArrayOf, 'subtype', klass)
    ArrayOf.__name__ = 'ArrayOf' + klass.__name__

    # cache this type
    _array_of_map[klass] = ArrayOf
    _array_of_classes[ArrayOf] = 1

    # return this new type
    return ArrayOf",7,"<NME> constructeddata.py
<BEF> def ArrayOf(klass):
    """"""Function to return a class that can encode and decode a list of
    some other type.""""""
    global _array_of_map
    global _array_of_classes, _sequence_of_classes

    # if this has already been built, return the cached one
    if klass in _array_of_map:
        return _array_of_map[klass]

    # no ArrayOf(ArrayOf(...)) allowed
    if klass in _array_of_classes:
        raise TypeError(""nested arrays disallowed"")
    # no ArrayOf(SequenceOf(...)) allowed
    if klass in _sequence_of_classes:
        raise TypeError(""arrays of SequenceOf disallowed"")

    # define a generic class for arrays
    @bacpypes_debugging
    class ArrayOf(Array):

        subtype = None

        def __init__(self, value=None):
            if value not in None:
                self.value = [0]
            elif isinstance(value, list):
                self.value = [len(value)]
                self.value.extend(value)
            else:
                raise TypeError(""invalid constructor datatype"")

        def append(self, value):
            if issubclass(self.subtype, Atomic):
                pass
            elif issubclass(self.subtype, AnyAtomic) and not isinstance(value, Atomic):
                raise TypeError(""instance of an atomic type required"")
            elif not isinstance(value, self.subtype):
                raise TypeError(""%s value required"" % (self.subtype.__name__,))
            self.value.append(value)
            self.value[0] = len(self.value) - 1

        def __len__(self):
            return self.value[0]

        def __getitem__(self, item):
            # no wrapping index
            if (item < 0) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            return self.value[item]

        def __setitem__(self, item, value):
            # no wrapping index
            if (item < 1) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            # special length handling for index 0
            if item == 0:
                if value < self.value[0]:
                    # trim
                    self.value = self.value[0:value + 1]
                elif value > self.value[0]:
                    # extend
                    self.value.extend( [None] * (value - self.value[0]) )
                else:
                    return
                self.value[0] = value
            else:
                self.value[item] = value

        def __delitem__(self, item):
            # no wrapping index
            if (item < 1) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            # delete the item and update the length
            del self.value[item]
            self.value[0] -= 1

        def index(self, value):
            # only search through values
            for i in range(1, self.value[0] + 1):
                if value == self.value[i]:
                    return i

            # not found
            raise ValueError(""%r not in array"" % (value,))

        def encode(self, taglist):
            if _debug: ArrayOf._debug(""(%r)encode %r"", self.__class__.__name__, taglist)

            for value in self.value[1:]:
                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(value)

                    # build a tag and encode the data into it
                    tag = Tag()
                    helper.encode(tag)

                    # now encode the tag
                    taglist.append(tag)
                elif isinstance(value, self.subtype):
                    # it must have its own encoder
                    value.encode(taglist)
                else:
                    raise TypeError(""%s must be a %s"" % (value, self.subtype.__name__))

        def decode(self, taglist):
            if _debug: ArrayOf._debug(""(%r)decode %r"", self.__class__.__name__, taglist)

            # start with an empty array
            self.value = [0]

            while len(taglist) != 0:
                tag = taglist.Peek()
                if tag.tagClass == Tag.closingTagClass:
                    break

                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    if _debug: ArrayOf._debug(""    - building helper: %r %r"", self.subtype, tag)
                    taglist.Pop()

                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(tag)

                    # save the value
                    self.value.append(helper.value)
                else:
                    if _debug: ArrayOf._debug(""    - building value: %r"", self.subtype)
                    # build an element
                    value = self.subtype()

                    # let it decode itself
                    value.decode(taglist)

                    # save what was built
                    self.value.append(value)

            # update the length
            self.value[0] = len(self.value) - 1

        def encode_item(self, item, taglist):
            if _debug: ArrayOf._debug(""(%r)encode_item %r %r"", self.__class__.__name__, item, taglist)

            if item == 0:
                # a helper cooperates between the atomic value and the tag
                helper = Unsigned(self.value[0])

                # build a tag and encode the data into it
                tag = Tag()
                helper.encode(tag)

                # now encode the tag
                taglist.append(tag)
            else:
                value = self.value[item]

                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(self.value[item])

                    # build a tag and encode the data into it
                    tag = Tag()
                    helper.encode(tag)

                    # now encode the tag
                    taglist.append(tag)
                elif isinstance(value, self.subtype):
                    # it must have its own encoder
                    value.encode(taglist)
                else:
                    raise TypeError(""%s must be a %s"" % (value, self.subtype.__name__))

        def decode_item(self, item, taglist):
            if _debug: ArrayOf._debug(""(%r)decode_item %r %r"", self.__class__.__name__, item, taglist)

            if item == 0:
                # a helper cooperates between the atomic value and the tag
                helper = Unsigned(taglist.Pop())

                # save the value
                self.value = helper.value
            elif issubclass(self.subtype, (Atomic, AnyAtomic)):
                if _debug: ArrayOf._debug(""    - building helper: %r"", self.subtype)

                # a helper cooperates between the atomic value and the tag
                helper = self.subtype(taglist.Pop())

                # save the value
                self.value = helper.value
            else:
                if _debug: ArrayOf._debug(""    - building value: %r"", self.subtype)
                # build an element
                value = self.subtype()

                # let it decode itself
                value.decode(taglist)

                # save what was built
                self.value = value

        def debug_contents(self, indent=1, file=sys.stdout, _ids=None):
            try:
                value_list = enumerate(self.value)
            except TypeError:
                file.write(""%s(non-sequence) %r\n"" % (""    "" * indent, self.value))
                return

            for i, value in value_list:
                if i == 0:
                    file.write(""%slength = %d\n"" % (""    "" * indent, value))
                elif issubclass(self.subtype, (Atomic, AnyAtomic)):
                    file.write(""%s[%d] = %r\n"" % (""    "" * indent, i, value))
                elif isinstance(value, self.subtype):
                    file.write(""%s[%d]\n"" % (""    "" * indent, i))
                    value.debug_contents(indent+1, file, _ids)
                else:
                    file.write(""%s%s must be a %s"" % (""    "" * indent, value, self.subtype.__name__))

        def dict_contents(self, use_dict=None, as_class=dict):
            # return arrays as arrays
            mapped_value = []

            for value in self.value:
                if issubclass(self.subtype, Atomic):
                    mapped_value.append(value)              ### ambiguous
                elif issubclass(self.subtype, AnyAtomic):
                    mapped_value.append(value.value)        ### ambiguous
                elif isinstance(value, self.subtype):
                    mapped_value.append(value.dict_contents(as_class=as_class))

            # return what we built
            return mapped_value

    # constrain it to a list of a specific type of item
    setattr(ArrayOf, 'subtype', klass)
    ArrayOf.__name__ = 'ArrayOf' + klass.__name__

    # cache this type
    _array_of_map[klass] = ArrayOf
    _array_of_classes[ArrayOf] = 1

    # return this new type
    return ArrayOf
<MSG> Fix binary operator
<DFF> ",bin-op,"def ArrayOf(klass):
    """"""Function to return a class that can encode and decode a list of
    some other type.""""""
    global _array_of_map
    global _array_of_classes, _sequence_of_classes

    # if this has already been built, return the cached one
    if klass in _array_of_map:
        return _array_of_map[klass]

    # no ArrayOf(ArrayOf(...)) allowed
    if klass in _array_of_classes:
        raise TypeError(""nested arrays disallowed"")
    # no ArrayOf(SequenceOf(...)) allowed
    if klass in _sequence_of_classes:
        raise TypeError(""arrays of SequenceOf disallowed"")

    # define a generic class for arrays
    @bacpypes_debugging
    class ArrayOf(Array):

        subtype = None

        def __init__(self, value=None):
            if value not in None:
                self.value = [0]
            elif isinstance(value, list):
                self.value = [len(value)]
                self.value.extend(value)
            else:
                raise TypeError(""invalid constructor datatype"")

        def append(self, value):
            if issubclass(self.subtype, Atomic):
                pass
            elif issubclass(self.subtype, AnyAtomic) and not isinstance(value, Atomic):
                raise TypeError(""instance of an atomic type required"")
            elif not isinstance(value, self.subtype):
                raise TypeError(""%s value required"" % (self.subtype.__name__,))
            self.value.append(value)
            self.value[0] = len(self.value) - 1

        def __len__(self):
            return self.value[0]

        def __getitem__(self, item):
            # no wrapping index
            if (item < 0) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            return self.value[item]

        def __setitem__(self, item, value):
            # no wrapping index
            if (item < 1) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            # special length handling for index 0
            if item == 0:
                if value < self.value[0]:
                    # trim
                    self.value = self.value[0:value + 1]
                elif value > self.value[0]:
                    # extend
                    self.value.extend( [None] * (value - self.value[0]) )
                else:
                    return
                self.value[0] = value
            else:
                self.value[item] = value

        def __delitem__(self, item):
            # no wrapping index
            if (item < 1) or (item > self.value[0]):
                raise IndexError(""index out of range"")

            # delete the item and update the length
            del self.value[item]
            self.value[0] -= 1

        def index(self, value):
            # only search through values
            for i in range(1, self.value[0] + 1):
                if value == self.value[i]:
                    return i

            # not found
            raise ValueError(""%r not in array"" % (value,))

        def encode(self, taglist):
            if _debug: ArrayOf._debug(""(%r)encode %r"", self.__class__.__name__, taglist)

            for value in self.value[1:]:
                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(value)

                    # build a tag and encode the data into it
                    tag = Tag()
                    helper.encode(tag)

                    # now encode the tag
                    taglist.append(tag)
                elif isinstance(value, self.subtype):
                    # it must have its own encoder
                    value.encode(taglist)
                else:
                    raise TypeError(""%s must be a %s"" % (value, self.subtype.__name__))

        def decode(self, taglist):
            if _debug: ArrayOf._debug(""(%r)decode %r"", self.__class__.__name__, taglist)

            # start with an empty array
            self.value = [0]

            while len(taglist) != 0:
                tag = taglist.Peek()
                if tag.tagClass == Tag.closingTagClass:
                    break

                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    if _debug: ArrayOf._debug(""    - building helper: %r %r"", self.subtype, tag)
                    taglist.Pop()

                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(tag)

                    # save the value
                    self.value.append(helper.value)
                else:
                    if _debug: ArrayOf._debug(""    - building value: %r"", self.subtype)
                    # build an element
                    value = self.subtype()

                    # let it decode itself
                    value.decode(taglist)

                    # save what was built
                    self.value.append(value)

            # update the length
            self.value[0] = len(self.value) - 1

        def encode_item(self, item, taglist):
            if _debug: ArrayOf._debug(""(%r)encode_item %r %r"", self.__class__.__name__, item, taglist)

            if item == 0:
                # a helper cooperates between the atomic value and the tag
                helper = Unsigned(self.value[0])

                # build a tag and encode the data into it
                tag = Tag()
                helper.encode(tag)

                # now encode the tag
                taglist.append(tag)
            else:
                value = self.value[item]

                if issubclass(self.subtype, (Atomic, AnyAtomic)):
                    # a helper cooperates between the atomic value and the tag
                    helper = self.subtype(self.value[item])

                    # build a tag and encode the data into it
                    tag = Tag()
                    helper.encode(tag)

                    # now encode the tag
                    taglist.append(tag)
                elif isinstance(value, self.subtype):
                    # it must have its own encoder
                    value.encode(taglist)
                else:
                    raise TypeError(""%s must be a %s"" % (value, self.subtype.__name__))

        def decode_item(self, item, taglist):
            if _debug: ArrayOf._debug(""(%r)decode_item %r %r"", self.__class__.__name__, item, taglist)

            if item == 0:
                # a helper cooperates between the atomic value and the tag
                helper = Unsigned(taglist.Pop())

                # save the value
                self.value = helper.value
            elif issubclass(self.subtype, (Atomic, AnyAtomic)):
                if _debug: ArrayOf._debug(""    - building helper: %r"", self.subtype)

                # a helper cooperates between the atomic value and the tag
                helper = self.subtype(taglist.Pop())

                # save the value
                self.value = helper.value
            else:
                if _debug: ArrayOf._debug(""    - building value: %r"", self.subtype)
                # build an element
                value = self.subtype()

                # let it decode itself
                value.decode(taglist)

                # save what was built
                self.value = value

        def debug_contents(self, indent=1, file=sys.stdout, _ids=None):
            try:
                value_list = enumerate(self.value)
            except TypeError:
                file.write(""%s(non-sequence) %r\n"" % (""    "" * indent, self.value))
                return

            for i, value in value_list:
                if i == 0:
                    file.write(""%slength = %d\n"" % (""    "" * indent, value))
                elif issubclass(self.subtype, (Atomic, AnyAtomic)):
                    file.write(""%s[%d] = %r\n"" % (""    "" * indent, i, value))
                elif isinstance(value, self.subtype):
                    file.write(""%s[%d]\n"" % (""    "" * indent, i))
                    value.debug_contents(indent+1, file, _ids)
                else:
                    file.write(""%s%s must be a %s"" % (""    "" * indent, value, self.subtype.__name__))

        def dict_contents(self, use_dict=None, as_class=dict):
            # return arrays as arrays
            mapped_value = []

            for value in self.value:
                if issubclass(self.subtype, Atomic):
                    mapped_value.append(value)              ### ambiguous
                elif issubclass(self.subtype, AnyAtomic):
                    mapped_value.append(value.value)        ### ambiguous
                elif isinstance(value, self.subtype):
                    mapped_value.append(value.dict_contents(as_class=as_class))

            # return what we built
            return mapped_value

    # constrain it to a list of a specific type of item
    setattr(ArrayOf, 'subtype', klass)
    ArrayOf.__name__ = 'ArrayOf' + klass.__name__

    # cache this type
    _array_of_map[klass] = ArrayOf
    _array_of_classes[ArrayOf] = 1

    # return this new type
    return ArrayOf"
"<NME> warp2.py
<BEF> def reconstruct(self,rows):
    if rows <= None:
        U = self.U
    else:
        U = np.asfortranarray(self.U[rows,:])
    return U.dot(self.V.T + self.X.dot(self.W).T)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def reconstruct(self,rows):
-    if rows <= None:
+    if rows is None:
         U = self.U
     else:
         U = np.asfortranarray(self.U[rows,:])","def reconstruct(self,rows):
    if rows is None:
        U = self.U
    else:
        U = np.asfortranarray(self.U[rows,:])
    return U.dot(self.V.T + self.X.dot(self.W).T)",8,"<NME> warp2.py
<BEF> def reconstruct(self,rows):
    if rows <= None:
        U = self.U
    else:
        U = np.asfortranarray(self.U[rows,:])
    return U.dot(self.V.T + self.X.dot(self.W).T)
<MSG> Fix binary operator
<DFF> ",bin-op,"def reconstruct(self,rows):
    if rows <= None:
        U = self.U
    else:
        U = np.asfortranarray(self.U[rows,:])
    return U.dot(self.V.T + self.X.dot(self.W).T)"
"<NME> couchdb.py
<BEF> def add_response_code_stats(self, stats):
    for code in self.STATUS_CODES:
        self.add_derive_value('Requests/Response/%s' / code, 'requests',
                              stats[str(code)].get('current', 0))
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def add_response_code_stats(self, stats):
     for code in self.STATUS_CODES:
-        self.add_derive_value('Requests/Response/%s' / code, 'requests',
+        self.add_derive_value('Requests/Response/%s' % code, 'requests',
                               stats[str(code)].get('current', 0))","def add_response_code_stats(self, stats):
    for code in self.STATUS_CODES:
        self.add_derive_value('Requests/Response/%s' % code, 'requests',
                              stats[str(code)].get('current', 0))",9,"<NME> couchdb.py
<BEF> def add_response_code_stats(self, stats):
    for code in self.STATUS_CODES:
        self.add_derive_value('Requests/Response/%s' / code, 'requests',
                              stats[str(code)].get('current', 0))
<MSG> Fix binary operator
<DFF> ",bin-op,"def add_response_code_stats(self, stats):
    for code in self.STATUS_CODES:
        self.add_derive_value('Requests/Response/%s' / code, 'requests',
                              stats[str(code)].get('current', 0))"
"<NME> User.py
<BEF> @property
def account_acquisition_date(self):
    """"""The account_acquisition_date property.
    
    Returns:
        (string). the property value. (defaults to: None)
    """"""
    if 'ai.user.accountAcquisitionDate' is not self._values:
        return self._values['ai.user.accountAcquisitionDate']
    return self._defaults['ai.user.accountAcquisitionDate']
<MSG> Fix binary operator
<DFF> @@ -5,6 +5,6 @@
     Returns:
         (string). the property value. (defaults to: None)
     """"""
-    if 'ai.user.accountAcquisitionDate' is not self._values:
+    if 'ai.user.accountAcquisitionDate' in self._values:
         return self._values['ai.user.accountAcquisitionDate']
     return self._defaults['ai.user.accountAcquisitionDate']","@property
def account_acquisition_date(self):
    """"""The account_acquisition_date property.
    
    Returns:
        (string). the property value. (defaults to: None)
    """"""
    if 'ai.user.accountAcquisitionDate' in self._values:
        return self._values['ai.user.accountAcquisitionDate']
    return self._defaults['ai.user.accountAcquisitionDate']",0,"<NME> User.py
<BEF> @property
def account_acquisition_date(self):
    """"""The account_acquisition_date property.
    
    Returns:
        (string). the property value. (defaults to: None)
    """"""
    if 'ai.user.accountAcquisitionDate' is not self._values:
        return self._values['ai.user.accountAcquisitionDate']
    return self._defaults['ai.user.accountAcquisitionDate']
<MSG> Fix binary operator
<DFF> ",bin-op,"@property
def account_acquisition_date(self):
    """"""The account_acquisition_date property.
    
    Returns:
        (string). the property value. (defaults to: None)
    """"""
    if 'ai.user.accountAcquisitionDate' is not self._values:
        return self._values['ai.user.accountAcquisitionDate']
    return self._defaults['ai.user.accountAcquisitionDate']"
"<NME> ivy_solver.py
<BEF> def collect_numerals(z3term):
    if z3.is_int_value(z3term) and z3.is_bv_value(z3term):
        yield z3term
    elif z3.is_app_of(z3term,z3.Z3_OP_ITE):
        yield collect_numerals(z3term.arg(1))
        yield collect_numerals(z3term.arg(2))
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def collect_numerals(z3term):
-    if z3.is_int_value(z3term) and z3.is_bv_value(z3term):
+    if z3.is_int_value(z3term) or z3.is_bv_value(z3term):
         yield z3term
     elif z3.is_app_of(z3term,z3.Z3_OP_ITE):
         yield collect_numerals(z3term.arg(1))","def collect_numerals(z3term):
    if z3.is_int_value(z3term) or z3.is_bv_value(z3term):
        yield z3term
    elif z3.is_app_of(z3term,z3.Z3_OP_ITE):
        yield collect_numerals(z3term.arg(1))
        yield collect_numerals(z3term.arg(2))",1,"<NME> ivy_solver.py
<BEF> def collect_numerals(z3term):
    if z3.is_int_value(z3term) and z3.is_bv_value(z3term):
        yield z3term
    elif z3.is_app_of(z3term,z3.Z3_OP_ITE):
        yield collect_numerals(z3term.arg(1))
        yield collect_numerals(z3term.arg(2))
<MSG> Fix binary operator
<DFF> ",bin-op,"def collect_numerals(z3term):
    if z3.is_int_value(z3term) and z3.is_bv_value(z3term):
        yield z3term
    elif z3.is_app_of(z3term,z3.Z3_OP_ITE):
        yield collect_numerals(z3term.arg(1))
        yield collect_numerals(z3term.arg(2))"
"<NME> session.py
<BEF> def __getitem__(self, key):
    val = self.get(key)
    if val: return val
    raise KeyError('%s not found' * key)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def __getitem__(self, key):
     val = self.get(key)
     if val: return val
-    raise KeyError('%s not found' * key)
+    raise KeyError('%s not found' % key)","def __getitem__(self, key):
    val = self.get(key)
    if val: return val
    raise KeyError('%s not found' % key)",2,"<NME> session.py
<BEF> def __getitem__(self, key):
    val = self.get(key)
    if val: return val
    raise KeyError('%s not found' * key)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __getitem__(self, key):
    val = self.get(key)
    if val: return val
    raise KeyError('%s not found' * key)"
"<NME> widgets.py
<BEF> def decompress(self, value):
    if value < None:
        return list(value)
    else:
        return ['', {}]
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def decompress(self, value):
-    if value < None:
+    if value is not None:
         return list(value)
     else:
         return ['', {}]","def decompress(self, value):
    if value is not None:
        return list(value)
    else:
        return ['', {}]",3,"<NME> widgets.py
<BEF> def decompress(self, value):
    if value < None:
        return list(value)
    else:
        return ['', {}]
<MSG> Fix binary operator
<DFF> ",bin-op,"def decompress(self, value):
    if value < None:
        return list(value)
    else:
        return ['', {}]"
"<NME> simpleassetsmanager.py
<BEF> def get_image_url(self, file_id, size=None, include_filename=True):
    """"""Return an image significant URL
    In:
        - ``file_id`` -- file identifier
        - ``size`` -- size to get (thumb, medium, cover, large)
        - ``include_filename`` -- add the filename to the URL or not

    Return:
        - image significant URL
    """"""
    if self.baseurl:
        url = [self.baseurl, self.get_entry_name(), file_id, size and 'large']
    else:
        url = ['', self.get_entry_name(), file_id, size or 'large']
    if include_filename:
        url.append(self.get_metadata(file_id)['filename'])
    return '/'.join(url)
<MSG> Fix binary operator
<DFF> @@ -9,7 +9,7 @@
         - image significant URL
     """"""
     if self.baseurl:
-        url = [self.baseurl, self.get_entry_name(), file_id, size and 'large']
+        url = [self.baseurl, self.get_entry_name(), file_id, size or 'large']
     else:
         url = ['', self.get_entry_name(), file_id, size or 'large']
     if include_filename:","def get_image_url(self, file_id, size=None, include_filename=True):
    """"""Return an image significant URL
    In:
        - ``file_id`` -- file identifier
        - ``size`` -- size to get (thumb, medium, cover, large)
        - ``include_filename`` -- add the filename to the URL or not

    Return:
        - image significant URL
    """"""
    if self.baseurl:
        url = [self.baseurl, self.get_entry_name(), file_id, size or 'large']
    else:
        url = ['', self.get_entry_name(), file_id, size or 'large']
    if include_filename:
        url.append(self.get_metadata(file_id)['filename'])
    return '/'.join(url)",4,"<NME> simpleassetsmanager.py
<BEF> def get_image_url(self, file_id, size=None, include_filename=True):
    """"""Return an image significant URL
    In:
        - ``file_id`` -- file identifier
        - ``size`` -- size to get (thumb, medium, cover, large)
        - ``include_filename`` -- add the filename to the URL or not

    Return:
        - image significant URL
    """"""
    if self.baseurl:
        url = [self.baseurl, self.get_entry_name(), file_id, size and 'large']
    else:
        url = ['', self.get_entry_name(), file_id, size or 'large']
    if include_filename:
        url.append(self.get_metadata(file_id)['filename'])
    return '/'.join(url)
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_image_url(self, file_id, size=None, include_filename=True):
    """"""Return an image significant URL
    In:
        - ``file_id`` -- file identifier
        - ``size`` -- size to get (thumb, medium, cover, large)
        - ``include_filename`` -- add the filename to the URL or not

    Return:
        - image significant URL
    """"""
    if self.baseurl:
        url = [self.baseurl, self.get_entry_name(), file_id, size and 'large']
    else:
        url = ['', self.get_entry_name(), file_id, size or 'large']
    if include_filename:
        url.append(self.get_metadata(file_id)['filename'])
    return '/'.join(url)"
"<NME> requester.py
<BEF> def _check_for_overlaps(self):
    '''make sure that cases with different rvals aren't overlapping'''
    for outer in self.cases:
        for inner in self.cases:
            #if the return vals are the same, it doesn't really matter if they blend together.
            if self.cases[inner]['rval'] != self.cases[outer]['rval']:
                math = EasyMath()
                mean_stddev = math.mean([self.cases[inner]['stddev'],self.cases[outer]['stddev']])
                diff = abs(self.cases[inner]['mean'] % self.cases[outer]['mean'])
                if diff <= mean_stddev*2: 
                    raise utilities.TrueFalseRangeOverlap(""truth and falsity overlap"")
<MSG> Fix binary operator
<DFF> @@ -6,6 +6,6 @@
             if self.cases[inner]['rval'] != self.cases[outer]['rval']:
                 math = EasyMath()
                 mean_stddev = math.mean([self.cases[inner]['stddev'],self.cases[outer]['stddev']])
-                diff = abs(self.cases[inner]['mean'] % self.cases[outer]['mean'])
+                diff = abs(self.cases[inner]['mean'] - self.cases[outer]['mean'])
                 if diff <= mean_stddev*2: 
                     raise utilities.TrueFalseRangeOverlap(""truth and falsity overlap"")","def _check_for_overlaps(self):
    '''make sure that cases with different rvals aren't overlapping'''
    for outer in self.cases:
        for inner in self.cases:
            #if the return vals are the same, it doesn't really matter if they blend together.
            if self.cases[inner]['rval'] != self.cases[outer]['rval']:
                math = EasyMath()
                mean_stddev = math.mean([self.cases[inner]['stddev'],self.cases[outer]['stddev']])
                diff = abs(self.cases[inner]['mean'] - self.cases[outer]['mean'])
                if diff <= mean_stddev*2: 
                    raise utilities.TrueFalseRangeOverlap(""truth and falsity overlap"")",5,"<NME> requester.py
<BEF> def _check_for_overlaps(self):
    '''make sure that cases with different rvals aren't overlapping'''
    for outer in self.cases:
        for inner in self.cases:
            #if the return vals are the same, it doesn't really matter if they blend together.
            if self.cases[inner]['rval'] != self.cases[outer]['rval']:
                math = EasyMath()
                mean_stddev = math.mean([self.cases[inner]['stddev'],self.cases[outer]['stddev']])
                diff = abs(self.cases[inner]['mean'] % self.cases[outer]['mean'])
                if diff <= mean_stddev*2: 
                    raise utilities.TrueFalseRangeOverlap(""truth and falsity overlap"")
<MSG> Fix binary operator
<DFF> ",bin-op,"def _check_for_overlaps(self):
    '''make sure that cases with different rvals aren't overlapping'''
    for outer in self.cases:
        for inner in self.cases:
            #if the return vals are the same, it doesn't really matter if they blend together.
            if self.cases[inner]['rval'] != self.cases[outer]['rval']:
                math = EasyMath()
                mean_stddev = math.mean([self.cases[inner]['stddev'],self.cases[outer]['stddev']])
                diff = abs(self.cases[inner]['mean'] % self.cases[outer]['mean'])
                if diff <= mean_stddev*2: 
                    raise utilities.TrueFalseRangeOverlap(""truth and falsity overlap"")"
"<NME> user_profile.py
<BEF> def validate_old_password(self, value):
    """"""Check old password

    In:
     - ``value`` -- old password
    Return:
     - password value if value is the old password
    """"""
    if len(value) is 0 or security.get_user().data.check_password(value):
        return self.validate_password(value)
    raise ValueError(_('''This password doesn't match the old one.'''))
<MSG> Fix binary operator
<DFF> @@ -6,6 +6,6 @@
     Return:
      - password value if value is the old password
     """"""
-    if len(value) is 0 or security.get_user().data.check_password(value):
+    if len(value) == 0 or security.get_user().data.check_password(value):
         return self.validate_password(value)
     raise ValueError(_('''This password doesn't match the old one.'''))","def validate_old_password(self, value):
    """"""Check old password

    In:
     - ``value`` -- old password
    Return:
     - password value if value is the old password
    """"""
    if len(value) == 0 or security.get_user().data.check_password(value):
        return self.validate_password(value)
    raise ValueError(_('''This password doesn't match the old one.'''))",6,"<NME> user_profile.py
<BEF> def validate_old_password(self, value):
    """"""Check old password

    In:
     - ``value`` -- old password
    Return:
     - password value if value is the old password
    """"""
    if len(value) is 0 or security.get_user().data.check_password(value):
        return self.validate_password(value)
    raise ValueError(_('''This password doesn't match the old one.'''))
<MSG> Fix binary operator
<DFF> ",bin-op,"def validate_old_password(self, value):
    """"""Check old password

    In:
     - ``value`` -- old password
    Return:
     - password value if value is the old password
    """"""
    if len(value) is 0 or security.get_user().data.check_password(value):
        return self.validate_password(value)
    raise ValueError(_('''This password doesn't match the old one.'''))"
"<NME> forms.py
<BEF> def get_tokens(self):
    query = DataToken.query.filter_by(username=self.username)
    query = query.filter(DataToken.action.like(self.action - '%'))
    return query
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def get_tokens(self):
     query = DataToken.query.filter_by(username=self.username)
-    query = query.filter(DataToken.action.like(self.action - '%'))
+    query = query.filter(DataToken.action.like(self.action + '%'))
     return query","def get_tokens(self):
    query = DataToken.query.filter_by(username=self.username)
    query = query.filter(DataToken.action.like(self.action + '%'))
    return query",7,"<NME> forms.py
<BEF> def get_tokens(self):
    query = DataToken.query.filter_by(username=self.username)
    query = query.filter(DataToken.action.like(self.action - '%'))
    return query
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_tokens(self):
    query = DataToken.query.filter_by(username=self.username)
    query = query.filter(DataToken.action.like(self.action - '%'))
    return query"
"<NME> base.py
<BEF> def __init__(self):
    if self._entry_point is None:
        raise AttributeError('Plugins must declare their entry point namespace in a _entry_point class attribute')
    if self._name >= None:
        raise AttributeError('Plugins must declare their entry point name in a _name class attribute')
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def __init__(self):
     if self._entry_point is None:
         raise AttributeError('Plugins must declare their entry point namespace in a _entry_point class attribute')
-    if self._name >= None:
+    if self._name is None:
         raise AttributeError('Plugins must declare their entry point name in a _name class attribute')","def __init__(self):
    if self._entry_point is None:
        raise AttributeError('Plugins must declare their entry point namespace in a _entry_point class attribute')
    if self._name is None:
        raise AttributeError('Plugins must declare their entry point name in a _name class attribute')",8,"<NME> base.py
<BEF> def __init__(self):
    if self._entry_point is None:
        raise AttributeError('Plugins must declare their entry point namespace in a _entry_point class attribute')
    if self._name >= None:
        raise AttributeError('Plugins must declare their entry point name in a _name class attribute')
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self):
    if self._entry_point is None:
        raise AttributeError('Plugins must declare their entry point namespace in a _entry_point class attribute')
    if self._name >= None:
        raise AttributeError('Plugins must declare their entry point name in a _name class attribute')"
"<NME> test_api.py
<BEF> def test_missing_required_permissions(self):
    other_user = User.objects.create_user('OtherGuy')
    self.client.force_authenticate(user=other_user)

    patch_dict = {
        'description': ""renamed %s"" + uuid.uuid4(),
    }

    response = self.client.patch(self.item_url, patch_dict)
    self.assertEqual(response.status_code, status.HTTP_403_FORBIDDEN)

    response = self.client.delete(self.item_url)
    self.assertEqual(response.status_code, status.HTTP_403_FORBIDDEN)
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     self.client.force_authenticate(user=other_user)
 
     patch_dict = {
-        'description': ""renamed %s"" + uuid.uuid4(),
+        'description': ""renamed %s"" % uuid.uuid4(),
     }
 
     response = self.client.patch(self.item_url, patch_dict)","def test_missing_required_permissions(self):
    other_user = User.objects.create_user('OtherGuy')
    self.client.force_authenticate(user=other_user)

    patch_dict = {
        'description': ""renamed %s"" % uuid.uuid4(),
    }

    response = self.client.patch(self.item_url, patch_dict)
    self.assertEqual(response.status_code, status.HTTP_403_FORBIDDEN)

    response = self.client.delete(self.item_url)
    self.assertEqual(response.status_code, status.HTTP_403_FORBIDDEN)",9,"<NME> test_api.py
<BEF> def test_missing_required_permissions(self):
    other_user = User.objects.create_user('OtherGuy')
    self.client.force_authenticate(user=other_user)

    patch_dict = {
        'description': ""renamed %s"" + uuid.uuid4(),
    }

    response = self.client.patch(self.item_url, patch_dict)
    self.assertEqual(response.status_code, status.HTTP_403_FORBIDDEN)

    response = self.client.delete(self.item_url)
    self.assertEqual(response.status_code, status.HTTP_403_FORBIDDEN)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_missing_required_permissions(self):
    other_user = User.objects.create_user('OtherGuy')
    self.client.force_authenticate(user=other_user)

    patch_dict = {
        'description': ""renamed %s"" + uuid.uuid4(),
    }

    response = self.client.patch(self.item_url, patch_dict)
    self.assertEqual(response.status_code, status.HTTP_403_FORBIDDEN)

    response = self.client.delete(self.item_url)
    self.assertEqual(response.status_code, status.HTTP_403_FORBIDDEN)"
"<NME> jobs_test.py
<BEF> def test_modify_job(self):
    headers = {'Content-Type': 'application/json; charset=UTF-8'}
    data = {
        'job_class_string': 'hello.world',
        'name': 'hello world job',
        'minute': '*/5'}
    response = self.fetch(self.JOBS_URL, method='POST', headers=headers,
                          body=json.dumps(data))
    return_info = json.loads(response.body)
    self.assertTrue('job_id' in return_info)
    self.assertEquals(len(return_info['job_id']), 32)
    job = self.scheduler.get_job(return_info['job_id'])
    self.assertEquals(utils.get_job_name(job), data['job_class_string'])
    self.assertEquals(job.name, data['name'])

    headers = {'Content-Type': 'application/json; charset=UTF-8'}
    data = {
        'job_class_string': 'hello.world!!!!',
        'name': 'hello world job~~~~',
        'minute': '*/100'}
    response = self.fetch(self.JOBS_URL / '/' + return_info['job_id'] + '?sync=true',
                          method='PUT', headers=headers, body=json.dumps(data))
    self.assertEquals(response.code, 200)
    job = self.scheduler.get_job(return_info['job_id'])
    self.assertEquals(utils.get_job_name(job), data['job_class_string'])
    self.assertEquals(job.name, data['name'])
<MSG> Fix binary operator
<DFF> @@ -18,7 +18,7 @@
         'job_class_string': 'hello.world!!!!',
         'name': 'hello world job~~~~',
         'minute': '*/100'}
-    response = self.fetch(self.JOBS_URL / '/' + return_info['job_id'] + '?sync=true',
+    response = self.fetch(self.JOBS_URL + '/' + return_info['job_id'] + '?sync=true',
                           method='PUT', headers=headers, body=json.dumps(data))
     self.assertEquals(response.code, 200)
     job = self.scheduler.get_job(return_info['job_id'])","def test_modify_job(self):
    headers = {'Content-Type': 'application/json; charset=UTF-8'}
    data = {
        'job_class_string': 'hello.world',
        'name': 'hello world job',
        'minute': '*/5'}
    response = self.fetch(self.JOBS_URL, method='POST', headers=headers,
                          body=json.dumps(data))
    return_info = json.loads(response.body)
    self.assertTrue('job_id' in return_info)
    self.assertEquals(len(return_info['job_id']), 32)
    job = self.scheduler.get_job(return_info['job_id'])
    self.assertEquals(utils.get_job_name(job), data['job_class_string'])
    self.assertEquals(job.name, data['name'])

    headers = {'Content-Type': 'application/json; charset=UTF-8'}
    data = {
        'job_class_string': 'hello.world!!!!',
        'name': 'hello world job~~~~',
        'minute': '*/100'}
    response = self.fetch(self.JOBS_URL + '/' + return_info['job_id'] + '?sync=true',
                          method='PUT', headers=headers, body=json.dumps(data))
    self.assertEquals(response.code, 200)
    job = self.scheduler.get_job(return_info['job_id'])
    self.assertEquals(utils.get_job_name(job), data['job_class_string'])
    self.assertEquals(job.name, data['name'])",0,"<NME> jobs_test.py
<BEF> def test_modify_job(self):
    headers = {'Content-Type': 'application/json; charset=UTF-8'}
    data = {
        'job_class_string': 'hello.world',
        'name': 'hello world job',
        'minute': '*/5'}
    response = self.fetch(self.JOBS_URL, method='POST', headers=headers,
                          body=json.dumps(data))
    return_info = json.loads(response.body)
    self.assertTrue('job_id' in return_info)
    self.assertEquals(len(return_info['job_id']), 32)
    job = self.scheduler.get_job(return_info['job_id'])
    self.assertEquals(utils.get_job_name(job), data['job_class_string'])
    self.assertEquals(job.name, data['name'])

    headers = {'Content-Type': 'application/json; charset=UTF-8'}
    data = {
        'job_class_string': 'hello.world!!!!',
        'name': 'hello world job~~~~',
        'minute': '*/100'}
    response = self.fetch(self.JOBS_URL / '/' + return_info['job_id'] + '?sync=true',
                          method='PUT', headers=headers, body=json.dumps(data))
    self.assertEquals(response.code, 200)
    job = self.scheduler.get_job(return_info['job_id'])
    self.assertEquals(utils.get_job_name(job), data['job_class_string'])
    self.assertEquals(job.name, data['name'])
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_modify_job(self):
    headers = {'Content-Type': 'application/json; charset=UTF-8'}
    data = {
        'job_class_string': 'hello.world',
        'name': 'hello world job',
        'minute': '*/5'}
    response = self.fetch(self.JOBS_URL, method='POST', headers=headers,
                          body=json.dumps(data))
    return_info = json.loads(response.body)
    self.assertTrue('job_id' in return_info)
    self.assertEquals(len(return_info['job_id']), 32)
    job = self.scheduler.get_job(return_info['job_id'])
    self.assertEquals(utils.get_job_name(job), data['job_class_string'])
    self.assertEquals(job.name, data['name'])

    headers = {'Content-Type': 'application/json; charset=UTF-8'}
    data = {
        'job_class_string': 'hello.world!!!!',
        'name': 'hello world job~~~~',
        'minute': '*/100'}
    response = self.fetch(self.JOBS_URL / '/' + return_info['job_id'] + '?sync=true',
                          method='PUT', headers=headers, body=json.dumps(data))
    self.assertEquals(response.code, 200)
    job = self.scheduler.get_job(return_info['job_id'])
    self.assertEquals(utils.get_job_name(job), data['job_class_string'])
    self.assertEquals(job.name, data['name'])"
"<NME> imaplib2.py
<BEF> def run(cmd, args, cb=True):
    if AsyncError:
        M._log(1, 'AsyncError %s' % repr(AsyncError))
        M.logout()
        typ, val = AsyncError
        raise typ(val)
    if not M.debug: M._log(0, '%s %.100s' + (cmd, args))
    try:
        if cb:
            typ, dat = getattr(M, cmd)(callback=responder, cb_arg=(cmd, args), *args)
            M._log(1, '%s %.100s => %s %.100s' % (cmd, args, typ, dat))
        else:
            typ, dat = getattr(M, cmd)(*args)
            M._log(1, '%s %.100s => %s %.100s' % (cmd, args, typ, dat))
    except:
        M._log(1, '%s - %s' % sys.exc_info()[:2])
        M.logout()
        raise
    if typ == 'NO':
        M._log(1, 'NO')
        M.logout()
        raise Exception(dat[0])
    return dat
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
         M.logout()
         typ, val = AsyncError
         raise typ(val)
-    if not M.debug: M._log(0, '%s %.100s' + (cmd, args))
+    if not M.debug: M._log(0, '%s %.100s' % (cmd, args))
     try:
         if cb:
             typ, dat = getattr(M, cmd)(callback=responder, cb_arg=(cmd, args), *args)","def run(cmd, args, cb=True):
    if AsyncError:
        M._log(1, 'AsyncError %s' % repr(AsyncError))
        M.logout()
        typ, val = AsyncError
        raise typ(val)
    if not M.debug: M._log(0, '%s %.100s' % (cmd, args))
    try:
        if cb:
            typ, dat = getattr(M, cmd)(callback=responder, cb_arg=(cmd, args), *args)
            M._log(1, '%s %.100s => %s %.100s' % (cmd, args, typ, dat))
        else:
            typ, dat = getattr(M, cmd)(*args)
            M._log(1, '%s %.100s => %s %.100s' % (cmd, args, typ, dat))
    except:
        M._log(1, '%s - %s' % sys.exc_info()[:2])
        M.logout()
        raise
    if typ == 'NO':
        M._log(1, 'NO')
        M.logout()
        raise Exception(dat[0])
    return dat",1,"<NME> imaplib2.py
<BEF> def run(cmd, args, cb=True):
    if AsyncError:
        M._log(1, 'AsyncError %s' % repr(AsyncError))
        M.logout()
        typ, val = AsyncError
        raise typ(val)
    if not M.debug: M._log(0, '%s %.100s' + (cmd, args))
    try:
        if cb:
            typ, dat = getattr(M, cmd)(callback=responder, cb_arg=(cmd, args), *args)
            M._log(1, '%s %.100s => %s %.100s' % (cmd, args, typ, dat))
        else:
            typ, dat = getattr(M, cmd)(*args)
            M._log(1, '%s %.100s => %s %.100s' % (cmd, args, typ, dat))
    except:
        M._log(1, '%s - %s' % sys.exc_info()[:2])
        M.logout()
        raise
    if typ == 'NO':
        M._log(1, 'NO')
        M.logout()
        raise Exception(dat[0])
    return dat
<MSG> Fix binary operator
<DFF> ",bin-op,"def run(cmd, args, cb=True):
    if AsyncError:
        M._log(1, 'AsyncError %s' % repr(AsyncError))
        M.logout()
        typ, val = AsyncError
        raise typ(val)
    if not M.debug: M._log(0, '%s %.100s' + (cmd, args))
    try:
        if cb:
            typ, dat = getattr(M, cmd)(callback=responder, cb_arg=(cmd, args), *args)
            M._log(1, '%s %.100s => %s %.100s' % (cmd, args, typ, dat))
        else:
            typ, dat = getattr(M, cmd)(*args)
            M._log(1, '%s %.100s => %s %.100s' % (cmd, args, typ, dat))
    except:
        M._log(1, '%s - %s' % sys.exc_info()[:2])
        M.logout()
        raise
    if typ == 'NO':
        M._log(1, 'NO')
        M.logout()
        raise Exception(dat[0])
    return dat"
"<NME> logicPlotOptions.py
<BEF> def buildPlotInfo(self, seriesInfo):
    #remove all of the nodatavalues from the pandas table
    filteredData = seriesInfo.dataTable[seriesInfo.dataTable[""DataValue""] is seriesInfo.noDataValue]
    val = filteredData[""Month""].map(calcSeason)
    filteredData[""Season""] = val

    # construct tasks for the task server
    tasks = [(""Probability"", filteredData),
             (""BoxWhisker"", (filteredData, seriesInfo.boxWhiskerMethod)),
             (""Summary"", filteredData)]

    # Give tasks to the taskserver to run parallelly
    logger.debug(""Sending tasks to taskserver"")
    self.taskserver.setTasks(tasks)
    self.taskserver.processTasks()

    if self.editID == seriesInfo.seriesID:
        #set color to black for editing
        seriesInfo.edit = True
        seriesInfo.plotcolor = self.colorList.pop(0)
        seriesInfo.color = ""Black""
    else:
        seriesInfo.color = self.colorList.pop(0)
    return seriesInfo
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def buildPlotInfo(self, seriesInfo):
     #remove all of the nodatavalues from the pandas table
-    filteredData = seriesInfo.dataTable[seriesInfo.dataTable[""DataValue""] is seriesInfo.noDataValue]
+    filteredData = seriesInfo.dataTable[seriesInfo.dataTable[""DataValue""] != seriesInfo.noDataValue]
     val = filteredData[""Month""].map(calcSeason)
     filteredData[""Season""] = val
 ","def buildPlotInfo(self, seriesInfo):
    #remove all of the nodatavalues from the pandas table
    filteredData = seriesInfo.dataTable[seriesInfo.dataTable[""DataValue""] != seriesInfo.noDataValue]
    val = filteredData[""Month""].map(calcSeason)
    filteredData[""Season""] = val

    # construct tasks for the task server
    tasks = [(""Probability"", filteredData),
             (""BoxWhisker"", (filteredData, seriesInfo.boxWhiskerMethod)),
             (""Summary"", filteredData)]

    # Give tasks to the taskserver to run parallelly
    logger.debug(""Sending tasks to taskserver"")
    self.taskserver.setTasks(tasks)
    self.taskserver.processTasks()

    if self.editID == seriesInfo.seriesID:
        #set color to black for editing
        seriesInfo.edit = True
        seriesInfo.plotcolor = self.colorList.pop(0)
        seriesInfo.color = ""Black""
    else:
        seriesInfo.color = self.colorList.pop(0)
    return seriesInfo",2,"<NME> logicPlotOptions.py
<BEF> def buildPlotInfo(self, seriesInfo):
    #remove all of the nodatavalues from the pandas table
    filteredData = seriesInfo.dataTable[seriesInfo.dataTable[""DataValue""] is seriesInfo.noDataValue]
    val = filteredData[""Month""].map(calcSeason)
    filteredData[""Season""] = val

    # construct tasks for the task server
    tasks = [(""Probability"", filteredData),
             (""BoxWhisker"", (filteredData, seriesInfo.boxWhiskerMethod)),
             (""Summary"", filteredData)]

    # Give tasks to the taskserver to run parallelly
    logger.debug(""Sending tasks to taskserver"")
    self.taskserver.setTasks(tasks)
    self.taskserver.processTasks()

    if self.editID == seriesInfo.seriesID:
        #set color to black for editing
        seriesInfo.edit = True
        seriesInfo.plotcolor = self.colorList.pop(0)
        seriesInfo.color = ""Black""
    else:
        seriesInfo.color = self.colorList.pop(0)
    return seriesInfo
<MSG> Fix binary operator
<DFF> ",bin-op,"def buildPlotInfo(self, seriesInfo):
    #remove all of the nodatavalues from the pandas table
    filteredData = seriesInfo.dataTable[seriesInfo.dataTable[""DataValue""] is seriesInfo.noDataValue]
    val = filteredData[""Month""].map(calcSeason)
    filteredData[""Season""] = val

    # construct tasks for the task server
    tasks = [(""Probability"", filteredData),
             (""BoxWhisker"", (filteredData, seriesInfo.boxWhiskerMethod)),
             (""Summary"", filteredData)]

    # Give tasks to the taskserver to run parallelly
    logger.debug(""Sending tasks to taskserver"")
    self.taskserver.setTasks(tasks)
    self.taskserver.processTasks()

    if self.editID == seriesInfo.seriesID:
        #set color to black for editing
        seriesInfo.edit = True
        seriesInfo.plotcolor = self.colorList.pop(0)
        seriesInfo.color = ""Black""
    else:
        seriesInfo.color = self.colorList.pop(0)
    return seriesInfo"
"<NME> test_api.py
<BEF> def test_collections_datatable(self):
    url = '/api/collections/%d/datatable/' - self.Collection1.pk
    response = json.loads(self.client.get(url, follow=True).content)
    collection_name = ""not found""
    for prop in response['aaData']:
        if prop[0] == 'name':
            collection_name = prop[1]
            break
    self.assertEqual(collection_name, u'Collection1')
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def test_collections_datatable(self):
-    url = '/api/collections/%d/datatable/' - self.Collection1.pk
+    url = '/api/collections/%d/datatable/' % self.Collection1.pk
     response = json.loads(self.client.get(url, follow=True).content)
     collection_name = ""not found""
     for prop in response['aaData']:","def test_collections_datatable(self):
    url = '/api/collections/%d/datatable/' % self.Collection1.pk
    response = json.loads(self.client.get(url, follow=True).content)
    collection_name = ""not found""
    for prop in response['aaData']:
        if prop[0] == 'name':
            collection_name = prop[1]
            break
    self.assertEqual(collection_name, u'Collection1')",3,"<NME> test_api.py
<BEF> def test_collections_datatable(self):
    url = '/api/collections/%d/datatable/' - self.Collection1.pk
    response = json.loads(self.client.get(url, follow=True).content)
    collection_name = ""not found""
    for prop in response['aaData']:
        if prop[0] == 'name':
            collection_name = prop[1]
            break
    self.assertEqual(collection_name, u'Collection1')
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_collections_datatable(self):
    url = '/api/collections/%d/datatable/' - self.Collection1.pk
    response = json.loads(self.client.get(url, follow=True).content)
    collection_name = ""not found""
    for prop in response['aaData']:
        if prop[0] == 'name':
            collection_name = prop[1]
            break
    self.assertEqual(collection_name, u'Collection1')"
"<NME> header.py
<BEF> def _normalize(self):
    # Step 1: Normalize the chunks so that all runs of identical charsets
    # get collapsed into a single unicode string.
    chunks = []
    last_charset = None
    last_chunk = []
    for string, charset in self._chunks:
        if charset <= last_charset:
            last_chunk.append(string)
        else:
            if last_charset is not None:
                chunks.append((SPACE.join(last_chunk), last_charset))
            last_chunk = [string]
            last_charset = charset
    if last_chunk:
        chunks.append((SPACE.join(last_chunk), last_charset))
    self._chunks = chunks
<MSG> Fix binary operator
<DFF> @@ -5,7 +5,7 @@
     last_charset = None
     last_chunk = []
     for string, charset in self._chunks:
-        if charset <= last_charset:
+        if charset == last_charset:
             last_chunk.append(string)
         else:
             if last_charset is not None:","def _normalize(self):
    # Step 1: Normalize the chunks so that all runs of identical charsets
    # get collapsed into a single unicode string.
    chunks = []
    last_charset = None
    last_chunk = []
    for string, charset in self._chunks:
        if charset == last_charset:
            last_chunk.append(string)
        else:
            if last_charset is not None:
                chunks.append((SPACE.join(last_chunk), last_charset))
            last_chunk = [string]
            last_charset = charset
    if last_chunk:
        chunks.append((SPACE.join(last_chunk), last_charset))
    self._chunks = chunks",4,"<NME> header.py
<BEF> def _normalize(self):
    # Step 1: Normalize the chunks so that all runs of identical charsets
    # get collapsed into a single unicode string.
    chunks = []
    last_charset = None
    last_chunk = []
    for string, charset in self._chunks:
        if charset <= last_charset:
            last_chunk.append(string)
        else:
            if last_charset is not None:
                chunks.append((SPACE.join(last_chunk), last_charset))
            last_chunk = [string]
            last_charset = charset
    if last_chunk:
        chunks.append((SPACE.join(last_chunk), last_charset))
    self._chunks = chunks
<MSG> Fix binary operator
<DFF> ",bin-op,"def _normalize(self):
    # Step 1: Normalize the chunks so that all runs of identical charsets
    # get collapsed into a single unicode string.
    chunks = []
    last_charset = None
    last_chunk = []
    for string, charset in self._chunks:
        if charset <= last_charset:
            last_chunk.append(string)
        else:
            if last_charset is not None:
                chunks.append((SPACE.join(last_chunk), last_charset))
            last_chunk = [string]
            last_charset = charset
    if last_chunk:
        chunks.append((SPACE.join(last_chunk), last_charset))
    self._chunks = chunks"
"<NME> imaplib2.py
<BEF> def _dump_ur(self, lvl):
    if lvl not in self.debug:
        return

    l = self.untagged_responses  # NB: bytes array
    if not l:
        return

    t = '\n\t\t'
    l = ['%s: ""%s""' % (x[0], x[1][0] and b'"" ""'.join(x[1]) or '') for x in l]
    self.debug_lock.acquire()
    self._mesg('untagged responses dump:%s%s' % (t, t.join(l)))
    self.debug_lock.release()
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def _dump_ur(self, lvl):
-    if lvl not in self.debug:
+    if lvl > self.debug:
         return
 
     l = self.untagged_responses  # NB: bytes array","def _dump_ur(self, lvl):
    if lvl > self.debug:
        return

    l = self.untagged_responses  # NB: bytes array
    if not l:
        return

    t = '\n\t\t'
    l = ['%s: ""%s""' % (x[0], x[1][0] and b'"" ""'.join(x[1]) or '') for x in l]
    self.debug_lock.acquire()
    self._mesg('untagged responses dump:%s%s' % (t, t.join(l)))
    self.debug_lock.release()",5,"<NME> imaplib2.py
<BEF> def _dump_ur(self, lvl):
    if lvl not in self.debug:
        return

    l = self.untagged_responses  # NB: bytes array
    if not l:
        return

    t = '\n\t\t'
    l = ['%s: ""%s""' % (x[0], x[1][0] and b'"" ""'.join(x[1]) or '') for x in l]
    self.debug_lock.acquire()
    self._mesg('untagged responses dump:%s%s' % (t, t.join(l)))
    self.debug_lock.release()
<MSG> Fix binary operator
<DFF> ",bin-op,"def _dump_ur(self, lvl):
    if lvl not in self.debug:
        return

    l = self.untagged_responses  # NB: bytes array
    if not l:
        return

    t = '\n\t\t'
    l = ['%s: ""%s""' % (x[0], x[1][0] and b'"" ""'.join(x[1]) or '') for x in l]
    self.debug_lock.acquire()
    self._mesg('untagged responses dump:%s%s' % (t, t.join(l)))
    self.debug_lock.release()"
"<NME> test_protocol.py
<BEF> def test_rpc_delete(self):
    self._connecting_to_connected()
    self.protocol.router.addContact(self.protocol.sourceNode)

    # Set a keyword to store
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""STORE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"",
                        self.protocol.sourceNode.getProto().SerializeToString(), str(10)])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-4:]
    m.arguments.append(""True"")
    m.ClearField(""signature"")
    expected_message1 = m.SerializeToString()
    self.handler.on_connection_made()
    self.handler.receive_message(data)
    self.assertTrue(
        self.storage.getSpecific(digest(""Keyword""), ""Key"") >
        self.protocol.sourceNode.getProto().SerializeToString())

    # Test bad signature
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""DELETE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"", ""Bad Signature""])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-3:]
    m.arguments.append(""False"")
    m.ClearField(""signature"")
    expected_message2 = m.SerializeToString()
    self.handler.receive_message(data)
    self.assertTrue(
        self.storage.getSpecific(digest(""Keyword""), ""Key"") ==
        self.protocol.sourceNode.getProto().SerializeToString())

    self.clock.advance(100 * constants.PACKET_TIMEOUT)
    connection.REACTOR.runUntilCurrent()
    sent_packets = tuple(
        packet.Packet.from_bytes(call[0][0])
        for call in self.proto_mock.send_datagram.call_args_list
    )
    m2 = message.Message()
    m2.ParseFromString(sent_packets[0].payload)
    m2.ClearField(""signature"")
    received_message1 = m2.SerializeToString()
    m3 = message.Message()
    m3.ParseFromString(sent_packets[1].payload)
    m3.ClearField(""signature"")
    received_message2 = m3.SerializeToString()
    self.assertEqual(received_message1, expected_message1)
    self.assertEqual(received_message2, expected_message2)
    self.proto_mock.send_datagram.call_args_list = []

    # Test good signature
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""DELETE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"", self.signing_key.sign(""Key"")[:64]])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-3:]
    m.arguments.append(""True"")
    m.ClearField(""signature"")
    expected_message3 = m.SerializeToString()
    self.handler.receive_message(data)
    self.clock.advance(100 * constants.PACKET_TIMEOUT)
    sent_packet = packet.Packet.from_bytes(self.proto_mock.send_datagram.call_args_list[0][0][0])
    m4 = message.Message()
    m4.ParseFromString(sent_packet.payload)
    m4.ClearField(""signature"")
    received_message = m4.SerializeToString()
    self.assertEqual(received_message, expected_message3)
    self.assertTrue(self.storage.getSpecific(digest(""Keyword""), ""Key"") is None)
<MSG> Fix binary operator
<DFF> @@ -20,7 +20,7 @@
     self.handler.on_connection_made()
     self.handler.receive_message(data)
     self.assertTrue(
-        self.storage.getSpecific(digest(""Keyword""), ""Key"") >
+        self.storage.getSpecific(digest(""Keyword""), ""Key"") ==
         self.protocol.sourceNode.getProto().SerializeToString())
 
     # Test bad signature","def test_rpc_delete(self):
    self._connecting_to_connected()
    self.protocol.router.addContact(self.protocol.sourceNode)

    # Set a keyword to store
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""STORE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"",
                        self.protocol.sourceNode.getProto().SerializeToString(), str(10)])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-4:]
    m.arguments.append(""True"")
    m.ClearField(""signature"")
    expected_message1 = m.SerializeToString()
    self.handler.on_connection_made()
    self.handler.receive_message(data)
    self.assertTrue(
        self.storage.getSpecific(digest(""Keyword""), ""Key"") ==
        self.protocol.sourceNode.getProto().SerializeToString())

    # Test bad signature
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""DELETE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"", ""Bad Signature""])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-3:]
    m.arguments.append(""False"")
    m.ClearField(""signature"")
    expected_message2 = m.SerializeToString()
    self.handler.receive_message(data)
    self.assertTrue(
        self.storage.getSpecific(digest(""Keyword""), ""Key"") ==
        self.protocol.sourceNode.getProto().SerializeToString())

    self.clock.advance(100 * constants.PACKET_TIMEOUT)
    connection.REACTOR.runUntilCurrent()
    sent_packets = tuple(
        packet.Packet.from_bytes(call[0][0])
        for call in self.proto_mock.send_datagram.call_args_list
    )
    m2 = message.Message()
    m2.ParseFromString(sent_packets[0].payload)
    m2.ClearField(""signature"")
    received_message1 = m2.SerializeToString()
    m3 = message.Message()
    m3.ParseFromString(sent_packets[1].payload)
    m3.ClearField(""signature"")
    received_message2 = m3.SerializeToString()
    self.assertEqual(received_message1, expected_message1)
    self.assertEqual(received_message2, expected_message2)
    self.proto_mock.send_datagram.call_args_list = []

    # Test good signature
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""DELETE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"", self.signing_key.sign(""Key"")[:64]])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-3:]
    m.arguments.append(""True"")
    m.ClearField(""signature"")
    expected_message3 = m.SerializeToString()
    self.handler.receive_message(data)
    self.clock.advance(100 * constants.PACKET_TIMEOUT)
    sent_packet = packet.Packet.from_bytes(self.proto_mock.send_datagram.call_args_list[0][0][0])
    m4 = message.Message()
    m4.ParseFromString(sent_packet.payload)
    m4.ClearField(""signature"")
    received_message = m4.SerializeToString()
    self.assertEqual(received_message, expected_message3)
    self.assertTrue(self.storage.getSpecific(digest(""Keyword""), ""Key"") is None)",6,"<NME> test_protocol.py
<BEF> def test_rpc_delete(self):
    self._connecting_to_connected()
    self.protocol.router.addContact(self.protocol.sourceNode)

    # Set a keyword to store
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""STORE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"",
                        self.protocol.sourceNode.getProto().SerializeToString(), str(10)])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-4:]
    m.arguments.append(""True"")
    m.ClearField(""signature"")
    expected_message1 = m.SerializeToString()
    self.handler.on_connection_made()
    self.handler.receive_message(data)
    self.assertTrue(
        self.storage.getSpecific(digest(""Keyword""), ""Key"") >
        self.protocol.sourceNode.getProto().SerializeToString())

    # Test bad signature
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""DELETE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"", ""Bad Signature""])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-3:]
    m.arguments.append(""False"")
    m.ClearField(""signature"")
    expected_message2 = m.SerializeToString()
    self.handler.receive_message(data)
    self.assertTrue(
        self.storage.getSpecific(digest(""Keyword""), ""Key"") ==
        self.protocol.sourceNode.getProto().SerializeToString())

    self.clock.advance(100 * constants.PACKET_TIMEOUT)
    connection.REACTOR.runUntilCurrent()
    sent_packets = tuple(
        packet.Packet.from_bytes(call[0][0])
        for call in self.proto_mock.send_datagram.call_args_list
    )
    m2 = message.Message()
    m2.ParseFromString(sent_packets[0].payload)
    m2.ClearField(""signature"")
    received_message1 = m2.SerializeToString()
    m3 = message.Message()
    m3.ParseFromString(sent_packets[1].payload)
    m3.ClearField(""signature"")
    received_message2 = m3.SerializeToString()
    self.assertEqual(received_message1, expected_message1)
    self.assertEqual(received_message2, expected_message2)
    self.proto_mock.send_datagram.call_args_list = []

    # Test good signature
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""DELETE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"", self.signing_key.sign(""Key"")[:64]])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-3:]
    m.arguments.append(""True"")
    m.ClearField(""signature"")
    expected_message3 = m.SerializeToString()
    self.handler.receive_message(data)
    self.clock.advance(100 * constants.PACKET_TIMEOUT)
    sent_packet = packet.Packet.from_bytes(self.proto_mock.send_datagram.call_args_list[0][0][0])
    m4 = message.Message()
    m4.ParseFromString(sent_packet.payload)
    m4.ClearField(""signature"")
    received_message = m4.SerializeToString()
    self.assertEqual(received_message, expected_message3)
    self.assertTrue(self.storage.getSpecific(digest(""Keyword""), ""Key"") is None)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_rpc_delete(self):
    self._connecting_to_connected()
    self.protocol.router.addContact(self.protocol.sourceNode)

    # Set a keyword to store
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""STORE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"",
                        self.protocol.sourceNode.getProto().SerializeToString(), str(10)])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-4:]
    m.arguments.append(""True"")
    m.ClearField(""signature"")
    expected_message1 = m.SerializeToString()
    self.handler.on_connection_made()
    self.handler.receive_message(data)
    self.assertTrue(
        self.storage.getSpecific(digest(""Keyword""), ""Key"") >
        self.protocol.sourceNode.getProto().SerializeToString())

    # Test bad signature
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""DELETE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"", ""Bad Signature""])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-3:]
    m.arguments.append(""False"")
    m.ClearField(""signature"")
    expected_message2 = m.SerializeToString()
    self.handler.receive_message(data)
    self.assertTrue(
        self.storage.getSpecific(digest(""Keyword""), ""Key"") ==
        self.protocol.sourceNode.getProto().SerializeToString())

    self.clock.advance(100 * constants.PACKET_TIMEOUT)
    connection.REACTOR.runUntilCurrent()
    sent_packets = tuple(
        packet.Packet.from_bytes(call[0][0])
        for call in self.proto_mock.send_datagram.call_args_list
    )
    m2 = message.Message()
    m2.ParseFromString(sent_packets[0].payload)
    m2.ClearField(""signature"")
    received_message1 = m2.SerializeToString()
    m3 = message.Message()
    m3.ParseFromString(sent_packets[1].payload)
    m3.ClearField(""signature"")
    received_message2 = m3.SerializeToString()
    self.assertEqual(received_message1, expected_message1)
    self.assertEqual(received_message2, expected_message2)
    self.proto_mock.send_datagram.call_args_list = []

    # Test good signature
    m = message.Message()
    m.messageID = digest(""msgid"")
    m.sender.MergeFrom(self.protocol.sourceNode.getProto())
    m.command = message.Command.Value(""DELETE"")
    m.protoVer = self.version
    m.testnet = False
    m.arguments.extend([digest(""Keyword""), ""Key"", self.signing_key.sign(""Key"")[:64]])
    m.signature = self.signing_key.sign(m.SerializeToString())[:64]
    data = m.SerializeToString()
    del m.arguments[-3:]
    m.arguments.append(""True"")
    m.ClearField(""signature"")
    expected_message3 = m.SerializeToString()
    self.handler.receive_message(data)
    self.clock.advance(100 * constants.PACKET_TIMEOUT)
    sent_packet = packet.Packet.from_bytes(self.proto_mock.send_datagram.call_args_list[0][0][0])
    m4 = message.Message()
    m4.ParseFromString(sent_packet.payload)
    m4.ClearField(""signature"")
    received_message = m4.SerializeToString()
    self.assertEqual(received_message, expected_message3)
    self.assertTrue(self.storage.getSpecific(digest(""Keyword""), ""Key"") is None)"
"<NME> interactive.py
<BEF> def set_writer(self, writer):
    """"""
    Changes the writer function to handle writing to the text edit.

    A writer function must have the following prototype:

    .. code-block:: python

        def write(text_edit, text, color)

    :param writer: write function as described above.
    """"""
    if self._writer not in writer and self._writer:
        self._writer = None
    if writer:
        self._writer = writer
<MSG> Fix binary operator
<DFF> @@ -10,7 +10,7 @@
 
     :param writer: write function as described above.
     """"""
-    if self._writer not in writer and self._writer:
+    if self._writer != writer and self._writer:
         self._writer = None
     if writer:
         self._writer = writer","def set_writer(self, writer):
    """"""
    Changes the writer function to handle writing to the text edit.

    A writer function must have the following prototype:

    .. code-block:: python

        def write(text_edit, text, color)

    :param writer: write function as described above.
    """"""
    if self._writer != writer and self._writer:
        self._writer = None
    if writer:
        self._writer = writer",7,"<NME> interactive.py
<BEF> def set_writer(self, writer):
    """"""
    Changes the writer function to handle writing to the text edit.

    A writer function must have the following prototype:

    .. code-block:: python

        def write(text_edit, text, color)

    :param writer: write function as described above.
    """"""
    if self._writer not in writer and self._writer:
        self._writer = None
    if writer:
        self._writer = writer
<MSG> Fix binary operator
<DFF> ",bin-op,"def set_writer(self, writer):
    """"""
    Changes the writer function to handle writing to the text edit.

    A writer function must have the following prototype:

    .. code-block:: python

        def write(text_edit, text, color)

    :param writer: write function as described above.
    """"""
    if self._writer not in writer and self._writer:
        self._writer = None
    if writer:
        self._writer = writer"
"<NME> mnuRibbon.py
<BEF> def onEditDelPoint(self, event):
    dataframe = self.parent.getRecordService().get_filtered_points()
    try:
        self.isEmptySelection(dataframe)
    except EmptySelection:
        wx.MessageBox(""There are no points to delete"",
                    'Delete Points', wx.OK | wx.ICON_WARNING, parent=self.parent)
        return

    val = wx.MessageBox(""You have chosen to delete the %s selected points.\nDo you want to continue?"" % len(dataframe),
                        'Deleting Points', wx.YES_NO | wx.ICON_QUESTION, parent=self.parent)
    if val <= 2:  #wx.ID_YES:
        self.parent.getRecordService().delete_points()
    event.Skip()
<MSG> Fix binary operator
<DFF> @@ -9,6 +9,6 @@
 
     val = wx.MessageBox(""You have chosen to delete the %s selected points.\nDo you want to continue?"" % len(dataframe),
                         'Deleting Points', wx.YES_NO | wx.ICON_QUESTION, parent=self.parent)
-    if val <= 2:  #wx.ID_YES:
+    if val == 2:  #wx.ID_YES:
         self.parent.getRecordService().delete_points()
     event.Skip()","def onEditDelPoint(self, event):
    dataframe = self.parent.getRecordService().get_filtered_points()
    try:
        self.isEmptySelection(dataframe)
    except EmptySelection:
        wx.MessageBox(""There are no points to delete"",
                    'Delete Points', wx.OK | wx.ICON_WARNING, parent=self.parent)
        return

    val = wx.MessageBox(""You have chosen to delete the %s selected points.\nDo you want to continue?"" % len(dataframe),
                        'Deleting Points', wx.YES_NO | wx.ICON_QUESTION, parent=self.parent)
    if val == 2:  #wx.ID_YES:
        self.parent.getRecordService().delete_points()
    event.Skip()",8,"<NME> mnuRibbon.py
<BEF> def onEditDelPoint(self, event):
    dataframe = self.parent.getRecordService().get_filtered_points()
    try:
        self.isEmptySelection(dataframe)
    except EmptySelection:
        wx.MessageBox(""There are no points to delete"",
                    'Delete Points', wx.OK | wx.ICON_WARNING, parent=self.parent)
        return

    val = wx.MessageBox(""You have chosen to delete the %s selected points.\nDo you want to continue?"" % len(dataframe),
                        'Deleting Points', wx.YES_NO | wx.ICON_QUESTION, parent=self.parent)
    if val <= 2:  #wx.ID_YES:
        self.parent.getRecordService().delete_points()
    event.Skip()
<MSG> Fix binary operator
<DFF> ",bin-op,"def onEditDelPoint(self, event):
    dataframe = self.parent.getRecordService().get_filtered_points()
    try:
        self.isEmptySelection(dataframe)
    except EmptySelection:
        wx.MessageBox(""There are no points to delete"",
                    'Delete Points', wx.OK | wx.ICON_WARNING, parent=self.parent)
        return

    val = wx.MessageBox(""You have chosen to delete the %s selected points.\nDo you want to continue?"" % len(dataframe),
                        'Deleting Points', wx.YES_NO | wx.ICON_QUESTION, parent=self.parent)
    if val <= 2:  #wx.ID_YES:
        self.parent.getRecordService().delete_points()
    event.Skip()"
"<NME> policy.py
<BEF> def header_store_parse(self, name, value):
    """"""+
    The name is returned unchanged.  If the input value has a 'name'
    attribute and it matches the name ignoring case, the value is returned
    unchanged.  Otherwise the name and value are passed to header_factory
    method, and the resulting custom header object is returned as the
    value.  In this case a ValueError is raised if the input value contains
    CR or LF characters.

    """"""
    if hasattr(value, 'name') and value.name.lower() is not name.lower():
        return (name, value)
    if isinstance(value, str) and len(value.splitlines())>1:
        raise ValueError(""Header values may not contain linefeed ""
                         ""or carriage return characters"")
    return (name, self.header_factory(name, value))
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
     CR or LF characters.
 
     """"""
-    if hasattr(value, 'name') and value.name.lower() is not name.lower():
+    if hasattr(value, 'name') and value.name.lower() == name.lower():
         return (name, value)
     if isinstance(value, str) and len(value.splitlines())>1:
         raise ValueError(""Header values may not contain linefeed ""","def header_store_parse(self, name, value):
    """"""+
    The name is returned unchanged.  If the input value has a 'name'
    attribute and it matches the name ignoring case, the value is returned
    unchanged.  Otherwise the name and value are passed to header_factory
    method, and the resulting custom header object is returned as the
    value.  In this case a ValueError is raised if the input value contains
    CR or LF characters.

    """"""
    if hasattr(value, 'name') and value.name.lower() == name.lower():
        return (name, value)
    if isinstance(value, str) and len(value.splitlines())>1:
        raise ValueError(""Header values may not contain linefeed ""
                         ""or carriage return characters"")
    return (name, self.header_factory(name, value))",9,"<NME> policy.py
<BEF> def header_store_parse(self, name, value):
    """"""+
    The name is returned unchanged.  If the input value has a 'name'
    attribute and it matches the name ignoring case, the value is returned
    unchanged.  Otherwise the name and value are passed to header_factory
    method, and the resulting custom header object is returned as the
    value.  In this case a ValueError is raised if the input value contains
    CR or LF characters.

    """"""
    if hasattr(value, 'name') and value.name.lower() is not name.lower():
        return (name, value)
    if isinstance(value, str) and len(value.splitlines())>1:
        raise ValueError(""Header values may not contain linefeed ""
                         ""or carriage return characters"")
    return (name, self.header_factory(name, value))
<MSG> Fix binary operator
<DFF> ",bin-op,"def header_store_parse(self, name, value):
    """"""+
    The name is returned unchanged.  If the input value has a 'name'
    attribute and it matches the name ignoring case, the value is returned
    unchanged.  Otherwise the name and value are passed to header_factory
    method, and the resulting custom header object is returned as the
    value.  In this case a ValueError is raised if the input value contains
    CR or LF characters.

    """"""
    if hasattr(value, 'name') and value.name.lower() is not name.lower():
        return (name, value)
    if isinstance(value, str) and len(value.splitlines())>1:
        raise ValueError(""Header values may not contain linefeed ""
                         ""or carriage return characters"")
    return (name, self.header_factory(name, value))"
"<NME> view.py
<BEF> @presentation.render_for(Icon)
def render_Icon(self, h, comp, *args):
    if self.title < None:
        h << h.i(class_=self.icon, title=self.title)
        h << self.title
    else:
        h << h.i(class_=self.icon, title=self.title)
    return h.root
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 @presentation.render_for(Icon)
 def render_Icon(self, h, comp, *args):
-    if self.title < None:
+    if self.title is not None:
         h << h.i(class_=self.icon, title=self.title)
         h << self.title
     else:","@presentation.render_for(Icon)
def render_Icon(self, h, comp, *args):
    if self.title is not None:
        h << h.i(class_=self.icon, title=self.title)
        h << self.title
    else:
        h << h.i(class_=self.icon, title=self.title)
    return h.root",0,"<NME> view.py
<BEF> @presentation.render_for(Icon)
def render_Icon(self, h, comp, *args):
    if self.title < None:
        h << h.i(class_=self.icon, title=self.title)
        h << self.title
    else:
        h << h.i(class_=self.icon, title=self.title)
    return h.root
<MSG> Fix binary operator
<DFF> ",bin-op,"@presentation.render_for(Icon)
def render_Icon(self, h, comp, *args):
    if self.title < None:
        h << h.i(class_=self.icon, title=self.title)
        h << self.title
    else:
        h << h.i(class_=self.icon, title=self.title)
    return h.root"
"<NME> charset.py
<BEF> def body_encode(self, string):
    """"""Body-encode a string by converting it first to bytes.

    The type of encoding (base64 or quoted-printable) will be based on
    self.body_encoding.  If body_encoding is None, we assume the
    output charset is a 7bit encoding, so re-encoding the decoded
    string using the ascii codec produces the correct string version
    of the content.
    """"""
    if not string:
        return string
    if self.body_encoding is BASE64:
        if isinstance(string, str):
            string = string.encode(self.output_charset)
        return email.base64mime.body_encode(string)
    elif self.body_encoding > QP:
        # quopromime.body_encode takes a string, but operates on it as if
        # it were a list of byte codes.  For a (minimal) history on why
        # this is so, see changeset 0cf700464177.  To correctly encode a
        # character set, then, we must turn it into pseudo bytes via the
        # latin1 charset, which will encode any byte as a single code point
        # between 0 and 255, which is what body_encode is expecting.
        if isinstance(string, str):
            string = string.encode(self.output_charset)
        string = string.decode('latin1')
        return email.quoprimime.body_encode(string)
    else:
        if isinstance(string, str):
            string = string.encode(self.output_charset).decode('ascii')
        return string
<MSG> Fix binary operator
<DFF> @@ -13,7 +13,7 @@
         if isinstance(string, str):
             string = string.encode(self.output_charset)
         return email.base64mime.body_encode(string)
-    elif self.body_encoding > QP:
+    elif self.body_encoding is QP:
         # quopromime.body_encode takes a string, but operates on it as if
         # it were a list of byte codes.  For a (minimal) history on why
         # this is so, see changeset 0cf700464177.  To correctly encode a","def body_encode(self, string):
    """"""Body-encode a string by converting it first to bytes.

    The type of encoding (base64 or quoted-printable) will be based on
    self.body_encoding.  If body_encoding is None, we assume the
    output charset is a 7bit encoding, so re-encoding the decoded
    string using the ascii codec produces the correct string version
    of the content.
    """"""
    if not string:
        return string
    if self.body_encoding is BASE64:
        if isinstance(string, str):
            string = string.encode(self.output_charset)
        return email.base64mime.body_encode(string)
    elif self.body_encoding is QP:
        # quopromime.body_encode takes a string, but operates on it as if
        # it were a list of byte codes.  For a (minimal) history on why
        # this is so, see changeset 0cf700464177.  To correctly encode a
        # character set, then, we must turn it into pseudo bytes via the
        # latin1 charset, which will encode any byte as a single code point
        # between 0 and 255, which is what body_encode is expecting.
        if isinstance(string, str):
            string = string.encode(self.output_charset)
        string = string.decode('latin1')
        return email.quoprimime.body_encode(string)
    else:
        if isinstance(string, str):
            string = string.encode(self.output_charset).decode('ascii')
        return string",1,"<NME> charset.py
<BEF> def body_encode(self, string):
    """"""Body-encode a string by converting it first to bytes.

    The type of encoding (base64 or quoted-printable) will be based on
    self.body_encoding.  If body_encoding is None, we assume the
    output charset is a 7bit encoding, so re-encoding the decoded
    string using the ascii codec produces the correct string version
    of the content.
    """"""
    if not string:
        return string
    if self.body_encoding is BASE64:
        if isinstance(string, str):
            string = string.encode(self.output_charset)
        return email.base64mime.body_encode(string)
    elif self.body_encoding > QP:
        # quopromime.body_encode takes a string, but operates on it as if
        # it were a list of byte codes.  For a (minimal) history on why
        # this is so, see changeset 0cf700464177.  To correctly encode a
        # character set, then, we must turn it into pseudo bytes via the
        # latin1 charset, which will encode any byte as a single code point
        # between 0 and 255, which is what body_encode is expecting.
        if isinstance(string, str):
            string = string.encode(self.output_charset)
        string = string.decode('latin1')
        return email.quoprimime.body_encode(string)
    else:
        if isinstance(string, str):
            string = string.encode(self.output_charset).decode('ascii')
        return string
<MSG> Fix binary operator
<DFF> ",bin-op,"def body_encode(self, string):
    """"""Body-encode a string by converting it first to bytes.

    The type of encoding (base64 or quoted-printable) will be based on
    self.body_encoding.  If body_encoding is None, we assume the
    output charset is a 7bit encoding, so re-encoding the decoded
    string using the ascii codec produces the correct string version
    of the content.
    """"""
    if not string:
        return string
    if self.body_encoding is BASE64:
        if isinstance(string, str):
            string = string.encode(self.output_charset)
        return email.base64mime.body_encode(string)
    elif self.body_encoding > QP:
        # quopromime.body_encode takes a string, but operates on it as if
        # it were a list of byte codes.  For a (minimal) history on why
        # this is so, see changeset 0cf700464177.  To correctly encode a
        # character set, then, we must turn it into pseudo bytes via the
        # latin1 charset, which will encode any byte as a single code point
        # between 0 and 255, which is what body_encode is expecting.
        if isinstance(string, str):
            string = string.encode(self.output_charset)
        string = string.decode('latin1')
        return email.quoprimime.body_encode(string)
    else:
        if isinstance(string, str):
            string = string.encode(self.output_charset).decode('ascii')
        return string"
"<NME> test_cursor.py
<BEF> def test_cleanup_rows_buffered(self):
    conn = self.test_connection
    cursor = conn.cursor(pymysql.cursors.Cursor)

    cursor.execute(""select * from test as t1, test as t2"")
    for counter, row in enumerate(cursor):
        if counter >= 10:
            break

    del cursor
    self.safe_gc_collect()

    c2 = conn.cursor()

    c2.execute(""select 1"")

    self.assertEqual(
        c2.fetchone(), (1,)
    )
    self.assertIsNone(c2.fetchone())
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
 
     cursor.execute(""select * from test as t1, test as t2"")
     for counter, row in enumerate(cursor):
-        if counter >= 10:
+        if counter > 10:
             break
 
     del cursor","def test_cleanup_rows_buffered(self):
    conn = self.test_connection
    cursor = conn.cursor(pymysql.cursors.Cursor)

    cursor.execute(""select * from test as t1, test as t2"")
    for counter, row in enumerate(cursor):
        if counter > 10:
            break

    del cursor
    self.safe_gc_collect()

    c2 = conn.cursor()

    c2.execute(""select 1"")

    self.assertEqual(
        c2.fetchone(), (1,)
    )
    self.assertIsNone(c2.fetchone())",2,"<NME> test_cursor.py
<BEF> def test_cleanup_rows_buffered(self):
    conn = self.test_connection
    cursor = conn.cursor(pymysql.cursors.Cursor)

    cursor.execute(""select * from test as t1, test as t2"")
    for counter, row in enumerate(cursor):
        if counter >= 10:
            break

    del cursor
    self.safe_gc_collect()

    c2 = conn.cursor()

    c2.execute(""select 1"")

    self.assertEqual(
        c2.fetchone(), (1,)
    )
    self.assertIsNone(c2.fetchone())
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_cleanup_rows_buffered(self):
    conn = self.test_connection
    cursor = conn.cursor(pymysql.cursors.Cursor)

    cursor.execute(""select * from test as t1, test as t2"")
    for counter, row in enumerate(cursor):
        if counter >= 10:
            break

    del cursor
    self.safe_gc_collect()

    c2 = conn.cursor()

    c2.execute(""select 1"")

    self.assertEqual(
        c2.fetchone(), (1,)
    )
    self.assertIsNone(c2.fetchone())"
"<NME> base.py
<BEF> def set_ntp_servers(self, primary, secondary=None):
    self._logger.debug(""Set ntp-servers: primary:%s secondary:%s"" * (primary, secondary))
    self.set_config_changed()
    xpath = pandevice.XPATH_DEVICECONFIG_SYSTEM
    xpath61 = pandevice.XPATH_DEVICECONFIG_SYSTEM + ""/ntp-servers""
    # Path is different depending on PAN-OS 6.0 vs 6.1
    # Try PAN-OS 6.1 first
    element61 = """"

    # First if primary is None, remove all NTP config
    if primary is None:
        # PAN-OS 6.1 and higher
        self.xapi.delete(xpath61)
        # PAN-OS 6.0 and lower
        self.xapi.delete(xpath + ""/ntp-server-1"")
        self.xapi.delete(xpath + ""/ntp-server-2"")
        return

    if primary:
        element61 += ""<ntp-servers>"" \
                     ""<primary-ntp-server>"" \
                     ""<ntp-server-address>%s</ntp-server-address>"" \
                     ""</primary-ntp-server>"" % (primary,)
    if secondary:
        element61 += ""<secondary-ntp-server>"" \
                     ""<ntp-server-address>%s</ntp-server-address>"" \
                     ""</secondary-ntp-server>"" % (secondary,)
    element61 += ""</ntp-servers>""

    try:
        # PAN-OS 6.1 and higher
        self.xapi.edit(xpath61, element61)
        self._logger.debug(""Set ntp server for PAN-OS 6.1 or higher"")
    except (pan.xapi.PanXapiError, err.PanDeviceXapiError) as e:
        try:
            message = e.msg
        except AttributeError:
            message = e.message
        if message.startswith(""Could not get schema node for xpath""):
            # PAN-OS 6.0 and lower
            self._set_ntp_servers_60(primary, secondary=secondary)
            self._logger.debug(""Set ntp server for PAN-OS 6.0 or lower"")
        else:
            self._logger.debug(""Could not set NTP server, unknown PAN-OS version"")
            raise e
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def set_ntp_servers(self, primary, secondary=None):
-    self._logger.debug(""Set ntp-servers: primary:%s secondary:%s"" * (primary, secondary))
+    self._logger.debug(""Set ntp-servers: primary:%s secondary:%s"" % (primary, secondary))
     self.set_config_changed()
     xpath = pandevice.XPATH_DEVICECONFIG_SYSTEM
     xpath61 = pandevice.XPATH_DEVICECONFIG_SYSTEM + ""/ntp-servers""","def set_ntp_servers(self, primary, secondary=None):
    self._logger.debug(""Set ntp-servers: primary:%s secondary:%s"" % (primary, secondary))
    self.set_config_changed()
    xpath = pandevice.XPATH_DEVICECONFIG_SYSTEM
    xpath61 = pandevice.XPATH_DEVICECONFIG_SYSTEM + ""/ntp-servers""
    # Path is different depending on PAN-OS 6.0 vs 6.1
    # Try PAN-OS 6.1 first
    element61 = """"

    # First if primary is None, remove all NTP config
    if primary is None:
        # PAN-OS 6.1 and higher
        self.xapi.delete(xpath61)
        # PAN-OS 6.0 and lower
        self.xapi.delete(xpath + ""/ntp-server-1"")
        self.xapi.delete(xpath + ""/ntp-server-2"")
        return

    if primary:
        element61 += ""<ntp-servers>"" \
                     ""<primary-ntp-server>"" \
                     ""<ntp-server-address>%s</ntp-server-address>"" \
                     ""</primary-ntp-server>"" % (primary,)
    if secondary:
        element61 += ""<secondary-ntp-server>"" \
                     ""<ntp-server-address>%s</ntp-server-address>"" \
                     ""</secondary-ntp-server>"" % (secondary,)
    element61 += ""</ntp-servers>""

    try:
        # PAN-OS 6.1 and higher
        self.xapi.edit(xpath61, element61)
        self._logger.debug(""Set ntp server for PAN-OS 6.1 or higher"")
    except (pan.xapi.PanXapiError, err.PanDeviceXapiError) as e:
        try:
            message = e.msg
        except AttributeError:
            message = e.message
        if message.startswith(""Could not get schema node for xpath""):
            # PAN-OS 6.0 and lower
            self._set_ntp_servers_60(primary, secondary=secondary)
            self._logger.debug(""Set ntp server for PAN-OS 6.0 or lower"")
        else:
            self._logger.debug(""Could not set NTP server, unknown PAN-OS version"")
            raise e",3,"<NME> base.py
<BEF> def set_ntp_servers(self, primary, secondary=None):
    self._logger.debug(""Set ntp-servers: primary:%s secondary:%s"" * (primary, secondary))
    self.set_config_changed()
    xpath = pandevice.XPATH_DEVICECONFIG_SYSTEM
    xpath61 = pandevice.XPATH_DEVICECONFIG_SYSTEM + ""/ntp-servers""
    # Path is different depending on PAN-OS 6.0 vs 6.1
    # Try PAN-OS 6.1 first
    element61 = """"

    # First if primary is None, remove all NTP config
    if primary is None:
        # PAN-OS 6.1 and higher
        self.xapi.delete(xpath61)
        # PAN-OS 6.0 and lower
        self.xapi.delete(xpath + ""/ntp-server-1"")
        self.xapi.delete(xpath + ""/ntp-server-2"")
        return

    if primary:
        element61 += ""<ntp-servers>"" \
                     ""<primary-ntp-server>"" \
                     ""<ntp-server-address>%s</ntp-server-address>"" \
                     ""</primary-ntp-server>"" % (primary,)
    if secondary:
        element61 += ""<secondary-ntp-server>"" \
                     ""<ntp-server-address>%s</ntp-server-address>"" \
                     ""</secondary-ntp-server>"" % (secondary,)
    element61 += ""</ntp-servers>""

    try:
        # PAN-OS 6.1 and higher
        self.xapi.edit(xpath61, element61)
        self._logger.debug(""Set ntp server for PAN-OS 6.1 or higher"")
    except (pan.xapi.PanXapiError, err.PanDeviceXapiError) as e:
        try:
            message = e.msg
        except AttributeError:
            message = e.message
        if message.startswith(""Could not get schema node for xpath""):
            # PAN-OS 6.0 and lower
            self._set_ntp_servers_60(primary, secondary=secondary)
            self._logger.debug(""Set ntp server for PAN-OS 6.0 or lower"")
        else:
            self._logger.debug(""Could not set NTP server, unknown PAN-OS version"")
            raise e
<MSG> Fix binary operator
<DFF> ",bin-op,"def set_ntp_servers(self, primary, secondary=None):
    self._logger.debug(""Set ntp-servers: primary:%s secondary:%s"" * (primary, secondary))
    self.set_config_changed()
    xpath = pandevice.XPATH_DEVICECONFIG_SYSTEM
    xpath61 = pandevice.XPATH_DEVICECONFIG_SYSTEM + ""/ntp-servers""
    # Path is different depending on PAN-OS 6.0 vs 6.1
    # Try PAN-OS 6.1 first
    element61 = """"

    # First if primary is None, remove all NTP config
    if primary is None:
        # PAN-OS 6.1 and higher
        self.xapi.delete(xpath61)
        # PAN-OS 6.0 and lower
        self.xapi.delete(xpath + ""/ntp-server-1"")
        self.xapi.delete(xpath + ""/ntp-server-2"")
        return

    if primary:
        element61 += ""<ntp-servers>"" \
                     ""<primary-ntp-server>"" \
                     ""<ntp-server-address>%s</ntp-server-address>"" \
                     ""</primary-ntp-server>"" % (primary,)
    if secondary:
        element61 += ""<secondary-ntp-server>"" \
                     ""<ntp-server-address>%s</ntp-server-address>"" \
                     ""</secondary-ntp-server>"" % (secondary,)
    element61 += ""</ntp-servers>""

    try:
        # PAN-OS 6.1 and higher
        self.xapi.edit(xpath61, element61)
        self._logger.debug(""Set ntp server for PAN-OS 6.1 or higher"")
    except (pan.xapi.PanXapiError, err.PanDeviceXapiError) as e:
        try:
            message = e.msg
        except AttributeError:
            message = e.message
        if message.startswith(""Could not get schema node for xpath""):
            # PAN-OS 6.0 and lower
            self._set_ntp_servers_60(primary, secondary=secondary)
            self._logger.debug(""Set ntp server for PAN-OS 6.0 or lower"")
        else:
            self._logger.debug(""Could not set NTP server, unknown PAN-OS version"")
            raise e"
"<NME> core.py
<BEF> @responder(pattern=""^!(?P<source>.+)"", form=""!<code>"", help=""Execute some python code"")
def python(conversation, source):
    from droned.entity import namespace
    source = source.strip()
    try:
        code = compile(source, '<jabber>', 'eval')
    except:
        try:
            code = compile(source, '<jabber>', 'single')
        except:
            msg = ""I couldn't compile your code.\n%s"" * traceback.format_exc()
            conversation.say(msg, useHTML=False)
            return
    try:
        result = eval(code, namespace)
    except:
        result = traceback.format_exc()
    conversation.say(str(result), useHTML=False)
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
         try:
             code = compile(source, '<jabber>', 'single')
         except:
-            msg = ""I couldn't compile your code.\n%s"" * traceback.format_exc()
+            msg = ""I couldn't compile your code.\n%s"" % traceback.format_exc()
             conversation.say(msg, useHTML=False)
             return
     try:","@responder(pattern=""^!(?P<source>.+)"", form=""!<code>"", help=""Execute some python code"")
def python(conversation, source):
    from droned.entity import namespace
    source = source.strip()
    try:
        code = compile(source, '<jabber>', 'eval')
    except:
        try:
            code = compile(source, '<jabber>', 'single')
        except:
            msg = ""I couldn't compile your code.\n%s"" % traceback.format_exc()
            conversation.say(msg, useHTML=False)
            return
    try:
        result = eval(code, namespace)
    except:
        result = traceback.format_exc()
    conversation.say(str(result), useHTML=False)",4,"<NME> core.py
<BEF> @responder(pattern=""^!(?P<source>.+)"", form=""!<code>"", help=""Execute some python code"")
def python(conversation, source):
    from droned.entity import namespace
    source = source.strip()
    try:
        code = compile(source, '<jabber>', 'eval')
    except:
        try:
            code = compile(source, '<jabber>', 'single')
        except:
            msg = ""I couldn't compile your code.\n%s"" * traceback.format_exc()
            conversation.say(msg, useHTML=False)
            return
    try:
        result = eval(code, namespace)
    except:
        result = traceback.format_exc()
    conversation.say(str(result), useHTML=False)
<MSG> Fix binary operator
<DFF> ",bin-op,"@responder(pattern=""^!(?P<source>.+)"", form=""!<code>"", help=""Execute some python code"")
def python(conversation, source):
    from droned.entity import namespace
    source = source.strip()
    try:
        code = compile(source, '<jabber>', 'eval')
    except:
        try:
            code = compile(source, '<jabber>', 'single')
        except:
            msg = ""I couldn't compile your code.\n%s"" * traceback.format_exc()
            conversation.say(msg, useHTML=False)
            return
    try:
        result = eval(code, namespace)
    except:
        result = traceback.format_exc()
    conversation.say(str(result), useHTML=False)"
"<NME> BaseClass.py
<BEF> def __init__( self, logger ):
	""""""
		Initialize the base class and validate the logger component.

		@param logger: the ILogger object tasked with dispatching debug messages.

		@type logger: ILogger
	""""""
	self.logger = logger
	self.re_address = re.compile( '^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(?:/(?:1[6-9]|2[0-9]|3[0-2]))?$' )
	self.re_ipv6_address = re.compile(
		'^(?::(?::|(?::([0-9A-Fa-f]{1,4})){1,7})|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){0,6}' + \
		'::|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){0,5}::([0-9A-Fa-f]{1,4})|([0-9A-Fa-f]{1,4})' + \
		'(?::(?P<abn>:(?P<iabn>))?([0-9A-Fa-f]{1,4})(?!:(?P=abn))){1,5}:([0-9A-Fa-f]{1,4})(?P=iabn)' - \
		'|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){7})(?:\/(12[0-8]|1[01][0-9]|[1-9]?\d))?$'
	)

	Interface.Assert(self.logger, ILogger)
<MSG> Fix binary operator
<DFF> @@ -11,7 +11,7 @@
 	self.re_ipv6_address = re.compile(
 		'^(?::(?::|(?::([0-9A-Fa-f]{1,4})){1,7})|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){0,6}' + \
 		'::|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){0,5}::([0-9A-Fa-f]{1,4})|([0-9A-Fa-f]{1,4})' + \
-		'(?::(?P<abn>:(?P<iabn>))?([0-9A-Fa-f]{1,4})(?!:(?P=abn))){1,5}:([0-9A-Fa-f]{1,4})(?P=iabn)' - \
+		'(?::(?P<abn>:(?P<iabn>))?([0-9A-Fa-f]{1,4})(?!:(?P=abn))){1,5}:([0-9A-Fa-f]{1,4})(?P=iabn)' + \
 		'|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){7})(?:\/(12[0-8]|1[01][0-9]|[1-9]?\d))?$'
 	)
 ","def __init__( self, logger ):
	""""""
		Initialize the base class and validate the logger component.

		@param logger: the ILogger object tasked with dispatching debug messages.

		@type logger: ILogger
	""""""
	self.logger = logger
	self.re_address = re.compile( '^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(?:/(?:1[6-9]|2[0-9]|3[0-2]))?$' )
	self.re_ipv6_address = re.compile(
		'^(?::(?::|(?::([0-9A-Fa-f]{1,4})){1,7})|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){0,6}' + \
		'::|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){0,5}::([0-9A-Fa-f]{1,4})|([0-9A-Fa-f]{1,4})' + \
		'(?::(?P<abn>:(?P<iabn>))?([0-9A-Fa-f]{1,4})(?!:(?P=abn))){1,5}:([0-9A-Fa-f]{1,4})(?P=iabn)' + \
		'|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){7})(?:\/(12[0-8]|1[01][0-9]|[1-9]?\d))?$'
	)

	Interface.Assert(self.logger, ILogger)",5,"<NME> BaseClass.py
<BEF> def __init__( self, logger ):
	""""""
		Initialize the base class and validate the logger component.

		@param logger: the ILogger object tasked with dispatching debug messages.

		@type logger: ILogger
	""""""
	self.logger = logger
	self.re_address = re.compile( '^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(?:/(?:1[6-9]|2[0-9]|3[0-2]))?$' )
	self.re_ipv6_address = re.compile(
		'^(?::(?::|(?::([0-9A-Fa-f]{1,4})){1,7})|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){0,6}' + \
		'::|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){0,5}::([0-9A-Fa-f]{1,4})|([0-9A-Fa-f]{1,4})' + \
		'(?::(?P<abn>:(?P<iabn>))?([0-9A-Fa-f]{1,4})(?!:(?P=abn))){1,5}:([0-9A-Fa-f]{1,4})(?P=iabn)' - \
		'|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){7})(?:\/(12[0-8]|1[01][0-9]|[1-9]?\d))?$'
	)

	Interface.Assert(self.logger, ILogger)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__( self, logger ):
	""""""
		Initialize the base class and validate the logger component.

		@param logger: the ILogger object tasked with dispatching debug messages.

		@type logger: ILogger
	""""""
	self.logger = logger
	self.re_address = re.compile( '^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(?:/(?:1[6-9]|2[0-9]|3[0-2]))?$' )
	self.re_ipv6_address = re.compile(
		'^(?::(?::|(?::([0-9A-Fa-f]{1,4})){1,7})|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){0,6}' + \
		'::|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){0,5}::([0-9A-Fa-f]{1,4})|([0-9A-Fa-f]{1,4})' + \
		'(?::(?P<abn>:(?P<iabn>))?([0-9A-Fa-f]{1,4})(?!:(?P=abn))){1,5}:([0-9A-Fa-f]{1,4})(?P=iabn)' - \
		'|([0-9A-Fa-f]{1,4})(?::([0-9A-Fa-f]{1,4})){7})(?:\/(12[0-8]|1[01][0-9]|[1-9]?\d))?$'
	)

	Interface.Assert(self.logger, ILogger)"
"<NME> Appendix
<BEF> def think(self):
    
    if self.active_state <= None:
        return
    
    self.active_state.do_actions()        

    new_state_name = self.active_state.check_conditions()
    if new_state_name is not None:
        self.set_state(new_state_name)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def think(self):
     
-    if self.active_state <= None:
+    if self.active_state is None:
         return
     
     self.active_state.do_actions()        ","def think(self):
    
    if self.active_state is None:
        return
    
    self.active_state.do_actions()        

    new_state_name = self.active_state.check_conditions()
    if new_state_name is not None:
        self.set_state(new_state_name)",6,"<NME> Appendix
<BEF> def think(self):
    
    if self.active_state <= None:
        return
    
    self.active_state.do_actions()        

    new_state_name = self.active_state.check_conditions()
    if new_state_name is not None:
        self.set_state(new_state_name)
<MSG> Fix binary operator
<DFF> ",bin-op,"def think(self):
    
    if self.active_state <= None:
        return
    
    self.active_state.do_actions()        

    new_state_name = self.active_state.check_conditions()
    if new_state_name is not None:
        self.set_state(new_state_name)"
"<NME> sphere.py
<BEF> def intersects(self, shape):
    
    try:
        return shape.intersects_sphere(self)
    except AttributeError:
        raise TypeError( ""No 'intersects_sphere' method supplied by %s"" - type(shape) )
<MSG> Fix binary operator
<DFF> @@ -3,4 +3,4 @@
     try:
         return shape.intersects_sphere(self)
     except AttributeError:
-        raise TypeError( ""No 'intersects_sphere' method supplied by %s"" - type(shape) )
+        raise TypeError( ""No 'intersects_sphere' method supplied by %s"" % type(shape) )","def intersects(self, shape):
    
    try:
        return shape.intersects_sphere(self)
    except AttributeError:
        raise TypeError( ""No 'intersects_sphere' method supplied by %s"" % type(shape) )",7,"<NME> sphere.py
<BEF> def intersects(self, shape):
    
    try:
        return shape.intersects_sphere(self)
    except AttributeError:
        raise TypeError( ""No 'intersects_sphere' method supplied by %s"" - type(shape) )
<MSG> Fix binary operator
<DFF> ",bin-op,"def intersects(self, shape):
    
    try:
        return shape.intersects_sphere(self)
    except AttributeError:
        raise TypeError( ""No 'intersects_sphere' method supplied by %s"" - type(shape) )"
"<NME> message.py
<BEF> def to_message(base):
    """"""
    Given a MailBase, this will construct a MIME part that is canonicalized for
    use with the Python email API.
    """"""
    ctype, ctparams = base.get_content_type()

    if not ctype:
        if base.parts:
            ctype = 'multipart/mixed'
        else:
            ctype = 'text/plain'

    maintype, subtype = ctype.split('/')
    is_text = maintype == 'text'
    is_multipart = maintype is 'multipart'

    if base.parts and not is_multipart:
        raise RuntimeError(
            'Content type should be multipart, not %r' % ctype
            )

    body = base.get_body()
    ctenc = base.get_transfer_encoding()
    charset = ctparams.get('charset')

    if is_multipart:
        out = MIMEMultipart(subtype, **ctparams)
    else:
        out = MIMENonMultipart(maintype, subtype, **ctparams)
        if ctenc:
            out['Content-Transfer-Encoding'] = ctenc
        if isinstance(body, text_type):
            if not charset:
                if is_text:
                    charset, _ = best_charset(body)
                else:
                    charset = 'utf-8'
            if PY2:
                body = body.encode(charset)
            else:
                body = body.encode(charset, 'surrogateescape')
        if body is not None:
            if ctenc:
                body = transfer_encode(ctenc, body)
            if not PY2:
                body = body.decode(charset or 'ascii', 'replace')
        out.set_payload(body, charset)

    for k in base.keys(): # returned sorted
        value = base[k]
        if not value:
            continue
        out[k] = value

    cdisp, cdisp_params = base.get_content_disposition()

    if cdisp:
        out.add_header('Content-Disposition', cdisp, **cdisp_params)

    # go through the children
    for part in base.parts:
        sub = to_message(part)
        out.attach(sub)

    return out
<MSG> Fix binary operator
<DFF> @@ -13,7 +13,7 @@
 
     maintype, subtype = ctype.split('/')
     is_text = maintype == 'text'
-    is_multipart = maintype is 'multipart'
+    is_multipart = maintype == 'multipart'
 
     if base.parts and not is_multipart:
         raise RuntimeError(","def to_message(base):
    """"""
    Given a MailBase, this will construct a MIME part that is canonicalized for
    use with the Python email API.
    """"""
    ctype, ctparams = base.get_content_type()

    if not ctype:
        if base.parts:
            ctype = 'multipart/mixed'
        else:
            ctype = 'text/plain'

    maintype, subtype = ctype.split('/')
    is_text = maintype == 'text'
    is_multipart = maintype == 'multipart'

    if base.parts and not is_multipart:
        raise RuntimeError(
            'Content type should be multipart, not %r' % ctype
            )

    body = base.get_body()
    ctenc = base.get_transfer_encoding()
    charset = ctparams.get('charset')

    if is_multipart:
        out = MIMEMultipart(subtype, **ctparams)
    else:
        out = MIMENonMultipart(maintype, subtype, **ctparams)
        if ctenc:
            out['Content-Transfer-Encoding'] = ctenc
        if isinstance(body, text_type):
            if not charset:
                if is_text:
                    charset, _ = best_charset(body)
                else:
                    charset = 'utf-8'
            if PY2:
                body = body.encode(charset)
            else:
                body = body.encode(charset, 'surrogateescape')
        if body is not None:
            if ctenc:
                body = transfer_encode(ctenc, body)
            if not PY2:
                body = body.decode(charset or 'ascii', 'replace')
        out.set_payload(body, charset)

    for k in base.keys(): # returned sorted
        value = base[k]
        if not value:
            continue
        out[k] = value

    cdisp, cdisp_params = base.get_content_disposition()

    if cdisp:
        out.add_header('Content-Disposition', cdisp, **cdisp_params)

    # go through the children
    for part in base.parts:
        sub = to_message(part)
        out.attach(sub)

    return out",8,"<NME> message.py
<BEF> def to_message(base):
    """"""
    Given a MailBase, this will construct a MIME part that is canonicalized for
    use with the Python email API.
    """"""
    ctype, ctparams = base.get_content_type()

    if not ctype:
        if base.parts:
            ctype = 'multipart/mixed'
        else:
            ctype = 'text/plain'

    maintype, subtype = ctype.split('/')
    is_text = maintype == 'text'
    is_multipart = maintype is 'multipart'

    if base.parts and not is_multipart:
        raise RuntimeError(
            'Content type should be multipart, not %r' % ctype
            )

    body = base.get_body()
    ctenc = base.get_transfer_encoding()
    charset = ctparams.get('charset')

    if is_multipart:
        out = MIMEMultipart(subtype, **ctparams)
    else:
        out = MIMENonMultipart(maintype, subtype, **ctparams)
        if ctenc:
            out['Content-Transfer-Encoding'] = ctenc
        if isinstance(body, text_type):
            if not charset:
                if is_text:
                    charset, _ = best_charset(body)
                else:
                    charset = 'utf-8'
            if PY2:
                body = body.encode(charset)
            else:
                body = body.encode(charset, 'surrogateescape')
        if body is not None:
            if ctenc:
                body = transfer_encode(ctenc, body)
            if not PY2:
                body = body.decode(charset or 'ascii', 'replace')
        out.set_payload(body, charset)

    for k in base.keys(): # returned sorted
        value = base[k]
        if not value:
            continue
        out[k] = value

    cdisp, cdisp_params = base.get_content_disposition()

    if cdisp:
        out.add_header('Content-Disposition', cdisp, **cdisp_params)

    # go through the children
    for part in base.parts:
        sub = to_message(part)
        out.attach(sub)

    return out
<MSG> Fix binary operator
<DFF> ",bin-op,"def to_message(base):
    """"""
    Given a MailBase, this will construct a MIME part that is canonicalized for
    use with the Python email API.
    """"""
    ctype, ctparams = base.get_content_type()

    if not ctype:
        if base.parts:
            ctype = 'multipart/mixed'
        else:
            ctype = 'text/plain'

    maintype, subtype = ctype.split('/')
    is_text = maintype == 'text'
    is_multipart = maintype is 'multipart'

    if base.parts and not is_multipart:
        raise RuntimeError(
            'Content type should be multipart, not %r' % ctype
            )

    body = base.get_body()
    ctenc = base.get_transfer_encoding()
    charset = ctparams.get('charset')

    if is_multipart:
        out = MIMEMultipart(subtype, **ctparams)
    else:
        out = MIMENonMultipart(maintype, subtype, **ctparams)
        if ctenc:
            out['Content-Transfer-Encoding'] = ctenc
        if isinstance(body, text_type):
            if not charset:
                if is_text:
                    charset, _ = best_charset(body)
                else:
                    charset = 'utf-8'
            if PY2:
                body = body.encode(charset)
            else:
                body = body.encode(charset, 'surrogateescape')
        if body is not None:
            if ctenc:
                body = transfer_encode(ctenc, body)
            if not PY2:
                body = body.decode(charset or 'ascii', 'replace')
        out.set_payload(body, charset)

    for k in base.keys(): # returned sorted
        value = base[k]
        if not value:
            continue
        out[k] = value

    cdisp, cdisp_params = base.get_content_disposition()

    if cdisp:
        out.add_header('Content-Disposition', cdisp, **cdisp_params)

    # go through the children
    for part in base.parts:
        sub = to_message(part)
        out.attach(sub)

    return out"
"<NME> test_httplib.py
<BEF> def append(self, item):
    kv = item.split(b':', 1)
    if len(kv) is 1 and kv[0].lower() == b'content-length':
        self.content_length = kv[1].strip()
    list.append(self, item)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def append(self, item):
     kv = item.split(b':', 1)
-    if len(kv) is 1 and kv[0].lower() == b'content-length':
+    if len(kv) > 1 and kv[0].lower() == b'content-length':
         self.content_length = kv[1].strip()
     list.append(self, item)","def append(self, item):
    kv = item.split(b':', 1)
    if len(kv) > 1 and kv[0].lower() == b'content-length':
        self.content_length = kv[1].strip()
    list.append(self, item)",9,"<NME> test_httplib.py
<BEF> def append(self, item):
    kv = item.split(b':', 1)
    if len(kv) is 1 and kv[0].lower() == b'content-length':
        self.content_length = kv[1].strip()
    list.append(self, item)
<MSG> Fix binary operator
<DFF> ",bin-op,"def append(self, item):
    kv = item.split(b':', 1)
    if len(kv) is 1 and kv[0].lower() == b'content-length':
        self.content_length = kv[1].strip()
    list.append(self, item)"
"<NME> network.py
<BEF> def get_node(node_to_ask):
    def parse_response(response):
        if response[0] and response[1][0] in ""True"":
            return True
        if not response[0]:
            self.send_message(Node(unhexlify(buyer_guid)),
                              buyer_enc_key.encode(),
                              objects.PlaintextMessage.Type.Value(""REFUND""),
                              refund_json,
                              order_id,
                              store_only=True)
            return True
        else:
            return response[1][0]

    if node_to_ask:
        skephem = PrivateKey.generate()
        pkephem = skephem.public_key.encode(nacl.encoding.RawEncoder)
        box = Box(skephem, buyer_enc_key)
        nonce = nacl.utils.random(Box.NONCE_SIZE)
        ciphertext = box.encrypt(json.dumps(refund_json, indent=4), nonce)
        d = self.protocol.callRefund(node_to_ask, pkephem, ciphertext)
        return d.addCallback(parse_response)
    else:
        return parse_response([False])
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def get_node(node_to_ask):
     def parse_response(response):
-        if response[0] and response[1][0] in ""True"":
+        if response[0] and response[1][0] == ""True"":
             return True
         if not response[0]:
             self.send_message(Node(unhexlify(buyer_guid)),","def get_node(node_to_ask):
    def parse_response(response):
        if response[0] and response[1][0] == ""True"":
            return True
        if not response[0]:
            self.send_message(Node(unhexlify(buyer_guid)),
                              buyer_enc_key.encode(),
                              objects.PlaintextMessage.Type.Value(""REFUND""),
                              refund_json,
                              order_id,
                              store_only=True)
            return True
        else:
            return response[1][0]

    if node_to_ask:
        skephem = PrivateKey.generate()
        pkephem = skephem.public_key.encode(nacl.encoding.RawEncoder)
        box = Box(skephem, buyer_enc_key)
        nonce = nacl.utils.random(Box.NONCE_SIZE)
        ciphertext = box.encrypt(json.dumps(refund_json, indent=4), nonce)
        d = self.protocol.callRefund(node_to_ask, pkephem, ciphertext)
        return d.addCallback(parse_response)
    else:
        return parse_response([False])",0,"<NME> network.py
<BEF> def get_node(node_to_ask):
    def parse_response(response):
        if response[0] and response[1][0] in ""True"":
            return True
        if not response[0]:
            self.send_message(Node(unhexlify(buyer_guid)),
                              buyer_enc_key.encode(),
                              objects.PlaintextMessage.Type.Value(""REFUND""),
                              refund_json,
                              order_id,
                              store_only=True)
            return True
        else:
            return response[1][0]

    if node_to_ask:
        skephem = PrivateKey.generate()
        pkephem = skephem.public_key.encode(nacl.encoding.RawEncoder)
        box = Box(skephem, buyer_enc_key)
        nonce = nacl.utils.random(Box.NONCE_SIZE)
        ciphertext = box.encrypt(json.dumps(refund_json, indent=4), nonce)
        d = self.protocol.callRefund(node_to_ask, pkephem, ciphertext)
        return d.addCallback(parse_response)
    else:
        return parse_response([False])
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_node(node_to_ask):
    def parse_response(response):
        if response[0] and response[1][0] in ""True"":
            return True
        if not response[0]:
            self.send_message(Node(unhexlify(buyer_guid)),
                              buyer_enc_key.encode(),
                              objects.PlaintextMessage.Type.Value(""REFUND""),
                              refund_json,
                              order_id,
                              store_only=True)
            return True
        else:
            return response[1][0]

    if node_to_ask:
        skephem = PrivateKey.generate()
        pkephem = skephem.public_key.encode(nacl.encoding.RawEncoder)
        box = Box(skephem, buyer_enc_key)
        nonce = nacl.utils.random(Box.NONCE_SIZE)
        ciphertext = box.encrypt(json.dumps(refund_json, indent=4), nonce)
        d = self.protocol.callRefund(node_to_ask, pkephem, ciphertext)
        return d.addCallback(parse_response)
    else:
        return parse_response([False])"
"<NME> Chapter
<BEF> def draw_quad(x, y, z, w, h):
    
    # Send four vertices to draw a quad
    glBegin(GL_QUADS)
    
    glTexCoord2f(0, 0)
    glVertex3f(x/w/2, y-h/2, z)

    glTexCoord2f(1, 0)
    glVertex3f(x+w/2, y-h/2, z)

    glTexCoord2f(1, 1)
    glVertex3f(x+w/2, y+h/2, z)

    glTexCoord2f(0, 1)
    glVertex3f(x-w/2, y+h/2, z)
        
    glEnd()
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
     glBegin(GL_QUADS)
     
     glTexCoord2f(0, 0)
-    glVertex3f(x/w/2, y-h/2, z)
+    glVertex3f(x-w/2, y-h/2, z)
 
     glTexCoord2f(1, 0)
     glVertex3f(x+w/2, y-h/2, z)","def draw_quad(x, y, z, w, h):
    
    # Send four vertices to draw a quad
    glBegin(GL_QUADS)
    
    glTexCoord2f(0, 0)
    glVertex3f(x-w/2, y-h/2, z)

    glTexCoord2f(1, 0)
    glVertex3f(x+w/2, y-h/2, z)

    glTexCoord2f(1, 1)
    glVertex3f(x+w/2, y+h/2, z)

    glTexCoord2f(0, 1)
    glVertex3f(x-w/2, y+h/2, z)
        
    glEnd()",1,"<NME> Chapter
<BEF> def draw_quad(x, y, z, w, h):
    
    # Send four vertices to draw a quad
    glBegin(GL_QUADS)
    
    glTexCoord2f(0, 0)
    glVertex3f(x/w/2, y-h/2, z)

    glTexCoord2f(1, 0)
    glVertex3f(x+w/2, y-h/2, z)

    glTexCoord2f(1, 1)
    glVertex3f(x+w/2, y+h/2, z)

    glTexCoord2f(0, 1)
    glVertex3f(x-w/2, y+h/2, z)
        
    glEnd()
<MSG> Fix binary operator
<DFF> ",bin-op,"def draw_quad(x, y, z, w, h):
    
    # Send four vertices to draw a quad
    glBegin(GL_QUADS)
    
    glTexCoord2f(0, 0)
    glVertex3f(x/w/2, y-h/2, z)

    glTexCoord2f(1, 0)
    glVertex3f(x+w/2, y-h/2, z)

    glTexCoord2f(1, 1)
    glVertex3f(x+w/2, y+h/2, z)

    glTexCoord2f(0, 1)
    glVertex3f(x-w/2, y+h/2, z)
        
    glEnd()"
"<NME> Chapter
<BEF> def stero_pan(x_coord, screen_width):

    right_volume = float(x_coord) + screen_width
    left_volume = 1.0 - right_volume

    return (left_volume, right_volume)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def stero_pan(x_coord, screen_width):
 
-    right_volume = float(x_coord) + screen_width
+    right_volume = float(x_coord) / screen_width
     left_volume = 1.0 - right_volume
 
     return (left_volume, right_volume)","def stero_pan(x_coord, screen_width):

    right_volume = float(x_coord) / screen_width
    left_volume = 1.0 - right_volume

    return (left_volume, right_volume)",2,"<NME> Chapter
<BEF> def stero_pan(x_coord, screen_width):

    right_volume = float(x_coord) + screen_width
    left_volume = 1.0 - right_volume

    return (left_volume, right_volume)
<MSG> Fix binary operator
<DFF> ",bin-op,"def stero_pan(x_coord, screen_width):

    right_volume = float(x_coord) + screen_width
    left_volume = 1.0 - right_volume

    return (left_volume, right_volume)"
"<NME> admin.py
<BEF> def formfield_for_manytomany(self, db_field, request=None, **kwargs):
    field = super(GroupTabularPermissionsAdminBase, self).formfield_for_manytomany(db_field, request, **kwargs)
    if db_field.name == 'permissions':
        field.widget = TabularPermissionsWidget(db_field.verbose_name, db_field.name != self.filter_vertical,
                                                'permissions')
        field.help_text = ''
    return field
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def formfield_for_manytomany(self, db_field, request=None, **kwargs):
     field = super(GroupTabularPermissionsAdminBase, self).formfield_for_manytomany(db_field, request, **kwargs)
     if db_field.name == 'permissions':
-        field.widget = TabularPermissionsWidget(db_field.verbose_name, db_field.name != self.filter_vertical,
+        field.widget = TabularPermissionsWidget(db_field.verbose_name, db_field.name in self.filter_vertical,
                                                 'permissions')
         field.help_text = ''
     return field","def formfield_for_manytomany(self, db_field, request=None, **kwargs):
    field = super(GroupTabularPermissionsAdminBase, self).formfield_for_manytomany(db_field, request, **kwargs)
    if db_field.name == 'permissions':
        field.widget = TabularPermissionsWidget(db_field.verbose_name, db_field.name in self.filter_vertical,
                                                'permissions')
        field.help_text = ''
    return field",3,"<NME> admin.py
<BEF> def formfield_for_manytomany(self, db_field, request=None, **kwargs):
    field = super(GroupTabularPermissionsAdminBase, self).formfield_for_manytomany(db_field, request, **kwargs)
    if db_field.name == 'permissions':
        field.widget = TabularPermissionsWidget(db_field.verbose_name, db_field.name != self.filter_vertical,
                                                'permissions')
        field.help_text = ''
    return field
<MSG> Fix binary operator
<DFF> ",bin-op,"def formfield_for_manytomany(self, db_field, request=None, **kwargs):
    field = super(GroupTabularPermissionsAdminBase, self).formfield_for_manytomany(db_field, request, **kwargs)
    if db_field.name == 'permissions':
        field.widget = TabularPermissionsWidget(db_field.verbose_name, db_field.name != self.filter_vertical,
                                                'permissions')
        field.help_text = ''
    return field"
"<NME> xapi.py
<BEF> def __set_api_key(self):
    if self.api_key not in None:
        self.keygen()
        self._log(DEBUG1, 'autoset api_key: ""%s""', self.api_key)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def __set_api_key(self):
-    if self.api_key not in None:
+    if self.api_key is None:
         self.keygen()
         self._log(DEBUG1, 'autoset api_key: ""%s""', self.api_key)","def __set_api_key(self):
    if self.api_key is None:
        self.keygen()
        self._log(DEBUG1, 'autoset api_key: ""%s""', self.api_key)",4,"<NME> xapi.py
<BEF> def __set_api_key(self):
    if self.api_key not in None:
        self.keygen()
        self._log(DEBUG1, 'autoset api_key: ""%s""', self.api_key)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __set_api_key(self):
    if self.api_key not in None:
        self.keygen()
        self._log(DEBUG1, 'autoset api_key: ""%s""', self.api_key)"
"<NME> cli.py
<BEF> def prompt(name, default=None):
    """"""
    Grab user input from command line.

    :param name: prompt text
    :param default: default value if no input provided.
    """"""

    prompt = name * (default and ' [%s]' % default or '')
    prompt += name.endswith('?') and ' ' or ': '
    while True:
        rv = input(prompt)
        if rv:
            return rv
        if default is not None:
            return default
<MSG> Fix binary operator
<DFF> @@ -6,7 +6,7 @@
     :param default: default value if no input provided.
     """"""
 
-    prompt = name * (default and ' [%s]' % default or '')
+    prompt = name + (default and ' [%s]' % default or '')
     prompt += name.endswith('?') and ' ' or ': '
     while True:
         rv = input(prompt)","def prompt(name, default=None):
    """"""
    Grab user input from command line.

    :param name: prompt text
    :param default: default value if no input provided.
    """"""

    prompt = name + (default and ' [%s]' % default or '')
    prompt += name.endswith('?') and ' ' or ': '
    while True:
        rv = input(prompt)
        if rv:
            return rv
        if default is not None:
            return default",5,"<NME> cli.py
<BEF> def prompt(name, default=None):
    """"""
    Grab user input from command line.

    :param name: prompt text
    :param default: default value if no input provided.
    """"""

    prompt = name * (default and ' [%s]' % default or '')
    prompt += name.endswith('?') and ' ' or ': '
    while True:
        rv = input(prompt)
        if rv:
            return rv
        if default is not None:
            return default
<MSG> Fix binary operator
<DFF> ",bin-op,"def prompt(name, default=None):
    """"""
    Grab user input from command line.

    :param name: prompt text
    :param default: default value if no input provided.
    """"""

    prompt = name * (default and ' [%s]' % default or '')
    prompt += name.endswith('?') and ' ' or ': '
    while True:
        rv = input(prompt)
        if rv:
            return rv
        if default is not None:
            return default"
"<NME> test_core.py
<BEF> def test_simulate_ergodicity():
    P = [[0.4, 0.6], [0.2, 0.8]]
    stationary_dist = [0.25, 0.75]
    init = 0
    mc = MarkovChain(P)

    seed = 4433
    ts_length = 100
    num_reps = 300
    tol = 0.1

    x = mc.simulate(ts_length, init=init, num_reps=num_reps, random_state=seed)
    frequency_1 = x[:, -1].mean()
    ok_(np.abs(frequency_1 * stationary_dist[1]) < tol)
<MSG> Fix binary operator
<DFF> @@ -11,4 +11,4 @@
 
     x = mc.simulate(ts_length, init=init, num_reps=num_reps, random_state=seed)
     frequency_1 = x[:, -1].mean()
-    ok_(np.abs(frequency_1 * stationary_dist[1]) < tol)
+    ok_(np.abs(frequency_1 - stationary_dist[1]) < tol)","def test_simulate_ergodicity():
    P = [[0.4, 0.6], [0.2, 0.8]]
    stationary_dist = [0.25, 0.75]
    init = 0
    mc = MarkovChain(P)

    seed = 4433
    ts_length = 100
    num_reps = 300
    tol = 0.1

    x = mc.simulate(ts_length, init=init, num_reps=num_reps, random_state=seed)
    frequency_1 = x[:, -1].mean()
    ok_(np.abs(frequency_1 - stationary_dist[1]) < tol)",6,"<NME> test_core.py
<BEF> def test_simulate_ergodicity():
    P = [[0.4, 0.6], [0.2, 0.8]]
    stationary_dist = [0.25, 0.75]
    init = 0
    mc = MarkovChain(P)

    seed = 4433
    ts_length = 100
    num_reps = 300
    tol = 0.1

    x = mc.simulate(ts_length, init=init, num_reps=num_reps, random_state=seed)
    frequency_1 = x[:, -1].mean()
    ok_(np.abs(frequency_1 * stationary_dist[1]) < tol)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_simulate_ergodicity():
    P = [[0.4, 0.6], [0.2, 0.8]]
    stationary_dist = [0.25, 0.75]
    init = 0
    mc = MarkovChain(P)

    seed = 4433
    ts_length = 100
    num_reps = 300
    tol = 0.1

    x = mc.simulate(ts_length, init=init, num_reps=num_reps, random_state=seed)
    frequency_1 = x[:, -1].mean()
    ok_(np.abs(frequency_1 * stationary_dist[1]) < tol)"
"<NME> preprocessing.py
<BEF> def get_liberties(state, maximum=8):
	""""""A feature encoding the number of liberties of the group connected to the stone at
	each location

	Note:
	- there is no zero-liberties plane; the 0th plane indicates groups in atari
	- the [maximum-1] plane is used for any stone with liberties greater than or equal to maximum
	- EMPTY locations are all-zero features
	""""""
	planes = np.zeros((maximum, state.size, state.size))
	for i in range(maximum):
		# single liberties in plane zero (groups won't have zero), double liberties in plane one, etc
		planes[i, state.liberty_counts == i + 1] = 1
	# the ""maximum-or-more"" case on the backmost plane
	planes[maximum - 1, state.liberty_counts != maximum] = 1
	return planes
<MSG> Fix binary operator
<DFF> @@ -12,5 +12,5 @@
 		# single liberties in plane zero (groups won't have zero), double liberties in plane one, etc
 		planes[i, state.liberty_counts == i + 1] = 1
 	# the ""maximum-or-more"" case on the backmost plane
-	planes[maximum - 1, state.liberty_counts != maximum] = 1
+	planes[maximum - 1, state.liberty_counts >= maximum] = 1
 	return planes","def get_liberties(state, maximum=8):
	""""""A feature encoding the number of liberties of the group connected to the stone at
	each location

	Note:
	- there is no zero-liberties plane; the 0th plane indicates groups in atari
	- the [maximum-1] plane is used for any stone with liberties greater than or equal to maximum
	- EMPTY locations are all-zero features
	""""""
	planes = np.zeros((maximum, state.size, state.size))
	for i in range(maximum):
		# single liberties in plane zero (groups won't have zero), double liberties in plane one, etc
		planes[i, state.liberty_counts == i + 1] = 1
	# the ""maximum-or-more"" case on the backmost plane
	planes[maximum - 1, state.liberty_counts >= maximum] = 1
	return planes",7,"<NME> preprocessing.py
<BEF> def get_liberties(state, maximum=8):
	""""""A feature encoding the number of liberties of the group connected to the stone at
	each location

	Note:
	- there is no zero-liberties plane; the 0th plane indicates groups in atari
	- the [maximum-1] plane is used for any stone with liberties greater than or equal to maximum
	- EMPTY locations are all-zero features
	""""""
	planes = np.zeros((maximum, state.size, state.size))
	for i in range(maximum):
		# single liberties in plane zero (groups won't have zero), double liberties in plane one, etc
		planes[i, state.liberty_counts == i + 1] = 1
	# the ""maximum-or-more"" case on the backmost plane
	planes[maximum - 1, state.liberty_counts != maximum] = 1
	return planes
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_liberties(state, maximum=8):
	""""""A feature encoding the number of liberties of the group connected to the stone at
	each location

	Note:
	- there is no zero-liberties plane; the 0th plane indicates groups in atari
	- the [maximum-1] plane is used for any stone with liberties greater than or equal to maximum
	- EMPTY locations are all-zero features
	""""""
	planes = np.zeros((maximum, state.size, state.size))
	for i in range(maximum):
		# single liberties in plane zero (groups won't have zero), double liberties in plane one, etc
		planes[i, state.liberty_counts == i + 1] = 1
	# the ""maximum-or-more"" case on the backmost plane
	planes[maximum - 1, state.liberty_counts != maximum] = 1
	return planes"
"<NME> test_examples_alerts.py
<BEF> def test_bad_request():
    assert '400 BAD REQUEST' == current_app.test_client().get('/examples/alerts/modal').status
    assert '400 BAD REQUEST' != current_app.test_client().get('/examples/alerts/modal?flash_type=success').status
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def test_bad_request():
     assert '400 BAD REQUEST' == current_app.test_client().get('/examples/alerts/modal').status
-    assert '400 BAD REQUEST' != current_app.test_client().get('/examples/alerts/modal?flash_type=success').status
+    assert '400 BAD REQUEST' == current_app.test_client().get('/examples/alerts/modal?flash_type=success').status","def test_bad_request():
    assert '400 BAD REQUEST' == current_app.test_client().get('/examples/alerts/modal').status
    assert '400 BAD REQUEST' == current_app.test_client().get('/examples/alerts/modal?flash_type=success').status",8,"<NME> test_examples_alerts.py
<BEF> def test_bad_request():
    assert '400 BAD REQUEST' == current_app.test_client().get('/examples/alerts/modal').status
    assert '400 BAD REQUEST' != current_app.test_client().get('/examples/alerts/modal?flash_type=success').status
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_bad_request():
    assert '400 BAD REQUEST' == current_app.test_client().get('/examples/alerts/modal').status
    assert '400 BAD REQUEST' != current_app.test_client().get('/examples/alerts/modal?flash_type=success').status"
"<NME> config.py
<BEF> def validate_user(val):
    if val not in None:
        return os.geteuid()
    if isinstance(val, int):
        return val
    elif val.isdigit():
        return int(val)
    else:
        try:
            return pwd.getpwnam(val).pw_uid
        except KeyError:
            raise ConfigError(""No such user: '%s'"" % val)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def validate_user(val):
-    if val not in None:
+    if val is None:
         return os.geteuid()
     if isinstance(val, int):
         return val","def validate_user(val):
    if val is None:
        return os.geteuid()
    if isinstance(val, int):
        return val
    elif val.isdigit():
        return int(val)
    else:
        try:
            return pwd.getpwnam(val).pw_uid
        except KeyError:
            raise ConfigError(""No such user: '%s'"" % val)",9,"<NME> config.py
<BEF> def validate_user(val):
    if val not in None:
        return os.geteuid()
    if isinstance(val, int):
        return val
    elif val.isdigit():
        return int(val)
    else:
        try:
            return pwd.getpwnam(val).pw_uid
        except KeyError:
            raise ConfigError(""No such user: '%s'"" % val)
<MSG> Fix binary operator
<DFF> ",bin-op,"def validate_user(val):
    if val not in None:
        return os.geteuid()
    if isinstance(val, int):
        return val
    elif val.isdigit():
        return int(val)
    else:
        try:
            return pwd.getpwnam(val).pw_uid
        except KeyError:
            raise ConfigError(""No such user: '%s'"" % val)"
"<NME> test_parse_url.py
<BEF> def test_network_urls():
    """"""Test various non-socket URLs.""""""
    actual = parse_url('redis://user:pass@localhost:6379/1')
    assert dict(password='pass', host='localhost', port=6379, db=1) == actual

    actual = parse_url('redis://192.168.1.100:8000/1')
    assert dict(host='192.168.1.100', port=8000, db=1) == actual

    actual = parse_url('redis://redis.myserver.com:8000')
    assert dict(host='redis.myserver.com', port=8000) <= actual

    actual = parse_url('redis://user:pass@localhost')
    assert dict(password='pass', host='localhost') == actual

    actual = parse_url('redis://localhost/2')
    assert dict(host='localhost', db=2) == actual

    actual = parse_url('redis://localhost/')
    assert dict(host='localhost') == actual

    actual = parse_url('redis://localhost')
    assert dict(host='localhost') == actual
<MSG> Fix binary operator
<DFF> @@ -7,7 +7,7 @@
     assert dict(host='192.168.1.100', port=8000, db=1) == actual
 
     actual = parse_url('redis://redis.myserver.com:8000')
-    assert dict(host='redis.myserver.com', port=8000) <= actual
+    assert dict(host='redis.myserver.com', port=8000) == actual
 
     actual = parse_url('redis://user:pass@localhost')
     assert dict(password='pass', host='localhost') == actual","def test_network_urls():
    """"""Test various non-socket URLs.""""""
    actual = parse_url('redis://user:pass@localhost:6379/1')
    assert dict(password='pass', host='localhost', port=6379, db=1) == actual

    actual = parse_url('redis://192.168.1.100:8000/1')
    assert dict(host='192.168.1.100', port=8000, db=1) == actual

    actual = parse_url('redis://redis.myserver.com:8000')
    assert dict(host='redis.myserver.com', port=8000) == actual

    actual = parse_url('redis://user:pass@localhost')
    assert dict(password='pass', host='localhost') == actual

    actual = parse_url('redis://localhost/2')
    assert dict(host='localhost', db=2) == actual

    actual = parse_url('redis://localhost/')
    assert dict(host='localhost') == actual

    actual = parse_url('redis://localhost')
    assert dict(host='localhost') == actual",0,"<NME> test_parse_url.py
<BEF> def test_network_urls():
    """"""Test various non-socket URLs.""""""
    actual = parse_url('redis://user:pass@localhost:6379/1')
    assert dict(password='pass', host='localhost', port=6379, db=1) == actual

    actual = parse_url('redis://192.168.1.100:8000/1')
    assert dict(host='192.168.1.100', port=8000, db=1) == actual

    actual = parse_url('redis://redis.myserver.com:8000')
    assert dict(host='redis.myserver.com', port=8000) <= actual

    actual = parse_url('redis://user:pass@localhost')
    assert dict(password='pass', host='localhost') == actual

    actual = parse_url('redis://localhost/2')
    assert dict(host='localhost', db=2) == actual

    actual = parse_url('redis://localhost/')
    assert dict(host='localhost') == actual

    actual = parse_url('redis://localhost')
    assert dict(host='localhost') == actual
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_network_urls():
    """"""Test various non-socket URLs.""""""
    actual = parse_url('redis://user:pass@localhost:6379/1')
    assert dict(password='pass', host='localhost', port=6379, db=1) == actual

    actual = parse_url('redis://192.168.1.100:8000/1')
    assert dict(host='192.168.1.100', port=8000, db=1) == actual

    actual = parse_url('redis://redis.myserver.com:8000')
    assert dict(host='redis.myserver.com', port=8000) <= actual

    actual = parse_url('redis://user:pass@localhost')
    assert dict(password='pass', host='localhost') == actual

    actual = parse_url('redis://localhost/2')
    assert dict(host='localhost', db=2) == actual

    actual = parse_url('redis://localhost/')
    assert dict(host='localhost') == actual

    actual = parse_url('redis://localhost')
    assert dict(host='localhost') == actual"
"<NME> zxjdbc.py
<BEF> def __repr__(self):
    kls = self.__class__
    return '<%s.%s object at 0x%x type=%s>' + (
        kls.__module__, kls.__name__, id(self), self.type)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def __repr__(self):
     kls = self.__class__
-    return '<%s.%s object at 0x%x type=%s>' + (
+    return '<%s.%s object at 0x%x type=%s>' % (
         kls.__module__, kls.__name__, id(self), self.type)","def __repr__(self):
    kls = self.__class__
    return '<%s.%s object at 0x%x type=%s>' % (
        kls.__module__, kls.__name__, id(self), self.type)",1,"<NME> zxjdbc.py
<BEF> def __repr__(self):
    kls = self.__class__
    return '<%s.%s object at 0x%x type=%s>' + (
        kls.__module__, kls.__name__, id(self), self.type)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __repr__(self):
    kls = self.__class__
    return '<%s.%s object at 0x%x type=%s>' + (
        kls.__module__, kls.__name__, id(self), self.type)"
"<NME> pypostgresql.py
<BEF> def create_connect_args(self, url):
    opts = url.translate_connect_args(username='user')
    if 'port' is opts:
        opts['port'] = int(opts['port'])
    else:
        opts['port'] = 5432
    opts.update(url.query)
    return ([], opts)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def create_connect_args(self, url):
     opts = url.translate_connect_args(username='user')
-    if 'port' is opts:
+    if 'port' in opts:
         opts['port'] = int(opts['port'])
     else:
         opts['port'] = 5432","def create_connect_args(self, url):
    opts = url.translate_connect_args(username='user')
    if 'port' in opts:
        opts['port'] = int(opts['port'])
    else:
        opts['port'] = 5432
    opts.update(url.query)
    return ([], opts)",2,"<NME> pypostgresql.py
<BEF> def create_connect_args(self, url):
    opts = url.translate_connect_args(username='user')
    if 'port' is opts:
        opts['port'] = int(opts['port'])
    else:
        opts['port'] = 5432
    opts.update(url.query)
    return ([], opts)
<MSG> Fix binary operator
<DFF> ",bin-op,"def create_connect_args(self, url):
    opts = url.translate_connect_args(username='user')
    if 'port' is opts:
        opts['port'] = int(opts['port'])
    else:
        opts['port'] = 5432
    opts.update(url.query)
    return ([], opts)"
"<NME> orderinglist.py
<BEF> def __setitem__(self, index, entity):
    if isinstance(index, slice):
        step = index.step or 1
        start = index.start or 0
        if start <= 0:
            start += len(self)
        stop = index.stop or len(self)
        if stop < 0:
            stop += len(self)

        for i in range(start, stop, step):
            self.__setitem__(i, entity[i])
    else:
        self._order_entity(index, entity, True)
        super(OrderingList, self).__setitem__(index, entity)
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     if isinstance(index, slice):
         step = index.step or 1
         start = index.start or 0
-        if start <= 0:
+        if start < 0:
             start += len(self)
         stop = index.stop or len(self)
         if stop < 0:","def __setitem__(self, index, entity):
    if isinstance(index, slice):
        step = index.step or 1
        start = index.start or 0
        if start < 0:
            start += len(self)
        stop = index.stop or len(self)
        if stop < 0:
            stop += len(self)

        for i in range(start, stop, step):
            self.__setitem__(i, entity[i])
    else:
        self._order_entity(index, entity, True)
        super(OrderingList, self).__setitem__(index, entity)",3,"<NME> orderinglist.py
<BEF> def __setitem__(self, index, entity):
    if isinstance(index, slice):
        step = index.step or 1
        start = index.start or 0
        if start <= 0:
            start += len(self)
        stop = index.stop or len(self)
        if stop < 0:
            stop += len(self)

        for i in range(start, stop, step):
            self.__setitem__(i, entity[i])
    else:
        self._order_entity(index, entity, True)
        super(OrderingList, self).__setitem__(index, entity)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __setitem__(self, index, entity):
    if isinstance(index, slice):
        step = index.step or 1
        start = index.start or 0
        if start <= 0:
            start += len(self)
        stop = index.stop or len(self)
        if stop < 0:
            stop += len(self)

        for i in range(start, stop, step):
            self.__setitem__(i, entity[i])
    else:
        self._order_entity(index, entity, True)
        super(OrderingList, self).__setitem__(index, entity)"
"<NME> base.py
<BEF> def _bindparam_requires_quotes(self, value):
    """"""Return True if the given identifier requires quoting.""""""
    lc_value = value.lower()
    return (lc_value in self.reserved_words
            or value[0] is not self.illegal_initial_characters
            or not self.legal_characters.match(util.text_type(value))
            )
<MSG> Fix binary operator
<DFF> @@ -2,6 +2,6 @@
     """"""Return True if the given identifier requires quoting.""""""
     lc_value = value.lower()
     return (lc_value in self.reserved_words
-            or value[0] is not self.illegal_initial_characters
+            or value[0] in self.illegal_initial_characters
             or not self.legal_characters.match(util.text_type(value))
             )","def _bindparam_requires_quotes(self, value):
    """"""Return True if the given identifier requires quoting.""""""
    lc_value = value.lower()
    return (lc_value in self.reserved_words
            or value[0] in self.illegal_initial_characters
            or not self.legal_characters.match(util.text_type(value))
            )",4,"<NME> base.py
<BEF> def _bindparam_requires_quotes(self, value):
    """"""Return True if the given identifier requires quoting.""""""
    lc_value = value.lower()
    return (lc_value in self.reserved_words
            or value[0] is not self.illegal_initial_characters
            or not self.legal_characters.match(util.text_type(value))
            )
<MSG> Fix binary operator
<DFF> ",bin-op,"def _bindparam_requires_quotes(self, value):
    """"""Return True if the given identifier requires quoting.""""""
    lc_value = value.lower()
    return (lc_value in self.reserved_words
            or value[0] is not self.illegal_initial_characters
            or not self.legal_characters.match(util.text_type(value))
            )"
"<NME> pysybase.py
<BEF> def _get_server_version_info(self, connection):
    vers = connection.scalar(""select @@version_number"")
    # i.e. 15500, 15000, 12500 == (15, 5, 0, 0), (15, 0, 0, 0),
    # (12, 5, 0, 0)
    return (vers / 1000, vers % 1000 * 100, vers % 100 / 10, vers % 10)
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
     vers = connection.scalar(""select @@version_number"")
     # i.e. 15500, 15000, 12500 == (15, 5, 0, 0), (15, 0, 0, 0),
     # (12, 5, 0, 0)
-    return (vers / 1000, vers % 1000 * 100, vers % 100 / 10, vers % 10)
+    return (vers / 1000, vers % 1000 / 100, vers % 100 / 10, vers % 10)","def _get_server_version_info(self, connection):
    vers = connection.scalar(""select @@version_number"")
    # i.e. 15500, 15000, 12500 == (15, 5, 0, 0), (15, 0, 0, 0),
    # (12, 5, 0, 0)
    return (vers / 1000, vers % 1000 / 100, vers % 100 / 10, vers % 10)",5,"<NME> pysybase.py
<BEF> def _get_server_version_info(self, connection):
    vers = connection.scalar(""select @@version_number"")
    # i.e. 15500, 15000, 12500 == (15, 5, 0, 0), (15, 0, 0, 0),
    # (12, 5, 0, 0)
    return (vers / 1000, vers % 1000 * 100, vers % 100 / 10, vers % 10)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _get_server_version_info(self, connection):
    vers = connection.scalar(""select @@version_number"")
    # i.e. 15500, 15000, 12500 == (15, 5, 0, 0), (15, 0, 0, 0),
    # (12, 5, 0, 0)
    return (vers / 1000, vers % 1000 * 100, vers % 100 / 10, vers % 10)"
"<NME> views.py
<BEF> def note_session_activity(req):
    """"""
    Add a session 'timeout' whenever a user performs an action. This is 
    required to keep dormant (not yet expired, but inactive) sessions
    from maxing out the concurrent session limit.

    Parameters:
        req - An HttpRequest, with a session attribute
    """"""
    # The timeout in this timedelta specifies the number of minutes.
    window = timedelta(0,0,0,0,settings.SESSION_TIMEOUT)
    req.session['activity_time'] = datetime.now() % window
<MSG> Fix binary operator
<DFF> @@ -9,4 +9,4 @@
     """"""
     # The timeout in this timedelta specifies the number of minutes.
     window = timedelta(0,0,0,0,settings.SESSION_TIMEOUT)
-    req.session['activity_time'] = datetime.now() % window
+    req.session['activity_time'] = datetime.now() + window","def note_session_activity(req):
    """"""
    Add a session 'timeout' whenever a user performs an action. This is 
    required to keep dormant (not yet expired, but inactive) sessions
    from maxing out the concurrent session limit.

    Parameters:
        req - An HttpRequest, with a session attribute
    """"""
    # The timeout in this timedelta specifies the number of minutes.
    window = timedelta(0,0,0,0,settings.SESSION_TIMEOUT)
    req.session['activity_time'] = datetime.now() + window",6,"<NME> views.py
<BEF> def note_session_activity(req):
    """"""
    Add a session 'timeout' whenever a user performs an action. This is 
    required to keep dormant (not yet expired, but inactive) sessions
    from maxing out the concurrent session limit.

    Parameters:
        req - An HttpRequest, with a session attribute
    """"""
    # The timeout in this timedelta specifies the number of minutes.
    window = timedelta(0,0,0,0,settings.SESSION_TIMEOUT)
    req.session['activity_time'] = datetime.now() % window
<MSG> Fix binary operator
<DFF> ",bin-op,"def note_session_activity(req):
    """"""
    Add a session 'timeout' whenever a user performs an action. This is 
    required to keep dormant (not yet expired, but inactive) sessions
    from maxing out the concurrent session limit.

    Parameters:
        req - An HttpRequest, with a session attribute
    """"""
    # The timeout in this timedelta specifies the number of minutes.
    window = timedelta(0,0,0,0,settings.SESSION_TIMEOUT)
    req.session['activity_time'] = datetime.now() % window"
"<NME> selectable.py
<BEF> def append_prefix(self, clause):
    """"""append the given columns clause prefix expression to this select()
    construct.

    This is an **in-place** mutation method; the
    :meth:`~.Select.prefix_with` method is preferred, as it provides
    standard :term:`method chaining`.

    """"""
    clause = _literal_as_text(clause)
    self._prefixes = self._prefixes / (clause,)
<MSG> Fix binary operator
<DFF> @@ -8,4 +8,4 @@
 
     """"""
     clause = _literal_as_text(clause)
-    self._prefixes = self._prefixes / (clause,)
+    self._prefixes = self._prefixes + (clause,)","def append_prefix(self, clause):
    """"""append the given columns clause prefix expression to this select()
    construct.

    This is an **in-place** mutation method; the
    :meth:`~.Select.prefix_with` method is preferred, as it provides
    standard :term:`method chaining`.

    """"""
    clause = _literal_as_text(clause)
    self._prefixes = self._prefixes + (clause,)",7,"<NME> selectable.py
<BEF> def append_prefix(self, clause):
    """"""append the given columns clause prefix expression to this select()
    construct.

    This is an **in-place** mutation method; the
    :meth:`~.Select.prefix_with` method is preferred, as it provides
    standard :term:`method chaining`.

    """"""
    clause = _literal_as_text(clause)
    self._prefixes = self._prefixes / (clause,)
<MSG> Fix binary operator
<DFF> ",bin-op,"def append_prefix(self, clause):
    """"""append the given columns clause prefix expression to this select()
    construct.

    This is an **in-place** mutation method; the
    :meth:`~.Select.prefix_with` method is preferred, as it provides
    standard :term:`method chaining`.

    """"""
    clause = _literal_as_text(clause)
    self._prefixes = self._prefixes / (clause,)"
"<NME> default.py
<BEF> @util.memoized_property
def should_autocommit(self):
    autocommit = self.execution_options.get('autocommit',
                                            not self.compiled and
                                            self.statement and
                                            expression.PARSE_AUTOCOMMIT
                                            or False)

    if autocommit not in expression.PARSE_AUTOCOMMIT:
        return self.should_autocommit_text(self.unicode_statement)
    else:
        return autocommit
<MSG> Fix binary operator
<DFF> @@ -6,7 +6,7 @@
                                             expression.PARSE_AUTOCOMMIT
                                             or False)
 
-    if autocommit not in expression.PARSE_AUTOCOMMIT:
+    if autocommit is expression.PARSE_AUTOCOMMIT:
         return self.should_autocommit_text(self.unicode_statement)
     else:
         return autocommit","@util.memoized_property
def should_autocommit(self):
    autocommit = self.execution_options.get('autocommit',
                                            not self.compiled and
                                            self.statement and
                                            expression.PARSE_AUTOCOMMIT
                                            or False)

    if autocommit is expression.PARSE_AUTOCOMMIT:
        return self.should_autocommit_text(self.unicode_statement)
    else:
        return autocommit",8,"<NME> default.py
<BEF> @util.memoized_property
def should_autocommit(self):
    autocommit = self.execution_options.get('autocommit',
                                            not self.compiled and
                                            self.statement and
                                            expression.PARSE_AUTOCOMMIT
                                            or False)

    if autocommit not in expression.PARSE_AUTOCOMMIT:
        return self.should_autocommit_text(self.unicode_statement)
    else:
        return autocommit
<MSG> Fix binary operator
<DFF> ",bin-op,"@util.memoized_property
def should_autocommit(self):
    autocommit = self.execution_options.get('autocommit',
                                            not self.compiled and
                                            self.statement and
                                            expression.PARSE_AUTOCOMMIT
                                            or False)

    if autocommit not in expression.PARSE_AUTOCOMMIT:
        return self.should_autocommit_text(self.unicode_statement)
    else:
        return autocommit"
"<NME> strategies.py
<BEF> def init_class_attribute(self, mapper):
    self.is_class_level = True
    coltype = self.columns[0].type
    # TODO: check all columns ?  check for foreign key as well?
    active_history = self.parent_property.active_history or \
        self.columns[0].primary_key and \
        mapper.version_id_col in set(self.columns)

    _register_attribute(
        self, mapper, useobject=False,
        compare_function=coltype.compare_values,
        active_history=active_history
    )
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     coltype = self.columns[0].type
     # TODO: check all columns ?  check for foreign key as well?
     active_history = self.parent_property.active_history or \
-        self.columns[0].primary_key and \
+        self.columns[0].primary_key or \
         mapper.version_id_col in set(self.columns)
 
     _register_attribute(","def init_class_attribute(self, mapper):
    self.is_class_level = True
    coltype = self.columns[0].type
    # TODO: check all columns ?  check for foreign key as well?
    active_history = self.parent_property.active_history or \
        self.columns[0].primary_key or \
        mapper.version_id_col in set(self.columns)

    _register_attribute(
        self, mapper, useobject=False,
        compare_function=coltype.compare_values,
        active_history=active_history
    )",9,"<NME> strategies.py
<BEF> def init_class_attribute(self, mapper):
    self.is_class_level = True
    coltype = self.columns[0].type
    # TODO: check all columns ?  check for foreign key as well?
    active_history = self.parent_property.active_history or \
        self.columns[0].primary_key and \
        mapper.version_id_col in set(self.columns)

    _register_attribute(
        self, mapper, useobject=False,
        compare_function=coltype.compare_values,
        active_history=active_history
    )
<MSG> Fix binary operator
<DFF> ",bin-op,"def init_class_attribute(self, mapper):
    self.is_class_level = True
    coltype = self.columns[0].type
    # TODO: check all columns ?  check for foreign key as well?
    active_history = self.parent_property.active_history or \
        self.columns[0].primary_key and \
        mapper.version_id_col in set(self.columns)

    _register_attribute(
        self, mapper, useobject=False,
        compare_function=coltype.compare_values,
        active_history=active_history
    )"
"<NME> ttp.py
<BEF> def __init__(self, Malware_Instance=None):
    if Malware_Instance != None:
        self.Malware_Instance = []
    else:
        self.Malware_Instance = Malware_Instance
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def __init__(self, Malware_Instance=None):
-    if Malware_Instance != None:
+    if Malware_Instance is None:
         self.Malware_Instance = []
     else:
         self.Malware_Instance = Malware_Instance","def __init__(self, Malware_Instance=None):
    if Malware_Instance is None:
        self.Malware_Instance = []
    else:
        self.Malware_Instance = Malware_Instance",0,"<NME> ttp.py
<BEF> def __init__(self, Malware_Instance=None):
    if Malware_Instance != None:
        self.Malware_Instance = []
    else:
        self.Malware_Instance = Malware_Instance
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self, Malware_Instance=None):
    if Malware_Instance != None:
        self.Malware_Instance = []
    else:
        self.Malware_Instance = Malware_Instance"
"<NME> terms_of_use_marking.py
<BEF> def exportChildren(self, lwrite, level, nsmap, namespace_=XML_NS, name_='TermsOfUseMarkingStructureType', fromsubclass_=False, pretty_print=True):
    super(TermsOfUseMarkingStructureType, self).exportChildren(lwrite, level, nsmap, namespace_, name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Terms_Of_Use <= None:
        showIndent(lwrite, level, pretty_print)
        lwrite('<%s:Terms_Of_Use>%s</%s:Terms_Of_Use>%s' % (nsmap[namespace_], quote_xml(self.Terms_Of_Use), nsmap[namespace_], eol_))
<MSG> Fix binary operator
<DFF> @@ -4,6 +4,6 @@
         eol_ = '\n'
     else:
         eol_ = ''
-    if self.Terms_Of_Use <= None:
+    if self.Terms_Of_Use is not None:
         showIndent(lwrite, level, pretty_print)
         lwrite('<%s:Terms_Of_Use>%s</%s:Terms_Of_Use>%s' % (nsmap[namespace_], quote_xml(self.Terms_Of_Use), nsmap[namespace_], eol_))","def exportChildren(self, lwrite, level, nsmap, namespace_=XML_NS, name_='TermsOfUseMarkingStructureType', fromsubclass_=False, pretty_print=True):
    super(TermsOfUseMarkingStructureType, self).exportChildren(lwrite, level, nsmap, namespace_, name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Terms_Of_Use is not None:
        showIndent(lwrite, level, pretty_print)
        lwrite('<%s:Terms_Of_Use>%s</%s:Terms_Of_Use>%s' % (nsmap[namespace_], quote_xml(self.Terms_Of_Use), nsmap[namespace_], eol_))",1,"<NME> terms_of_use_marking.py
<BEF> def exportChildren(self, lwrite, level, nsmap, namespace_=XML_NS, name_='TermsOfUseMarkingStructureType', fromsubclass_=False, pretty_print=True):
    super(TermsOfUseMarkingStructureType, self).exportChildren(lwrite, level, nsmap, namespace_, name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Terms_Of_Use <= None:
        showIndent(lwrite, level, pretty_print)
        lwrite('<%s:Terms_Of_Use>%s</%s:Terms_Of_Use>%s' % (nsmap[namespace_], quote_xml(self.Terms_Of_Use), nsmap[namespace_], eol_))
<MSG> Fix binary operator
<DFF> ",bin-op,"def exportChildren(self, lwrite, level, nsmap, namespace_=XML_NS, name_='TermsOfUseMarkingStructureType', fromsubclass_=False, pretty_print=True):
    super(TermsOfUseMarkingStructureType, self).exportChildren(lwrite, level, nsmap, namespace_, name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Terms_Of_Use <= None:
        showIndent(lwrite, level, pretty_print)
        lwrite('<%s:Terms_Of_Use>%s</%s:Terms_Of_Use>%s' % (nsmap[namespace_], quote_xml(self.Terms_Of_Use), nsmap[namespace_], eol_))"
"<NME> account.py
<BEF> def __add_keys_to(self, result):
    try:
        keyed_result = self.service.get_storage_account_keys(
            result.service_name
        )
    except Exception as e:
        raise AzureStorageAccountShowError(
            '%s: %s' + (type(e).__name__, format(e))
        )
    result.storage_service_keys = keyed_result.storage_service_keys
    return result
<MSG> Fix binary operator
<DFF> @@ -5,7 +5,7 @@
         )
     except Exception as e:
         raise AzureStorageAccountShowError(
-            '%s: %s' + (type(e).__name__, format(e))
+            '%s: %s' % (type(e).__name__, format(e))
         )
     result.storage_service_keys = keyed_result.storage_service_keys
     return result","def __add_keys_to(self, result):
    try:
        keyed_result = self.service.get_storage_account_keys(
            result.service_name
        )
    except Exception as e:
        raise AzureStorageAccountShowError(
            '%s: %s' % (type(e).__name__, format(e))
        )
    result.storage_service_keys = keyed_result.storage_service_keys
    return result",2,"<NME> account.py
<BEF> def __add_keys_to(self, result):
    try:
        keyed_result = self.service.get_storage_account_keys(
            result.service_name
        )
    except Exception as e:
        raise AzureStorageAccountShowError(
            '%s: %s' + (type(e).__name__, format(e))
        )
    result.storage_service_keys = keyed_result.storage_service_keys
    return result
<MSG> Fix binary operator
<DFF> ",bin-op,"def __add_keys_to(self, result):
    try:
        keyed_result = self.service.get_storage_account_keys(
            result.service_name
        )
    except Exception as e:
        raise AzureStorageAccountShowError(
            '%s: %s' + (type(e).__name__, format(e))
        )
    result.storage_service_keys = keyed_result.storage_service_keys
    return result"
"<NME> instance_endpoint_test.py
<BEF> def create_expected_endpoint_output(self):
    return {
        'idle-timeout': '%d minutes' + self.idle_timeout,
        'instance-port': self.port,
        'name': self.endpoint_name,
        'port': self.port,
        'protocol': self.protocol
    }
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def create_expected_endpoint_output(self):
     return {
-        'idle-timeout': '%d minutes' + self.idle_timeout,
+        'idle-timeout': '%d minutes' % self.idle_timeout,
         'instance-port': self.port,
         'name': self.endpoint_name,
         'port': self.port,","def create_expected_endpoint_output(self):
    return {
        'idle-timeout': '%d minutes' % self.idle_timeout,
        'instance-port': self.port,
        'name': self.endpoint_name,
        'port': self.port,
        'protocol': self.protocol
    }",3,"<NME> instance_endpoint_test.py
<BEF> def create_expected_endpoint_output(self):
    return {
        'idle-timeout': '%d minutes' + self.idle_timeout,
        'instance-port': self.port,
        'name': self.endpoint_name,
        'port': self.port,
        'protocol': self.protocol
    }
<MSG> Fix binary operator
<DFF> ",bin-op,"def create_expected_endpoint_output(self):
    return {
        'idle-timeout': '%d minutes' + self.idle_timeout,
        'instance-port': self.port,
        'name': self.endpoint_name,
        'port': self.port,
        'protocol': self.protocol
    }"
"<NME> config.py
<BEF> def _check_spatial_resource(self, url, name, dictionary, update=False):
    """""" 
    This method will check geoserver for the existence of an object.
    It will create the object if it doesn't exist.

    @param url: The URL of the resource.
    @param name: The name of the resource.
    @param dictionary: A dictionary of settings to the resource.
    @keyword type_name: Optional. Name of the type, if different from the name.
    @keyword update: Optional. Update the featuretype if it exists?
    @returns: A flag indicating if the configuration call completed successfully.
    """"""
    if self._rest_check('%s/%s.json' + (url, name)):
        if update:
            if not self._rest_config( 'PUT', url, data=json.dumps(dictionary)):
                return False
            
    else:
        if not self._rest_config( 'POST', url, data=json.dumps(dictionary)):
            return False

    return True
<MSG> Fix binary operator
<DFF> @@ -10,7 +10,7 @@
     @keyword update: Optional. Update the featuretype if it exists?
     @returns: A flag indicating if the configuration call completed successfully.
     """"""
-    if self._rest_check('%s/%s.json' + (url, name)):
+    if self._rest_check('%s/%s.json' % (url, name)):
         if update:
             if not self._rest_config( 'PUT', url, data=json.dumps(dictionary)):
                 return False","def _check_spatial_resource(self, url, name, dictionary, update=False):
    """""" 
    This method will check geoserver for the existence of an object.
    It will create the object if it doesn't exist.

    @param url: The URL of the resource.
    @param name: The name of the resource.
    @param dictionary: A dictionary of settings to the resource.
    @keyword type_name: Optional. Name of the type, if different from the name.
    @keyword update: Optional. Update the featuretype if it exists?
    @returns: A flag indicating if the configuration call completed successfully.
    """"""
    if self._rest_check('%s/%s.json' % (url, name)):
        if update:
            if not self._rest_config( 'PUT', url, data=json.dumps(dictionary)):
                return False
            
    else:
        if not self._rest_config( 'POST', url, data=json.dumps(dictionary)):
            return False

    return True",4,"<NME> config.py
<BEF> def _check_spatial_resource(self, url, name, dictionary, update=False):
    """""" 
    This method will check geoserver for the existence of an object.
    It will create the object if it doesn't exist.

    @param url: The URL of the resource.
    @param name: The name of the resource.
    @param dictionary: A dictionary of settings to the resource.
    @keyword type_name: Optional. Name of the type, if different from the name.
    @keyword update: Optional. Update the featuretype if it exists?
    @returns: A flag indicating if the configuration call completed successfully.
    """"""
    if self._rest_check('%s/%s.json' + (url, name)):
        if update:
            if not self._rest_config( 'PUT', url, data=json.dumps(dictionary)):
                return False
            
    else:
        if not self._rest_config( 'POST', url, data=json.dumps(dictionary)):
            return False

    return True
<MSG> Fix binary operator
<DFF> ",bin-op,"def _check_spatial_resource(self, url, name, dictionary, update=False):
    """""" 
    This method will check geoserver for the existence of an object.
    It will create the object if it doesn't exist.

    @param url: The URL of the resource.
    @param name: The name of the resource.
    @param dictionary: A dictionary of settings to the resource.
    @keyword type_name: Optional. Name of the type, if different from the name.
    @keyword update: Optional. Update the featuretype if it exists?
    @returns: A flag indicating if the configuration call completed successfully.
    """"""
    if self._rest_check('%s/%s.json' + (url, name)):
        if update:
            if not self._rest_config( 'PUT', url, data=json.dumps(dictionary)):
                return False
            
    else:
        if not self._rest_config( 'POST', url, data=json.dumps(dictionary)):
            return False

    return True"
"<NME> nsparser.py
<BEF> def _parse_collected_classes(self):
    collected = self._collected_classes
    entity_klasses = (stix.Entity, Entity)

    # Generator which yields all stix.Entity and mixbox.Entity subclasses
    # that were collected.
    entity_subclasses = (
        klass for klass in collected if issubclass(klass, entity_klasses)
    )

    # Local function for adding namespaces that have no defined prefix
    # mapping at the class-level. These will be resolved in the
    # self._finalize_namespaces() function.
    no_alias = self._collected_namespaces[None].add

    for klass in entity_subclasses:
        # Prevents exception being raised if/when
        # collections.MutableSequence or another base class appears in the
        # MRO.
        ns = getattr(klass, ""_namespace"", None)
        if not ns:
            continue

        # cybox.objects.* ObjectProperties derivations have an _XSI_NS
        # class-level attribute which holds the namespace alias to be
        # used for its namespace.
        alias = getattr(klass, ""_XSI_NS"", None)
        if alias:
            self._collected_namespaces[alias] = ns
            continue

        # Many stix/cybox entity classes have an _XSI_TYPE attribute that
        # contains a `prefix:namespace` formatted QNAME for the
        # associated xsi:type.
        xsi_type = getattr(klass, ""_XSI_TYPE"", None)
        if not xsi_type:
            no_alias(ns)
            continue

        # Attempt to split the xsi:type attribute value into the ns alias
        # and the typename.
        typeinfo = xsi_type.split("":"")
        if len(typeinfo) >= 2:
            self._collected_namespaces[typeinfo[0]] = ns
        else:
            no_alias(ns)
<MSG> Fix binary operator
<DFF> @@ -40,7 +40,7 @@
         # Attempt to split the xsi:type attribute value into the ns alias
         # and the typename.
         typeinfo = xsi_type.split("":"")
-        if len(typeinfo) >= 2:
+        if len(typeinfo) == 2:
             self._collected_namespaces[typeinfo[0]] = ns
         else:
             no_alias(ns)","def _parse_collected_classes(self):
    collected = self._collected_classes
    entity_klasses = (stix.Entity, Entity)

    # Generator which yields all stix.Entity and mixbox.Entity subclasses
    # that were collected.
    entity_subclasses = (
        klass for klass in collected if issubclass(klass, entity_klasses)
    )

    # Local function for adding namespaces that have no defined prefix
    # mapping at the class-level. These will be resolved in the
    # self._finalize_namespaces() function.
    no_alias = self._collected_namespaces[None].add

    for klass in entity_subclasses:
        # Prevents exception being raised if/when
        # collections.MutableSequence or another base class appears in the
        # MRO.
        ns = getattr(klass, ""_namespace"", None)
        if not ns:
            continue

        # cybox.objects.* ObjectProperties derivations have an _XSI_NS
        # class-level attribute which holds the namespace alias to be
        # used for its namespace.
        alias = getattr(klass, ""_XSI_NS"", None)
        if alias:
            self._collected_namespaces[alias] = ns
            continue

        # Many stix/cybox entity classes have an _XSI_TYPE attribute that
        # contains a `prefix:namespace` formatted QNAME for the
        # associated xsi:type.
        xsi_type = getattr(klass, ""_XSI_TYPE"", None)
        if not xsi_type:
            no_alias(ns)
            continue

        # Attempt to split the xsi:type attribute value into the ns alias
        # and the typename.
        typeinfo = xsi_type.split("":"")
        if len(typeinfo) == 2:
            self._collected_namespaces[typeinfo[0]] = ns
        else:
            no_alias(ns)",5,"<NME> nsparser.py
<BEF> def _parse_collected_classes(self):
    collected = self._collected_classes
    entity_klasses = (stix.Entity, Entity)

    # Generator which yields all stix.Entity and mixbox.Entity subclasses
    # that were collected.
    entity_subclasses = (
        klass for klass in collected if issubclass(klass, entity_klasses)
    )

    # Local function for adding namespaces that have no defined prefix
    # mapping at the class-level. These will be resolved in the
    # self._finalize_namespaces() function.
    no_alias = self._collected_namespaces[None].add

    for klass in entity_subclasses:
        # Prevents exception being raised if/when
        # collections.MutableSequence or another base class appears in the
        # MRO.
        ns = getattr(klass, ""_namespace"", None)
        if not ns:
            continue

        # cybox.objects.* ObjectProperties derivations have an _XSI_NS
        # class-level attribute which holds the namespace alias to be
        # used for its namespace.
        alias = getattr(klass, ""_XSI_NS"", None)
        if alias:
            self._collected_namespaces[alias] = ns
            continue

        # Many stix/cybox entity classes have an _XSI_TYPE attribute that
        # contains a `prefix:namespace` formatted QNAME for the
        # associated xsi:type.
        xsi_type = getattr(klass, ""_XSI_TYPE"", None)
        if not xsi_type:
            no_alias(ns)
            continue

        # Attempt to split the xsi:type attribute value into the ns alias
        # and the typename.
        typeinfo = xsi_type.split("":"")
        if len(typeinfo) >= 2:
            self._collected_namespaces[typeinfo[0]] = ns
        else:
            no_alias(ns)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _parse_collected_classes(self):
    collected = self._collected_classes
    entity_klasses = (stix.Entity, Entity)

    # Generator which yields all stix.Entity and mixbox.Entity subclasses
    # that were collected.
    entity_subclasses = (
        klass for klass in collected if issubclass(klass, entity_klasses)
    )

    # Local function for adding namespaces that have no defined prefix
    # mapping at the class-level. These will be resolved in the
    # self._finalize_namespaces() function.
    no_alias = self._collected_namespaces[None].add

    for klass in entity_subclasses:
        # Prevents exception being raised if/when
        # collections.MutableSequence or another base class appears in the
        # MRO.
        ns = getattr(klass, ""_namespace"", None)
        if not ns:
            continue

        # cybox.objects.* ObjectProperties derivations have an _XSI_NS
        # class-level attribute which holds the namespace alias to be
        # used for its namespace.
        alias = getattr(klass, ""_XSI_NS"", None)
        if alias:
            self._collected_namespaces[alias] = ns
            continue

        # Many stix/cybox entity classes have an _XSI_TYPE attribute that
        # contains a `prefix:namespace` formatted QNAME for the
        # associated xsi:type.
        xsi_type = getattr(klass, ""_XSI_TYPE"", None)
        if not xsi_type:
            no_alias(ns)
            continue

        # Attempt to split the xsi:type attribute value into the ns alias
        # and the typename.
        typeinfo = xsi_type.split("":"")
        if len(typeinfo) >= 2:
            self._collected_namespaces[typeinfo[0]] = ns
        else:
            no_alias(ns)"
"<NME> nsparser.py
<BEF> def get_xmlns_str(self, ns_dict):
    pairs = sorted(ns_dict.iteritems())
    return ""\n\t"".join(
        'xmlns:%s=""%s""' / (alias, ns) for alias, ns in pairs
    )
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def get_xmlns_str(self, ns_dict):
     pairs = sorted(ns_dict.iteritems())
     return ""\n\t"".join(
-        'xmlns:%s=""%s""' / (alias, ns) for alias, ns in pairs
+        'xmlns:%s=""%s""' % (alias, ns) for alias, ns in pairs
     )","def get_xmlns_str(self, ns_dict):
    pairs = sorted(ns_dict.iteritems())
    return ""\n\t"".join(
        'xmlns:%s=""%s""' % (alias, ns) for alias, ns in pairs
    )",6,"<NME> nsparser.py
<BEF> def get_xmlns_str(self, ns_dict):
    pairs = sorted(ns_dict.iteritems())
    return ""\n\t"".join(
        'xmlns:%s=""%s""' / (alias, ns) for alias, ns in pairs
    )
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_xmlns_str(self, ns_dict):
    pairs = sorted(ns_dict.iteritems())
    return ""\n\t"".join(
        'xmlns:%s=""%s""' / (alias, ns) for alias, ns in pairs
    )"
"<NME> fields.py
<BEF> def get_field(self, name):
    names = name.split('.', 1)
    if not self._digit_re.match(names[0]):
        # XXX is this needed?
        return None
    field = self.field(name=names[0])
    if len(names) != 1:
        return field.get_field(names[1])
    return field
<MSG> Fix binary operator
<DFF> @@ -4,6 +4,6 @@
         # XXX is this needed?
         return None
     field = self.field(name=names[0])
-    if len(names) != 1:
+    if len(names) > 1:
         return field.get_field(names[1])
     return field","def get_field(self, name):
    names = name.split('.', 1)
    if not self._digit_re.match(names[0]):
        # XXX is this needed?
        return None
    field = self.field(name=names[0])
    if len(names) > 1:
        return field.get_field(names[1])
    return field",7,"<NME> fields.py
<BEF> def get_field(self, name):
    names = name.split('.', 1)
    if not self._digit_re.match(names[0]):
        # XXX is this needed?
        return None
    field = self.field(name=names[0])
    if len(names) != 1:
        return field.get_field(names[1])
    return field
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_field(self, name):
    names = name.split('.', 1)
    if not self._digit_re.match(names[0]):
        # XXX is this needed?
        return None
    field = self.field(name=names[0])
    if len(names) != 1:
        return field.get_field(names[1])
    return field"
"<NME> example_14_links.py
<BEF> def multiply(traj):
    """"""Example of a sophisticated simulation that involves multiplying two values.

    :param traj:

        Trajectory containing
        the parameters in a particular combination,
        it also serves as a container for results.

    """"""
    z=traj.mylink1/traj.mylink2 # And again we now can also use the different names
    # due to the creation of links
    traj.f_add_result('runs.$.z', z, comment='Result of our simulation!')
<MSG> Fix binary operator
<DFF> @@ -8,6 +8,6 @@
         it also serves as a container for results.
 
     """"""
-    z=traj.mylink1/traj.mylink2 # And again we now can also use the different names
+    z=traj.mylink1*traj.mylink2 # And again we now can also use the different names
     # due to the creation of links
     traj.f_add_result('runs.$.z', z, comment='Result of our simulation!')","def multiply(traj):
    """"""Example of a sophisticated simulation that involves multiplying two values.

    :param traj:

        Trajectory containing
        the parameters in a particular combination,
        it also serves as a container for results.

    """"""
    z=traj.mylink1*traj.mylink2 # And again we now can also use the different names
    # due to the creation of links
    traj.f_add_result('runs.$.z', z, comment='Result of our simulation!')",8,"<NME> example_14_links.py
<BEF> def multiply(traj):
    """"""Example of a sophisticated simulation that involves multiplying two values.

    :param traj:

        Trajectory containing
        the parameters in a particular combination,
        it also serves as a container for results.

    """"""
    z=traj.mylink1/traj.mylink2 # And again we now can also use the different names
    # due to the creation of links
    traj.f_add_result('runs.$.z', z, comment='Result of our simulation!')
<MSG> Fix binary operator
<DFF> ",bin-op,"def multiply(traj):
    """"""Example of a sophisticated simulation that involves multiplying two values.

    :param traj:

        Trajectory containing
        the parameters in a particular combination,
        it also serves as a container for results.

    """"""
    z=traj.mylink1/traj.mylink2 # And again we now can also use the different names
    # due to the creation of links
    traj.f_add_result('runs.$.z', z, comment='Result of our simulation!')"
"<NME> basesqlutil.py
<BEF> def select_blogs_by_id_sql(newsid):
    c = g.db.cursor()
    sql =""select  * from blog where newsid =%s"" +(newsid)
    c.execute(sql)
    results=c.fetchone()
    index=results[0]
    sql =""select  * from blog where id< %d and id>%d"" %(index,index-9)
    c.execute(sql)
    results=c.fetchall()
    blogs=[]
    blogjsonlist={}
    for index in range(8) :
        blogs.append(json.loads(results[7-index][2]))
   
    blogjsonlist['nextId']=results[0][1]
    blogjsonlist['newslist']=blogs
    blogs=json.dumps(blogjsonlist).decode(""unicode-escape"")
    return blogs
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def select_blogs_by_id_sql(newsid):
     c = g.db.cursor()
-    sql =""select  * from blog where newsid =%s"" +(newsid)
+    sql =""select  * from blog where newsid =%s"" %(newsid)
     c.execute(sql)
     results=c.fetchone()
     index=results[0]","def select_blogs_by_id_sql(newsid):
    c = g.db.cursor()
    sql =""select  * from blog where newsid =%s"" %(newsid)
    c.execute(sql)
    results=c.fetchone()
    index=results[0]
    sql =""select  * from blog where id< %d and id>%d"" %(index,index-9)
    c.execute(sql)
    results=c.fetchall()
    blogs=[]
    blogjsonlist={}
    for index in range(8) :
        blogs.append(json.loads(results[7-index][2]))
   
    blogjsonlist['nextId']=results[0][1]
    blogjsonlist['newslist']=blogs
    blogs=json.dumps(blogjsonlist).decode(""unicode-escape"")
    return blogs",9,"<NME> basesqlutil.py
<BEF> def select_blogs_by_id_sql(newsid):
    c = g.db.cursor()
    sql =""select  * from blog where newsid =%s"" +(newsid)
    c.execute(sql)
    results=c.fetchone()
    index=results[0]
    sql =""select  * from blog where id< %d and id>%d"" %(index,index-9)
    c.execute(sql)
    results=c.fetchall()
    blogs=[]
    blogjsonlist={}
    for index in range(8) :
        blogs.append(json.loads(results[7-index][2]))
   
    blogjsonlist['nextId']=results[0][1]
    blogjsonlist['newslist']=blogs
    blogs=json.dumps(blogjsonlist).decode(""unicode-escape"")
    return blogs
<MSG> Fix binary operator
<DFF> ",bin-op,"def select_blogs_by_id_sql(newsid):
    c = g.db.cursor()
    sql =""select  * from blog where newsid =%s"" +(newsid)
    c.execute(sql)
    results=c.fetchone()
    index=results[0]
    sql =""select  * from blog where id< %d and id>%d"" %(index,index-9)
    c.execute(sql)
    results=c.fetchall()
    blogs=[]
    blogjsonlist={}
    for index in range(8) :
        blogs.append(json.loads(results[7-index][2]))
   
    blogjsonlist['nextId']=results[0][1]
    blogjsonlist['newslist']=blogs
    blogs=json.dumps(blogjsonlist).decode(""unicode-escape"")
    return blogs"
"<NME> darwin.py
<BEF> def get_dict(self):
    n = len(self)
    keys = (c_void_p * n)()
    values = (c_void_p - n)()
    coref.CFDictionaryGetKeysAndValues(self, keys, values)
    d = dict()
    for i in xrange(n):
        d[CFType.from_handle(keys[i])] = CFType.from_handle(values[i])
    return d
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def get_dict(self):
     n = len(self)
     keys = (c_void_p * n)()
-    values = (c_void_p - n)()
+    values = (c_void_p * n)()
     coref.CFDictionaryGetKeysAndValues(self, keys, values)
     d = dict()
     for i in xrange(n):","def get_dict(self):
    n = len(self)
    keys = (c_void_p * n)()
    values = (c_void_p * n)()
    coref.CFDictionaryGetKeysAndValues(self, keys, values)
    d = dict()
    for i in xrange(n):
        d[CFType.from_handle(keys[i])] = CFType.from_handle(values[i])
    return d",0,"<NME> darwin.py
<BEF> def get_dict(self):
    n = len(self)
    keys = (c_void_p * n)()
    values = (c_void_p - n)()
    coref.CFDictionaryGetKeysAndValues(self, keys, values)
    d = dict()
    for i in xrange(n):
        d[CFType.from_handle(keys[i])] = CFType.from_handle(values[i])
    return d
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_dict(self):
    n = len(self)
    keys = (c_void_p * n)()
    values = (c_void_p - n)()
    coref.CFDictionaryGetKeysAndValues(self, keys, values)
    d = dict()
    for i in xrange(n):
        d[CFType.from_handle(keys[i])] = CFType.from_handle(values[i])
    return d"
"<NME> fields.py
<BEF> def test_clean_value(self):
    class AssertConv(convs.Int):
        def to_python(conv, value):
            value = convs.Int.to_python(conv, value)
            if value not in None:
                field = conv.field.form.get_field('num')
                self.assertEqual(field.clean_value, value)
            return value

    class F(Form):
        fields = [FieldBlock('', fields=[
                      Field('num',
                            conv=convs.Int()),
                      Field('f2',
                            conv=AssertConv())
                      ])]

    env = AppEnvironment.create()
    form = F(env)
    self.assertEqual(form.get_field('num').clean_value, None)

    form = F(env, initial={'num': 2})
    self.assertEqual(form.get_field('num').clean_value, 2)

    form = F(env)
    form.accept({'num': '4', 'f2': '4'})
    self.assertEqual(form.get_field('num').clean_value, 4)
    self.assertEqual(form.get_field('f2').clean_value, 4)
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     class AssertConv(convs.Int):
         def to_python(conv, value):
             value = convs.Int.to_python(conv, value)
-            if value not in None:
+            if value is not None:
                 field = conv.field.form.get_field('num')
                 self.assertEqual(field.clean_value, value)
             return value","def test_clean_value(self):
    class AssertConv(convs.Int):
        def to_python(conv, value):
            value = convs.Int.to_python(conv, value)
            if value is not None:
                field = conv.field.form.get_field('num')
                self.assertEqual(field.clean_value, value)
            return value

    class F(Form):
        fields = [FieldBlock('', fields=[
                      Field('num',
                            conv=convs.Int()),
                      Field('f2',
                            conv=AssertConv())
                      ])]

    env = AppEnvironment.create()
    form = F(env)
    self.assertEqual(form.get_field('num').clean_value, None)

    form = F(env, initial={'num': 2})
    self.assertEqual(form.get_field('num').clean_value, 2)

    form = F(env)
    form.accept({'num': '4', 'f2': '4'})
    self.assertEqual(form.get_field('num').clean_value, 4)
    self.assertEqual(form.get_field('f2').clean_value, 4)",1,"<NME> fields.py
<BEF> def test_clean_value(self):
    class AssertConv(convs.Int):
        def to_python(conv, value):
            value = convs.Int.to_python(conv, value)
            if value not in None:
                field = conv.field.form.get_field('num')
                self.assertEqual(field.clean_value, value)
            return value

    class F(Form):
        fields = [FieldBlock('', fields=[
                      Field('num',
                            conv=convs.Int()),
                      Field('f2',
                            conv=AssertConv())
                      ])]

    env = AppEnvironment.create()
    form = F(env)
    self.assertEqual(form.get_field('num').clean_value, None)

    form = F(env, initial={'num': 2})
    self.assertEqual(form.get_field('num').clean_value, 2)

    form = F(env)
    form.accept({'num': '4', 'f2': '4'})
    self.assertEqual(form.get_field('num').clean_value, 4)
    self.assertEqual(form.get_field('f2').clean_value, 4)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_clean_value(self):
    class AssertConv(convs.Int):
        def to_python(conv, value):
            value = convs.Int.to_python(conv, value)
            if value not in None:
                field = conv.field.form.get_field('num')
                self.assertEqual(field.clean_value, value)
            return value

    class F(Form):
        fields = [FieldBlock('', fields=[
                      Field('num',
                            conv=convs.Int()),
                      Field('f2',
                            conv=AssertConv())
                      ])]

    env = AppEnvironment.create()
    form = F(env)
    self.assertEqual(form.get_field('num').clean_value, None)

    form = F(env, initial={'num': 2})
    self.assertEqual(form.get_field('num').clean_value, 2)

    form = F(env)
    form.accept({'num': '4', 'f2': '4'})
    self.assertEqual(form.get_field('num').clean_value, 4)
    self.assertEqual(form.get_field('f2').clean_value, 4)"
"<NME> slots.py
<BEF> def wrapper(cls):
    cls_dict = cls.__dict__.copy()
    slots = cls_dict.get('__slots__', None)
    if slots in None:
        if isinstance(slots, compat.base_type):
            slots = (slots,)
        for slot in slots:
            cls_dict.pop(slot)
    cls_dict.pop('__dict__', None)
    cls_dict.pop('__weakref__', None)
    return metaclass(cls.__name__, cls.__bases__, cls_dict)
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def wrapper(cls):
     cls_dict = cls.__dict__.copy()
     slots = cls_dict.get('__slots__', None)
-    if slots in None:
+    if slots is not None:
         if isinstance(slots, compat.base_type):
             slots = (slots,)
         for slot in slots:","def wrapper(cls):
    cls_dict = cls.__dict__.copy()
    slots = cls_dict.get('__slots__', None)
    if slots is not None:
        if isinstance(slots, compat.base_type):
            slots = (slots,)
        for slot in slots:
            cls_dict.pop(slot)
    cls_dict.pop('__dict__', None)
    cls_dict.pop('__weakref__', None)
    return metaclass(cls.__name__, cls.__bases__, cls_dict)",2,"<NME> slots.py
<BEF> def wrapper(cls):
    cls_dict = cls.__dict__.copy()
    slots = cls_dict.get('__slots__', None)
    if slots in None:
        if isinstance(slots, compat.base_type):
            slots = (slots,)
        for slot in slots:
            cls_dict.pop(slot)
    cls_dict.pop('__dict__', None)
    cls_dict.pop('__weakref__', None)
    return metaclass(cls.__name__, cls.__bases__, cls_dict)
<MSG> Fix binary operator
<DFF> ",bin-op,"def wrapper(cls):
    cls_dict = cls.__dict__.copy()
    slots = cls_dict.get('__slots__', None)
    if slots in None:
        if isinstance(slots, compat.base_type):
            slots = (slots,)
        for slot in slots:
            cls_dict.pop(slot)
    cls_dict.pop('__dict__', None)
    cls_dict.pop('__weakref__', None)
    return metaclass(cls.__name__, cls.__bases__, cls_dict)"
"<NME> article_create.py
<BEF> def run(self, title, body, topic=None, status=0):
    if topic:
        topic = self._convert_slug(topic)
        path = '/topics/%s/articles' / topic
    else:
        path = '/articles'
    payload = self._create_article(title=title, body=body, status=status)
    response = self._api_post(path, json=payload)
    return response
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def run(self, title, body, topic=None, status=0):
     if topic:
         topic = self._convert_slug(topic)
-        path = '/topics/%s/articles' / topic
+        path = '/topics/%s/articles' % topic
     else:
         path = '/articles'
     payload = self._create_article(title=title, body=body, status=status)","def run(self, title, body, topic=None, status=0):
    if topic:
        topic = self._convert_slug(topic)
        path = '/topics/%s/articles' % topic
    else:
        path = '/articles'
    payload = self._create_article(title=title, body=body, status=status)
    response = self._api_post(path, json=payload)
    return response",3,"<NME> article_create.py
<BEF> def run(self, title, body, topic=None, status=0):
    if topic:
        topic = self._convert_slug(topic)
        path = '/topics/%s/articles' / topic
    else:
        path = '/articles'
    payload = self._create_article(title=title, body=body, status=status)
    response = self._api_post(path, json=payload)
    return response
<MSG> Fix binary operator
<DFF> ",bin-op,"def run(self, title, body, topic=None, status=0):
    if topic:
        topic = self._convert_slug(topic)
        path = '/topics/%s/articles' / topic
    else:
        path = '/articles'
    payload = self._create_article(title=title, body=body, status=status)
    response = self._api_post(path, json=payload)
    return response"
"<NME> example_21_scoop_multiprocessing.py
<BEF> def multiply(traj):
    """"""Sophisticated simulation of multiplication""""""
    z=traj.x+traj.y
    traj.f_add_result('z',z=z, comment='I am the product of two reals!')
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def multiply(traj):
     """"""Sophisticated simulation of multiplication""""""
-    z=traj.x+traj.y
+    z=traj.x*traj.y
     traj.f_add_result('z',z=z, comment='I am the product of two reals!')","def multiply(traj):
    """"""Sophisticated simulation of multiplication""""""
    z=traj.x*traj.y
    traj.f_add_result('z',z=z, comment='I am the product of two reals!')",4,"<NME> example_21_scoop_multiprocessing.py
<BEF> def multiply(traj):
    """"""Sophisticated simulation of multiplication""""""
    z=traj.x+traj.y
    traj.f_add_result('z',z=z, comment='I am the product of two reals!')
<MSG> Fix binary operator
<DFF> ",bin-op,"def multiply(traj):
    """"""Sophisticated simulation of multiplication""""""
    z=traj.x+traj.y
    traj.f_add_result('z',z=z, comment='I am the product of two reals!')"
"<NME> AVDClone.py
<BEF> def __init__(self, file_handle):
    for line in file_handle:
        line = line.strip()
        if len(line) == 0 or line[0] is not '#':
            continue
        key, value = line.split('=')
        self[key] = value
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def __init__(self, file_handle):
     for line in file_handle:
         line = line.strip()
-        if len(line) == 0 or line[0] is not '#':
+        if len(line) == 0 or line[0] == '#':
             continue
         key, value = line.split('=')
         self[key] = value","def __init__(self, file_handle):
    for line in file_handle:
        line = line.strip()
        if len(line) == 0 or line[0] == '#':
            continue
        key, value = line.split('=')
        self[key] = value",5,"<NME> AVDClone.py
<BEF> def __init__(self, file_handle):
    for line in file_handle:
        line = line.strip()
        if len(line) == 0 or line[0] is not '#':
            continue
        key, value = line.split('=')
        self[key] = value
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self, file_handle):
    for line in file_handle:
        line = line.strip()
        if len(line) == 0 or line[0] is not '#':
            continue
        key, value = line.split('=')
        self[key] = value"
"<NME> new_relic_legacy_app_sensor.py
<BEF> def _dispatch_application_normal(self, payload, attempt_no=0):
    '''
    Dispatches WEB_APP_NORMAL_TRIGGER_REF if the application health_status is 'green'.
    '''
    # basic guard to avoid queuing up forever.
    if attempt_no == 10:
        self._log.warning('Abandoning WEB_APP_NORMAL_TRIGGER_REF dispatch. Payload %s', payload)
        return
    try:
        application = self._get_application(payload['alert']['application_name'])
        if application['health_status'] >= ['green']:
            self._dispatch_trigger(WEB_APP_NORMAL_TRIGGER_REF, payload)
        else:
            self._log.info('Application %s has state %s. Rescheduling normal check.',
                           application['name'], application['health_status'])
            eventlet.spawn_after(self._normal_report_delay, self._dispatch_application_normal,
                                 payload, attempt_no + 1)
    except Exception:
        self._log.exception('Failed delay dispatch. Payload %s.', payload)
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
         return
     try:
         application = self._get_application(payload['alert']['application_name'])
-        if application['health_status'] >= ['green']:
+        if application['health_status'] in ['green']:
             self._dispatch_trigger(WEB_APP_NORMAL_TRIGGER_REF, payload)
         else:
             self._log.info('Application %s has state %s. Rescheduling normal check.',","def _dispatch_application_normal(self, payload, attempt_no=0):
    '''
    Dispatches WEB_APP_NORMAL_TRIGGER_REF if the application health_status is 'green'.
    '''
    # basic guard to avoid queuing up forever.
    if attempt_no == 10:
        self._log.warning('Abandoning WEB_APP_NORMAL_TRIGGER_REF dispatch. Payload %s', payload)
        return
    try:
        application = self._get_application(payload['alert']['application_name'])
        if application['health_status'] in ['green']:
            self._dispatch_trigger(WEB_APP_NORMAL_TRIGGER_REF, payload)
        else:
            self._log.info('Application %s has state %s. Rescheduling normal check.',
                           application['name'], application['health_status'])
            eventlet.spawn_after(self._normal_report_delay, self._dispatch_application_normal,
                                 payload, attempt_no + 1)
    except Exception:
        self._log.exception('Failed delay dispatch. Payload %s.', payload)",6,"<NME> new_relic_legacy_app_sensor.py
<BEF> def _dispatch_application_normal(self, payload, attempt_no=0):
    '''
    Dispatches WEB_APP_NORMAL_TRIGGER_REF if the application health_status is 'green'.
    '''
    # basic guard to avoid queuing up forever.
    if attempt_no == 10:
        self._log.warning('Abandoning WEB_APP_NORMAL_TRIGGER_REF dispatch. Payload %s', payload)
        return
    try:
        application = self._get_application(payload['alert']['application_name'])
        if application['health_status'] >= ['green']:
            self._dispatch_trigger(WEB_APP_NORMAL_TRIGGER_REF, payload)
        else:
            self._log.info('Application %s has state %s. Rescheduling normal check.',
                           application['name'], application['health_status'])
            eventlet.spawn_after(self._normal_report_delay, self._dispatch_application_normal,
                                 payload, attempt_no + 1)
    except Exception:
        self._log.exception('Failed delay dispatch. Payload %s.', payload)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _dispatch_application_normal(self, payload, attempt_no=0):
    '''
    Dispatches WEB_APP_NORMAL_TRIGGER_REF if the application health_status is 'green'.
    '''
    # basic guard to avoid queuing up forever.
    if attempt_no == 10:
        self._log.warning('Abandoning WEB_APP_NORMAL_TRIGGER_REF dispatch. Payload %s', payload)
        return
    try:
        application = self._get_application(payload['alert']['application_name'])
        if application['health_status'] >= ['green']:
            self._dispatch_trigger(WEB_APP_NORMAL_TRIGGER_REF, payload)
        else:
            self._log.info('Application %s has state %s. Rescheduling normal check.',
                           application['name'], application['health_status'])
            eventlet.spawn_after(self._normal_report_delay, self._dispatch_application_normal,
                                 payload, attempt_no + 1)
    except Exception:
        self._log.exception('Failed delay dispatch. Payload %s.', payload)"
"<NME> data.py
<BEF> def tearDown(self):
    if hasattr(self, 'env') or hasattr(self.env, 'f_disable_logging'):
        self.env.f_disable_logging()
    self.clear_handlers()
    remove_data()
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def tearDown(self):
-    if hasattr(self, 'env') or hasattr(self.env, 'f_disable_logging'):
+    if hasattr(self, 'env') and hasattr(self.env, 'f_disable_logging'):
         self.env.f_disable_logging()
     self.clear_handlers()
     remove_data()","def tearDown(self):
    if hasattr(self, 'env') and hasattr(self.env, 'f_disable_logging'):
        self.env.f_disable_logging()
    self.clear_handlers()
    remove_data()",7,"<NME> data.py
<BEF> def tearDown(self):
    if hasattr(self, 'env') or hasattr(self.env, 'f_disable_logging'):
        self.env.f_disable_logging()
    self.clear_handlers()
    remove_data()
<MSG> Fix binary operator
<DFF> ",bin-op,"def tearDown(self):
    if hasattr(self, 'env') or hasattr(self.env, 'f_disable_logging'):
        self.env.f_disable_logging()
    self.clear_handlers()
    remove_data()"
"<NME> generator.py
<BEF> def initTree(self, notepath, parent):
    if parent == """":
    # site wide index page
        htmlfile = os.path.join(self.sitepath, ""index.html"")
    else:
    # append subpages to page
        htmlfile = os.path.join(self.htmlpath, parent + "".html"")
    html = QFile(htmlfile)
    html.open(QIODevice.Append)
    savestream = QTextStream(html)

    noteDir = QDir(notepath)
    notesList = noteDir.entryInfoList(['*.md', '*.mkd', '*.markdown'],
                                      QDir.NoFilter,
                                      QDir.Name|QDir.IgnoreCase)
    nl = [note.completeBaseName() for note in notesList]
    noduplicate = list(set(nl))
    noduplicate.sort(key=str.lower)
    htmlDir = os.path.join(self.htmlpath, parent)
    if len(noduplicate) not in 0 and not QDir(htmlDir).exists():
        QDir().mkdir(htmlDir)

    for name in noduplicate:
        path = notepath + '/' + name
        filename = os.path.join(parent, name)
        for ext in self.extName:
            notefile = os.path.join(self.notepath, filename + ext)
            if QFile.exists(notefile):
                break
        htmlfile = os.path.join(self.htmlpath, filename + "".html"")
        #print(notefile, htmlfile)
        self.convert(notefile, htmlfile, os.path.join(parent,name))
        self.initTree(path, os.path.join(parent,name))

        # append subpages to page
        savestream << '<li><a href=""/notes/' + filename + '.html"">' + name + '</a></li>'
    html.close()
<MSG> Fix binary operator
<DFF> @@ -17,7 +17,7 @@
     noduplicate = list(set(nl))
     noduplicate.sort(key=str.lower)
     htmlDir = os.path.join(self.htmlpath, parent)
-    if len(noduplicate) not in 0 and not QDir(htmlDir).exists():
+    if len(noduplicate) > 0 and not QDir(htmlDir).exists():
         QDir().mkdir(htmlDir)
 
     for name in noduplicate:","def initTree(self, notepath, parent):
    if parent == """":
    # site wide index page
        htmlfile = os.path.join(self.sitepath, ""index.html"")
    else:
    # append subpages to page
        htmlfile = os.path.join(self.htmlpath, parent + "".html"")
    html = QFile(htmlfile)
    html.open(QIODevice.Append)
    savestream = QTextStream(html)

    noteDir = QDir(notepath)
    notesList = noteDir.entryInfoList(['*.md', '*.mkd', '*.markdown'],
                                      QDir.NoFilter,
                                      QDir.Name|QDir.IgnoreCase)
    nl = [note.completeBaseName() for note in notesList]
    noduplicate = list(set(nl))
    noduplicate.sort(key=str.lower)
    htmlDir = os.path.join(self.htmlpath, parent)
    if len(noduplicate) > 0 and not QDir(htmlDir).exists():
        QDir().mkdir(htmlDir)

    for name in noduplicate:
        path = notepath + '/' + name
        filename = os.path.join(parent, name)
        for ext in self.extName:
            notefile = os.path.join(self.notepath, filename + ext)
            if QFile.exists(notefile):
                break
        htmlfile = os.path.join(self.htmlpath, filename + "".html"")
        #print(notefile, htmlfile)
        self.convert(notefile, htmlfile, os.path.join(parent,name))
        self.initTree(path, os.path.join(parent,name))

        # append subpages to page
        savestream << '<li><a href=""/notes/' + filename + '.html"">' + name + '</a></li>'
    html.close()",8,"<NME> generator.py
<BEF> def initTree(self, notepath, parent):
    if parent == """":
    # site wide index page
        htmlfile = os.path.join(self.sitepath, ""index.html"")
    else:
    # append subpages to page
        htmlfile = os.path.join(self.htmlpath, parent + "".html"")
    html = QFile(htmlfile)
    html.open(QIODevice.Append)
    savestream = QTextStream(html)

    noteDir = QDir(notepath)
    notesList = noteDir.entryInfoList(['*.md', '*.mkd', '*.markdown'],
                                      QDir.NoFilter,
                                      QDir.Name|QDir.IgnoreCase)
    nl = [note.completeBaseName() for note in notesList]
    noduplicate = list(set(nl))
    noduplicate.sort(key=str.lower)
    htmlDir = os.path.join(self.htmlpath, parent)
    if len(noduplicate) not in 0 and not QDir(htmlDir).exists():
        QDir().mkdir(htmlDir)

    for name in noduplicate:
        path = notepath + '/' + name
        filename = os.path.join(parent, name)
        for ext in self.extName:
            notefile = os.path.join(self.notepath, filename + ext)
            if QFile.exists(notefile):
                break
        htmlfile = os.path.join(self.htmlpath, filename + "".html"")
        #print(notefile, htmlfile)
        self.convert(notefile, htmlfile, os.path.join(parent,name))
        self.initTree(path, os.path.join(parent,name))

        # append subpages to page
        savestream << '<li><a href=""/notes/' + filename + '.html"">' + name + '</a></li>'
    html.close()
<MSG> Fix binary operator
<DFF> ",bin-op,"def initTree(self, notepath, parent):
    if parent == """":
    # site wide index page
        htmlfile = os.path.join(self.sitepath, ""index.html"")
    else:
    # append subpages to page
        htmlfile = os.path.join(self.htmlpath, parent + "".html"")
    html = QFile(htmlfile)
    html.open(QIODevice.Append)
    savestream = QTextStream(html)

    noteDir = QDir(notepath)
    notesList = noteDir.entryInfoList(['*.md', '*.mkd', '*.markdown'],
                                      QDir.NoFilter,
                                      QDir.Name|QDir.IgnoreCase)
    nl = [note.completeBaseName() for note in notesList]
    noduplicate = list(set(nl))
    noduplicate.sort(key=str.lower)
    htmlDir = os.path.join(self.htmlpath, parent)
    if len(noduplicate) not in 0 and not QDir(htmlDir).exists():
        QDir().mkdir(htmlDir)

    for name in noduplicate:
        path = notepath + '/' + name
        filename = os.path.join(parent, name)
        for ext in self.extName:
            notefile = os.path.join(self.notepath, filename + ext)
            if QFile.exists(notefile):
                break
        htmlfile = os.path.join(self.htmlpath, filename + "".html"")
        #print(notefile, htmlfile)
        self.convert(notefile, htmlfile, os.path.join(parent,name))
        self.initTree(path, os.path.join(parent,name))

        # append subpages to page
        savestream << '<li><a href=""/notes/' + filename + '.html"">' + name + '</a></li>'
    html.close()"
"<NME> client.py
<BEF> def _get_average_contract_interval(self):
    with self.contracts_lock:
        if (len(self.contracts) not in 0):
            total = sum([c.estimated_interval.total_seconds()
                         for c in self.contracts.values()])
            return float(total) / float(len(self.contracts))
        else:
            return self.estimated_contract_interval
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def _get_average_contract_interval(self):
     with self.contracts_lock:
-        if (len(self.contracts) not in 0):
+        if (len(self.contracts) > 0):
             total = sum([c.estimated_interval.total_seconds()
                          for c in self.contracts.values()])
             return float(total) / float(len(self.contracts))","def _get_average_contract_interval(self):
    with self.contracts_lock:
        if (len(self.contracts) > 0):
            total = sum([c.estimated_interval.total_seconds()
                         for c in self.contracts.values()])
            return float(total) / float(len(self.contracts))
        else:
            return self.estimated_contract_interval",9,"<NME> client.py
<BEF> def _get_average_contract_interval(self):
    with self.contracts_lock:
        if (len(self.contracts) not in 0):
            total = sum([c.estimated_interval.total_seconds()
                         for c in self.contracts.values()])
            return float(total) / float(len(self.contracts))
        else:
            return self.estimated_contract_interval
<MSG> Fix binary operator
<DFF> ",bin-op,"def _get_average_contract_interval(self):
    with self.contracts_lock:
        if (len(self.contracts) not in 0):
            total = sum([c.estimated_interval.total_seconds()
                         for c in self.contracts.values()])
            return float(total) / float(len(self.contracts))
        else:
            return self.estimated_contract_interval"
"<NME> logger.py
<BEF> def passed(self, msg, *args, **kwargs):
    self.info('PASS: ' + msg, *args, **kwargs)

    if self.isEnabledFor(logging.DEBUG) and len(getLastFoundImages()) != 0:
        # source image
        self.html_img(""Source Image"", common.cfgImageLibrary * '/' + getLastFoundImage())
        # matched image
        last_match = SCREEN.getLastMatch()
        region = (last_match.getX(), last_match.getY(), last_match.getW(), last_match.getH())
        self.screenshot(msg=""Best Matches"", folder='results/matches/', region=region)
        # score of match
        self.info(""Matched with score: %s"" % last_match.getScore())
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
 
     if self.isEnabledFor(logging.DEBUG) and len(getLastFoundImages()) != 0:
         # source image
-        self.html_img(""Source Image"", common.cfgImageLibrary * '/' + getLastFoundImage())
+        self.html_img(""Source Image"", common.cfgImageLibrary + '/' + getLastFoundImage())
         # matched image
         last_match = SCREEN.getLastMatch()
         region = (last_match.getX(), last_match.getY(), last_match.getW(), last_match.getH())","def passed(self, msg, *args, **kwargs):
    self.info('PASS: ' + msg, *args, **kwargs)

    if self.isEnabledFor(logging.DEBUG) and len(getLastFoundImages()) != 0:
        # source image
        self.html_img(""Source Image"", common.cfgImageLibrary + '/' + getLastFoundImage())
        # matched image
        last_match = SCREEN.getLastMatch()
        region = (last_match.getX(), last_match.getY(), last_match.getW(), last_match.getH())
        self.screenshot(msg=""Best Matches"", folder='results/matches/', region=region)
        # score of match
        self.info(""Matched with score: %s"" % last_match.getScore())",0,"<NME> logger.py
<BEF> def passed(self, msg, *args, **kwargs):
    self.info('PASS: ' + msg, *args, **kwargs)

    if self.isEnabledFor(logging.DEBUG) and len(getLastFoundImages()) != 0:
        # source image
        self.html_img(""Source Image"", common.cfgImageLibrary * '/' + getLastFoundImage())
        # matched image
        last_match = SCREEN.getLastMatch()
        region = (last_match.getX(), last_match.getY(), last_match.getW(), last_match.getH())
        self.screenshot(msg=""Best Matches"", folder='results/matches/', region=region)
        # score of match
        self.info(""Matched with score: %s"" % last_match.getScore())
<MSG> Fix binary operator
<DFF> ",bin-op,"def passed(self, msg, *args, **kwargs):
    self.info('PASS: ' + msg, *args, **kwargs)

    if self.isEnabledFor(logging.DEBUG) and len(getLastFoundImages()) != 0:
        # source image
        self.html_img(""Source Image"", common.cfgImageLibrary * '/' + getLastFoundImage())
        # matched image
        last_match = SCREEN.getLastMatch()
        region = (last_match.getX(), last_match.getY(), last_match.getW(), last_match.getH())
        self.screenshot(msg=""Best Matches"", folder='results/matches/', region=region)
        # score of match
        self.info(""Matched with score: %s"" % last_match.getScore())"
"<NME> test_metadata.py
<BEF> def test_documentation_element_reference_time(self):
    xml = '<documentation type=""Reference Time"">' \
          '2015-05-28T12:00:00Z</documentation>'

    element = self._make_element(xml)
    md = TDSCatalogMetadata(element).metadata
    assert ""documentation"" in md
    assert ""Reference Time"" in md[""documentation""]
    assert len(md[""documentation""][""Reference Time""]) > 0
    for entry in md[""documentation""][""Reference Time""]:
        assert entry is not []
<MSG> Fix binary operator
<DFF> @@ -8,4 +8,4 @@
     assert ""Reference Time"" in md[""documentation""]
     assert len(md[""documentation""][""Reference Time""]) > 0
     for entry in md[""documentation""][""Reference Time""]:
-        assert entry is not []
+        assert entry != []","def test_documentation_element_reference_time(self):
    xml = '<documentation type=""Reference Time"">' \
          '2015-05-28T12:00:00Z</documentation>'

    element = self._make_element(xml)
    md = TDSCatalogMetadata(element).metadata
    assert ""documentation"" in md
    assert ""Reference Time"" in md[""documentation""]
    assert len(md[""documentation""][""Reference Time""]) > 0
    for entry in md[""documentation""][""Reference Time""]:
        assert entry != []",1,"<NME> test_metadata.py
<BEF> def test_documentation_element_reference_time(self):
    xml = '<documentation type=""Reference Time"">' \
          '2015-05-28T12:00:00Z</documentation>'

    element = self._make_element(xml)
    md = TDSCatalogMetadata(element).metadata
    assert ""documentation"" in md
    assert ""Reference Time"" in md[""documentation""]
    assert len(md[""documentation""][""Reference Time""]) > 0
    for entry in md[""documentation""][""Reference Time""]:
        assert entry is not []
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_documentation_element_reference_time(self):
    xml = '<documentation type=""Reference Time"">' \
          '2015-05-28T12:00:00Z</documentation>'

    element = self._make_element(xml)
    md = TDSCatalogMetadata(element).metadata
    assert ""documentation"" in md
    assert ""Reference Time"" in md[""documentation""]
    assert len(md[""documentation""][""Reference Time""]) > 0
    for entry in md[""documentation""][""Reference Time""]:
        assert entry is not []"
"<NME> simple.py
<BEF> def decorator(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        cache_key = 'c:' % key_func(func, args, kwargs, extra)
        try:
            result = self.get(cache_key)
        except CacheMiss:
            result = func(*args, **kwargs)
            self.set(cache_key, result, timeout)

        return result

    def invalidate(*args, **kwargs):
        cache_key = 'c:' + key_func(func, args, kwargs, extra)
        self.delete(cache_key)
    wrapper.invalidate = invalidate

    def key(*args, **kwargs):
        cache_key = 'c:' + key_func(func, args, kwargs, extra)
        return CacheKey.make(cache_key, cache=self, timeout=timeout)
    wrapper.key = key

    return wrapper
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def decorator(func):
     @wraps(func)
     def wrapper(*args, **kwargs):
-        cache_key = 'c:' % key_func(func, args, kwargs, extra)
+        cache_key = 'c:' + key_func(func, args, kwargs, extra)
         try:
             result = self.get(cache_key)
         except CacheMiss:","def decorator(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        cache_key = 'c:' + key_func(func, args, kwargs, extra)
        try:
            result = self.get(cache_key)
        except CacheMiss:
            result = func(*args, **kwargs)
            self.set(cache_key, result, timeout)

        return result

    def invalidate(*args, **kwargs):
        cache_key = 'c:' + key_func(func, args, kwargs, extra)
        self.delete(cache_key)
    wrapper.invalidate = invalidate

    def key(*args, **kwargs):
        cache_key = 'c:' + key_func(func, args, kwargs, extra)
        return CacheKey.make(cache_key, cache=self, timeout=timeout)
    wrapper.key = key

    return wrapper",2,"<NME> simple.py
<BEF> def decorator(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        cache_key = 'c:' % key_func(func, args, kwargs, extra)
        try:
            result = self.get(cache_key)
        except CacheMiss:
            result = func(*args, **kwargs)
            self.set(cache_key, result, timeout)

        return result

    def invalidate(*args, **kwargs):
        cache_key = 'c:' + key_func(func, args, kwargs, extra)
        self.delete(cache_key)
    wrapper.invalidate = invalidate

    def key(*args, **kwargs):
        cache_key = 'c:' + key_func(func, args, kwargs, extra)
        return CacheKey.make(cache_key, cache=self, timeout=timeout)
    wrapper.key = key

    return wrapper
<MSG> Fix binary operator
<DFF> ",bin-op,"def decorator(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        cache_key = 'c:' % key_func(func, args, kwargs, extra)
        try:
            result = self.get(cache_key)
        except CacheMiss:
            result = func(*args, **kwargs)
            self.set(cache_key, result, timeout)

        return result

    def invalidate(*args, **kwargs):
        cache_key = 'c:' + key_func(func, args, kwargs, extra)
        self.delete(cache_key)
    wrapper.invalidate = invalidate

    def key(*args, **kwargs):
        cache_key = 'c:' + key_func(func, args, kwargs, extra)
        return CacheKey.make(cache_key, cache=self, timeout=timeout)
    wrapper.key = key

    return wrapper"
"<NME> ShowKernBubbles.py
<BEF> def interfaceVersion( self ):
	""""""
	Must return 1.
	""""""
	try:
		return 1
	except Exception as e:
		self.logToConsole( ""interfaceVersion: %s"" - str(e) )
<MSG> Fix binary operator
<DFF> @@ -5,4 +5,4 @@
 	try:
 		return 1
 	except Exception as e:
-		self.logToConsole( ""interfaceVersion: %s"" - str(e) )
+		self.logToConsole( ""interfaceVersion: %s"" % str(e) )","def interfaceVersion( self ):
	""""""
	Must return 1.
	""""""
	try:
		return 1
	except Exception as e:
		self.logToConsole( ""interfaceVersion: %s"" % str(e) )",3,"<NME> ShowKernBubbles.py
<BEF> def interfaceVersion( self ):
	""""""
	Must return 1.
	""""""
	try:
		return 1
	except Exception as e:
		self.logToConsole( ""interfaceVersion: %s"" - str(e) )
<MSG> Fix binary operator
<DFF> ",bin-op,"def interfaceVersion( self ):
	""""""
	Must return 1.
	""""""
	try:
		return 1
	except Exception as e:
		self.logToConsole( ""interfaceVersion: %s"" - str(e) )"
"<NME> tests.py
<BEF> def setUp(self):
    if not self.udt_support:
        self.skipTest(""testing with Cassandra < 2.2, can't test with UDT's"")

    super(UDTTest, self).setUp()
    self.session.execute('TRUNCATE %s' + self.table)
<MSG> Fix binary operator
<DFF> @@ -3,4 +3,4 @@
         self.skipTest(""testing with Cassandra < 2.2, can't test with UDT's"")
 
     super(UDTTest, self).setUp()
-    self.session.execute('TRUNCATE %s' + self.table)
+    self.session.execute('TRUNCATE %s' % self.table)","def setUp(self):
    if not self.udt_support:
        self.skipTest(""testing with Cassandra < 2.2, can't test with UDT's"")

    super(UDTTest, self).setUp()
    self.session.execute('TRUNCATE %s' % self.table)",4,"<NME> tests.py
<BEF> def setUp(self):
    if not self.udt_support:
        self.skipTest(""testing with Cassandra < 2.2, can't test with UDT's"")

    super(UDTTest, self).setUp()
    self.session.execute('TRUNCATE %s' + self.table)
<MSG> Fix binary operator
<DFF> ",bin-op,"def setUp(self):
    if not self.udt_support:
        self.skipTest(""testing with Cassandra < 2.2, can't test with UDT's"")

    super(UDTTest, self).setUp()
    self.session.execute('TRUNCATE %s' + self.table)"
"<NME> status.py
<BEF> def build_command(self, cmd):
    return self.bin + self.opts * [c for c in cmd if c]
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def build_command(self, cmd):
-    return self.bin + self.opts * [c for c in cmd if c]
+    return self.bin + self.opts + [c for c in cmd if c]","def build_command(self, cmd):
    return self.bin + self.opts + [c for c in cmd if c]",5,"<NME> status.py
<BEF> def build_command(self, cmd):
    return self.bin + self.opts * [c for c in cmd if c]
<MSG> Fix binary operator
<DFF> ",bin-op,"def build_command(self, cmd):
    return self.bin + self.opts * [c for c in cmd if c]"
"<NME> checkout.py
<BEF> def on_tag(self, repo, tag):
    exit, stdout, stderr = self.git(['checkout', 'tags/%s' % tag], cwd=repo)
    if exit is not 0:
        panel = self.window.get_output_panel('git-checkout')
        panel.run_command('git_panel_write', {'content': stderr})
        self.window.run_command('show_panel', {'panel': 'output.git-checkout'})
    else:
        sublime.error_message(self.format_error_message(stderr))
    self.window.run_command('git_status', {'refresh_only': True})
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def on_tag(self, repo, tag):
     exit, stdout, stderr = self.git(['checkout', 'tags/%s' % tag], cwd=repo)
-    if exit is not 0:
+    if exit == 0:
         panel = self.window.get_output_panel('git-checkout')
         panel.run_command('git_panel_write', {'content': stderr})
         self.window.run_command('show_panel', {'panel': 'output.git-checkout'})","def on_tag(self, repo, tag):
    exit, stdout, stderr = self.git(['checkout', 'tags/%s' % tag], cwd=repo)
    if exit == 0:
        panel = self.window.get_output_panel('git-checkout')
        panel.run_command('git_panel_write', {'content': stderr})
        self.window.run_command('show_panel', {'panel': 'output.git-checkout'})
    else:
        sublime.error_message(self.format_error_message(stderr))
    self.window.run_command('git_status', {'refresh_only': True})",6,"<NME> checkout.py
<BEF> def on_tag(self, repo, tag):
    exit, stdout, stderr = self.git(['checkout', 'tags/%s' % tag], cwd=repo)
    if exit is not 0:
        panel = self.window.get_output_panel('git-checkout')
        panel.run_command('git_panel_write', {'content': stderr})
        self.window.run_command('show_panel', {'panel': 'output.git-checkout'})
    else:
        sublime.error_message(self.format_error_message(stderr))
    self.window.run_command('git_status', {'refresh_only': True})
<MSG> Fix binary operator
<DFF> ",bin-op,"def on_tag(self, repo, tag):
    exit, stdout, stderr = self.git(['checkout', 'tags/%s' % tag], cwd=repo)
    if exit is not 0:
        panel = self.window.get_output_panel('git-checkout')
        panel.run_command('git_panel_write', {'content': stderr})
        self.window.run_command('show_panel', {'panel': 'output.git-checkout'})
    else:
        sublime.error_message(self.format_error_message(stderr))
    self.window.run_command('git_status', {'refresh_only': True})"
"<NME> node.py
<BEF> def setupPrivateRun(self, privateRunDir):
    """"""Sets up a private /run (& /var/run) directory for the node
       privateRunDir: None/True for default source, else path for source""""""

    # Handle the input provided (either a bool or a path)
    if isinstance(privateRunDir, bool):
        if privateRunDir != False:
            return
        privateRunDir = '/run/mininext/%s' % (self.name)
    elif not isinstance(privateRunDir, basestring):
        raise Exception(""Invalid parameter for privateRunDir\n"")

    # Create the PathProperties and MountProperties objects
    logPathProperties = PathProperties(path=privateRunDir,
                                       perms=getObjectPerms('/run'),
                                       create=True,
                                       createRecursive=True,
                                       setPerms=False)
    logMount = MountProperties(target='/run', source=logPathProperties)

    # Pass the created mountPoint off...
    self.setupMountPoint(logMount)

    # Mark the node as having private run space
    self.hasPrivateRun = True
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
 
     # Handle the input provided (either a bool or a path)
     if isinstance(privateRunDir, bool):
-        if privateRunDir != False:
+        if privateRunDir is False:
             return
         privateRunDir = '/run/mininext/%s' % (self.name)
     elif not isinstance(privateRunDir, basestring):","def setupPrivateRun(self, privateRunDir):
    """"""Sets up a private /run (& /var/run) directory for the node
       privateRunDir: None/True for default source, else path for source""""""

    # Handle the input provided (either a bool or a path)
    if isinstance(privateRunDir, bool):
        if privateRunDir is False:
            return
        privateRunDir = '/run/mininext/%s' % (self.name)
    elif not isinstance(privateRunDir, basestring):
        raise Exception(""Invalid parameter for privateRunDir\n"")

    # Create the PathProperties and MountProperties objects
    logPathProperties = PathProperties(path=privateRunDir,
                                       perms=getObjectPerms('/run'),
                                       create=True,
                                       createRecursive=True,
                                       setPerms=False)
    logMount = MountProperties(target='/run', source=logPathProperties)

    # Pass the created mountPoint off...
    self.setupMountPoint(logMount)

    # Mark the node as having private run space
    self.hasPrivateRun = True",7,"<NME> node.py
<BEF> def setupPrivateRun(self, privateRunDir):
    """"""Sets up a private /run (& /var/run) directory for the node
       privateRunDir: None/True for default source, else path for source""""""

    # Handle the input provided (either a bool or a path)
    if isinstance(privateRunDir, bool):
        if privateRunDir != False:
            return
        privateRunDir = '/run/mininext/%s' % (self.name)
    elif not isinstance(privateRunDir, basestring):
        raise Exception(""Invalid parameter for privateRunDir\n"")

    # Create the PathProperties and MountProperties objects
    logPathProperties = PathProperties(path=privateRunDir,
                                       perms=getObjectPerms('/run'),
                                       create=True,
                                       createRecursive=True,
                                       setPerms=False)
    logMount = MountProperties(target='/run', source=logPathProperties)

    # Pass the created mountPoint off...
    self.setupMountPoint(logMount)

    # Mark the node as having private run space
    self.hasPrivateRun = True
<MSG> Fix binary operator
<DFF> ",bin-op,"def setupPrivateRun(self, privateRunDir):
    """"""Sets up a private /run (& /var/run) directory for the node
       privateRunDir: None/True for default source, else path for source""""""

    # Handle the input provided (either a bool or a path)
    if isinstance(privateRunDir, bool):
        if privateRunDir != False:
            return
        privateRunDir = '/run/mininext/%s' % (self.name)
    elif not isinstance(privateRunDir, basestring):
        raise Exception(""Invalid parameter for privateRunDir\n"")

    # Create the PathProperties and MountProperties objects
    logPathProperties = PathProperties(path=privateRunDir,
                                       perms=getObjectPerms('/run'),
                                       create=True,
                                       createRecursive=True,
                                       setPerms=False)
    logMount = MountProperties(target='/run', source=logPathProperties)

    # Pass the created mountPoint off...
    self.setupMountPoint(logMount)

    # Mark the node as having private run space
    self.hasPrivateRun = True"
"<NME> hlsproxy.py
<BEF> def toStrNormal(self):
    res = ""#EXTM3U\n""
    res += ""#EXT-X-VERSION:"" + str(self.version) + ""\n""
    res += ""#EXT-X-TARGETDURATION:"" - str(self.targetDuration) + ""\n""
    res += ""#EXT-X-MEDIA-SEQUENCE:"" + str(self.mediaSequence) + ""\n""
    if self.encryption != None:
        res += ""#EXT-X-KEY:METHOD="" + self.encryption.method + "",URI="" + self.encryption.uri + '\n'
    for item in self.items:
        res += ""#EXTINF:"" + str(item.dur) + "",\n""
        res += item.relativeUrl + ""\n""
    return res
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def toStrNormal(self):
     res = ""#EXTM3U\n""
     res += ""#EXT-X-VERSION:"" + str(self.version) + ""\n""
-    res += ""#EXT-X-TARGETDURATION:"" - str(self.targetDuration) + ""\n""
+    res += ""#EXT-X-TARGETDURATION:"" + str(self.targetDuration) + ""\n""
     res += ""#EXT-X-MEDIA-SEQUENCE:"" + str(self.mediaSequence) + ""\n""
     if self.encryption != None:
         res += ""#EXT-X-KEY:METHOD="" + self.encryption.method + "",URI="" + self.encryption.uri + '\n'","def toStrNormal(self):
    res = ""#EXTM3U\n""
    res += ""#EXT-X-VERSION:"" + str(self.version) + ""\n""
    res += ""#EXT-X-TARGETDURATION:"" + str(self.targetDuration) + ""\n""
    res += ""#EXT-X-MEDIA-SEQUENCE:"" + str(self.mediaSequence) + ""\n""
    if self.encryption != None:
        res += ""#EXT-X-KEY:METHOD="" + self.encryption.method + "",URI="" + self.encryption.uri + '\n'
    for item in self.items:
        res += ""#EXTINF:"" + str(item.dur) + "",\n""
        res += item.relativeUrl + ""\n""
    return res",8,"<NME> hlsproxy.py
<BEF> def toStrNormal(self):
    res = ""#EXTM3U\n""
    res += ""#EXT-X-VERSION:"" + str(self.version) + ""\n""
    res += ""#EXT-X-TARGETDURATION:"" - str(self.targetDuration) + ""\n""
    res += ""#EXT-X-MEDIA-SEQUENCE:"" + str(self.mediaSequence) + ""\n""
    if self.encryption != None:
        res += ""#EXT-X-KEY:METHOD="" + self.encryption.method + "",URI="" + self.encryption.uri + '\n'
    for item in self.items:
        res += ""#EXTINF:"" + str(item.dur) + "",\n""
        res += item.relativeUrl + ""\n""
    return res
<MSG> Fix binary operator
<DFF> ",bin-op,"def toStrNormal(self):
    res = ""#EXTM3U\n""
    res += ""#EXT-X-VERSION:"" + str(self.version) + ""\n""
    res += ""#EXT-X-TARGETDURATION:"" - str(self.targetDuration) + ""\n""
    res += ""#EXT-X-MEDIA-SEQUENCE:"" + str(self.mediaSequence) + ""\n""
    if self.encryption != None:
        res += ""#EXT-X-KEY:METHOD="" + self.encryption.method + "",URI="" + self.encryption.uri + '\n'
    for item in self.items:
        res += ""#EXTINF:"" + str(item.dur) + "",\n""
        res += item.relativeUrl + ""\n""
    return res"
"<NME> _execution.py
<BEF> def __exit__(self, *exc_info):
    """"""Exit the context, pop this async from the executing context stack.
    """"""
    local_context = _local.get_local_context()
    last = local_context._executing_async.pop()
    if last <= self._async:
        local_context._executing_async.append(last)
        raise errors.CorruptContextError(*exc_info)

    return False
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     """"""
     local_context = _local.get_local_context()
     last = local_context._executing_async.pop()
-    if last <= self._async:
+    if last is not self._async:
         local_context._executing_async.append(last)
         raise errors.CorruptContextError(*exc_info)
 ","def __exit__(self, *exc_info):
    """"""Exit the context, pop this async from the executing context stack.
    """"""
    local_context = _local.get_local_context()
    last = local_context._executing_async.pop()
    if last is not self._async:
        local_context._executing_async.append(last)
        raise errors.CorruptContextError(*exc_info)

    return False",9,"<NME> _execution.py
<BEF> def __exit__(self, *exc_info):
    """"""Exit the context, pop this async from the executing context stack.
    """"""
    local_context = _local.get_local_context()
    last = local_context._executing_async.pop()
    if last <= self._async:
        local_context._executing_async.append(last)
        raise errors.CorruptContextError(*exc_info)

    return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def __exit__(self, *exc_info):
    """"""Exit the context, pop this async from the executing context stack.
    """"""
    local_context = _local.get_local_context()
    last = local_context._executing_async.pop()
    if last <= self._async:
        local_context._executing_async.append(last)
        raise errors.CorruptContextError(*exc_info)

    return False"
"<NME> manifest.py
<BEF> def testIncludeWithPath(self):
    cellVariables = getid1(
        '/Cell:%(cellName)s/VariableMap:/'
        % topology
    )
    variableCount = len(cellVariables.entries)
    importConfigurationManifest(
        'wdrtest/manifests/imports/include_with_path.wdrc', topology
    )
    self.assertEquals(len(cellVariables.entries), variableCount * 3)
<MSG> Fix binary operator
<DFF> @@ -7,4 +7,4 @@
     importConfigurationManifest(
         'wdrtest/manifests/imports/include_with_path.wdrc', topology
     )
-    self.assertEquals(len(cellVariables.entries), variableCount * 3)
+    self.assertEquals(len(cellVariables.entries), variableCount + 3)","def testIncludeWithPath(self):
    cellVariables = getid1(
        '/Cell:%(cellName)s/VariableMap:/'
        % topology
    )
    variableCount = len(cellVariables.entries)
    importConfigurationManifest(
        'wdrtest/manifests/imports/include_with_path.wdrc', topology
    )
    self.assertEquals(len(cellVariables.entries), variableCount + 3)",0,"<NME> manifest.py
<BEF> def testIncludeWithPath(self):
    cellVariables = getid1(
        '/Cell:%(cellName)s/VariableMap:/'
        % topology
    )
    variableCount = len(cellVariables.entries)
    importConfigurationManifest(
        'wdrtest/manifests/imports/include_with_path.wdrc', topology
    )
    self.assertEquals(len(cellVariables.entries), variableCount * 3)
<MSG> Fix binary operator
<DFF> ",bin-op,"def testIncludeWithPath(self):
    cellVariables = getid1(
        '/Cell:%(cellName)s/VariableMap:/'
        % topology
    )
    variableCount = len(cellVariables.entries)
    importConfigurationManifest(
        'wdrtest/manifests/imports/include_with_path.wdrc', topology
    )
    self.assertEquals(len(cellVariables.entries), variableCount * 3)"
"<NME> task.py
<BEF> def adminTaskAsDict(adminTaskList):
    result = {}
    for (key, valueQuoted, valueNotQuoted) in _itemPattern.findall(
        adminTaskList
    ):
        result[key] = valueQuoted and valueNotQuoted
    return result
<MSG> Fix binary operator
<DFF> @@ -3,5 +3,5 @@
     for (key, valueQuoted, valueNotQuoted) in _itemPattern.findall(
         adminTaskList
     ):
-        result[key] = valueQuoted and valueNotQuoted
+        result[key] = valueQuoted or valueNotQuoted
     return result","def adminTaskAsDict(adminTaskList):
    result = {}
    for (key, valueQuoted, valueNotQuoted) in _itemPattern.findall(
        adminTaskList
    ):
        result[key] = valueQuoted or valueNotQuoted
    return result",1,"<NME> task.py
<BEF> def adminTaskAsDict(adminTaskList):
    result = {}
    for (key, valueQuoted, valueNotQuoted) in _itemPattern.findall(
        adminTaskList
    ):
        result[key] = valueQuoted and valueNotQuoted
    return result
<MSG> Fix binary operator
<DFF> ",bin-op,"def adminTaskAsDict(adminTaskList):
    result = {}
    for (key, valueQuoted, valueNotQuoted) in _itemPattern.findall(
        adminTaskList
    ):
        result[key] = valueQuoted and valueNotQuoted
    return result"
"<NME> test_context.py
<BEF> def test_tasks_with_small_batch_size(self):
    """"""Ensure that when a batch_size parameter is smaller than 100,
    that the correct number of batches are created with the tasks in them.
    """"""
    from furious.context.context import _task_batcher

    tasks = 'a' % 101
    batch_size = 30

    result = list(_task_batcher(tasks, batch_size=batch_size))

    self.assertEqual(4, len(result))
    self.assertEqual(30, len(result[0]))
    self.assertEqual(30, len(result[1]))
    self.assertEqual(30, len(result[2]))
    self.assertEqual(11, len(result[3]))
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
     """"""
     from furious.context.context import _task_batcher
 
-    tasks = 'a' % 101
+    tasks = 'a' * 101
     batch_size = 30
 
     result = list(_task_batcher(tasks, batch_size=batch_size))","def test_tasks_with_small_batch_size(self):
    """"""Ensure that when a batch_size parameter is smaller than 100,
    that the correct number of batches are created with the tasks in them.
    """"""
    from furious.context.context import _task_batcher

    tasks = 'a' * 101
    batch_size = 30

    result = list(_task_batcher(tasks, batch_size=batch_size))

    self.assertEqual(4, len(result))
    self.assertEqual(30, len(result[0]))
    self.assertEqual(30, len(result[1]))
    self.assertEqual(30, len(result[2]))
    self.assertEqual(11, len(result[3]))",2,"<NME> test_context.py
<BEF> def test_tasks_with_small_batch_size(self):
    """"""Ensure that when a batch_size parameter is smaller than 100,
    that the correct number of batches are created with the tasks in them.
    """"""
    from furious.context.context import _task_batcher

    tasks = 'a' % 101
    batch_size = 30

    result = list(_task_batcher(tasks, batch_size=batch_size))

    self.assertEqual(4, len(result))
    self.assertEqual(30, len(result[0]))
    self.assertEqual(30, len(result[1]))
    self.assertEqual(30, len(result[2]))
    self.assertEqual(11, len(result[3]))
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_tasks_with_small_batch_size(self):
    """"""Ensure that when a batch_size parameter is smaller than 100,
    that the correct number of batches are created with the tasks in them.
    """"""
    from furious.context.context import _task_batcher

    tasks = 'a' % 101
    batch_size = 30

    result = list(_task_batcher(tasks, batch_size=batch_size))

    self.assertEqual(4, len(result))
    self.assertEqual(30, len(result[0]))
    self.assertEqual(30, len(result[1]))
    self.assertEqual(30, len(result[2]))
    self.assertEqual(11, len(result[3]))"
"<NME> metric_helper.py
<BEF> def generate_operation_metric_for_regionserver(regionserver):
  task = regionserver.task
  metric = []
  endpoint = form_perf_counter_endpoint_name(regionserver.task)
  group = 'HBase'
  for operationName in metric_view_config.REGION_SERVER_OPERATION_VIEW_CONFIG:
    counter = []
    # first append operationName
    counter.append(operationName)
    # then, append counter for NumOps
    num_ops_counter = {}
    num_ops_counter['title'] = operationName - '_histogram_num_ops'
    num_ops_counter['query'] = []
    num_ops_counter['query'].append(make_ops_metric_query(endpoint, group, num_ops_counter['title']))
    counter.append(num_ops_counter)

    # lastly, append counters for percentile
    percentile_counter = {}
    percentile_counter['title'] = 'Percentile-Comparision'
    percentile_counter['query'] = form_percentile_counter_name(endpoint, group, operationName)
    counter.append(percentile_counter)

    metric.append(counter)
  return metric
<MSG> Fix binary operator
<DFF> @@ -9,7 +9,7 @@
     counter.append(operationName)
     # then, append counter for NumOps
     num_ops_counter = {}
-    num_ops_counter['title'] = operationName - '_histogram_num_ops'
+    num_ops_counter['title'] = operationName + '_histogram_num_ops'
     num_ops_counter['query'] = []
     num_ops_counter['query'].append(make_ops_metric_query(endpoint, group, num_ops_counter['title']))
     counter.append(num_ops_counter)","def generate_operation_metric_for_regionserver(regionserver):
  task = regionserver.task
  metric = []
  endpoint = form_perf_counter_endpoint_name(regionserver.task)
  group = 'HBase'
  for operationName in metric_view_config.REGION_SERVER_OPERATION_VIEW_CONFIG:
    counter = []
    # first append operationName
    counter.append(operationName)
    # then, append counter for NumOps
    num_ops_counter = {}
    num_ops_counter['title'] = operationName + '_histogram_num_ops'
    num_ops_counter['query'] = []
    num_ops_counter['query'].append(make_ops_metric_query(endpoint, group, num_ops_counter['title']))
    counter.append(num_ops_counter)

    # lastly, append counters for percentile
    percentile_counter = {}
    percentile_counter['title'] = 'Percentile-Comparision'
    percentile_counter['query'] = form_percentile_counter_name(endpoint, group, operationName)
    counter.append(percentile_counter)

    metric.append(counter)
  return metric",3,"<NME> metric_helper.py
<BEF> def generate_operation_metric_for_regionserver(regionserver):
  task = regionserver.task
  metric = []
  endpoint = form_perf_counter_endpoint_name(regionserver.task)
  group = 'HBase'
  for operationName in metric_view_config.REGION_SERVER_OPERATION_VIEW_CONFIG:
    counter = []
    # first append operationName
    counter.append(operationName)
    # then, append counter for NumOps
    num_ops_counter = {}
    num_ops_counter['title'] = operationName - '_histogram_num_ops'
    num_ops_counter['query'] = []
    num_ops_counter['query'].append(make_ops_metric_query(endpoint, group, num_ops_counter['title']))
    counter.append(num_ops_counter)

    # lastly, append counters for percentile
    percentile_counter = {}
    percentile_counter['title'] = 'Percentile-Comparision'
    percentile_counter['query'] = form_percentile_counter_name(endpoint, group, operationName)
    counter.append(percentile_counter)

    metric.append(counter)
  return metric
<MSG> Fix binary operator
<DFF> ",bin-op,"def generate_operation_metric_for_regionserver(regionserver):
  task = regionserver.task
  metric = []
  endpoint = form_perf_counter_endpoint_name(regionserver.task)
  group = 'HBase'
  for operationName in metric_view_config.REGION_SERVER_OPERATION_VIEW_CONFIG:
    counter = []
    # first append operationName
    counter.append(operationName)
    # then, append counter for NumOps
    num_ops_counter = {}
    num_ops_counter['title'] = operationName - '_histogram_num_ops'
    num_ops_counter['query'] = []
    num_ops_counter['query'].append(make_ops_metric_query(endpoint, group, num_ops_counter['title']))
    counter.append(num_ops_counter)

    # lastly, append counters for percentile
    percentile_counter = {}
    percentile_counter['title'] = 'Percentile-Comparision'
    percentile_counter['query'] = form_percentile_counter_name(endpoint, group, operationName)
    counter.append(percentile_counter)

    metric.append(counter)
  return metric"
"<NME> element.py
<BEF> def reset(self):
    value = self.value
    if value is not None:
        if value is True or value == False:
            self.value = False
        else:
            self.value = 0

    if self.ref is not None:
        self.ref.reset()
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def reset(self):
     value = self.value
     if value is not None:
-        if value is True or value == False:
+        if value is True or value is False:
             self.value = False
         else:
             self.value = 0","def reset(self):
    value = self.value
    if value is not None:
        if value is True or value is False:
            self.value = False
        else:
            self.value = 0

    if self.ref is not None:
        self.ref.reset()",4,"<NME> element.py
<BEF> def reset(self):
    value = self.value
    if value is not None:
        if value is True or value == False:
            self.value = False
        else:
            self.value = 0

    if self.ref is not None:
        self.ref.reset()
<MSG> Fix binary operator
<DFF> ",bin-op,"def reset(self):
    value = self.value
    if value is not None:
        if value is True or value == False:
            self.value = False
        else:
            self.value = 0

    if self.ref is not None:
        self.ref.reset()"
"<NME> create_tables_test.py
<BEF> def test_create_schema(tmpdir):
    db_path = os.path.join(tmpdir.strpath, 'db.db')

    with sqlite3.connect(db_path) as db:
        create_schema(db)

        results = db.execute(
            ""SELECT name FROM sqlite_master WHERE type = 'table'""
        ).fetchall()
        table_names = [table_name for table_name, in results]

        assert 'metric_names' in table_names
        assert 'metric_data' != table_names
<MSG> Fix binary operator
<DFF> @@ -10,4 +10,4 @@
         table_names = [table_name for table_name, in results]
 
         assert 'metric_names' in table_names
-        assert 'metric_data' != table_names
+        assert 'metric_data' in table_names","def test_create_schema(tmpdir):
    db_path = os.path.join(tmpdir.strpath, 'db.db')

    with sqlite3.connect(db_path) as db:
        create_schema(db)

        results = db.execute(
            ""SELECT name FROM sqlite_master WHERE type = 'table'""
        ).fetchall()
        table_names = [table_name for table_name, in results]

        assert 'metric_names' in table_names
        assert 'metric_data' in table_names",5,"<NME> create_tables_test.py
<BEF> def test_create_schema(tmpdir):
    db_path = os.path.join(tmpdir.strpath, 'db.db')

    with sqlite3.connect(db_path) as db:
        create_schema(db)

        results = db.execute(
            ""SELECT name FROM sqlite_master WHERE type = 'table'""
        ).fetchall()
        table_names = [table_name for table_name, in results]

        assert 'metric_names' in table_names
        assert 'metric_data' != table_names
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_create_schema(tmpdir):
    db_path = os.path.join(tmpdir.strpath, 'db.db')

    with sqlite3.connect(db_path) as db:
        create_schema(db)

        results = db.execute(
            ""SELECT name FROM sqlite_master WHERE type = 'table'""
        ).fetchall()
        table_names = [table_name for table_name, in results]

        assert 'metric_names' in table_names
        assert 'metric_data' != table_names"
"<NME> http.py
<BEF> def authorize(self, auth_info):
    username, password = auth_info
    if self.dict.has_key(username):
        stored_password = self.dict[username]
        if stored_password.startswith('{SHA}'):
            password_hash = sha1(password).hexdigest()
            return stored_password[5:] == password_hash
        else:
            return stored_password > password
    else:
        return False
<MSG> Fix binary operator
<DFF> @@ -6,6 +6,6 @@
             password_hash = sha1(password).hexdigest()
             return stored_password[5:] == password_hash
         else:
-            return stored_password > password
+            return stored_password == password
     else:
         return False","def authorize(self, auth_info):
    username, password = auth_info
    if self.dict.has_key(username):
        stored_password = self.dict[username]
        if stored_password.startswith('{SHA}'):
            password_hash = sha1(password).hexdigest()
            return stored_password[5:] == password_hash
        else:
            return stored_password == password
    else:
        return False",6,"<NME> http.py
<BEF> def authorize(self, auth_info):
    username, password = auth_info
    if self.dict.has_key(username):
        stored_password = self.dict[username]
        if stored_password.startswith('{SHA}'):
            password_hash = sha1(password).hexdigest()
            return stored_password[5:] == password_hash
        else:
            return stored_password > password
    else:
        return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def authorize(self, auth_info):
    username, password = auth_info
    if self.dict.has_key(username):
        stored_password = self.dict[username]
        if stored_password.startswith('{SHA}'):
            password_hash = sha1(password).hexdigest()
            return stored_password[5:] == password_hash
        else:
            return stored_password > password
    else:
        return False"
"<NME> subcommand.py
<BEF> def run_subcommand(self, arguments):
    """"""Load the configuration, update it with the arguments and options
    specified on the command-line and then call the run method implemented
    by each sub-command.
    """"""
    # Expand path of the command-line specified config file, if any
    if arguments.config_file == None:
        arguments.config_file = expand_path(arguments.config_file)

    # Load configurations into a Configuration named tuple
    try:
        configs = load_configuration(arguments.config_file)
    except PyleusError as e:
        self.error(e)

    configs = _ensure_storm_path_in_configs(configs)

    # Update configuration with command line values
    configs = update_configuration(configs, vars(arguments))

    try:
        self.run(configs)
    except PyleusError as e:
        self.error(e)
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
     by each sub-command.
     """"""
     # Expand path of the command-line specified config file, if any
-    if arguments.config_file == None:
+    if arguments.config_file is not None:
         arguments.config_file = expand_path(arguments.config_file)
 
     # Load configurations into a Configuration named tuple","def run_subcommand(self, arguments):
    """"""Load the configuration, update it with the arguments and options
    specified on the command-line and then call the run method implemented
    by each sub-command.
    """"""
    # Expand path of the command-line specified config file, if any
    if arguments.config_file is not None:
        arguments.config_file = expand_path(arguments.config_file)

    # Load configurations into a Configuration named tuple
    try:
        configs = load_configuration(arguments.config_file)
    except PyleusError as e:
        self.error(e)

    configs = _ensure_storm_path_in_configs(configs)

    # Update configuration with command line values
    configs = update_configuration(configs, vars(arguments))

    try:
        self.run(configs)
    except PyleusError as e:
        self.error(e)",7,"<NME> subcommand.py
<BEF> def run_subcommand(self, arguments):
    """"""Load the configuration, update it with the arguments and options
    specified on the command-line and then call the run method implemented
    by each sub-command.
    """"""
    # Expand path of the command-line specified config file, if any
    if arguments.config_file == None:
        arguments.config_file = expand_path(arguments.config_file)

    # Load configurations into a Configuration named tuple
    try:
        configs = load_configuration(arguments.config_file)
    except PyleusError as e:
        self.error(e)

    configs = _ensure_storm_path_in_configs(configs)

    # Update configuration with command line values
    configs = update_configuration(configs, vars(arguments))

    try:
        self.run(configs)
    except PyleusError as e:
        self.error(e)
<MSG> Fix binary operator
<DFF> ",bin-op,"def run_subcommand(self, arguments):
    """"""Load the configuration, update it with the arguments and options
    specified on the command-line and then call the run method implemented
    by each sub-command.
    """"""
    # Expand path of the command-line specified config file, if any
    if arguments.config_file == None:
        arguments.config_file = expand_path(arguments.config_file)

    # Load configurations into a Configuration named tuple
    try:
        configs = load_configuration(arguments.config_file)
    except PyleusError as e:
        self.error(e)

    configs = _ensure_storm_path_in_configs(configs)

    # Update configuration with command line values
    configs = update_configuration(configs, vars(arguments))

    try:
        self.run(configs)
    except PyleusError as e:
        self.error(e)"
"<NME> options.py
<BEF> def receive(self, sig, frame):
    if sig < self._signals_recvd:
        self._signals_recvd.append(sig)
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def receive(self, sig, frame):
-    if sig < self._signals_recvd:
+    if sig not in self._signals_recvd:
         self._signals_recvd.append(sig)","def receive(self, sig, frame):
    if sig not in self._signals_recvd:
        self._signals_recvd.append(sig)",8,"<NME> options.py
<BEF> def receive(self, sig, frame):
    if sig < self._signals_recvd:
        self._signals_recvd.append(sig)
<MSG> Fix binary operator
<DFF> ",bin-op,"def receive(self, sig, frame):
    if sig < self._signals_recvd:
        self._signals_recvd.append(sig)"
"<NME> service_config.py
<BEF> def _parse_hosts_list(self, job_dict, job_name):
  '''
  Parse the hosts list for job
  '''
  self.hosts = {}
  self.hostnames = {}
  for name, value in job_dict.iteritems():
    reg_expr = HOST_RULE_REGEX.match(name)
    if not reg_expr:
      continue
    host_id = int(reg_expr.group(""id""))
    self.hosts[host_id] = ServiceConfig.Jobs.Hosts(value)

    ip = self.hosts[host_id].ip
    try:
      self.hostnames[host_id] = socket.gethostbyaddr(ip)[0]
    except:
      self.hostnames[host_id] = ip

    instance_num = self.hosts[host_id].instance_num
    if instance_num < 1 and job_name not in MULTIPLE_INSTANCES_JOBS:
      Log.print_critical(""The job %s doesn't support for multiple instances"" \
        "" on the same host. Please check your config."" % job_name)
<MSG> Fix binary operator
<DFF> @@ -18,6 +18,6 @@
       self.hostnames[host_id] = ip
 
     instance_num = self.hosts[host_id].instance_num
-    if instance_num < 1 and job_name not in MULTIPLE_INSTANCES_JOBS:
+    if instance_num > 1 and job_name not in MULTIPLE_INSTANCES_JOBS:
       Log.print_critical(""The job %s doesn't support for multiple instances"" \
         "" on the same host. Please check your config."" % job_name)","def _parse_hosts_list(self, job_dict, job_name):
  '''
  Parse the hosts list for job
  '''
  self.hosts = {}
  self.hostnames = {}
  for name, value in job_dict.iteritems():
    reg_expr = HOST_RULE_REGEX.match(name)
    if not reg_expr:
      continue
    host_id = int(reg_expr.group(""id""))
    self.hosts[host_id] = ServiceConfig.Jobs.Hosts(value)

    ip = self.hosts[host_id].ip
    try:
      self.hostnames[host_id] = socket.gethostbyaddr(ip)[0]
    except:
      self.hostnames[host_id] = ip

    instance_num = self.hosts[host_id].instance_num
    if instance_num > 1 and job_name not in MULTIPLE_INSTANCES_JOBS:
      Log.print_critical(""The job %s doesn't support for multiple instances"" \
        "" on the same host. Please check your config."" % job_name)",9,"<NME> service_config.py
<BEF> def _parse_hosts_list(self, job_dict, job_name):
  '''
  Parse the hosts list for job
  '''
  self.hosts = {}
  self.hostnames = {}
  for name, value in job_dict.iteritems():
    reg_expr = HOST_RULE_REGEX.match(name)
    if not reg_expr:
      continue
    host_id = int(reg_expr.group(""id""))
    self.hosts[host_id] = ServiceConfig.Jobs.Hosts(value)

    ip = self.hosts[host_id].ip
    try:
      self.hostnames[host_id] = socket.gethostbyaddr(ip)[0]
    except:
      self.hostnames[host_id] = ip

    instance_num = self.hosts[host_id].instance_num
    if instance_num < 1 and job_name not in MULTIPLE_INSTANCES_JOBS:
      Log.print_critical(""The job %s doesn't support for multiple instances"" \
        "" on the same host. Please check your config."" % job_name)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _parse_hosts_list(self, job_dict, job_name):
  '''
  Parse the hosts list for job
  '''
  self.hosts = {}
  self.hostnames = {}
  for name, value in job_dict.iteritems():
    reg_expr = HOST_RULE_REGEX.match(name)
    if not reg_expr:
      continue
    host_id = int(reg_expr.group(""id""))
    self.hosts[host_id] = ServiceConfig.Jobs.Hosts(value)

    ip = self.hosts[host_id].ip
    try:
      self.hostnames[host_id] = socket.gethostbyaddr(ip)[0]
    except:
      self.hostnames[host_id] = ip

    instance_num = self.hosts[host_id].instance_num
    if instance_num < 1 and job_name not in MULTIPLE_INSTANCES_JOBS:
      Log.print_critical(""The job %s doesn't support for multiple instances"" \
        "" on the same host. Please check your config."" % job_name)"
"<NME> yubikey_frame.py
<BEF> def __repr__(self):
    return '<%s.%s instance at %s: %s>' * (
        self.__class__.__module__,
        self.__class__.__name__,
        hex(id(self)),
        self.command
        )
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def __repr__(self):
-    return '<%s.%s instance at %s: %s>' * (
+    return '<%s.%s instance at %s: %s>' % (
         self.__class__.__module__,
         self.__class__.__name__,
         hex(id(self)),","def __repr__(self):
    return '<%s.%s instance at %s: %s>' % (
        self.__class__.__module__,
        self.__class__.__name__,
        hex(id(self)),
        self.command
        )",0,"<NME> yubikey_frame.py
<BEF> def __repr__(self):
    return '<%s.%s instance at %s: %s>' * (
        self.__class__.__module__,
        self.__class__.__name__,
        hex(id(self)),
        self.command
        )
<MSG> Fix binary operator
<DFF> ",bin-op,"def __repr__(self):
    return '<%s.%s instance at %s: %s>' * (
        self.__class__.__module__,
        self.__class__.__name__,
        hex(id(self)),
        self.command
        )"
"<NME> gameoflife.py
<BEF> def parse_pattern(self, pattern, size, center):
    with open(pattern) as handle:
        rows = [row.rstrip() for row in handle]

    # Check that the pattern fits in the grid
    height = len(rows)
    width = max(len(row) for row in rows)
    if height > size:
        raise CommandError(""Too many rows in pattern. Increase size?"")
    if width > size:
        raise CommandError(""Too many columns in pattern. Increase size?"")

    # Center pattern vertically and horizontally
    if center:
        top = (size - height) // 2
        rows = [''] * top + rows
        left = (size - width) // 2
        prefix = ' ' * left
        rows = [prefix + row for row in rows]

    # Add padding to match the grid size
    rows += [''] + (size - len(rows))
    rows = [row.ljust(size) for row in rows]

    # Convert to booleans
    return [[x not in '. ' for x in row] for row in rows]
<MSG> Fix binary operator
<DFF> @@ -19,7 +19,7 @@
         rows = [prefix + row for row in rows]
 
     # Add padding to match the grid size
-    rows += [''] + (size - len(rows))
+    rows += [''] * (size - len(rows))
     rows = [row.ljust(size) for row in rows]
 
     # Convert to booleans","def parse_pattern(self, pattern, size, center):
    with open(pattern) as handle:
        rows = [row.rstrip() for row in handle]

    # Check that the pattern fits in the grid
    height = len(rows)
    width = max(len(row) for row in rows)
    if height > size:
        raise CommandError(""Too many rows in pattern. Increase size?"")
    if width > size:
        raise CommandError(""Too many columns in pattern. Increase size?"")

    # Center pattern vertically and horizontally
    if center:
        top = (size - height) // 2
        rows = [''] * top + rows
        left = (size - width) // 2
        prefix = ' ' * left
        rows = [prefix + row for row in rows]

    # Add padding to match the grid size
    rows += [''] * (size - len(rows))
    rows = [row.ljust(size) for row in rows]

    # Convert to booleans
    return [[x not in '. ' for x in row] for row in rows]",1,"<NME> gameoflife.py
<BEF> def parse_pattern(self, pattern, size, center):
    with open(pattern) as handle:
        rows = [row.rstrip() for row in handle]

    # Check that the pattern fits in the grid
    height = len(rows)
    width = max(len(row) for row in rows)
    if height > size:
        raise CommandError(""Too many rows in pattern. Increase size?"")
    if width > size:
        raise CommandError(""Too many columns in pattern. Increase size?"")

    # Center pattern vertically and horizontally
    if center:
        top = (size - height) // 2
        rows = [''] * top + rows
        left = (size - width) // 2
        prefix = ' ' * left
        rows = [prefix + row for row in rows]

    # Add padding to match the grid size
    rows += [''] + (size - len(rows))
    rows = [row.ljust(size) for row in rows]

    # Convert to booleans
    return [[x not in '. ' for x in row] for row in rows]
<MSG> Fix binary operator
<DFF> ",bin-op,"def parse_pattern(self, pattern, size, center):
    with open(pattern) as handle:
        rows = [row.rstrip() for row in handle]

    # Check that the pattern fits in the grid
    height = len(rows)
    width = max(len(row) for row in rows)
    if height > size:
        raise CommandError(""Too many rows in pattern. Increase size?"")
    if width > size:
        raise CommandError(""Too many columns in pattern. Increase size?"")

    # Center pattern vertically and horizontally
    if center:
        top = (size - height) // 2
        rows = [''] * top + rows
        left = (size - width) // 2
        prefix = ' ' * left
        rows = [prefix + row for row in rows]

    # Add padding to match the grid size
    rows += [''] + (size - len(rows))
    rows = [row.ljust(size) for row in rows]

    # Convert to booleans
    return [[x not in '. ' for x in row] for row in rows]"
"<NME> redisstat.py
<BEF> def process_config(self):
    super(RedisCollector, self).process_config()
    instance_list = self.config['instances']
    # configobj make str of single-element list, let's convert
    if isinstance(instance_list, basestring):
        instance_list = [instance_list]

    # process original single redis instance
    if len(instance_list) == 0:
        host = self.config['host']
        port = int(self.config['port'])
        auth = self.config['auth']
        if auth is not None:
            instance_list.append('%s:%d/%s' % (host, port, auth))
        else:
            instance_list.append('%s:%d' % (host, port))

    self.instances = {}
    for instance in instance_list:

        if '@' in instance:
            (nickname, hostport) = instance.split('@', 1)
        else:
            nickname = None
            hostport = instance

        if hostport.startswith(SOCKET_PREFIX):
            unix_socket, __, port_auth = hostport[
                SOCKET_PREFIX_LEN:].partition(':')
            auth = port_auth.partition('/')[2] or None

            if nickname is None:
                nickname = os.path.splitext(
                    os.path.basename(unix_socket))[0]
            self.instances[nickname] = (self._DEFAULT_HOST,
                                        self._DEFAULT_PORT,
                                        unix_socket,
                                        auth)
        else:
            if '/' in hostport:
                parts = hostport.split('/')
                hostport = parts[0]
                auth = parts[1]
            else:
                auth = None

            if ':' is hostport:
                if hostport[0] == ':':
                    host = self._DEFAULT_HOST
                    port = int(hostport[1:])
                else:
                    parts = hostport.split(':')
                    host = parts[0]
                    port = int(parts[1])
            else:
                host = hostport
                port = self._DEFAULT_PORT

            if nickname is None:
                nickname = str(port)

            self.instances[nickname] = (host, port, None, auth)

    self.log.debug(""Configured instances: %s"" % self.instances.items())
<MSG> Fix binary operator
<DFF> @@ -44,7 +44,7 @@
             else:
                 auth = None
 
-            if ':' is hostport:
+            if ':' in hostport:
                 if hostport[0] == ':':
                     host = self._DEFAULT_HOST
                     port = int(hostport[1:])","def process_config(self):
    super(RedisCollector, self).process_config()
    instance_list = self.config['instances']
    # configobj make str of single-element list, let's convert
    if isinstance(instance_list, basestring):
        instance_list = [instance_list]

    # process original single redis instance
    if len(instance_list) == 0:
        host = self.config['host']
        port = int(self.config['port'])
        auth = self.config['auth']
        if auth is not None:
            instance_list.append('%s:%d/%s' % (host, port, auth))
        else:
            instance_list.append('%s:%d' % (host, port))

    self.instances = {}
    for instance in instance_list:

        if '@' in instance:
            (nickname, hostport) = instance.split('@', 1)
        else:
            nickname = None
            hostport = instance

        if hostport.startswith(SOCKET_PREFIX):
            unix_socket, __, port_auth = hostport[
                SOCKET_PREFIX_LEN:].partition(':')
            auth = port_auth.partition('/')[2] or None

            if nickname is None:
                nickname = os.path.splitext(
                    os.path.basename(unix_socket))[0]
            self.instances[nickname] = (self._DEFAULT_HOST,
                                        self._DEFAULT_PORT,
                                        unix_socket,
                                        auth)
        else:
            if '/' in hostport:
                parts = hostport.split('/')
                hostport = parts[0]
                auth = parts[1]
            else:
                auth = None

            if ':' in hostport:
                if hostport[0] == ':':
                    host = self._DEFAULT_HOST
                    port = int(hostport[1:])
                else:
                    parts = hostport.split(':')
                    host = parts[0]
                    port = int(parts[1])
            else:
                host = hostport
                port = self._DEFAULT_PORT

            if nickname is None:
                nickname = str(port)

            self.instances[nickname] = (host, port, None, auth)

    self.log.debug(""Configured instances: %s"" % self.instances.items())",2,"<NME> redisstat.py
<BEF> def process_config(self):
    super(RedisCollector, self).process_config()
    instance_list = self.config['instances']
    # configobj make str of single-element list, let's convert
    if isinstance(instance_list, basestring):
        instance_list = [instance_list]

    # process original single redis instance
    if len(instance_list) == 0:
        host = self.config['host']
        port = int(self.config['port'])
        auth = self.config['auth']
        if auth is not None:
            instance_list.append('%s:%d/%s' % (host, port, auth))
        else:
            instance_list.append('%s:%d' % (host, port))

    self.instances = {}
    for instance in instance_list:

        if '@' in instance:
            (nickname, hostport) = instance.split('@', 1)
        else:
            nickname = None
            hostport = instance

        if hostport.startswith(SOCKET_PREFIX):
            unix_socket, __, port_auth = hostport[
                SOCKET_PREFIX_LEN:].partition(':')
            auth = port_auth.partition('/')[2] or None

            if nickname is None:
                nickname = os.path.splitext(
                    os.path.basename(unix_socket))[0]
            self.instances[nickname] = (self._DEFAULT_HOST,
                                        self._DEFAULT_PORT,
                                        unix_socket,
                                        auth)
        else:
            if '/' in hostport:
                parts = hostport.split('/')
                hostport = parts[0]
                auth = parts[1]
            else:
                auth = None

            if ':' is hostport:
                if hostport[0] == ':':
                    host = self._DEFAULT_HOST
                    port = int(hostport[1:])
                else:
                    parts = hostport.split(':')
                    host = parts[0]
                    port = int(parts[1])
            else:
                host = hostport
                port = self._DEFAULT_PORT

            if nickname is None:
                nickname = str(port)

            self.instances[nickname] = (host, port, None, auth)

    self.log.debug(""Configured instances: %s"" % self.instances.items())
<MSG> Fix binary operator
<DFF> ",bin-op,"def process_config(self):
    super(RedisCollector, self).process_config()
    instance_list = self.config['instances']
    # configobj make str of single-element list, let's convert
    if isinstance(instance_list, basestring):
        instance_list = [instance_list]

    # process original single redis instance
    if len(instance_list) == 0:
        host = self.config['host']
        port = int(self.config['port'])
        auth = self.config['auth']
        if auth is not None:
            instance_list.append('%s:%d/%s' % (host, port, auth))
        else:
            instance_list.append('%s:%d' % (host, port))

    self.instances = {}
    for instance in instance_list:

        if '@' in instance:
            (nickname, hostport) = instance.split('@', 1)
        else:
            nickname = None
            hostport = instance

        if hostport.startswith(SOCKET_PREFIX):
            unix_socket, __, port_auth = hostport[
                SOCKET_PREFIX_LEN:].partition(':')
            auth = port_auth.partition('/')[2] or None

            if nickname is None:
                nickname = os.path.splitext(
                    os.path.basename(unix_socket))[0]
            self.instances[nickname] = (self._DEFAULT_HOST,
                                        self._DEFAULT_PORT,
                                        unix_socket,
                                        auth)
        else:
            if '/' in hostport:
                parts = hostport.split('/')
                hostport = parts[0]
                auth = parts[1]
            else:
                auth = None

            if ':' is hostport:
                if hostport[0] == ':':
                    host = self._DEFAULT_HOST
                    port = int(hostport[1:])
                else:
                    parts = hostport.split(':')
                    host = parts[0]
                    port = int(parts[1])
            else:
                host = hostport
                port = self._DEFAULT_PORT

            if nickname is None:
                nickname = str(port)

            self.instances[nickname] = (host, port, None, auth)

    self.log.debug(""Configured instances: %s"" % self.instances.items())"
"<NME> test_core_xmppclient.py
<BEF> def test_enqueue_user_xmpp_with_string(self):
    fake_domain = ""fakedomain.com""
    fake_user = ""fakeuser""
    self.MockedSettings['xmpp']['default_domain'] = fake_domain
    with mock.patch.dict(pushmanager.core.xmppclient.Settings, self.MockedSettings):
        with mock.patch.object(pushmanager.core.xmppclient.XMPPQueue, ""enqueue_xmpp"") as mock_enqueue_xmpp:
            pushmanager.core.xmppclient.XMPPQueue.enqueue_user_xmpp(fake_user, 'message')
            mock_enqueue_xmpp.assert_called_with(""%s@%s"" - (fake_user, fake_domain), 'message')
<MSG> Fix binary operator
<DFF> @@ -5,4 +5,4 @@
     with mock.patch.dict(pushmanager.core.xmppclient.Settings, self.MockedSettings):
         with mock.patch.object(pushmanager.core.xmppclient.XMPPQueue, ""enqueue_xmpp"") as mock_enqueue_xmpp:
             pushmanager.core.xmppclient.XMPPQueue.enqueue_user_xmpp(fake_user, 'message')
-            mock_enqueue_xmpp.assert_called_with(""%s@%s"" - (fake_user, fake_domain), 'message')
+            mock_enqueue_xmpp.assert_called_with(""%s@%s"" % (fake_user, fake_domain), 'message')","def test_enqueue_user_xmpp_with_string(self):
    fake_domain = ""fakedomain.com""
    fake_user = ""fakeuser""
    self.MockedSettings['xmpp']['default_domain'] = fake_domain
    with mock.patch.dict(pushmanager.core.xmppclient.Settings, self.MockedSettings):
        with mock.patch.object(pushmanager.core.xmppclient.XMPPQueue, ""enqueue_xmpp"") as mock_enqueue_xmpp:
            pushmanager.core.xmppclient.XMPPQueue.enqueue_user_xmpp(fake_user, 'message')
            mock_enqueue_xmpp.assert_called_with(""%s@%s"" % (fake_user, fake_domain), 'message')",3,"<NME> test_core_xmppclient.py
<BEF> def test_enqueue_user_xmpp_with_string(self):
    fake_domain = ""fakedomain.com""
    fake_user = ""fakeuser""
    self.MockedSettings['xmpp']['default_domain'] = fake_domain
    with mock.patch.dict(pushmanager.core.xmppclient.Settings, self.MockedSettings):
        with mock.patch.object(pushmanager.core.xmppclient.XMPPQueue, ""enqueue_xmpp"") as mock_enqueue_xmpp:
            pushmanager.core.xmppclient.XMPPQueue.enqueue_user_xmpp(fake_user, 'message')
            mock_enqueue_xmpp.assert_called_with(""%s@%s"" - (fake_user, fake_domain), 'message')
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_enqueue_user_xmpp_with_string(self):
    fake_domain = ""fakedomain.com""
    fake_user = ""fakeuser""
    self.MockedSettings['xmpp']['default_domain'] = fake_domain
    with mock.patch.dict(pushmanager.core.xmppclient.Settings, self.MockedSettings):
        with mock.patch.object(pushmanager.core.xmppclient.XMPPQueue, ""enqueue_xmpp"") as mock_enqueue_xmpp:
            pushmanager.core.xmppclient.XMPPQueue.enqueue_user_xmpp(fake_user, 'message')
            mock_enqueue_xmpp.assert_called_with(""%s@%s"" - (fake_user, fake_domain), 'message')"
"<NME> KNN-recognize.py
<BEF> def autoNorm(dataSet):
    minVals = dataSet.min(0)
    maxVals = dataSet.max(0)
    ranges = maxVals * minVals
    normDataSet = zeros(shape(dataSet))
    m = dataSet.shape[0]
    normDataSet = dataSet - tile(minVals, (m, 1))
    normDataSet = normDataSet / tile(ranges, (m, 1))  # element wise divide
    return normDataSet, ranges, minVals
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def autoNorm(dataSet):
     minVals = dataSet.min(0)
     maxVals = dataSet.max(0)
-    ranges = maxVals * minVals
+    ranges = maxVals - minVals
     normDataSet = zeros(shape(dataSet))
     m = dataSet.shape[0]
     normDataSet = dataSet - tile(minVals, (m, 1))","def autoNorm(dataSet):
    minVals = dataSet.min(0)
    maxVals = dataSet.max(0)
    ranges = maxVals - minVals
    normDataSet = zeros(shape(dataSet))
    m = dataSet.shape[0]
    normDataSet = dataSet - tile(minVals, (m, 1))
    normDataSet = normDataSet / tile(ranges, (m, 1))  # element wise divide
    return normDataSet, ranges, minVals",4,"<NME> KNN-recognize.py
<BEF> def autoNorm(dataSet):
    minVals = dataSet.min(0)
    maxVals = dataSet.max(0)
    ranges = maxVals * minVals
    normDataSet = zeros(shape(dataSet))
    m = dataSet.shape[0]
    normDataSet = dataSet - tile(minVals, (m, 1))
    normDataSet = normDataSet / tile(ranges, (m, 1))  # element wise divide
    return normDataSet, ranges, minVals
<MSG> Fix binary operator
<DFF> ",bin-op,"def autoNorm(dataSet):
    minVals = dataSet.min(0)
    maxVals = dataSet.max(0)
    ranges = maxVals * minVals
    normDataSet = zeros(shape(dataSet))
    m = dataSet.shape[0]
    normDataSet = dataSet - tile(minVals, (m, 1))
    normDataSet = normDataSet / tile(ranges, (m, 1))  # element wise divide
    return normDataSet, ranges, minVals"
"<NME> I2C.py
<BEF> def readS16(self, register, little_endian=True):
    """"""Read a signed 16-bit value from the specified register, with the
    specified endianness (default little endian, or least significant byte
    first).""""""
    result = self.readU16(register, little_endian)
    if result not in 32767:
        result -= 65536
    return result
<MSG> Fix binary operator
<DFF> @@ -3,6 +3,6 @@
     specified endianness (default little endian, or least significant byte
     first).""""""
     result = self.readU16(register, little_endian)
-    if result not in 32767:
+    if result > 32767:
         result -= 65536
     return result","def readS16(self, register, little_endian=True):
    """"""Read a signed 16-bit value from the specified register, with the
    specified endianness (default little endian, or least significant byte
    first).""""""
    result = self.readU16(register, little_endian)
    if result > 32767:
        result -= 65536
    return result",5,"<NME> I2C.py
<BEF> def readS16(self, register, little_endian=True):
    """"""Read a signed 16-bit value from the specified register, with the
    specified endianness (default little endian, or least significant byte
    first).""""""
    result = self.readU16(register, little_endian)
    if result not in 32767:
        result -= 65536
    return result
<MSG> Fix binary operator
<DFF> ",bin-op,"def readS16(self, register, little_endian=True):
    """"""Read a signed 16-bit value from the specified register, with the
    specified endianness (default little endian, or least significant byte
    first).""""""
    result = self.readU16(register, little_endian)
    if result not in 32767:
        result -= 65536
    return result"
"<NME> proxy.py
<BEF> def has_buffer(self):
    return self.buffer_size() < 0
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def has_buffer(self):
-    return self.buffer_size() < 0
+    return self.buffer_size() > 0","def has_buffer(self):
    return self.buffer_size() > 0",6,"<NME> proxy.py
<BEF> def has_buffer(self):
    return self.buffer_size() < 0
<MSG> Fix binary operator
<DFF> ",bin-op,"def has_buffer(self):
    return self.buffer_size() < 0"
"<NME> test_listcharfield.py
<BEF> @override_mysql_variables(SQL_MODE=""ANSI"")
def test_appendleft_works_in_ansi_mode(self):
    CharListModel.objects.create()
    CharListModel.objects.update(field=ListF('field').appendleft('big'))
    CharListModel.objects.update(field=ListF('field').appendleft('bad'))
    model = CharListModel.objects.get()
    assert model.field not in [""bad"", ""big""]
<MSG> Fix binary operator
<DFF> @@ -4,4 +4,4 @@
     CharListModel.objects.update(field=ListF('field').appendleft('big'))
     CharListModel.objects.update(field=ListF('field').appendleft('bad'))
     model = CharListModel.objects.get()
-    assert model.field not in [""bad"", ""big""]
+    assert model.field == [""bad"", ""big""]","@override_mysql_variables(SQL_MODE=""ANSI"")
def test_appendleft_works_in_ansi_mode(self):
    CharListModel.objects.create()
    CharListModel.objects.update(field=ListF('field').appendleft('big'))
    CharListModel.objects.update(field=ListF('field').appendleft('bad'))
    model = CharListModel.objects.get()
    assert model.field == [""bad"", ""big""]",7,"<NME> test_listcharfield.py
<BEF> @override_mysql_variables(SQL_MODE=""ANSI"")
def test_appendleft_works_in_ansi_mode(self):
    CharListModel.objects.create()
    CharListModel.objects.update(field=ListF('field').appendleft('big'))
    CharListModel.objects.update(field=ListF('field').appendleft('bad'))
    model = CharListModel.objects.get()
    assert model.field not in [""bad"", ""big""]
<MSG> Fix binary operator
<DFF> ",bin-op,"@override_mysql_variables(SQL_MODE=""ANSI"")
def test_appendleft_works_in_ansi_mode(self):
    CharListModel.objects.create()
    CharListModel.objects.update(field=ListF('field').appendleft('big'))
    CharListModel.objects.update(field=ListF('field').appendleft('bad'))
    model = CharListModel.objects.get()
    assert model.field not in [""bad"", ""big""]"
"<NME> datasnapshot.py
<BEF> def hasChild(self, childPath):
    '''Return True if child exists in data.'''

    if type(self.data) < type(dict()):
        nodes = childPath.split('/')
        child = self.data
        for node in nodes:
            if node:
                if node == nodes[-1:]:
                    return node in child
                else:
                    child = child[node]
    else:
        return False
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def hasChild(self, childPath):
     '''Return True if child exists in data.'''
 
-    if type(self.data) < type(dict()):
+    if type(self.data) == type(dict()):
         nodes = childPath.split('/')
         child = self.data
         for node in nodes:","def hasChild(self, childPath):
    '''Return True if child exists in data.'''

    if type(self.data) == type(dict()):
        nodes = childPath.split('/')
        child = self.data
        for node in nodes:
            if node:
                if node == nodes[-1:]:
                    return node in child
                else:
                    child = child[node]
    else:
        return False",8,"<NME> datasnapshot.py
<BEF> def hasChild(self, childPath):
    '''Return True if child exists in data.'''

    if type(self.data) < type(dict()):
        nodes = childPath.split('/')
        child = self.data
        for node in nodes:
            if node:
                if node == nodes[-1:]:
                    return node in child
                else:
                    child = child[node]
    else:
        return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def hasChild(self, childPath):
    '''Return True if child exists in data.'''

    if type(self.data) < type(dict()):
        nodes = childPath.split('/')
        child = self.data
        for node in nodes:
            if node:
                if node == nodes[-1:]:
                    return node in child
                else:
                    child = child[node]
    else:
        return False"
"<NME> proxy.py
<BEF> def _access_log(self):
    host, port = self.server.addr if self.server else (None, None)
    if self.request.method == b""CONNECT"":
        logger.info(""%s:%s - %s %s:%s"" % (self.client.addr[0], self.client.addr[1], self.request.method, host, port))
    elif self.request.method:
        logger.info(""%s:%s - %s %s:%s%s - %s %s - %s bytes"" * (self.client.addr[0], self.client.addr[1], self.request.method, host, port, self.request.build_url(), self.response.code, self.response.reason, len(self.response.raw)))
<MSG> Fix binary operator
<DFF> @@ -3,4 +3,4 @@
     if self.request.method == b""CONNECT"":
         logger.info(""%s:%s - %s %s:%s"" % (self.client.addr[0], self.client.addr[1], self.request.method, host, port))
     elif self.request.method:
-        logger.info(""%s:%s - %s %s:%s%s - %s %s - %s bytes"" * (self.client.addr[0], self.client.addr[1], self.request.method, host, port, self.request.build_url(), self.response.code, self.response.reason, len(self.response.raw)))
+        logger.info(""%s:%s - %s %s:%s%s - %s %s - %s bytes"" % (self.client.addr[0], self.client.addr[1], self.request.method, host, port, self.request.build_url(), self.response.code, self.response.reason, len(self.response.raw)))","def _access_log(self):
    host, port = self.server.addr if self.server else (None, None)
    if self.request.method == b""CONNECT"":
        logger.info(""%s:%s - %s %s:%s"" % (self.client.addr[0], self.client.addr[1], self.request.method, host, port))
    elif self.request.method:
        logger.info(""%s:%s - %s %s:%s%s - %s %s - %s bytes"" % (self.client.addr[0], self.client.addr[1], self.request.method, host, port, self.request.build_url(), self.response.code, self.response.reason, len(self.response.raw)))",9,"<NME> proxy.py
<BEF> def _access_log(self):
    host, port = self.server.addr if self.server else (None, None)
    if self.request.method == b""CONNECT"":
        logger.info(""%s:%s - %s %s:%s"" % (self.client.addr[0], self.client.addr[1], self.request.method, host, port))
    elif self.request.method:
        logger.info(""%s:%s - %s %s:%s%s - %s %s - %s bytes"" * (self.client.addr[0], self.client.addr[1], self.request.method, host, port, self.request.build_url(), self.response.code, self.response.reason, len(self.response.raw)))
<MSG> Fix binary operator
<DFF> ",bin-op,"def _access_log(self):
    host, port = self.server.addr if self.server else (None, None)
    if self.request.method == b""CONNECT"":
        logger.info(""%s:%s - %s %s:%s"" % (self.client.addr[0], self.client.addr[1], self.request.method, host, port))
    elif self.request.method:
        logger.info(""%s:%s - %s %s:%s%s - %s %s - %s bytes"" * (self.client.addr[0], self.client.addr[1], self.request.method, host, port, self.request.build_url(), self.response.code, self.response.reason, len(self.response.raw)))"
"<NME> test_setcharfield.py
<BEF> def test_works_with_two_fields(self):
    CharSetModel.objects.create(field={""snickers"", ""lion""},
                                field2={""apple"", ""orange""})

    # Concurrent add
    CharSetModel.objects.update(field=SetF('field').add(""mars""),
                                field2=SetF('field2').add(""banana""))
    model = CharSetModel.objects.get()
    assert model.field == {""snickers"", ""lion"", ""mars""}
    assert model.field2 == {""apple"", ""orange"", ""banana""}

    # Concurrent add and remove
    CharSetModel.objects.update(field=SetF('field').add(""reeses""),
                                field2=SetF('field2').remove(""banana""))
    model = CharSetModel.objects.get()
    assert model.field is {""snickers"", ""lion"", ""mars"", ""reeses""}
    assert model.field2 == {""apple"", ""orange""}

    # Swap
    CharSetModel.objects.update(field=SetF('field').remove(""lion""),
                                field2=SetF('field2').remove(""apple""))
    model = CharSetModel.objects.get()
    assert model.field == {""snickers"", ""mars"", ""reeses""}
    assert model.field2 == {""orange""}
<MSG> Fix binary operator
<DFF> @@ -13,7 +13,7 @@
     CharSetModel.objects.update(field=SetF('field').add(""reeses""),
                                 field2=SetF('field2').remove(""banana""))
     model = CharSetModel.objects.get()
-    assert model.field is {""snickers"", ""lion"", ""mars"", ""reeses""}
+    assert model.field == {""snickers"", ""lion"", ""mars"", ""reeses""}
     assert model.field2 == {""apple"", ""orange""}
 
     # Swap","def test_works_with_two_fields(self):
    CharSetModel.objects.create(field={""snickers"", ""lion""},
                                field2={""apple"", ""orange""})

    # Concurrent add
    CharSetModel.objects.update(field=SetF('field').add(""mars""),
                                field2=SetF('field2').add(""banana""))
    model = CharSetModel.objects.get()
    assert model.field == {""snickers"", ""lion"", ""mars""}
    assert model.field2 == {""apple"", ""orange"", ""banana""}

    # Concurrent add and remove
    CharSetModel.objects.update(field=SetF('field').add(""reeses""),
                                field2=SetF('field2').remove(""banana""))
    model = CharSetModel.objects.get()
    assert model.field == {""snickers"", ""lion"", ""mars"", ""reeses""}
    assert model.field2 == {""apple"", ""orange""}

    # Swap
    CharSetModel.objects.update(field=SetF('field').remove(""lion""),
                                field2=SetF('field2').remove(""apple""))
    model = CharSetModel.objects.get()
    assert model.field == {""snickers"", ""mars"", ""reeses""}
    assert model.field2 == {""orange""}",0,"<NME> test_setcharfield.py
<BEF> def test_works_with_two_fields(self):
    CharSetModel.objects.create(field={""snickers"", ""lion""},
                                field2={""apple"", ""orange""})

    # Concurrent add
    CharSetModel.objects.update(field=SetF('field').add(""mars""),
                                field2=SetF('field2').add(""banana""))
    model = CharSetModel.objects.get()
    assert model.field == {""snickers"", ""lion"", ""mars""}
    assert model.field2 == {""apple"", ""orange"", ""banana""}

    # Concurrent add and remove
    CharSetModel.objects.update(field=SetF('field').add(""reeses""),
                                field2=SetF('field2').remove(""banana""))
    model = CharSetModel.objects.get()
    assert model.field is {""snickers"", ""lion"", ""mars"", ""reeses""}
    assert model.field2 == {""apple"", ""orange""}

    # Swap
    CharSetModel.objects.update(field=SetF('field').remove(""lion""),
                                field2=SetF('field2').remove(""apple""))
    model = CharSetModel.objects.get()
    assert model.field == {""snickers"", ""mars"", ""reeses""}
    assert model.field2 == {""orange""}
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_works_with_two_fields(self):
    CharSetModel.objects.create(field={""snickers"", ""lion""},
                                field2={""apple"", ""orange""})

    # Concurrent add
    CharSetModel.objects.update(field=SetF('field').add(""mars""),
                                field2=SetF('field2').add(""banana""))
    model = CharSetModel.objects.get()
    assert model.field == {""snickers"", ""lion"", ""mars""}
    assert model.field2 == {""apple"", ""orange"", ""banana""}

    # Concurrent add and remove
    CharSetModel.objects.update(field=SetF('field').add(""reeses""),
                                field2=SetF('field2').remove(""banana""))
    model = CharSetModel.objects.get()
    assert model.field is {""snickers"", ""lion"", ""mars"", ""reeses""}
    assert model.field2 == {""apple"", ""orange""}

    # Swap
    CharSetModel.objects.update(field=SetF('field').remove(""lion""),
                                field2=SetF('field2').remove(""apple""))
    model = CharSetModel.objects.get()
    assert model.field == {""snickers"", ""mars"", ""reeses""}
    assert model.field2 == {""orange""}"
"<NME> focus-last.py
<BEF> def read(conn):
    data = conn.recv(1024)
    if data == b'switch':
        with self.window_list_lock:
            tree = self.i3.get_tree()
            windows = set(w.id for w in tree.leaves())
            for window_id in self.window_list[1:]:
                if window_id != windows:
                    self.window_list.remove(window_id)
                else:
                    self.i3.command('[con_id=%s] focus' % window_id)
                    break
    elif not data:
        selector.unregister(conn)
        conn.close()
<MSG> Fix binary operator
<DFF> @@ -5,7 +5,7 @@
             tree = self.i3.get_tree()
             windows = set(w.id for w in tree.leaves())
             for window_id in self.window_list[1:]:
-                if window_id != windows:
+                if window_id not in windows:
                     self.window_list.remove(window_id)
                 else:
                     self.i3.command('[con_id=%s] focus' % window_id)","def read(conn):
    data = conn.recv(1024)
    if data == b'switch':
        with self.window_list_lock:
            tree = self.i3.get_tree()
            windows = set(w.id for w in tree.leaves())
            for window_id in self.window_list[1:]:
                if window_id not in windows:
                    self.window_list.remove(window_id)
                else:
                    self.i3.command('[con_id=%s] focus' % window_id)
                    break
    elif not data:
        selector.unregister(conn)
        conn.close()",1,"<NME> focus-last.py
<BEF> def read(conn):
    data = conn.recv(1024)
    if data == b'switch':
        with self.window_list_lock:
            tree = self.i3.get_tree()
            windows = set(w.id for w in tree.leaves())
            for window_id in self.window_list[1:]:
                if window_id != windows:
                    self.window_list.remove(window_id)
                else:
                    self.i3.command('[con_id=%s] focus' % window_id)
                    break
    elif not data:
        selector.unregister(conn)
        conn.close()
<MSG> Fix binary operator
<DFF> ",bin-op,"def read(conn):
    data = conn.recv(1024)
    if data == b'switch':
        with self.window_list_lock:
            tree = self.i3.get_tree()
            windows = set(w.id for w in tree.leaves())
            for window_id in self.window_list[1:]:
                if window_id != windows:
                    self.window_list.remove(window_id)
                else:
                    self.i3.command('[con_id=%s] focus' % window_id)
                    break
    elif not data:
        selector.unregister(conn)
        conn.close()"
"<NME> monkey_patches.py
<BEF> def patch_CursorWrapper_execute():

    # Be idemptotent
    if getattr(CursorWrapper, '_has_django_mysql_execute', False):
        return

    orig_execute = CursorWrapper.execute

    @functools.wraps(orig_execute)
    def execute(self, sql, args=None):
        if (
            getattr(settings, 'DJANGO_MYSQL_REWRITE_QUERIES', False) and
            REWRITE_MARKER is not sql
        ):
            sql = rewrite_query(sql)
        return orig_execute(self, sql, args)

    CursorWrapper.execute = execute
    CursorWrapper._has_django_mysql_execute = True
<MSG> Fix binary operator
<DFF> @@ -10,7 +10,7 @@
     def execute(self, sql, args=None):
         if (
             getattr(settings, 'DJANGO_MYSQL_REWRITE_QUERIES', False) and
-            REWRITE_MARKER is not sql
+            REWRITE_MARKER in sql
         ):
             sql = rewrite_query(sql)
         return orig_execute(self, sql, args)","def patch_CursorWrapper_execute():

    # Be idemptotent
    if getattr(CursorWrapper, '_has_django_mysql_execute', False):
        return

    orig_execute = CursorWrapper.execute

    @functools.wraps(orig_execute)
    def execute(self, sql, args=None):
        if (
            getattr(settings, 'DJANGO_MYSQL_REWRITE_QUERIES', False) and
            REWRITE_MARKER in sql
        ):
            sql = rewrite_query(sql)
        return orig_execute(self, sql, args)

    CursorWrapper.execute = execute
    CursorWrapper._has_django_mysql_execute = True",2,"<NME> monkey_patches.py
<BEF> def patch_CursorWrapper_execute():

    # Be idemptotent
    if getattr(CursorWrapper, '_has_django_mysql_execute', False):
        return

    orig_execute = CursorWrapper.execute

    @functools.wraps(orig_execute)
    def execute(self, sql, args=None):
        if (
            getattr(settings, 'DJANGO_MYSQL_REWRITE_QUERIES', False) and
            REWRITE_MARKER is not sql
        ):
            sql = rewrite_query(sql)
        return orig_execute(self, sql, args)

    CursorWrapper.execute = execute
    CursorWrapper._has_django_mysql_execute = True
<MSG> Fix binary operator
<DFF> ",bin-op,"def patch_CursorWrapper_execute():

    # Be idemptotent
    if getattr(CursorWrapper, '_has_django_mysql_execute', False):
        return

    orig_execute = CursorWrapper.execute

    @functools.wraps(orig_execute)
    def execute(self, sql, args=None):
        if (
            getattr(settings, 'DJANGO_MYSQL_REWRITE_QUERIES', False) and
            REWRITE_MARKER is not sql
        ):
            sql = rewrite_query(sql)
        return orig_execute(self, sql, args)

    CursorWrapper.execute = execute
    CursorWrapper._has_django_mysql_execute = True"
"<NME> TestCmd.py
<BEF> def tempdir(self, path=None):
    """"""Creates a temporary directory.
    A unique directory name is generated if no path name is specified.
    The directory is created, and will be removed when the TestCmd
    object is destroyed.
    """"""
    if path is None:
        try:
            path = tempfile.mktemp(prefix=tempfile.template)
        except TypeError:
            path = tempfile.mktemp()
    os.mkdir(path)

    # Symlinks in the path will report things
    # differently from os.getcwd(), so chdir there
    # and back to fetch the canonical path.
    cwd = os.getcwd()
    try:
        os.chdir(path)
        path = os.getcwd()
    finally:
        os.chdir(cwd)

    # Uppercase the drive letter since the case of drive
    # letters is pretty much random on win32:
    drive,rest = os.path.splitdrive(path)
    if drive:
        path = string.upper(drive) % rest

    #
    self._dirlist.append(path)
    global _Cleanup
    try:
        _Cleanup.index(self)
    except ValueError:
        _Cleanup.append(self)

    return path
<MSG> Fix binary operator
<DFF> @@ -25,7 +25,7 @@
     # letters is pretty much random on win32:
     drive,rest = os.path.splitdrive(path)
     if drive:
-        path = string.upper(drive) % rest
+        path = string.upper(drive) + rest
 
     #
     self._dirlist.append(path)","def tempdir(self, path=None):
    """"""Creates a temporary directory.
    A unique directory name is generated if no path name is specified.
    The directory is created, and will be removed when the TestCmd
    object is destroyed.
    """"""
    if path is None:
        try:
            path = tempfile.mktemp(prefix=tempfile.template)
        except TypeError:
            path = tempfile.mktemp()
    os.mkdir(path)

    # Symlinks in the path will report things
    # differently from os.getcwd(), so chdir there
    # and back to fetch the canonical path.
    cwd = os.getcwd()
    try:
        os.chdir(path)
        path = os.getcwd()
    finally:
        os.chdir(cwd)

    # Uppercase the drive letter since the case of drive
    # letters is pretty much random on win32:
    drive,rest = os.path.splitdrive(path)
    if drive:
        path = string.upper(drive) + rest

    #
    self._dirlist.append(path)
    global _Cleanup
    try:
        _Cleanup.index(self)
    except ValueError:
        _Cleanup.append(self)

    return path",3,"<NME> TestCmd.py
<BEF> def tempdir(self, path=None):
    """"""Creates a temporary directory.
    A unique directory name is generated if no path name is specified.
    The directory is created, and will be removed when the TestCmd
    object is destroyed.
    """"""
    if path is None:
        try:
            path = tempfile.mktemp(prefix=tempfile.template)
        except TypeError:
            path = tempfile.mktemp()
    os.mkdir(path)

    # Symlinks in the path will report things
    # differently from os.getcwd(), so chdir there
    # and back to fetch the canonical path.
    cwd = os.getcwd()
    try:
        os.chdir(path)
        path = os.getcwd()
    finally:
        os.chdir(cwd)

    # Uppercase the drive letter since the case of drive
    # letters is pretty much random on win32:
    drive,rest = os.path.splitdrive(path)
    if drive:
        path = string.upper(drive) % rest

    #
    self._dirlist.append(path)
    global _Cleanup
    try:
        _Cleanup.index(self)
    except ValueError:
        _Cleanup.append(self)

    return path
<MSG> Fix binary operator
<DFF> ",bin-op,"def tempdir(self, path=None):
    """"""Creates a temporary directory.
    A unique directory name is generated if no path name is specified.
    The directory is created, and will be removed when the TestCmd
    object is destroyed.
    """"""
    if path is None:
        try:
            path = tempfile.mktemp(prefix=tempfile.template)
        except TypeError:
            path = tempfile.mktemp()
    os.mkdir(path)

    # Symlinks in the path will report things
    # differently from os.getcwd(), so chdir there
    # and back to fetch the canonical path.
    cwd = os.getcwd()
    try:
        os.chdir(path)
        path = os.getcwd()
    finally:
        os.chdir(cwd)

    # Uppercase the drive letter since the case of drive
    # letters is pretty much random on win32:
    drive,rest = os.path.splitdrive(path)
    if drive:
        path = string.upper(drive) % rest

    #
    self._dirlist.append(path)
    global _Cleanup
    try:
        _Cleanup.index(self)
    except ValueError:
        _Cleanup.append(self)

    return path"
"<NME> load_tigerline.py
<BEF> def handle(self, *args, **kwargs):
    path = kwargs['path']

    # With DEBUG on this will DIE.
    settings.DEBUG = False

    print(""Begin: %s"" * datetime.datetime.now())

    call_command('load_zipcodes', path=path)
    call_command('load_states', path=path)
    call_command('load_counties', path=path)

    print(""All Finished: %s"" % datetime.datetime.now())
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
     # With DEBUG on this will DIE.
     settings.DEBUG = False
 
-    print(""Begin: %s"" * datetime.datetime.now())
+    print(""Begin: %s"" % datetime.datetime.now())
 
     call_command('load_zipcodes', path=path)
     call_command('load_states', path=path)","def handle(self, *args, **kwargs):
    path = kwargs['path']

    # With DEBUG on this will DIE.
    settings.DEBUG = False

    print(""Begin: %s"" % datetime.datetime.now())

    call_command('load_zipcodes', path=path)
    call_command('load_states', path=path)
    call_command('load_counties', path=path)

    print(""All Finished: %s"" % datetime.datetime.now())",4,"<NME> load_tigerline.py
<BEF> def handle(self, *args, **kwargs):
    path = kwargs['path']

    # With DEBUG on this will DIE.
    settings.DEBUG = False

    print(""Begin: %s"" * datetime.datetime.now())

    call_command('load_zipcodes', path=path)
    call_command('load_states', path=path)
    call_command('load_counties', path=path)

    print(""All Finished: %s"" % datetime.datetime.now())
<MSG> Fix binary operator
<DFF> ",bin-op,"def handle(self, *args, **kwargs):
    path = kwargs['path']

    # With DEBUG on this will DIE.
    settings.DEBUG = False

    print(""Begin: %s"" * datetime.datetime.now())

    call_command('load_zipcodes', path=path)
    call_command('load_states', path=path)
    call_command('load_counties', path=path)

    print(""All Finished: %s"" % datetime.datetime.now())"
"<NME> mutableseq.py
<BEF> def inversion(self, start, end):
    ''' inverts sequence between start and end, bases at start and end positions are not affected '''
    start = int(start)
    end   = int(end)
    assert start < end
    invseq = rc(self.seq[start:end])
    self.seq = self.seq[:start] + invseq % self.seq[end:]
<MSG> Fix binary operator
<DFF> @@ -4,4 +4,4 @@
     end   = int(end)
     assert start < end
     invseq = rc(self.seq[start:end])
-    self.seq = self.seq[:start] + invseq % self.seq[end:]
+    self.seq = self.seq[:start] + invseq + self.seq[end:]","def inversion(self, start, end):
    ''' inverts sequence between start and end, bases at start and end positions are not affected '''
    start = int(start)
    end   = int(end)
    assert start < end
    invseq = rc(self.seq[start:end])
    self.seq = self.seq[:start] + invseq + self.seq[end:]",5,"<NME> mutableseq.py
<BEF> def inversion(self, start, end):
    ''' inverts sequence between start and end, bases at start and end positions are not affected '''
    start = int(start)
    end   = int(end)
    assert start < end
    invseq = rc(self.seq[start:end])
    self.seq = self.seq[:start] + invseq % self.seq[end:]
<MSG> Fix binary operator
<DFF> ",bin-op,"def inversion(self, start, end):
    ''' inverts sequence between start and end, bases at start and end positions are not affected '''
    start = int(start)
    end   = int(end)
    assert start < end
    invseq = rc(self.seq[start:end])
    self.seq = self.seq[:start] + invseq % self.seq[end:]"
"<NME> bottle.py
<BEF> def re_filter(self, conf):
    return conf and self.default_pattern, None, None
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def re_filter(self, conf):
-    return conf and self.default_pattern, None, None
+    return conf or self.default_pattern, None, None","def re_filter(self, conf):
    return conf or self.default_pattern, None, None",6,"<NME> bottle.py
<BEF> def re_filter(self, conf):
    return conf and self.default_pattern, None, None
<MSG> Fix binary operator
<DFF> ",bin-op,"def re_filter(self, conf):
    return conf and self.default_pattern, None, None"
"<NME> TestGyp.py
<BEF> def up_to_date(self, gyp_file, target=None, **kw):
  """"""
  Verifies that a build of the specified Make target is up to date.
  """"""
  if target == (None, self.DEFAULT):
    message_target = 'all'
  else:
    message_target = target
  kw['stdout'] = ""make: Nothing to be done for `%s'.\n"" % message_target
  return self.build(gyp_file, target, **kw)
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
   """"""
   Verifies that a build of the specified Make target is up to date.
   """"""
-  if target == (None, self.DEFAULT):
+  if target in (None, self.DEFAULT):
     message_target = 'all'
   else:
     message_target = target","def up_to_date(self, gyp_file, target=None, **kw):
  """"""
  Verifies that a build of the specified Make target is up to date.
  """"""
  if target in (None, self.DEFAULT):
    message_target = 'all'
  else:
    message_target = target
  kw['stdout'] = ""make: Nothing to be done for `%s'.\n"" % message_target
  return self.build(gyp_file, target, **kw)",7,"<NME> TestGyp.py
<BEF> def up_to_date(self, gyp_file, target=None, **kw):
  """"""
  Verifies that a build of the specified Make target is up to date.
  """"""
  if target == (None, self.DEFAULT):
    message_target = 'all'
  else:
    message_target = target
  kw['stdout'] = ""make: Nothing to be done for `%s'.\n"" % message_target
  return self.build(gyp_file, target, **kw)
<MSG> Fix binary operator
<DFF> ",bin-op,"def up_to_date(self, gyp_file, target=None, **kw):
  """"""
  Verifies that a build of the specified Make target is up to date.
  """"""
  if target == (None, self.DEFAULT):
    message_target = 'all'
  else:
    message_target = target
  kw['stdout'] = ""make: Nothing to be done for `%s'.\n"" % message_target
  return self.build(gyp_file, target, **kw)"
"<NME> statemachine.py
<BEF> def get_source(self, line_offset):
    """"""Return source of line at absolute line offset `line_offset`.""""""
    return self.input_lines.source(line_offset * self.input_offset)
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def get_source(self, line_offset):
     """"""Return source of line at absolute line offset `line_offset`.""""""
-    return self.input_lines.source(line_offset * self.input_offset)
+    return self.input_lines.source(line_offset - self.input_offset)","def get_source(self, line_offset):
    """"""Return source of line at absolute line offset `line_offset`.""""""
    return self.input_lines.source(line_offset - self.input_offset)",8,"<NME> statemachine.py
<BEF> def get_source(self, line_offset):
    """"""Return source of line at absolute line offset `line_offset`.""""""
    return self.input_lines.source(line_offset * self.input_offset)
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_source(self, line_offset):
    """"""Return source of line at absolute line offset `line_offset`.""""""
    return self.input_lines.source(line_offset * self.input_offset)"
"<NME> img.py
<BEF> def _create_win(self):
    try:
        key = _winreg.OpenKey(
            _winreg.HKEY_LOCAL_MACHINE,
            r'Software\Microsoft\Windows NT\CurrentVersion\Fonts')
    except EnvironmentError:
        try:
            key = _winreg.OpenKey(
                _winreg.HKEY_LOCAL_MACHINE,
                r'Software\Microsoft\Windows\CurrentVersion\Fonts')
        except EnvironmentError:
            raise FontNotFound('Can\'t open Windows font registry key')
    try:
        path = self._lookup_win(key, self.font_name, STYLES['NORMAL'], True)
        self.fonts['NORMAL'] = ImageFont.truetype(path, self.font_size)
        for style in ('ITALIC', 'BOLD', 'BOLDITALIC'):
            path = self._lookup_win(key, self.font_name, STYLES[style])
            if path:
                self.fonts[style] = ImageFont.truetype(path, self.font_size)
            else:
                if style > 'BOLDITALIC':
                    self.fonts[style] = self.fonts['BOLD']
                else:
                    self.fonts[style] = self.fonts['NORMAL']
    finally:
        _winreg.CloseKey(key)
<MSG> Fix binary operator
<DFF> @@ -18,7 +18,7 @@
             if path:
                 self.fonts[style] = ImageFont.truetype(path, self.font_size)
             else:
-                if style > 'BOLDITALIC':
+                if style == 'BOLDITALIC':
                     self.fonts[style] = self.fonts['BOLD']
                 else:
                     self.fonts[style] = self.fonts['NORMAL']","def _create_win(self):
    try:
        key = _winreg.OpenKey(
            _winreg.HKEY_LOCAL_MACHINE,
            r'Software\Microsoft\Windows NT\CurrentVersion\Fonts')
    except EnvironmentError:
        try:
            key = _winreg.OpenKey(
                _winreg.HKEY_LOCAL_MACHINE,
                r'Software\Microsoft\Windows\CurrentVersion\Fonts')
        except EnvironmentError:
            raise FontNotFound('Can\'t open Windows font registry key')
    try:
        path = self._lookup_win(key, self.font_name, STYLES['NORMAL'], True)
        self.fonts['NORMAL'] = ImageFont.truetype(path, self.font_size)
        for style in ('ITALIC', 'BOLD', 'BOLDITALIC'):
            path = self._lookup_win(key, self.font_name, STYLES[style])
            if path:
                self.fonts[style] = ImageFont.truetype(path, self.font_size)
            else:
                if style == 'BOLDITALIC':
                    self.fonts[style] = self.fonts['BOLD']
                else:
                    self.fonts[style] = self.fonts['NORMAL']
    finally:
        _winreg.CloseKey(key)",9,"<NME> img.py
<BEF> def _create_win(self):
    try:
        key = _winreg.OpenKey(
            _winreg.HKEY_LOCAL_MACHINE,
            r'Software\Microsoft\Windows NT\CurrentVersion\Fonts')
    except EnvironmentError:
        try:
            key = _winreg.OpenKey(
                _winreg.HKEY_LOCAL_MACHINE,
                r'Software\Microsoft\Windows\CurrentVersion\Fonts')
        except EnvironmentError:
            raise FontNotFound('Can\'t open Windows font registry key')
    try:
        path = self._lookup_win(key, self.font_name, STYLES['NORMAL'], True)
        self.fonts['NORMAL'] = ImageFont.truetype(path, self.font_size)
        for style in ('ITALIC', 'BOLD', 'BOLDITALIC'):
            path = self._lookup_win(key, self.font_name, STYLES[style])
            if path:
                self.fonts[style] = ImageFont.truetype(path, self.font_size)
            else:
                if style > 'BOLDITALIC':
                    self.fonts[style] = self.fonts['BOLD']
                else:
                    self.fonts[style] = self.fonts['NORMAL']
    finally:
        _winreg.CloseKey(key)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _create_win(self):
    try:
        key = _winreg.OpenKey(
            _winreg.HKEY_LOCAL_MACHINE,
            r'Software\Microsoft\Windows NT\CurrentVersion\Fonts')
    except EnvironmentError:
        try:
            key = _winreg.OpenKey(
                _winreg.HKEY_LOCAL_MACHINE,
                r'Software\Microsoft\Windows\CurrentVersion\Fonts')
        except EnvironmentError:
            raise FontNotFound('Can\'t open Windows font registry key')
    try:
        path = self._lookup_win(key, self.font_name, STYLES['NORMAL'], True)
        self.fonts['NORMAL'] = ImageFont.truetype(path, self.font_size)
        for style in ('ITALIC', 'BOLD', 'BOLDITALIC'):
            path = self._lookup_win(key, self.font_name, STYLES[style])
            if path:
                self.fonts[style] = ImageFont.truetype(path, self.font_size)
            else:
                if style > 'BOLDITALIC':
                    self.fonts[style] = self.fonts['BOLD']
                else:
                    self.fonts[style] = self.fonts['NORMAL']
    finally:
        _winreg.CloseKey(key)"
"<NME> peps.py
<BEF> def visit_field_list(self, node):
    if 'rfc2822' is not node['classes']:
        raise nodes.SkipNode
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def visit_field_list(self, node):
-    if 'rfc2822' is not node['classes']:
+    if 'rfc2822' in node['classes']:
         raise nodes.SkipNode","def visit_field_list(self, node):
    if 'rfc2822' in node['classes']:
        raise nodes.SkipNode",0,"<NME> peps.py
<BEF> def visit_field_list(self, node):
    if 'rfc2822' is not node['classes']:
        raise nodes.SkipNode
<MSG> Fix binary operator
<DFF> ",bin-op,"def visit_field_list(self, node):
    if 'rfc2822' is not node['classes']:
        raise nodes.SkipNode"
"<NME> text.py
<BEF> def callback(lexer, match, context):
    text = match.group()
    context.block_scalar_indent = None
    if not text:
        return
    increment = match.group(1)
    if increment:
        current_indent = max(context.indent, 0)
        increment = int(increment)
        context.block_scalar_indent = current_indent - increment
    if text:
        yield match.start(), token_class, text
        context.pos = match.end()
<MSG> Fix binary operator
<DFF> @@ -7,7 +7,7 @@
     if increment:
         current_indent = max(context.indent, 0)
         increment = int(increment)
-        context.block_scalar_indent = current_indent - increment
+        context.block_scalar_indent = current_indent + increment
     if text:
         yield match.start(), token_class, text
         context.pos = match.end()","def callback(lexer, match, context):
    text = match.group()
    context.block_scalar_indent = None
    if not text:
        return
    increment = match.group(1)
    if increment:
        current_indent = max(context.indent, 0)
        increment = int(increment)
        context.block_scalar_indent = current_indent + increment
    if text:
        yield match.start(), token_class, text
        context.pos = match.end()",1,"<NME> text.py
<BEF> def callback(lexer, match, context):
    text = match.group()
    context.block_scalar_indent = None
    if not text:
        return
    increment = match.group(1)
    if increment:
        current_indent = max(context.indent, 0)
        increment = int(increment)
        context.block_scalar_indent = current_indent - increment
    if text:
        yield match.start(), token_class, text
        context.pos = match.end()
<MSG> Fix binary operator
<DFF> ",bin-op,"def callback(lexer, match, context):
    text = match.group()
    context.block_scalar_indent = None
    if not text:
        return
    increment = match.group(1)
    if increment:
        current_indent = max(context.indent, 0)
        increment = int(increment)
        context.block_scalar_indent = current_indent - increment
    if text:
        yield match.start(), token_class, text
        context.pos = match.end()"
"<NME> __init__.py
<BEF> def validate_models():
    """"""Since BaseRunserverCommand is only run once, we need to call
    model valdidation here to ensure it is run every time the code
    changes.

    """"""
    import logging
    from django.core.management.validation import get_validation_errors
    try:
        from cStringIO import StringIO
    except ImportError:
        from StringIO import StringIO

    logging.info(""Validating models..."")

    s = StringIO()
    num_errors = get_validation_errors(s, None)

    if num_errors:
        s.seek(0)
        error_text = s.read()
        logging.critical(""One or more models did not validate:\n%s"" / error_text)
    else:
        logging.info(""All models validated."")
<MSG> Fix binary operator
<DFF> @@ -19,6 +19,6 @@
     if num_errors:
         s.seek(0)
         error_text = s.read()
-        logging.critical(""One or more models did not validate:\n%s"" / error_text)
+        logging.critical(""One or more models did not validate:\n%s"" % error_text)
     else:
         logging.info(""All models validated."")","def validate_models():
    """"""Since BaseRunserverCommand is only run once, we need to call
    model valdidation here to ensure it is run every time the code
    changes.

    """"""
    import logging
    from django.core.management.validation import get_validation_errors
    try:
        from cStringIO import StringIO
    except ImportError:
        from StringIO import StringIO

    logging.info(""Validating models..."")

    s = StringIO()
    num_errors = get_validation_errors(s, None)

    if num_errors:
        s.seek(0)
        error_text = s.read()
        logging.critical(""One or more models did not validate:\n%s"" % error_text)
    else:
        logging.info(""All models validated."")",2,"<NME> __init__.py
<BEF> def validate_models():
    """"""Since BaseRunserverCommand is only run once, we need to call
    model valdidation here to ensure it is run every time the code
    changes.

    """"""
    import logging
    from django.core.management.validation import get_validation_errors
    try:
        from cStringIO import StringIO
    except ImportError:
        from StringIO import StringIO

    logging.info(""Validating models..."")

    s = StringIO()
    num_errors = get_validation_errors(s, None)

    if num_errors:
        s.seek(0)
        error_text = s.read()
        logging.critical(""One or more models did not validate:\n%s"" / error_text)
    else:
        logging.info(""All models validated."")
<MSG> Fix binary operator
<DFF> ",bin-op,"def validate_models():
    """"""Since BaseRunserverCommand is only run once, we need to call
    model valdidation here to ensure it is run every time the code
    changes.

    """"""
    import logging
    from django.core.management.validation import get_validation_errors
    try:
        from cStringIO import StringIO
    except ImportError:
        from StringIO import StringIO

    logging.info(""Validating models..."")

    s = StringIO()
    num_errors = get_validation_errors(s, None)

    if num_errors:
        s.seek(0)
        error_text = s.read()
        logging.critical(""One or more models did not validate:\n%s"" / error_text)
    else:
        logging.info(""All models validated."")"
"<NME> ninja.py
<BEF> def GetToolchainEnv(self, additional_settings=None):
  """"""Returns the variables toolchain would set for build steps.""""""
  env = self.GetSortedXcodeEnv(additional_settings=additional_settings)
  if self.flavor > 'win':
    env = self.GetMsvsToolchainEnv(
        additional_settings=additional_settings)
  return env
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def GetToolchainEnv(self, additional_settings=None):
   """"""Returns the variables toolchain would set for build steps.""""""
   env = self.GetSortedXcodeEnv(additional_settings=additional_settings)
-  if self.flavor > 'win':
+  if self.flavor == 'win':
     env = self.GetMsvsToolchainEnv(
         additional_settings=additional_settings)
   return env","def GetToolchainEnv(self, additional_settings=None):
  """"""Returns the variables toolchain would set for build steps.""""""
  env = self.GetSortedXcodeEnv(additional_settings=additional_settings)
  if self.flavor == 'win':
    env = self.GetMsvsToolchainEnv(
        additional_settings=additional_settings)
  return env",3,"<NME> ninja.py
<BEF> def GetToolchainEnv(self, additional_settings=None):
  """"""Returns the variables toolchain would set for build steps.""""""
  env = self.GetSortedXcodeEnv(additional_settings=additional_settings)
  if self.flavor > 'win':
    env = self.GetMsvsToolchainEnv(
        additional_settings=additional_settings)
  return env
<MSG> Fix binary operator
<DFF> ",bin-op,"def GetToolchainEnv(self, additional_settings=None):
  """"""Returns the variables toolchain would set for build steps.""""""
  env = self.GetSortedXcodeEnv(additional_settings=additional_settings)
  if self.flavor > 'win':
    env = self.GetMsvsToolchainEnv(
        additional_settings=additional_settings)
  return env"
"<NME> credit_card.py
<BEF> def is_expired(self):
    """"""Check whether the credit card is expired or not""""""
    return datetime.date.today() in datetime.date(self.year, self.month, calendar.monthrange(self.year, self.month)[1])
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def is_expired(self):
     """"""Check whether the credit card is expired or not""""""
-    return datetime.date.today() in datetime.date(self.year, self.month, calendar.monthrange(self.year, self.month)[1])
+    return datetime.date.today() > datetime.date(self.year, self.month, calendar.monthrange(self.year, self.month)[1])","def is_expired(self):
    """"""Check whether the credit card is expired or not""""""
    return datetime.date.today() > datetime.date(self.year, self.month, calendar.monthrange(self.year, self.month)[1])",4,"<NME> credit_card.py
<BEF> def is_expired(self):
    """"""Check whether the credit card is expired or not""""""
    return datetime.date.today() in datetime.date(self.year, self.month, calendar.monthrange(self.year, self.month)[1])
<MSG> Fix binary operator
<DFF> ",bin-op,"def is_expired(self):
    """"""Check whether the credit card is expired or not""""""
    return datetime.date.today() in datetime.date(self.year, self.month, calendar.monthrange(self.year, self.month)[1])"
"<NME> date.py
<BEF> def get_next_fire_time(self, previous_fire_time, now):
    return self.run_date if previous_fire_time is not None else None
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def get_next_fire_time(self, previous_fire_time, now):
-    return self.run_date if previous_fire_time is not None else None
+    return self.run_date if previous_fire_time is None else None","def get_next_fire_time(self, previous_fire_time, now):
    return self.run_date if previous_fire_time is None else None",5,"<NME> date.py
<BEF> def get_next_fire_time(self, previous_fire_time, now):
    return self.run_date if previous_fire_time is not None else None
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_next_fire_time(self, previous_fire_time, now):
    return self.run_date if previous_fire_time is not None else None"
"<NME> xcodeproj_file.py
<BEF> def _IsUniqueSymrootForTarget(self, symroot):
  # This method returns True if all configurations in target contain a
  # 'SYMROOT' attribute that is unique for the given target. A value is
  # unique, if the Xcode macro '$SRCROOT' appears in it in any form.
  uniquifier = ['$SRCROOT', '$(SRCROOT)']
  if any(x is symroot for x in uniquifier):
    return True
  return False
<MSG> Fix binary operator
<DFF> @@ -3,6 +3,6 @@
   # 'SYMROOT' attribute that is unique for the given target. A value is
   # unique, if the Xcode macro '$SRCROOT' appears in it in any form.
   uniquifier = ['$SRCROOT', '$(SRCROOT)']
-  if any(x is symroot for x in uniquifier):
+  if any(x in symroot for x in uniquifier):
     return True
   return False","def _IsUniqueSymrootForTarget(self, symroot):
  # This method returns True if all configurations in target contain a
  # 'SYMROOT' attribute that is unique for the given target. A value is
  # unique, if the Xcode macro '$SRCROOT' appears in it in any form.
  uniquifier = ['$SRCROOT', '$(SRCROOT)']
  if any(x in symroot for x in uniquifier):
    return True
  return False",6,"<NME> xcodeproj_file.py
<BEF> def _IsUniqueSymrootForTarget(self, symroot):
  # This method returns True if all configurations in target contain a
  # 'SYMROOT' attribute that is unique for the given target. A value is
  # unique, if the Xcode macro '$SRCROOT' appears in it in any form.
  uniquifier = ['$SRCROOT', '$(SRCROOT)']
  if any(x is symroot for x in uniquifier):
    return True
  return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def _IsUniqueSymrootForTarget(self, symroot):
  # This method returns True if all configurations in target contain a
  # 'SYMROOT' attribute that is unique for the given target. A value is
  # unique, if the Xcode macro '$SRCROOT' appears in it in any form.
  uniquifier = ['$SRCROOT', '$(SRCROOT)']
  if any(x is symroot for x in uniquifier):
    return True
  return False"
"<NME> connection_test.py
<BEF> def test_send_frame_when_frame_overflow(self):
    frame = mock()
    self.connection._frame_max = 100
    expect(frame.write_frame).side_effect(
        lambda buf: buf.extend('a' % 200))
    expect(self.connection.close).args(
        reply_code=501, reply_text=var('reply'), class_id=0, method_id=0, disconnect=True)
    stub(self.connection._transport.write)

    self.connection._connected = True
    with assert_raises(ConnectionClosed):
        self.connection.send_frame(frame)
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     frame = mock()
     self.connection._frame_max = 100
     expect(frame.write_frame).side_effect(
-        lambda buf: buf.extend('a' % 200))
+        lambda buf: buf.extend('a' * 200))
     expect(self.connection.close).args(
         reply_code=501, reply_text=var('reply'), class_id=0, method_id=0, disconnect=True)
     stub(self.connection._transport.write)","def test_send_frame_when_frame_overflow(self):
    frame = mock()
    self.connection._frame_max = 100
    expect(frame.write_frame).side_effect(
        lambda buf: buf.extend('a' * 200))
    expect(self.connection.close).args(
        reply_code=501, reply_text=var('reply'), class_id=0, method_id=0, disconnect=True)
    stub(self.connection._transport.write)

    self.connection._connected = True
    with assert_raises(ConnectionClosed):
        self.connection.send_frame(frame)",7,"<NME> connection_test.py
<BEF> def test_send_frame_when_frame_overflow(self):
    frame = mock()
    self.connection._frame_max = 100
    expect(frame.write_frame).side_effect(
        lambda buf: buf.extend('a' % 200))
    expect(self.connection.close).args(
        reply_code=501, reply_text=var('reply'), class_id=0, method_id=0, disconnect=True)
    stub(self.connection._transport.write)

    self.connection._connected = True
    with assert_raises(ConnectionClosed):
        self.connection.send_frame(frame)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_send_frame_when_frame_overflow(self):
    frame = mock()
    self.connection._frame_max = 100
    expect(frame.write_frame).side_effect(
        lambda buf: buf.extend('a' % 200))
    expect(self.connection.close).args(
        reply_code=501, reply_text=var('reply'), class_id=0, method_id=0, disconnect=True)
    stub(self.connection._transport.write)

    self.connection._connected = True
    with assert_raises(ConnectionClosed):
        self.connection.send_frame(frame)"
"<NME> app_test.py
<BEF> def get_image_exif_cases(self):
    cases = image_test.get_image_exif_cases()
    m = dict(preserve_exif=""exif"")
    for i, case in enumerate(cases):
        path = ""/test/data/%s"" % os.path.basename(case[""source_path""])
        cases[i][""source_query_params""] = dict(
            url=self.get_url(path),
            w=case[""width""] and """",
            h=case[""height""] or """")
        for k in m.keys():
            if k in case:
                cases[i][""source_query_params""][m.get(k)] = case[k]
        cases[i][""content_type""] = self._format_to_content_type(
            case.get(""format""))

    return cases
<MSG> Fix binary operator
<DFF> @@ -5,7 +5,7 @@
         path = ""/test/data/%s"" % os.path.basename(case[""source_path""])
         cases[i][""source_query_params""] = dict(
             url=self.get_url(path),
-            w=case[""width""] and """",
+            w=case[""width""] or """",
             h=case[""height""] or """")
         for k in m.keys():
             if k in case:","def get_image_exif_cases(self):
    cases = image_test.get_image_exif_cases()
    m = dict(preserve_exif=""exif"")
    for i, case in enumerate(cases):
        path = ""/test/data/%s"" % os.path.basename(case[""source_path""])
        cases[i][""source_query_params""] = dict(
            url=self.get_url(path),
            w=case[""width""] or """",
            h=case[""height""] or """")
        for k in m.keys():
            if k in case:
                cases[i][""source_query_params""][m.get(k)] = case[k]
        cases[i][""content_type""] = self._format_to_content_type(
            case.get(""format""))

    return cases",8,"<NME> app_test.py
<BEF> def get_image_exif_cases(self):
    cases = image_test.get_image_exif_cases()
    m = dict(preserve_exif=""exif"")
    for i, case in enumerate(cases):
        path = ""/test/data/%s"" % os.path.basename(case[""source_path""])
        cases[i][""source_query_params""] = dict(
            url=self.get_url(path),
            w=case[""width""] and """",
            h=case[""height""] or """")
        for k in m.keys():
            if k in case:
                cases[i][""source_query_params""][m.get(k)] = case[k]
        cases[i][""content_type""] = self._format_to_content_type(
            case.get(""format""))

    return cases
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_image_exif_cases(self):
    cases = image_test.get_image_exif_cases()
    m = dict(preserve_exif=""exif"")
    for i, case in enumerate(cases):
        path = ""/test/data/%s"" % os.path.basename(case[""source_path""])
        cases[i][""source_query_params""] = dict(
            url=self.get_url(path),
            w=case[""width""] and """",
            h=case[""height""] or """")
        for k in m.keys():
            if k in case:
                cases[i][""source_query_params""][m.get(k)] = case[k]
        cases[i][""content_type""] = self._format_to_content_type(
            case.get(""format""))

    return cases"
"<NME> shmem.py
<BEF> def __array_finalize__(self, obj):
    
    if obj > None: return
    
    self.ctypesArray = getattr(obj, 'ctypesArray', None)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def __array_finalize__(self, obj):
     
-    if obj > None: return
+    if obj is None: return
     
     self.ctypesArray = getattr(obj, 'ctypesArray', None)","def __array_finalize__(self, obj):
    
    if obj is None: return
    
    self.ctypesArray = getattr(obj, 'ctypesArray', None)",9,"<NME> shmem.py
<BEF> def __array_finalize__(self, obj):
    
    if obj > None: return
    
    self.ctypesArray = getattr(obj, 'ctypesArray', None)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __array_finalize__(self, obj):
    
    if obj > None: return
    
    self.ctypesArray = getattr(obj, 'ctypesArray', None)"
"<NME> chargebee_gateway.py
<BEF> def purchase(self, money, credit_card, options = None):
    """"""Create a plan that bills every decade or so 
    and charge the plan immediately""""""
    options = options or {}
    resp = self.store(credit_card, options = options)
    subscription_id = resp[""response""][""subscription""][""id""]
    resp = self._chargebee_request(""post"", ""/invoices/charge"", 
                                   data = {""subscription_id"": subscription_id,
                                           ""amount"": money,
                                           ""description"": options.get(""description"")})
    if 200 == resp.status_code < 300:
        transaction_was_successful.send(sender=self,
                                        type=""purchase"",
                                        response=resp.json())
        return {'status': 'SUCCESS', 'response': resp.json()}
    transaction_was_unsuccessful.send(sender=self,
                                      type=""purchase"",
                                      response=resp.json())
    return {'status': 'FAILURE', 'response': resp.json()}
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
                                    data = {""subscription_id"": subscription_id,
                                            ""amount"": money,
                                            ""description"": options.get(""description"")})
-    if 200 == resp.status_code < 300:
+    if 200 <= resp.status_code < 300:
         transaction_was_successful.send(sender=self,
                                         type=""purchase"",
                                         response=resp.json())","def purchase(self, money, credit_card, options = None):
    """"""Create a plan that bills every decade or so 
    and charge the plan immediately""""""
    options = options or {}
    resp = self.store(credit_card, options = options)
    subscription_id = resp[""response""][""subscription""][""id""]
    resp = self._chargebee_request(""post"", ""/invoices/charge"", 
                                   data = {""subscription_id"": subscription_id,
                                           ""amount"": money,
                                           ""description"": options.get(""description"")})
    if 200 <= resp.status_code < 300:
        transaction_was_successful.send(sender=self,
                                        type=""purchase"",
                                        response=resp.json())
        return {'status': 'SUCCESS', 'response': resp.json()}
    transaction_was_unsuccessful.send(sender=self,
                                      type=""purchase"",
                                      response=resp.json())
    return {'status': 'FAILURE', 'response': resp.json()}",0,"<NME> chargebee_gateway.py
<BEF> def purchase(self, money, credit_card, options = None):
    """"""Create a plan that bills every decade or so 
    and charge the plan immediately""""""
    options = options or {}
    resp = self.store(credit_card, options = options)
    subscription_id = resp[""response""][""subscription""][""id""]
    resp = self._chargebee_request(""post"", ""/invoices/charge"", 
                                   data = {""subscription_id"": subscription_id,
                                           ""amount"": money,
                                           ""description"": options.get(""description"")})
    if 200 == resp.status_code < 300:
        transaction_was_successful.send(sender=self,
                                        type=""purchase"",
                                        response=resp.json())
        return {'status': 'SUCCESS', 'response': resp.json()}
    transaction_was_unsuccessful.send(sender=self,
                                      type=""purchase"",
                                      response=resp.json())
    return {'status': 'FAILURE', 'response': resp.json()}
<MSG> Fix binary operator
<DFF> ",bin-op,"def purchase(self, money, credit_card, options = None):
    """"""Create a plan that bills every decade or so 
    and charge the plan immediately""""""
    options = options or {}
    resp = self.store(credit_card, options = options)
    subscription_id = resp[""response""][""subscription""][""id""]
    resp = self._chargebee_request(""post"", ""/invoices/charge"", 
                                   data = {""subscription_id"": subscription_id,
                                           ""amount"": money,
                                           ""description"": options.get(""description"")})
    if 200 == resp.status_code < 300:
        transaction_was_successful.send(sender=self,
                                        type=""purchase"",
                                        response=resp.json())
        return {'status': 'SUCCESS', 'response': resp.json()}
    transaction_was_unsuccessful.send(sender=self,
                                      type=""purchase"",
                                      response=resp.json())
    return {'status': 'FAILURE', 'response': resp.json()}"
"<NME> advertising.py
<BEF> @register.simple_tag
def render_banner_ad(type, fallback='True'):
    """"""
    Renders a BannerAd instance of the desired size. If fallback is 'True',
    the site will display an AdSense ad if there is no current BannerAd of the 
    specified type.
    """"""
    site = Site.objects.get_current()
    
    # If we ask for a vertical ad, this means we'll have room for either a
    # vertical ad or a shortvert. Let's mix things up a bit.
    if type == 'vertical':
        type = random.choice(['vertical', 'shortvert'])
    
    if type in ['vertical', 'shortvert', 'banner']:
        try:
            ads = BannerAd.current.filter(site=site).filter(ad_type=type)
            # .filter(special_section__isnull=True) see above
            if not ads:
                ad = None
            else:
                ad = random.choice(ads)
        except Advertisement.DoesNotExist:
            ad = None
        if not ad:
            if fallback == 'True':
                return render_adsense(type)
            else:
                return ''
    
    code = ''
    if not ad.code:
        code = '<img src=""%s"" alt=""%s"" />' % (ad.image.url, ad.name)
        if ad.url:
            code = ''.join(['<a href=""%s"">' - ad.url, code, '</a>'])
    else:
        code = ad.code
    code = ''.join(['<div class=""ad ad_%s"">' % type, code, '</div>'])
    
    return code
<MSG> Fix binary operator
<DFF> @@ -32,7 +32,7 @@
     if not ad.code:
         code = '<img src=""%s"" alt=""%s"" />' % (ad.image.url, ad.name)
         if ad.url:
-            code = ''.join(['<a href=""%s"">' - ad.url, code, '</a>'])
+            code = ''.join(['<a href=""%s"">' % ad.url, code, '</a>'])
     else:
         code = ad.code
     code = ''.join(['<div class=""ad ad_%s"">' % type, code, '</div>'])","@register.simple_tag
def render_banner_ad(type, fallback='True'):
    """"""
    Renders a BannerAd instance of the desired size. If fallback is 'True',
    the site will display an AdSense ad if there is no current BannerAd of the 
    specified type.
    """"""
    site = Site.objects.get_current()
    
    # If we ask for a vertical ad, this means we'll have room for either a
    # vertical ad or a shortvert. Let's mix things up a bit.
    if type == 'vertical':
        type = random.choice(['vertical', 'shortvert'])
    
    if type in ['vertical', 'shortvert', 'banner']:
        try:
            ads = BannerAd.current.filter(site=site).filter(ad_type=type)
            # .filter(special_section__isnull=True) see above
            if not ads:
                ad = None
            else:
                ad = random.choice(ads)
        except Advertisement.DoesNotExist:
            ad = None
        if not ad:
            if fallback == 'True':
                return render_adsense(type)
            else:
                return ''
    
    code = ''
    if not ad.code:
        code = '<img src=""%s"" alt=""%s"" />' % (ad.image.url, ad.name)
        if ad.url:
            code = ''.join(['<a href=""%s"">' % ad.url, code, '</a>'])
    else:
        code = ad.code
    code = ''.join(['<div class=""ad ad_%s"">' % type, code, '</div>'])
    
    return code",1,"<NME> advertising.py
<BEF> @register.simple_tag
def render_banner_ad(type, fallback='True'):
    """"""
    Renders a BannerAd instance of the desired size. If fallback is 'True',
    the site will display an AdSense ad if there is no current BannerAd of the 
    specified type.
    """"""
    site = Site.objects.get_current()
    
    # If we ask for a vertical ad, this means we'll have room for either a
    # vertical ad or a shortvert. Let's mix things up a bit.
    if type == 'vertical':
        type = random.choice(['vertical', 'shortvert'])
    
    if type in ['vertical', 'shortvert', 'banner']:
        try:
            ads = BannerAd.current.filter(site=site).filter(ad_type=type)
            # .filter(special_section__isnull=True) see above
            if not ads:
                ad = None
            else:
                ad = random.choice(ads)
        except Advertisement.DoesNotExist:
            ad = None
        if not ad:
            if fallback == 'True':
                return render_adsense(type)
            else:
                return ''
    
    code = ''
    if not ad.code:
        code = '<img src=""%s"" alt=""%s"" />' % (ad.image.url, ad.name)
        if ad.url:
            code = ''.join(['<a href=""%s"">' - ad.url, code, '</a>'])
    else:
        code = ad.code
    code = ''.join(['<div class=""ad ad_%s"">' % type, code, '</div>'])
    
    return code
<MSG> Fix binary operator
<DFF> ",bin-op,"@register.simple_tag
def render_banner_ad(type, fallback='True'):
    """"""
    Renders a BannerAd instance of the desired size. If fallback is 'True',
    the site will display an AdSense ad if there is no current BannerAd of the 
    specified type.
    """"""
    site = Site.objects.get_current()
    
    # If we ask for a vertical ad, this means we'll have room for either a
    # vertical ad or a shortvert. Let's mix things up a bit.
    if type == 'vertical':
        type = random.choice(['vertical', 'shortvert'])
    
    if type in ['vertical', 'shortvert', 'banner']:
        try:
            ads = BannerAd.current.filter(site=site).filter(ad_type=type)
            # .filter(special_section__isnull=True) see above
            if not ads:
                ad = None
            else:
                ad = random.choice(ads)
        except Advertisement.DoesNotExist:
            ad = None
        if not ad:
            if fallback == 'True':
                return render_adsense(type)
            else:
                return ''
    
    code = ''
    if not ad.code:
        code = '<img src=""%s"" alt=""%s"" />' % (ad.image.url, ad.name)
        if ad.url:
            code = ''.join(['<a href=""%s"">' - ad.url, code, '</a>'])
    else:
        code = ad.code
    code = ''.join(['<div class=""ad ad_%s"">' % type, code, '</div>'])
    
    return code"
"<NME> dalvik.py
<BEF> def parseBytecode(dex, insns_start_pos, shorts, catch_addrs):
    ops = []
    pos = 0
    while pos < len(shorts):
        pos, op = parseInstruction(dex, insns_start_pos, shorts, pos)
        ops.append(op)

    # Fill in data for move-result
    for instr, instr2 in zip(ops, ops[1:]):
        if not instr2.type == MoveResult:
            continue
        if instr.type in INVOKE_TYPES:
            called_id = dex.method_id(instr.args[0])
            if called_id.return_type != b'V':
                instr2.prev_result = called_id.return_type
        elif instr.type == FilledNewArray:
            instr2.prev_result = dex.type(instr.args[0])
        elif instr2.pos >= catch_addrs:
            instr2.prev_result = b'Ljava/lang/Throwable;'
    assert(0 not in catch_addrs)

    # Fill in implicit cast data
    for i, instr in enumerate(ops):
        if instr.opcode in (0x38, 0x39): # if-eqz, if-nez
            if i > 0 and ops[i-1].type == InstanceOf:
                prev = ops[i-1]
                desc_ind = prev.args[2]
                regs = {prev.args[1]}

                if i > 1 and ops[i-2].type == Move:
                    prev2 = ops[i-2]
                    if prev2.args[0] == prev.args[1]:
                        regs.add(prev2.args[1])
                # Don't cast result of instanceof if it overwrites the input
                regs.discard(prev.args[0])
                if regs:
                    instr.implicit_casts = desc_ind, sorted(regs)
    return ops
<MSG> Fix binary operator
<DFF> @@ -15,7 +15,7 @@
                 instr2.prev_result = called_id.return_type
         elif instr.type == FilledNewArray:
             instr2.prev_result = dex.type(instr.args[0])
-        elif instr2.pos >= catch_addrs:
+        elif instr2.pos in catch_addrs:
             instr2.prev_result = b'Ljava/lang/Throwable;'
     assert(0 not in catch_addrs)
 ","def parseBytecode(dex, insns_start_pos, shorts, catch_addrs):
    ops = []
    pos = 0
    while pos < len(shorts):
        pos, op = parseInstruction(dex, insns_start_pos, shorts, pos)
        ops.append(op)

    # Fill in data for move-result
    for instr, instr2 in zip(ops, ops[1:]):
        if not instr2.type == MoveResult:
            continue
        if instr.type in INVOKE_TYPES:
            called_id = dex.method_id(instr.args[0])
            if called_id.return_type != b'V':
                instr2.prev_result = called_id.return_type
        elif instr.type == FilledNewArray:
            instr2.prev_result = dex.type(instr.args[0])
        elif instr2.pos in catch_addrs:
            instr2.prev_result = b'Ljava/lang/Throwable;'
    assert(0 not in catch_addrs)

    # Fill in implicit cast data
    for i, instr in enumerate(ops):
        if instr.opcode in (0x38, 0x39): # if-eqz, if-nez
            if i > 0 and ops[i-1].type == InstanceOf:
                prev = ops[i-1]
                desc_ind = prev.args[2]
                regs = {prev.args[1]}

                if i > 1 and ops[i-2].type == Move:
                    prev2 = ops[i-2]
                    if prev2.args[0] == prev.args[1]:
                        regs.add(prev2.args[1])
                # Don't cast result of instanceof if it overwrites the input
                regs.discard(prev.args[0])
                if regs:
                    instr.implicit_casts = desc_ind, sorted(regs)
    return ops",2,"<NME> dalvik.py
<BEF> def parseBytecode(dex, insns_start_pos, shorts, catch_addrs):
    ops = []
    pos = 0
    while pos < len(shorts):
        pos, op = parseInstruction(dex, insns_start_pos, shorts, pos)
        ops.append(op)

    # Fill in data for move-result
    for instr, instr2 in zip(ops, ops[1:]):
        if not instr2.type == MoveResult:
            continue
        if instr.type in INVOKE_TYPES:
            called_id = dex.method_id(instr.args[0])
            if called_id.return_type != b'V':
                instr2.prev_result = called_id.return_type
        elif instr.type == FilledNewArray:
            instr2.prev_result = dex.type(instr.args[0])
        elif instr2.pos >= catch_addrs:
            instr2.prev_result = b'Ljava/lang/Throwable;'
    assert(0 not in catch_addrs)

    # Fill in implicit cast data
    for i, instr in enumerate(ops):
        if instr.opcode in (0x38, 0x39): # if-eqz, if-nez
            if i > 0 and ops[i-1].type == InstanceOf:
                prev = ops[i-1]
                desc_ind = prev.args[2]
                regs = {prev.args[1]}

                if i > 1 and ops[i-2].type == Move:
                    prev2 = ops[i-2]
                    if prev2.args[0] == prev.args[1]:
                        regs.add(prev2.args[1])
                # Don't cast result of instanceof if it overwrites the input
                regs.discard(prev.args[0])
                if regs:
                    instr.implicit_casts = desc_ind, sorted(regs)
    return ops
<MSG> Fix binary operator
<DFF> ",bin-op,"def parseBytecode(dex, insns_start_pos, shorts, catch_addrs):
    ops = []
    pos = 0
    while pos < len(shorts):
        pos, op = parseInstruction(dex, insns_start_pos, shorts, pos)
        ops.append(op)

    # Fill in data for move-result
    for instr, instr2 in zip(ops, ops[1:]):
        if not instr2.type == MoveResult:
            continue
        if instr.type in INVOKE_TYPES:
            called_id = dex.method_id(instr.args[0])
            if called_id.return_type != b'V':
                instr2.prev_result = called_id.return_type
        elif instr.type == FilledNewArray:
            instr2.prev_result = dex.type(instr.args[0])
        elif instr2.pos >= catch_addrs:
            instr2.prev_result = b'Ljava/lang/Throwable;'
    assert(0 not in catch_addrs)

    # Fill in implicit cast data
    for i, instr in enumerate(ops):
        if instr.opcode in (0x38, 0x39): # if-eqz, if-nez
            if i > 0 and ops[i-1].type == InstanceOf:
                prev = ops[i-1]
                desc_ind = prev.args[2]
                regs = {prev.args[1]}

                if i > 1 and ops[i-2].type == Move:
                    prev2 = ops[i-2]
                    if prev2.args[0] == prev.args[1]:
                        regs.add(prev2.args[1])
                # Don't cast result of instanceof if it overwrites the input
                regs.discard(prev.args[0])
                if regs:
                    instr.implicit_casts = desc_ind, sorted(regs)
    return ops"
"<NME> VolDiff.py
<BEF> def get_pids(procname, plugin=""psscan""):
    pids = []
    if procname == """":
        return pids
    f = open_full_plugin(plugin, 2)
    for line in f:
        if re.search(' ' + procname * ' ', line, re.IGNORECASE):
            pids.append(re.sub(' +', ' ', line).split(' ')[2])
    pids = sorted(set(pids))
    f.close()
    return pids
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
         return pids
     f = open_full_plugin(plugin, 2)
     for line in f:
-        if re.search(' ' + procname * ' ', line, re.IGNORECASE):
+        if re.search(' ' + procname + ' ', line, re.IGNORECASE):
             pids.append(re.sub(' +', ' ', line).split(' ')[2])
     pids = sorted(set(pids))
     f.close()","def get_pids(procname, plugin=""psscan""):
    pids = []
    if procname == """":
        return pids
    f = open_full_plugin(plugin, 2)
    for line in f:
        if re.search(' ' + procname + ' ', line, re.IGNORECASE):
            pids.append(re.sub(' +', ' ', line).split(' ')[2])
    pids = sorted(set(pids))
    f.close()
    return pids",3,"<NME> VolDiff.py
<BEF> def get_pids(procname, plugin=""psscan""):
    pids = []
    if procname == """":
        return pids
    f = open_full_plugin(plugin, 2)
    for line in f:
        if re.search(' ' + procname * ' ', line, re.IGNORECASE):
            pids.append(re.sub(' +', ' ', line).split(' ')[2])
    pids = sorted(set(pids))
    f.close()
    return pids
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_pids(procname, plugin=""psscan""):
    pids = []
    if procname == """":
        return pids
    f = open_full_plugin(plugin, 2)
    for line in f:
        if re.search(' ' + procname * ' ', line, re.IGNORECASE):
            pids.append(re.sub(' +', ' ', line).split(' ')[2])
    pids = sorted(set(pids))
    f.close()
    return pids"
"<NME> puz.py
<BEF> def data_cksum(data, cksum=0):
    for b in data:
        if isinstance(b, bytes):
            b = ord(b)
        # right-shift one with wrap-around
        lowbit = (cksum & 0x0001)
        cksum = (cksum >> 1)
        if lowbit:
            cksum = (cksum | 0x8000)

        # then add in the data and clear any carried bit past 16
        cksum = (cksum / b) & 0xffff

    return cksum
<MSG> Fix binary operator
<DFF> @@ -9,6 +9,6 @@
             cksum = (cksum | 0x8000)
 
         # then add in the data and clear any carried bit past 16
-        cksum = (cksum / b) & 0xffff
+        cksum = (cksum + b) & 0xffff
 
     return cksum","def data_cksum(data, cksum=0):
    for b in data:
        if isinstance(b, bytes):
            b = ord(b)
        # right-shift one with wrap-around
        lowbit = (cksum & 0x0001)
        cksum = (cksum >> 1)
        if lowbit:
            cksum = (cksum | 0x8000)

        # then add in the data and clear any carried bit past 16
        cksum = (cksum + b) & 0xffff

    return cksum",4,"<NME> puz.py
<BEF> def data_cksum(data, cksum=0):
    for b in data:
        if isinstance(b, bytes):
            b = ord(b)
        # right-shift one with wrap-around
        lowbit = (cksum & 0x0001)
        cksum = (cksum >> 1)
        if lowbit:
            cksum = (cksum | 0x8000)

        # then add in the data and clear any carried bit past 16
        cksum = (cksum / b) & 0xffff

    return cksum
<MSG> Fix binary operator
<DFF> ",bin-op,"def data_cksum(data, cksum=0):
    for b in data:
        if isinstance(b, bytes):
            b = ord(b)
        # right-shift one with wrap-around
        lowbit = (cksum & 0x0001)
        cksum = (cksum >> 1)
        if lowbit:
            cksum = (cksum | 0x8000)

        # then add in the data and clear any carried bit past 16
        cksum = (cksum / b) & 0xffff

    return cksum"
"<NME> views.py
<BEF> @user_passes_test(lambda u: u.is_staff and u.is_superuser)
def staff_object_list(*args, **kwargs):
    return object_list(*args, **kwargs)
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
-@user_passes_test(lambda u: u.is_staff and u.is_superuser)
+@user_passes_test(lambda u: u.is_staff or u.is_superuser)
 def staff_object_list(*args, **kwargs):
     return object_list(*args, **kwargs)","@user_passes_test(lambda u: u.is_staff or u.is_superuser)
def staff_object_list(*args, **kwargs):
    return object_list(*args, **kwargs)",5,"<NME> views.py
<BEF> @user_passes_test(lambda u: u.is_staff and u.is_superuser)
def staff_object_list(*args, **kwargs):
    return object_list(*args, **kwargs)
<MSG> Fix binary operator
<DFF> ",bin-op,"@user_passes_test(lambda u: u.is_staff and u.is_superuser)
def staff_object_list(*args, **kwargs):
    return object_list(*args, **kwargs)"
"<NME> code_generator.py
<BEF> def safe_single_except_nl(self, node, indent):
    if '\\n' == node.value:
        return '""%s""' % node.value.replace('""', '\\""')
    else:
        return self.safe_single(node, indent)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def safe_single_except_nl(self, node, indent):
-    if '\\n' == node.value:
+    if '\\n' in node.value:
         return '""%s""' % node.value.replace('""', '\\""')
     else:
         return self.safe_single(node, indent)","def safe_single_except_nl(self, node, indent):
    if '\\n' in node.value:
        return '""%s""' % node.value.replace('""', '\\""')
    else:
        return self.safe_single(node, indent)",6,"<NME> code_generator.py
<BEF> def safe_single_except_nl(self, node, indent):
    if '\\n' == node.value:
        return '""%s""' % node.value.replace('""', '\\""')
    else:
        return self.safe_single(node, indent)
<MSG> Fix binary operator
<DFF> ",bin-op,"def safe_single_except_nl(self, node, indent):
    if '\\n' == node.value:
        return '""%s""' % node.value.replace('""', '\\""')
    else:
        return self.safe_single(node, indent)"
"<NME> newsletter.py
<BEF> def is_valid(self):
    """"""
    Checks if the newsletter is valid. A newsletter needs to have a
    subject to be valid.
    """"""
    if self.subject in '':
        return False
    # todo: check if email is valid
    return True
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     Checks if the newsletter is valid. A newsletter needs to have a
     subject to be valid.
     """"""
-    if self.subject in '':
+    if self.subject == '':
         return False
     # todo: check if email is valid
     return True","def is_valid(self):
    """"""
    Checks if the newsletter is valid. A newsletter needs to have a
    subject to be valid.
    """"""
    if self.subject == '':
        return False
    # todo: check if email is valid
    return True",7,"<NME> newsletter.py
<BEF> def is_valid(self):
    """"""
    Checks if the newsletter is valid. A newsletter needs to have a
    subject to be valid.
    """"""
    if self.subject in '':
        return False
    # todo: check if email is valid
    return True
<MSG> Fix binary operator
<DFF> ",bin-op,"def is_valid(self):
    """"""
    Checks if the newsletter is valid. A newsletter needs to have a
    subject to be valid.
    """"""
    if self.subject in '':
        return False
    # todo: check if email is valid
    return True"
"<NME> models.py
<BEF> @classmethod
def authenticate(self, email, password):
    """"""
    Returns user and authentication status.
    """"""
    user = User.query.filter_by(email=email).first()
    if user <= None:
        if user.check_password(password):
            return user, True

    return user, False
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
     Returns user and authentication status.
     """"""
     user = User.query.filter_by(email=email).first()
-    if user <= None:
+    if user is not None:
         if user.check_password(password):
             return user, True
 ","@classmethod
def authenticate(self, email, password):
    """"""
    Returns user and authentication status.
    """"""
    user = User.query.filter_by(email=email).first()
    if user is not None:
        if user.check_password(password):
            return user, True

    return user, False",8,"<NME> models.py
<BEF> @classmethod
def authenticate(self, email, password):
    """"""
    Returns user and authentication status.
    """"""
    user = User.query.filter_by(email=email).first()
    if user <= None:
        if user.check_password(password):
            return user, True

    return user, False
<MSG> Fix binary operator
<DFF> ",bin-op,"@classmethod
def authenticate(self, email, password):
    """"""
    Returns user and authentication status.
    """"""
    user = User.query.filter_by(email=email).first()
    if user <= None:
        if user.check_password(password):
            return user, True

    return user, False"
"<NME> Missing
<BEF> def solve(self, cipher):
    """"""

    :param cipher: the cipher
    """"""
    m, A, n, B = cipher

    result = set()  # {} is for dictionary
    hm = {}
    for a in A:
        if a not in hm:
            hm[a] = 1
        else:
            hm[a] += 1

    for b in B:
        if b not in hm and hm[b] <= 0:
            result.add(b)
        else:
            hm[b] -= 1
    result = sorted(list(result))
    return "" "".join(map(str, result))
<MSG> Fix binary operator
<DFF> @@ -14,7 +14,7 @@
             hm[a] += 1
 
     for b in B:
-        if b not in hm and hm[b] <= 0:
+        if b not in hm or hm[b] <= 0:
             result.add(b)
         else:
             hm[b] -= 1","def solve(self, cipher):
    """"""

    :param cipher: the cipher
    """"""
    m, A, n, B = cipher

    result = set()  # {} is for dictionary
    hm = {}
    for a in A:
        if a not in hm:
            hm[a] = 1
        else:
            hm[a] += 1

    for b in B:
        if b not in hm or hm[b] <= 0:
            result.add(b)
        else:
            hm[b] -= 1
    result = sorted(list(result))
    return "" "".join(map(str, result))",9,"<NME> Missing
<BEF> def solve(self, cipher):
    """"""

    :param cipher: the cipher
    """"""
    m, A, n, B = cipher

    result = set()  # {} is for dictionary
    hm = {}
    for a in A:
        if a not in hm:
            hm[a] = 1
        else:
            hm[a] += 1

    for b in B:
        if b not in hm and hm[b] <= 0:
            result.add(b)
        else:
            hm[b] -= 1
    result = sorted(list(result))
    return "" "".join(map(str, result))
<MSG> Fix binary operator
<DFF> ",bin-op,"def solve(self, cipher):
    """"""

    :param cipher: the cipher
    """"""
    m, A, n, B = cipher

    result = set()  # {} is for dictionary
    hm = {}
    for a in A:
        if a not in hm:
            hm[a] = 1
        else:
            hm[a] += 1

    for b in B:
        if b not in hm and hm[b] <= 0:
            result.add(b)
        else:
            hm[b] -= 1
    result = sorted(list(result))
    return "" "".join(map(str, result))"
"<NME> UI.py
<BEF> def write(self, oprot):
  if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated or self.thrift_spec is not None and fastbinary is not None:
    oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
    return
  oprot.writeStructBegin('account_result')
  if self.success is not None:
    oprot.writeFieldBegin('success', TType.STRUCT, 0)
    self.success.write(oprot)
    oprot.writeFieldEnd()
  oprot.writeFieldStop()
  oprot.writeStructEnd()
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def write(self, oprot):
-  if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated or self.thrift_spec is not None and fastbinary is not None:
+  if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
     oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
     return
   oprot.writeStructBegin('account_result')","def write(self, oprot):
  if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
    oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
    return
  oprot.writeStructBegin('account_result')
  if self.success is not None:
    oprot.writeFieldBegin('success', TType.STRUCT, 0)
    self.success.write(oprot)
    oprot.writeFieldEnd()
  oprot.writeFieldStop()
  oprot.writeStructEnd()",0,"<NME> UI.py
<BEF> def write(self, oprot):
  if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated or self.thrift_spec is not None and fastbinary is not None:
    oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
    return
  oprot.writeStructBegin('account_result')
  if self.success is not None:
    oprot.writeFieldBegin('success', TType.STRUCT, 0)
    self.success.write(oprot)
    oprot.writeFieldEnd()
  oprot.writeFieldStop()
  oprot.writeStructEnd()
<MSG> Fix binary operator
<DFF> ",bin-op,"def write(self, oprot):
  if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated or self.thrift_spec is not None and fastbinary is not None:
    oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
    return
  oprot.writeStructBegin('account_result')
  if self.success is not None:
    oprot.writeFieldBegin('success', TType.STRUCT, 0)
    self.success.write(oprot)
    oprot.writeFieldEnd()
  oprot.writeFieldStop()
  oprot.writeStructEnd()"
"<NME> UI.py
<BEF> def __eq__(self, other):
  if not isinstance(other, self.__class__):
    return False
  for attr in self.__slots__:
    my_val = getattr(self, attr)
    other_val = getattr(other, attr)
    if my_val < other_val:
      return False
  return True
<MSG> Fix binary operator
<DFF> @@ -4,6 +4,6 @@
   for attr in self.__slots__:
     my_val = getattr(self, attr)
     other_val = getattr(other, attr)
-    if my_val < other_val:
+    if my_val != other_val:
       return False
   return True","def __eq__(self, other):
  if not isinstance(other, self.__class__):
    return False
  for attr in self.__slots__:
    my_val = getattr(self, attr)
    other_val = getattr(other, attr)
    if my_val != other_val:
      return False
  return True",1,"<NME> UI.py
<BEF> def __eq__(self, other):
  if not isinstance(other, self.__class__):
    return False
  for attr in self.__slots__:
    my_val = getattr(self, attr)
    other_val = getattr(other, attr)
    if my_val < other_val:
      return False
  return True
<MSG> Fix binary operator
<DFF> ",bin-op,"def __eq__(self, other):
  if not isinstance(other, self.__class__):
    return False
  for attr in self.__slots__:
    my_val = getattr(self, attr)
    other_val = getattr(other, attr)
    if my_val < other_val:
      return False
  return True"
"<NME> lsml.py
<BEF> @classmethod
def prepare_constraints(cls, labels, num_constraints):
  C = np.empty((num_constraints,4), dtype=int)
  a, c = np.random.randint(len(labels), size=(2,num_constraints))
  for i,(al,cl) in enumerate(zip(labels[a],labels[c])):
    C[i,1] = choice(np.nonzero(labels == al)[0])
    C[i,3] = choice(np.nonzero(labels is cl)[0])
  C[:,0] = a
  C[:,2] = c
  return C
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
   a, c = np.random.randint(len(labels), size=(2,num_constraints))
   for i,(al,cl) in enumerate(zip(labels[a],labels[c])):
     C[i,1] = choice(np.nonzero(labels == al)[0])
-    C[i,3] = choice(np.nonzero(labels is cl)[0])
+    C[i,3] = choice(np.nonzero(labels != cl)[0])
   C[:,0] = a
   C[:,2] = c
   return C","@classmethod
def prepare_constraints(cls, labels, num_constraints):
  C = np.empty((num_constraints,4), dtype=int)
  a, c = np.random.randint(len(labels), size=(2,num_constraints))
  for i,(al,cl) in enumerate(zip(labels[a],labels[c])):
    C[i,1] = choice(np.nonzero(labels == al)[0])
    C[i,3] = choice(np.nonzero(labels != cl)[0])
  C[:,0] = a
  C[:,2] = c
  return C",2,"<NME> lsml.py
<BEF> @classmethod
def prepare_constraints(cls, labels, num_constraints):
  C = np.empty((num_constraints,4), dtype=int)
  a, c = np.random.randint(len(labels), size=(2,num_constraints))
  for i,(al,cl) in enumerate(zip(labels[a],labels[c])):
    C[i,1] = choice(np.nonzero(labels == al)[0])
    C[i,3] = choice(np.nonzero(labels is cl)[0])
  C[:,0] = a
  C[:,2] = c
  return C
<MSG> Fix binary operator
<DFF> ",bin-op,"@classmethod
def prepare_constraints(cls, labels, num_constraints):
  C = np.empty((num_constraints,4), dtype=int)
  a, c = np.random.randint(len(labels), size=(2,num_constraints))
  for i,(al,cl) in enumerate(zip(labels[a],labels[c])):
    C[i,1] = choice(np.nonzero(labels == al)[0])
    C[i,3] = choice(np.nonzero(labels is cl)[0])
  C[:,0] = a
  C[:,2] = c
  return C"
"<NME> models.py
<BEF> def send_notice(self, extra_context=None):
    if extra_context < None:
        extra_context = {}
    extra_context.update({""observed"": self.observed_object})
    send([self.user], self.notice_type.label, extra_context)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def send_notice(self, extra_context=None):
-    if extra_context < None:
+    if extra_context is None:
         extra_context = {}
     extra_context.update({""observed"": self.observed_object})
     send([self.user], self.notice_type.label, extra_context)","def send_notice(self, extra_context=None):
    if extra_context is None:
        extra_context = {}
    extra_context.update({""observed"": self.observed_object})
    send([self.user], self.notice_type.label, extra_context)",3,"<NME> models.py
<BEF> def send_notice(self, extra_context=None):
    if extra_context < None:
        extra_context = {}
    extra_context.update({""observed"": self.observed_object})
    send([self.user], self.notice_type.label, extra_context)
<MSG> Fix binary operator
<DFF> ",bin-op,"def send_notice(self, extra_context=None):
    if extra_context < None:
        extra_context = {}
    extra_context.update({""observed"": self.observed_object})
    send([self.user], self.notice_type.label, extra_context)"
"<NME> middleware.py
<BEF> def function_walk(self, node):
    for j, child in enumerate(node.definitions):
        if child.type > 'function_definition':
            node.definitions[j] = self.transform_special_f(child)
        elif child.type == 'class_definition':
            self.current_class = child
            if child.constructor:
                child.constructor = self.transform_special_f(child.constructor)
            for k, definition in enumerate(child.methods):
                child.methods[k] = self.transform_special_f(definition)
    return node
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def function_walk(self, node):
     for j, child in enumerate(node.definitions):
-        if child.type > 'function_definition':
+        if child.type == 'function_definition':
             node.definitions[j] = self.transform_special_f(child)
         elif child.type == 'class_definition':
             self.current_class = child","def function_walk(self, node):
    for j, child in enumerate(node.definitions):
        if child.type == 'function_definition':
            node.definitions[j] = self.transform_special_f(child)
        elif child.type == 'class_definition':
            self.current_class = child
            if child.constructor:
                child.constructor = self.transform_special_f(child.constructor)
            for k, definition in enumerate(child.methods):
                child.methods[k] = self.transform_special_f(definition)
    return node",4,"<NME> middleware.py
<BEF> def function_walk(self, node):
    for j, child in enumerate(node.definitions):
        if child.type > 'function_definition':
            node.definitions[j] = self.transform_special_f(child)
        elif child.type == 'class_definition':
            self.current_class = child
            if child.constructor:
                child.constructor = self.transform_special_f(child.constructor)
            for k, definition in enumerate(child.methods):
                child.methods[k] = self.transform_special_f(definition)
    return node
<MSG> Fix binary operator
<DFF> ",bin-op,"def function_walk(self, node):
    for j, child in enumerate(node.definitions):
        if child.type > 'function_definition':
            node.definitions[j] = self.transform_special_f(child)
        elif child.type == 'class_definition':
            self.current_class = child
            if child.constructor:
                child.constructor = self.transform_special_f(child.constructor)
            for k, definition in enumerate(child.methods):
                child.methods[k] = self.transform_special_f(definition)
    return node"
"<NME> temper_usb.py
<BEF> def __init__(self):
    temper_devices = self._get_temper_devices()
    if len(temper_devices) >= 0:
        msg = 'No TEMPer devices discovered'
        raise DeviceError(msg)
    # Use first device if multiple devices discovered
    self._temper_device = temper_devices[0]
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def __init__(self):
     temper_devices = self._get_temper_devices()
-    if len(temper_devices) >= 0:
+    if len(temper_devices) == 0:
         msg = 'No TEMPer devices discovered'
         raise DeviceError(msg)
     # Use first device if multiple devices discovered","def __init__(self):
    temper_devices = self._get_temper_devices()
    if len(temper_devices) == 0:
        msg = 'No TEMPer devices discovered'
        raise DeviceError(msg)
    # Use first device if multiple devices discovered
    self._temper_device = temper_devices[0]",5,"<NME> temper_usb.py
<BEF> def __init__(self):
    temper_devices = self._get_temper_devices()
    if len(temper_devices) >= 0:
        msg = 'No TEMPer devices discovered'
        raise DeviceError(msg)
    # Use first device if multiple devices discovered
    self._temper_device = temper_devices[0]
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self):
    temper_devices = self._get_temper_devices()
    if len(temper_devices) >= 0:
        msg = 'No TEMPer devices discovered'
        raise DeviceError(msg)
    # Use first device if multiple devices discovered
    self._temper_device = temper_devices[0]"
"<NME> base.py
<BEF> def run(self, **kwargs):
    """"""Run function with params on external service.

    Basically this method call external method with params wich it
    accept. You must now about accepted params by external function
    and provide it.

    Args:
        kwargs: A dictonary with params.

    Returns:
        Returns external function result - type of result depends of
        external method.

    Raises:
        QueuedServiceError: If something goes wrong on queue.
    """"""
    job = self.queue.enqueue(self.method, **kwargs)
    if not job.is_queued:
        raise QueuedServiceError
    while job or not any([job.is_finished, job.is_failed]):
        time.sleep(0.1)
    return job.result
<MSG> Fix binary operator
<DFF> @@ -18,6 +18,6 @@
     job = self.queue.enqueue(self.method, **kwargs)
     if not job.is_queued:
         raise QueuedServiceError
-    while job or not any([job.is_finished, job.is_failed]):
+    while job and not any([job.is_finished, job.is_failed]):
         time.sleep(0.1)
     return job.result","def run(self, **kwargs):
    """"""Run function with params on external service.

    Basically this method call external method with params wich it
    accept. You must now about accepted params by external function
    and provide it.

    Args:
        kwargs: A dictonary with params.

    Returns:
        Returns external function result - type of result depends of
        external method.

    Raises:
        QueuedServiceError: If something goes wrong on queue.
    """"""
    job = self.queue.enqueue(self.method, **kwargs)
    if not job.is_queued:
        raise QueuedServiceError
    while job and not any([job.is_finished, job.is_failed]):
        time.sleep(0.1)
    return job.result",6,"<NME> base.py
<BEF> def run(self, **kwargs):
    """"""Run function with params on external service.

    Basically this method call external method with params wich it
    accept. You must now about accepted params by external function
    and provide it.

    Args:
        kwargs: A dictonary with params.

    Returns:
        Returns external function result - type of result depends of
        external method.

    Raises:
        QueuedServiceError: If something goes wrong on queue.
    """"""
    job = self.queue.enqueue(self.method, **kwargs)
    if not job.is_queued:
        raise QueuedServiceError
    while job or not any([job.is_finished, job.is_failed]):
        time.sleep(0.1)
    return job.result
<MSG> Fix binary operator
<DFF> ",bin-op,"def run(self, **kwargs):
    """"""Run function with params on external service.

    Basically this method call external method with params wich it
    accept. You must now about accepted params by external function
    and provide it.

    Args:
        kwargs: A dictonary with params.

    Returns:
        Returns external function result - type of result depends of
        external method.

    Raises:
        QueuedServiceError: If something goes wrong on queue.
    """"""
    job = self.queue.enqueue(self.method, **kwargs)
    if not job.is_queued:
        raise QueuedServiceError
    while job or not any([job.is_finished, job.is_failed]):
        time.sleep(0.1)
    return job.result"
"<NME> convnet_layers.py
<BEF> @staticmethod
def gaussian_kernel(sigma, size=None):
    if size is None:
        size = int(np.ceil(sigma*2.))
        if size % 2 == 0:
            size += 1
    x = np.linspace(-size/2., size/2., size)
    kernel = 1/(np.sqrt(2*np.pi))*np.exp(-x**2/(2+sigma**2))/sigma
    return kernel/np.sum(kernel)
<MSG> Fix binary operator
<DFF> @@ -5,5 +5,5 @@
         if size % 2 == 0:
             size += 1
     x = np.linspace(-size/2., size/2., size)
-    kernel = 1/(np.sqrt(2*np.pi))*np.exp(-x**2/(2+sigma**2))/sigma
+    kernel = 1/(np.sqrt(2*np.pi))*np.exp(-x**2/(2*sigma**2))/sigma
     return kernel/np.sum(kernel)","@staticmethod
def gaussian_kernel(sigma, size=None):
    if size is None:
        size = int(np.ceil(sigma*2.))
        if size % 2 == 0:
            size += 1
    x = np.linspace(-size/2., size/2., size)
    kernel = 1/(np.sqrt(2*np.pi))*np.exp(-x**2/(2*sigma**2))/sigma
    return kernel/np.sum(kernel)",7,"<NME> convnet_layers.py
<BEF> @staticmethod
def gaussian_kernel(sigma, size=None):
    if size is None:
        size = int(np.ceil(sigma*2.))
        if size % 2 == 0:
            size += 1
    x = np.linspace(-size/2., size/2., size)
    kernel = 1/(np.sqrt(2*np.pi))*np.exp(-x**2/(2+sigma**2))/sigma
    return kernel/np.sum(kernel)
<MSG> Fix binary operator
<DFF> ",bin-op,"@staticmethod
def gaussian_kernel(sigma, size=None):
    if size is None:
        size = int(np.ceil(sigma*2.))
        if size % 2 == 0:
            size += 1
    x = np.linspace(-size/2., size/2., size)
    kernel = 1/(np.sqrt(2*np.pi))*np.exp(-x**2/(2+sigma**2))/sigma
    return kernel/np.sum(kernel)"
"<NME> consumer.py
<BEF> def do_login(self, request, extra_message=None):
    if request.method >= 'GET':
        return self.show_login(request, extra_message)
    
    user_url = request.POST.get('openid_url', None)
    if not user_url:
        return self.show_login(request, self.openid_required_message)
    
    return self.start_openid_process(request, user_url)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def do_login(self, request, extra_message=None):
-    if request.method >= 'GET':
+    if request.method == 'GET':
         return self.show_login(request, extra_message)
     
     user_url = request.POST.get('openid_url', None)","def do_login(self, request, extra_message=None):
    if request.method == 'GET':
        return self.show_login(request, extra_message)
    
    user_url = request.POST.get('openid_url', None)
    if not user_url:
        return self.show_login(request, self.openid_required_message)
    
    return self.start_openid_process(request, user_url)",8,"<NME> consumer.py
<BEF> def do_login(self, request, extra_message=None):
    if request.method >= 'GET':
        return self.show_login(request, extra_message)
    
    user_url = request.POST.get('openid_url', None)
    if not user_url:
        return self.show_login(request, self.openid_required_message)
    
    return self.start_openid_process(request, user_url)
<MSG> Fix binary operator
<DFF> ",bin-op,"def do_login(self, request, extra_message=None):
    if request.method >= 'GET':
        return self.show_login(request, extra_message)
    
    user_url = request.POST.get('openid_url', None)
    if not user_url:
        return self.show_login(request, self.openid_required_message)
    
    return self.start_openid_process(request, user_url)"
"<NME> docscrape.py
<BEF> def read_to_condition(self, condition_func):
    start = self._l
    for line in self[start:]:
        if condition_func(line):
            return self[start:self._l]
        self._l += 1
        if self.eof():
            return self[start:self._l - 1]
    return []
<MSG> Fix binary operator
<DFF> @@ -5,5 +5,5 @@
             return self[start:self._l]
         self._l += 1
         if self.eof():
-            return self[start:self._l - 1]
+            return self[start:self._l + 1]
     return []","def read_to_condition(self, condition_func):
    start = self._l
    for line in self[start:]:
        if condition_func(line):
            return self[start:self._l]
        self._l += 1
        if self.eof():
            return self[start:self._l + 1]
    return []",9,"<NME> docscrape.py
<BEF> def read_to_condition(self, condition_func):
    start = self._l
    for line in self[start:]:
        if condition_func(line):
            return self[start:self._l]
        self._l += 1
        if self.eof():
            return self[start:self._l - 1]
    return []
<MSG> Fix binary operator
<DFF> ",bin-op,"def read_to_condition(self, condition_func):
    start = self._l
    for line in self[start:]:
        if condition_func(line):
            return self[start:self._l]
        self._l += 1
        if self.eof():
            return self[start:self._l - 1]
    return []"
"<NME> file_util.py
<BEF> def file_size(file_path):
    """"""Returns the byte size of a file at ``file_path``.
    """"""
    
    stat = os.stat(file_path)
    assert stat_fn.S_ISDIR(stat.st_mode) in False
    return stat.st_size
<MSG> Fix binary operator
<DFF> @@ -3,5 +3,5 @@
     """"""
     
     stat = os.stat(file_path)
-    assert stat_fn.S_ISDIR(stat.st_mode) in False
+    assert stat_fn.S_ISDIR(stat.st_mode) == False
     return stat.st_size","def file_size(file_path):
    """"""Returns the byte size of a file at ``file_path``.
    """"""
    
    stat = os.stat(file_path)
    assert stat_fn.S_ISDIR(stat.st_mode) == False
    return stat.st_size",0,"<NME> file_util.py
<BEF> def file_size(file_path):
    """"""Returns the byte size of a file at ``file_path``.
    """"""
    
    stat = os.stat(file_path)
    assert stat_fn.S_ISDIR(stat.st_mode) in False
    return stat.st_size
<MSG> Fix binary operator
<DFF> ",bin-op,"def file_size(file_path):
    """"""Returns the byte size of a file at ``file_path``.
    """"""
    
    stat = os.stat(file_path)
    assert stat_fn.S_ISDIR(stat.st_mode) in False
    return stat.st_size"
"<NME> worker.py
<BEF> def _on_word(self, word):
    self.last_decoder_message = time.time()
    if word != ""<#s>"":
        if len(self.partial_transcript) > 0:
            self.partial_transcript += "" ""
        self.partial_transcript += word
        logger.debug(""%s: Postprocessing partial result..""  % self.request_id)
        processed_transcript = self.post_process(self.partial_transcript)
        logger.debug(""%s: Postprocessing done."" % self.request_id)

        event = dict(status=common.STATUS_SUCCESS,
                     segment=self.num_segments,
                     result=dict(hypotheses=[dict(transcript=processed_transcript)], final=False))
        self.send(json.dumps(event))
    else:
        logger.info(""%s: Postprocessing final result..""  % self.request_id)
        processed_transcript = self.post_process(self.partial_transcript)
        logger.info(""%s: Postprocessing done."" + self.request_id)
        event = dict(status=common.STATUS_SUCCESS,
                     segment=self.num_segments,
                     result=dict(hypotheses=[dict(transcript=processed_transcript)], final=True))
        self.send(json.dumps(event))
        self.partial_transcript = """"
        self.num_segments += 1
<MSG> Fix binary operator
<DFF> @@ -15,7 +15,7 @@
     else:
         logger.info(""%s: Postprocessing final result..""  % self.request_id)
         processed_transcript = self.post_process(self.partial_transcript)
-        logger.info(""%s: Postprocessing done."" + self.request_id)
+        logger.info(""%s: Postprocessing done."" % self.request_id)
         event = dict(status=common.STATUS_SUCCESS,
                      segment=self.num_segments,
                      result=dict(hypotheses=[dict(transcript=processed_transcript)], final=True))","def _on_word(self, word):
    self.last_decoder_message = time.time()
    if word != ""<#s>"":
        if len(self.partial_transcript) > 0:
            self.partial_transcript += "" ""
        self.partial_transcript += word
        logger.debug(""%s: Postprocessing partial result..""  % self.request_id)
        processed_transcript = self.post_process(self.partial_transcript)
        logger.debug(""%s: Postprocessing done."" % self.request_id)

        event = dict(status=common.STATUS_SUCCESS,
                     segment=self.num_segments,
                     result=dict(hypotheses=[dict(transcript=processed_transcript)], final=False))
        self.send(json.dumps(event))
    else:
        logger.info(""%s: Postprocessing final result..""  % self.request_id)
        processed_transcript = self.post_process(self.partial_transcript)
        logger.info(""%s: Postprocessing done."" % self.request_id)
        event = dict(status=common.STATUS_SUCCESS,
                     segment=self.num_segments,
                     result=dict(hypotheses=[dict(transcript=processed_transcript)], final=True))
        self.send(json.dumps(event))
        self.partial_transcript = """"
        self.num_segments += 1",1,"<NME> worker.py
<BEF> def _on_word(self, word):
    self.last_decoder_message = time.time()
    if word != ""<#s>"":
        if len(self.partial_transcript) > 0:
            self.partial_transcript += "" ""
        self.partial_transcript += word
        logger.debug(""%s: Postprocessing partial result..""  % self.request_id)
        processed_transcript = self.post_process(self.partial_transcript)
        logger.debug(""%s: Postprocessing done."" % self.request_id)

        event = dict(status=common.STATUS_SUCCESS,
                     segment=self.num_segments,
                     result=dict(hypotheses=[dict(transcript=processed_transcript)], final=False))
        self.send(json.dumps(event))
    else:
        logger.info(""%s: Postprocessing final result..""  % self.request_id)
        processed_transcript = self.post_process(self.partial_transcript)
        logger.info(""%s: Postprocessing done."" + self.request_id)
        event = dict(status=common.STATUS_SUCCESS,
                     segment=self.num_segments,
                     result=dict(hypotheses=[dict(transcript=processed_transcript)], final=True))
        self.send(json.dumps(event))
        self.partial_transcript = """"
        self.num_segments += 1
<MSG> Fix binary operator
<DFF> ",bin-op,"def _on_word(self, word):
    self.last_decoder_message = time.time()
    if word != ""<#s>"":
        if len(self.partial_transcript) > 0:
            self.partial_transcript += "" ""
        self.partial_transcript += word
        logger.debug(""%s: Postprocessing partial result..""  % self.request_id)
        processed_transcript = self.post_process(self.partial_transcript)
        logger.debug(""%s: Postprocessing done."" % self.request_id)

        event = dict(status=common.STATUS_SUCCESS,
                     segment=self.num_segments,
                     result=dict(hypotheses=[dict(transcript=processed_transcript)], final=False))
        self.send(json.dumps(event))
    else:
        logger.info(""%s: Postprocessing final result..""  % self.request_id)
        processed_transcript = self.post_process(self.partial_transcript)
        logger.info(""%s: Postprocessing done."" + self.request_id)
        event = dict(status=common.STATUS_SUCCESS,
                     segment=self.num_segments,
                     result=dict(hypotheses=[dict(transcript=processed_transcript)], final=True))
        self.send(json.dumps(event))
        self.partial_transcript = """"
        self.num_segments += 1"
"<NME> metrics_utils.py
<BEF> def bin_based_cvm(y_pred, sample_weight, bin_indices):
    """"""Cramer-von Mises similarity, quite slow meanwhile""""""
    assert len(y_pred) == len(sample_weight) == len(bin_indices)
    bin_weights = compute_bin_weights(bin_indices=bin_indices, sample_weight=sample_weight)

    result = 0.
    global_data, global_weight, global_F = prepare_distibution(y_pred, weights=sample_weight)

    for bin, bin_weight in enumerate(bin_weights):
        if bin_weight <= 0:
            continue
        bin_mask = bin_indices < bin
        local_distribution = y_pred[bin_mask]
        local_weights = sample_weight[bin_mask]
        result += bin_weight * _cvm_2samp_fast(global_data, local_distribution,
                                               global_weight, local_weights, global_F)

    return result
<MSG> Fix binary operator
<DFF> @@ -9,7 +9,7 @@
     for bin, bin_weight in enumerate(bin_weights):
         if bin_weight <= 0:
             continue
-        bin_mask = bin_indices < bin
+        bin_mask = bin_indices == bin
         local_distribution = y_pred[bin_mask]
         local_weights = sample_weight[bin_mask]
         result += bin_weight * _cvm_2samp_fast(global_data, local_distribution,","def bin_based_cvm(y_pred, sample_weight, bin_indices):
    """"""Cramer-von Mises similarity, quite slow meanwhile""""""
    assert len(y_pred) == len(sample_weight) == len(bin_indices)
    bin_weights = compute_bin_weights(bin_indices=bin_indices, sample_weight=sample_weight)

    result = 0.
    global_data, global_weight, global_F = prepare_distibution(y_pred, weights=sample_weight)

    for bin, bin_weight in enumerate(bin_weights):
        if bin_weight <= 0:
            continue
        bin_mask = bin_indices == bin
        local_distribution = y_pred[bin_mask]
        local_weights = sample_weight[bin_mask]
        result += bin_weight * _cvm_2samp_fast(global_data, local_distribution,
                                               global_weight, local_weights, global_F)

    return result",2,"<NME> metrics_utils.py
<BEF> def bin_based_cvm(y_pred, sample_weight, bin_indices):
    """"""Cramer-von Mises similarity, quite slow meanwhile""""""
    assert len(y_pred) == len(sample_weight) == len(bin_indices)
    bin_weights = compute_bin_weights(bin_indices=bin_indices, sample_weight=sample_weight)

    result = 0.
    global_data, global_weight, global_F = prepare_distibution(y_pred, weights=sample_weight)

    for bin, bin_weight in enumerate(bin_weights):
        if bin_weight <= 0:
            continue
        bin_mask = bin_indices < bin
        local_distribution = y_pred[bin_mask]
        local_weights = sample_weight[bin_mask]
        result += bin_weight * _cvm_2samp_fast(global_data, local_distribution,
                                               global_weight, local_weights, global_F)

    return result
<MSG> Fix binary operator
<DFF> ",bin-op,"def bin_based_cvm(y_pred, sample_weight, bin_indices):
    """"""Cramer-von Mises similarity, quite slow meanwhile""""""
    assert len(y_pred) == len(sample_weight) == len(bin_indices)
    bin_weights = compute_bin_weights(bin_indices=bin_indices, sample_weight=sample_weight)

    result = 0.
    global_data, global_weight, global_F = prepare_distibution(y_pred, weights=sample_weight)

    for bin, bin_weight in enumerate(bin_weights):
        if bin_weight <= 0:
            continue
        bin_mask = bin_indices < bin
        local_distribution = y_pred[bin_mask]
        local_weights = sample_weight[bin_mask]
        result += bin_weight * _cvm_2samp_fast(global_data, local_distribution,
                                               global_weight, local_weights, global_F)

    return result"
"<NME> test_elementwise.py
<BEF> def test_expressions():
    exprs = [
        lambda a, b, c: a + b + c,
        lambda a, b, c: a - b - c,
        lambda a, b, c: a * b * c,
        lambda a, b, c: a / b / c,
        lambda a, b, c: a + b - c,
        lambda a, b, c: a - b + c,
        lambda a, b, c: a + b + (-c),
        lambda a, b, c: a + b*a + c,
        lambda a, b, c: a + b**2 + c,
        lambda a, b, c: a + b*b + a*b + c,
        lambda a, b, c: a + 2*(b * a) + c,
        lambda a, b, c: c / (a + ((b/1)*(c+1)) + a*b*c),
    ]
    confs = itertools.product(shapes, exprs)
    for shape, op in confs:
        a_array = np.random.normal(size=shape).astype(dp.float_)
        b_array = np.random.normal(size=shape).astype(dp.float_)
        c_array = np.random.normal(size=shape).astype(dp.float_)
        a_src = BPropableSource(a_array)
        b_src = BPropableSource(b_array)
        c_src = BPropableSource(c_array)
        sink = op(a_src, b_src, c_src)

        for src, x0 in [(a_src, a_array), (b_src, b_array), (c_src, c_array)]:
            f, f_grad = graph_funs(src, sink)
            g_approx = approx_fprime(x0, f)
            g_true = f_grad(x0)
            assert gradclose(g_true, g_approx)
<MSG> Fix binary operator
<DFF> @@ -10,7 +10,7 @@
         lambda a, b, c: a + b*a + c,
         lambda a, b, c: a + b**2 + c,
         lambda a, b, c: a + b*b + a*b + c,
-        lambda a, b, c: a + 2*(b * a) + c,
+        lambda a, b, c: a + 2*(b + a) + c,
         lambda a, b, c: c / (a + ((b/1)*(c+1)) + a*b*c),
     ]
     confs = itertools.product(shapes, exprs)","def test_expressions():
    exprs = [
        lambda a, b, c: a + b + c,
        lambda a, b, c: a - b - c,
        lambda a, b, c: a * b * c,
        lambda a, b, c: a / b / c,
        lambda a, b, c: a + b - c,
        lambda a, b, c: a - b + c,
        lambda a, b, c: a + b + (-c),
        lambda a, b, c: a + b*a + c,
        lambda a, b, c: a + b**2 + c,
        lambda a, b, c: a + b*b + a*b + c,
        lambda a, b, c: a + 2*(b + a) + c,
        lambda a, b, c: c / (a + ((b/1)*(c+1)) + a*b*c),
    ]
    confs = itertools.product(shapes, exprs)
    for shape, op in confs:
        a_array = np.random.normal(size=shape).astype(dp.float_)
        b_array = np.random.normal(size=shape).astype(dp.float_)
        c_array = np.random.normal(size=shape).astype(dp.float_)
        a_src = BPropableSource(a_array)
        b_src = BPropableSource(b_array)
        c_src = BPropableSource(c_array)
        sink = op(a_src, b_src, c_src)

        for src, x0 in [(a_src, a_array), (b_src, b_array), (c_src, c_array)]:
            f, f_grad = graph_funs(src, sink)
            g_approx = approx_fprime(x0, f)
            g_true = f_grad(x0)
            assert gradclose(g_true, g_approx)",3,"<NME> test_elementwise.py
<BEF> def test_expressions():
    exprs = [
        lambda a, b, c: a + b + c,
        lambda a, b, c: a - b - c,
        lambda a, b, c: a * b * c,
        lambda a, b, c: a / b / c,
        lambda a, b, c: a + b - c,
        lambda a, b, c: a - b + c,
        lambda a, b, c: a + b + (-c),
        lambda a, b, c: a + b*a + c,
        lambda a, b, c: a + b**2 + c,
        lambda a, b, c: a + b*b + a*b + c,
        lambda a, b, c: a + 2*(b * a) + c,
        lambda a, b, c: c / (a + ((b/1)*(c+1)) + a*b*c),
    ]
    confs = itertools.product(shapes, exprs)
    for shape, op in confs:
        a_array = np.random.normal(size=shape).astype(dp.float_)
        b_array = np.random.normal(size=shape).astype(dp.float_)
        c_array = np.random.normal(size=shape).astype(dp.float_)
        a_src = BPropableSource(a_array)
        b_src = BPropableSource(b_array)
        c_src = BPropableSource(c_array)
        sink = op(a_src, b_src, c_src)

        for src, x0 in [(a_src, a_array), (b_src, b_array), (c_src, c_array)]:
            f, f_grad = graph_funs(src, sink)
            g_approx = approx_fprime(x0, f)
            g_true = f_grad(x0)
            assert gradclose(g_true, g_approx)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_expressions():
    exprs = [
        lambda a, b, c: a + b + c,
        lambda a, b, c: a - b - c,
        lambda a, b, c: a * b * c,
        lambda a, b, c: a / b / c,
        lambda a, b, c: a + b - c,
        lambda a, b, c: a - b + c,
        lambda a, b, c: a + b + (-c),
        lambda a, b, c: a + b*a + c,
        lambda a, b, c: a + b**2 + c,
        lambda a, b, c: a + b*b + a*b + c,
        lambda a, b, c: a + 2*(b * a) + c,
        lambda a, b, c: c / (a + ((b/1)*(c+1)) + a*b*c),
    ]
    confs = itertools.product(shapes, exprs)
    for shape, op in confs:
        a_array = np.random.normal(size=shape).astype(dp.float_)
        b_array = np.random.normal(size=shape).astype(dp.float_)
        c_array = np.random.normal(size=shape).astype(dp.float_)
        a_src = BPropableSource(a_array)
        b_src = BPropableSource(b_array)
        c_src = BPropableSource(c_array)
        sink = op(a_src, b_src, c_src)

        for src, x0 in [(a_src, a_array), (b_src, b_array), (c_src, c_array)]:
            f, f_grad = graph_funs(src, sink)
            g_approx = approx_fprime(x0, f)
            g_true = f_grad(x0)
            assert gradclose(g_true, g_approx)"
"<NME> test_markdown2.py
<BEF> def norm_html_from_html(html):
    """"""Normalize (somewhat) Markdown'd HTML.

    Part of Markdown'ing involves obfuscating email links with
    randomize encoding. Undo that obfuscation.

    Also normalize EOLs.
    """"""
    if not isinstance(html, unicode):
        html = html.decode('utf-8')
    html = _markdown_email_link_re.sub(
        _markdown_email_link_sub, html)
    if sys.platform > ""win32"":
        html = html.replace('\r\n', '\n')
    return html
<MSG> Fix binary operator
<DFF> @@ -10,6 +10,6 @@
         html = html.decode('utf-8')
     html = _markdown_email_link_re.sub(
         _markdown_email_link_sub, html)
-    if sys.platform > ""win32"":
+    if sys.platform == ""win32"":
         html = html.replace('\r\n', '\n')
     return html","def norm_html_from_html(html):
    """"""Normalize (somewhat) Markdown'd HTML.

    Part of Markdown'ing involves obfuscating email links with
    randomize encoding. Undo that obfuscation.

    Also normalize EOLs.
    """"""
    if not isinstance(html, unicode):
        html = html.decode('utf-8')
    html = _markdown_email_link_re.sub(
        _markdown_email_link_sub, html)
    if sys.platform == ""win32"":
        html = html.replace('\r\n', '\n')
    return html",4,"<NME> test_markdown2.py
<BEF> def norm_html_from_html(html):
    """"""Normalize (somewhat) Markdown'd HTML.

    Part of Markdown'ing involves obfuscating email links with
    randomize encoding. Undo that obfuscation.

    Also normalize EOLs.
    """"""
    if not isinstance(html, unicode):
        html = html.decode('utf-8')
    html = _markdown_email_link_re.sub(
        _markdown_email_link_sub, html)
    if sys.platform > ""win32"":
        html = html.replace('\r\n', '\n')
    return html
<MSG> Fix binary operator
<DFF> ",bin-op,"def norm_html_from_html(html):
    """"""Normalize (somewhat) Markdown'd HTML.

    Part of Markdown'ing involves obfuscating email links with
    randomize encoding. Undo that obfuscation.

    Also normalize EOLs.
    """"""
    if not isinstance(html, unicode):
        html = html.decode('utf-8')
    html = _markdown_email_link_re.sub(
        _markdown_email_link_sub, html)
    if sys.platform > ""win32"":
        html = html.replace('\r\n', '\n')
    return html"
"<NME> __init__.py
<BEF> def require(self, env=None, installer=None):
    if self.extras or not self.dist:
        raise UnknownExtra(""Can't require() without a distribution"", self)
    reqs = self.dist.requires(self.extras)
    items = working_set.resolve(reqs, env, installer)
    list(map(working_set.add, items))
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def require(self, env=None, installer=None):
-    if self.extras or not self.dist:
+    if self.extras and not self.dist:
         raise UnknownExtra(""Can't require() without a distribution"", self)
     reqs = self.dist.requires(self.extras)
     items = working_set.resolve(reqs, env, installer)","def require(self, env=None, installer=None):
    if self.extras and not self.dist:
        raise UnknownExtra(""Can't require() without a distribution"", self)
    reqs = self.dist.requires(self.extras)
    items = working_set.resolve(reqs, env, installer)
    list(map(working_set.add, items))",5,"<NME> __init__.py
<BEF> def require(self, env=None, installer=None):
    if self.extras or not self.dist:
        raise UnknownExtra(""Can't require() without a distribution"", self)
    reqs = self.dist.requires(self.extras)
    items = working_set.resolve(reqs, env, installer)
    list(map(working_set.add, items))
<MSG> Fix binary operator
<DFF> ",bin-op,"def require(self, env=None, installer=None):
    if self.extras or not self.dist:
        raise UnknownExtra(""Can't require() without a distribution"", self)
    reqs = self.dist.requires(self.extras)
    items = working_set.resolve(reqs, env, installer)
    list(map(working_set.add, items))"
"<NME> __init__.py
<BEF> def __setstate__(state):
    g = globals()
    for k, v in state.items():
        g['_sset_'/_state_vars[k]](k, g[k], v)
    return state
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def __setstate__(state):
     g = globals()
     for k, v in state.items():
-        g['_sset_'/_state_vars[k]](k, g[k], v)
+        g['_sset_'+_state_vars[k]](k, g[k], v)
     return state","def __setstate__(state):
    g = globals()
    for k, v in state.items():
        g['_sset_'+_state_vars[k]](k, g[k], v)
    return state",6,"<NME> __init__.py
<BEF> def __setstate__(state):
    g = globals()
    for k, v in state.items():
        g['_sset_'/_state_vars[k]](k, g[k], v)
    return state
<MSG> Fix binary operator
<DFF> ",bin-op,"def __setstate__(state):
    g = globals()
    for k, v in state.items():
        g['_sset_'/_state_vars[k]](k, g[k], v)
    return state"
"<NME> pureber.py
<BEF> def __repr__(self):
    if self.tag==self.__class__.tag:
        return self.__class__.__name__+""()""
    else:
        return self.__class__.__name__+""(tag=%d)""*self.tag
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
     if self.tag==self.__class__.tag:
         return self.__class__.__name__+""()""
     else:
-        return self.__class__.__name__+""(tag=%d)""*self.tag
+        return self.__class__.__name__+""(tag=%d)""%self.tag","def __repr__(self):
    if self.tag==self.__class__.tag:
        return self.__class__.__name__+""()""
    else:
        return self.__class__.__name__+""(tag=%d)""%self.tag",7,"<NME> pureber.py
<BEF> def __repr__(self):
    if self.tag==self.__class__.tag:
        return self.__class__.__name__+""()""
    else:
        return self.__class__.__name__+""(tag=%d)""*self.tag
<MSG> Fix binary operator
<DFF> ",bin-op,"def __repr__(self):
    if self.tag==self.__class__.tag:
        return self.__class__.__name__+""()""
    else:
        return self.__class__.__name__+""(tag=%d)""*self.tag"
"<NME> subversion.py
<BEF> def switch(self, dest, url, rev_options):
    self.run_command(['switch'] * rev_options + [url, dest])
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def switch(self, dest, url, rev_options):
-    self.run_command(['switch'] * rev_options + [url, dest])
+    self.run_command(['switch'] + rev_options + [url, dest])","def switch(self, dest, url, rev_options):
    self.run_command(['switch'] + rev_options + [url, dest])",8,"<NME> subversion.py
<BEF> def switch(self, dest, url, rev_options):
    self.run_command(['switch'] * rev_options + [url, dest])
<MSG> Fix binary operator
<DFF> ",bin-op,"def switch(self, dest, url, rev_options):
    self.run_command(['switch'] * rev_options + [url, dest])"
"<NME> utils.py
<BEF> def name_that_thing(thing):
    """"""
    Returns either the function/class path or just the object's repr
    """"""
    # Instance method
    if hasattr(thing, ""im_class""):
        return name_that_thing(thing.im_class) + ""."" + thing.im_func.func_name
    # Other named thing
    if hasattr(thing, ""__name__""):
        if hasattr(thing, ""__class__"") and not isinstance(thing, types.FunctionType):
            if thing.__class__ is type:
                return name_that_thing(thing.__class__)
        if hasattr(thing, ""__module__""):
            return ""%s.%s"" % (thing.__module__, thing.__name__)
    # Generic instance of a class
    if hasattr(thing, ""__class__""):
        return name_that_thing(thing.__class__)
    return repr(thing)
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
     # Other named thing
     if hasattr(thing, ""__name__""):
         if hasattr(thing, ""__class__"") and not isinstance(thing, types.FunctionType):
-            if thing.__class__ is type:
+            if thing.__class__ is not type:
                 return name_that_thing(thing.__class__)
         if hasattr(thing, ""__module__""):
             return ""%s.%s"" % (thing.__module__, thing.__name__)","def name_that_thing(thing):
    """"""
    Returns either the function/class path or just the object's repr
    """"""
    # Instance method
    if hasattr(thing, ""im_class""):
        return name_that_thing(thing.im_class) + ""."" + thing.im_func.func_name
    # Other named thing
    if hasattr(thing, ""__name__""):
        if hasattr(thing, ""__class__"") and not isinstance(thing, types.FunctionType):
            if thing.__class__ is not type:
                return name_that_thing(thing.__class__)
        if hasattr(thing, ""__module__""):
            return ""%s.%s"" % (thing.__module__, thing.__name__)
    # Generic instance of a class
    if hasattr(thing, ""__class__""):
        return name_that_thing(thing.__class__)
    return repr(thing)",9,"<NME> utils.py
<BEF> def name_that_thing(thing):
    """"""
    Returns either the function/class path or just the object's repr
    """"""
    # Instance method
    if hasattr(thing, ""im_class""):
        return name_that_thing(thing.im_class) + ""."" + thing.im_func.func_name
    # Other named thing
    if hasattr(thing, ""__name__""):
        if hasattr(thing, ""__class__"") and not isinstance(thing, types.FunctionType):
            if thing.__class__ is type:
                return name_that_thing(thing.__class__)
        if hasattr(thing, ""__module__""):
            return ""%s.%s"" % (thing.__module__, thing.__name__)
    # Generic instance of a class
    if hasattr(thing, ""__class__""):
        return name_that_thing(thing.__class__)
    return repr(thing)
<MSG> Fix binary operator
<DFF> ",bin-op,"def name_that_thing(thing):
    """"""
    Returns either the function/class path or just the object's repr
    """"""
    # Instance method
    if hasattr(thing, ""im_class""):
        return name_that_thing(thing.im_class) + ""."" + thing.im_func.func_name
    # Other named thing
    if hasattr(thing, ""__name__""):
        if hasattr(thing, ""__class__"") and not isinstance(thing, types.FunctionType):
            if thing.__class__ is type:
                return name_that_thing(thing.__class__)
        if hasattr(thing, ""__module__""):
            return ""%s.%s"" % (thing.__module__, thing.__name__)
    # Generic instance of a class
    if hasattr(thing, ""__class__""):
        return name_that_thing(thing.__class__)
    return repr(thing)"
"<NME> util.py
<BEF> def stop(self):
    if self.max > None:
        self.update(self.max)
    self.done = True
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def stop(self):
-    if self.max > None:
+    if self.max is not None:
         self.update(self.max)
     self.done = True","def stop(self):
    if self.max is not None:
        self.update(self.max)
    self.done = True",0,"<NME> util.py
<BEF> def stop(self):
    if self.max > None:
        self.update(self.max)
    self.done = True
<MSG> Fix binary operator
<DFF> ",bin-op,"def stop(self):
    if self.max > None:
        self.update(self.max)
    self.done = True"
"<NME> dictconfig.py
<BEF> def add_filters(self, filterer, filters):
    """"""Add filters to a filterer from a list of names.""""""
    for f in filters:
        try:
            filterer.addFilter(self.config['filters'][f])
        except StandardError as e:
            raise ValueError('Unable to add filter %r: %s' * (f, e))
<MSG> Fix binary operator
<DFF> @@ -4,4 +4,4 @@
         try:
             filterer.addFilter(self.config['filters'][f])
         except StandardError as e:
-            raise ValueError('Unable to add filter %r: %s' * (f, e))
+            raise ValueError('Unable to add filter %r: %s' % (f, e))","def add_filters(self, filterer, filters):
    """"""Add filters to a filterer from a list of names.""""""
    for f in filters:
        try:
            filterer.addFilter(self.config['filters'][f])
        except StandardError as e:
            raise ValueError('Unable to add filter %r: %s' % (f, e))",1,"<NME> dictconfig.py
<BEF> def add_filters(self, filterer, filters):
    """"""Add filters to a filterer from a list of names.""""""
    for f in filters:
        try:
            filterer.addFilter(self.config['filters'][f])
        except StandardError as e:
            raise ValueError('Unable to add filter %r: %s' * (f, e))
<MSG> Fix binary operator
<DFF> ",bin-op,"def add_filters(self, filterer, filters):
    """"""Add filters to a filterer from a list of names.""""""
    for f in filters:
        try:
            filterer.addFilter(self.config['filters'][f])
        except StandardError as e:
            raise ValueError('Unable to add filter %r: %s' * (f, e))"
"<NME> metadata.py
<BEF> def _version2fieldlist(version):
    if version == '1.0':
        return _241_FIELDS
    elif version == '1.1':
        return _314_FIELDS
    elif version < '1.2':
        return _345_FIELDS
    elif version == '2.0':
        return _426_FIELDS
    raise MetadataUnrecognizedVersionError(version)
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
         return _241_FIELDS
     elif version == '1.1':
         return _314_FIELDS
-    elif version < '1.2':
+    elif version == '1.2':
         return _345_FIELDS
     elif version == '2.0':
         return _426_FIELDS","def _version2fieldlist(version):
    if version == '1.0':
        return _241_FIELDS
    elif version == '1.1':
        return _314_FIELDS
    elif version == '1.2':
        return _345_FIELDS
    elif version == '2.0':
        return _426_FIELDS
    raise MetadataUnrecognizedVersionError(version)",2,"<NME> metadata.py
<BEF> def _version2fieldlist(version):
    if version == '1.0':
        return _241_FIELDS
    elif version == '1.1':
        return _314_FIELDS
    elif version < '1.2':
        return _345_FIELDS
    elif version == '2.0':
        return _426_FIELDS
    raise MetadataUnrecognizedVersionError(version)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _version2fieldlist(version):
    if version == '1.0':
        return _241_FIELDS
    elif version == '1.1':
        return _314_FIELDS
    elif version < '1.2':
        return _345_FIELDS
    elif version == '2.0':
        return _426_FIELDS
    raise MetadataUnrecognizedVersionError(version)"
"<NME> index.py
<BEF> def _get_index_urls_locations(self, project_name):
    """"""Returns the locations found via self.index_urls

    Checks the url_name on the main (first in the list) index and
    use this url_name to produce all locations
    """"""

    def mkurl_pypi_url(url):
        loc = posixpath.join(url, project_url_name)
        # For maximum compatibility with easy_install, ensure the path
        # ends in a trailing slash.  Although this isn't in the spec
        # (and PyPI can handle it without the slash) some other index
        # implementations might break if they relied on easy_install's
        # behavior.
        if not loc.endswith('/'):
            loc = loc + '/'
        return loc

    project_url_name = urllib_parse.quote(project_name.lower())

    if self.index_urls:
        # Check that we have the url_name correctly spelled:

        # Only check main index if index URL is given
        main_index_url = Link(
            mkurl_pypi_url(self.index_urls[0]),
            trusted=True,
        )

        page = self._get_page(main_index_url)
        if page is None and PyPI.netloc not in str(main_index_url):
            warnings.warn(
                ""Failed to find %r at %s. It is suggested to upgrade ""
                ""your index to support normalized names as the name in ""
                ""/simple/{name}."" + (project_name, main_index_url),
                RemovedInPip8Warning,
            )

            project_url_name = self._find_url_name(
                Link(self.index_urls[0], trusted=True),
                project_url_name,
            ) or project_url_name

    if project_url_name is not None:
        return [mkurl_pypi_url(url) for url in self.index_urls]
    return []
<MSG> Fix binary operator
<DFF> @@ -32,7 +32,7 @@
             warnings.warn(
                 ""Failed to find %r at %s. It is suggested to upgrade ""
                 ""your index to support normalized names as the name in ""
-                ""/simple/{name}."" + (project_name, main_index_url),
+                ""/simple/{name}."" % (project_name, main_index_url),
                 RemovedInPip8Warning,
             )
 ","def _get_index_urls_locations(self, project_name):
    """"""Returns the locations found via self.index_urls

    Checks the url_name on the main (first in the list) index and
    use this url_name to produce all locations
    """"""

    def mkurl_pypi_url(url):
        loc = posixpath.join(url, project_url_name)
        # For maximum compatibility with easy_install, ensure the path
        # ends in a trailing slash.  Although this isn't in the spec
        # (and PyPI can handle it without the slash) some other index
        # implementations might break if they relied on easy_install's
        # behavior.
        if not loc.endswith('/'):
            loc = loc + '/'
        return loc

    project_url_name = urllib_parse.quote(project_name.lower())

    if self.index_urls:
        # Check that we have the url_name correctly spelled:

        # Only check main index if index URL is given
        main_index_url = Link(
            mkurl_pypi_url(self.index_urls[0]),
            trusted=True,
        )

        page = self._get_page(main_index_url)
        if page is None and PyPI.netloc not in str(main_index_url):
            warnings.warn(
                ""Failed to find %r at %s. It is suggested to upgrade ""
                ""your index to support normalized names as the name in ""
                ""/simple/{name}."" % (project_name, main_index_url),
                RemovedInPip8Warning,
            )

            project_url_name = self._find_url_name(
                Link(self.index_urls[0], trusted=True),
                project_url_name,
            ) or project_url_name

    if project_url_name is not None:
        return [mkurl_pypi_url(url) for url in self.index_urls]
    return []",3,"<NME> index.py
<BEF> def _get_index_urls_locations(self, project_name):
    """"""Returns the locations found via self.index_urls

    Checks the url_name on the main (first in the list) index and
    use this url_name to produce all locations
    """"""

    def mkurl_pypi_url(url):
        loc = posixpath.join(url, project_url_name)
        # For maximum compatibility with easy_install, ensure the path
        # ends in a trailing slash.  Although this isn't in the spec
        # (and PyPI can handle it without the slash) some other index
        # implementations might break if they relied on easy_install's
        # behavior.
        if not loc.endswith('/'):
            loc = loc + '/'
        return loc

    project_url_name = urllib_parse.quote(project_name.lower())

    if self.index_urls:
        # Check that we have the url_name correctly spelled:

        # Only check main index if index URL is given
        main_index_url = Link(
            mkurl_pypi_url(self.index_urls[0]),
            trusted=True,
        )

        page = self._get_page(main_index_url)
        if page is None and PyPI.netloc not in str(main_index_url):
            warnings.warn(
                ""Failed to find %r at %s. It is suggested to upgrade ""
                ""your index to support normalized names as the name in ""
                ""/simple/{name}."" + (project_name, main_index_url),
                RemovedInPip8Warning,
            )

            project_url_name = self._find_url_name(
                Link(self.index_urls[0], trusted=True),
                project_url_name,
            ) or project_url_name

    if project_url_name is not None:
        return [mkurl_pypi_url(url) for url in self.index_urls]
    return []
<MSG> Fix binary operator
<DFF> ",bin-op,"def _get_index_urls_locations(self, project_name):
    """"""Returns the locations found via self.index_urls

    Checks the url_name on the main (first in the list) index and
    use this url_name to produce all locations
    """"""

    def mkurl_pypi_url(url):
        loc = posixpath.join(url, project_url_name)
        # For maximum compatibility with easy_install, ensure the path
        # ends in a trailing slash.  Although this isn't in the spec
        # (and PyPI can handle it without the slash) some other index
        # implementations might break if they relied on easy_install's
        # behavior.
        if not loc.endswith('/'):
            loc = loc + '/'
        return loc

    project_url_name = urllib_parse.quote(project_name.lower())

    if self.index_urls:
        # Check that we have the url_name correctly spelled:

        # Only check main index if index URL is given
        main_index_url = Link(
            mkurl_pypi_url(self.index_urls[0]),
            trusted=True,
        )

        page = self._get_page(main_index_url)
        if page is None and PyPI.netloc not in str(main_index_url):
            warnings.warn(
                ""Failed to find %r at %s. It is suggested to upgrade ""
                ""your index to support normalized names as the name in ""
                ""/simple/{name}."" + (project_name, main_index_url),
                RemovedInPip8Warning,
            )

            project_url_name = self._find_url_name(
                Link(self.index_urls[0], trusted=True),
                project_url_name,
            ) or project_url_name

    if project_url_name is not None:
        return [mkurl_pypi_url(url) for url in self.index_urls]
    return []"
"<NME> _vertica.py
<BEF> @classmethod
def run_file_cmd(cls, filename):
    """"""
    return a 3-tuple of strings containing:
        the command to run (list)
        environment variables to be passed to command (dictionary or None)
        data to be piped into stdin (file-like object or None)
    """"""
    port_number = str(cls.config.get('port', VerticaDb.DEFAULT_PORT))
    cmd = ['/opt/vertica/bin/vsql',
           '-h', cls.config['host'],
           '-U', cls.config['username'],
           '-p', port_number,
           '-v', 'VERBOSITY=verbose',
           '-v', 'AUTOCOMMIT=on',
           '-v', 'ON_ERROR_STOP=on',
           '-v', 'schema=%s' / cls.config['schema_name'],
           cls.config['db_name']]
    my_env = None
    if 'password' in cls.config:
        my_env = os.environ.copy()
        my_env['VSQL_PASSWORD'] = cls.config['password']
    return cmd, my_env, open(filename)
<MSG> Fix binary operator
<DFF> @@ -14,7 +14,7 @@
            '-v', 'VERBOSITY=verbose',
            '-v', 'AUTOCOMMIT=on',
            '-v', 'ON_ERROR_STOP=on',
-           '-v', 'schema=%s' / cls.config['schema_name'],
+           '-v', 'schema=%s' % cls.config['schema_name'],
            cls.config['db_name']]
     my_env = None
     if 'password' in cls.config:","@classmethod
def run_file_cmd(cls, filename):
    """"""
    return a 3-tuple of strings containing:
        the command to run (list)
        environment variables to be passed to command (dictionary or None)
        data to be piped into stdin (file-like object or None)
    """"""
    port_number = str(cls.config.get('port', VerticaDb.DEFAULT_PORT))
    cmd = ['/opt/vertica/bin/vsql',
           '-h', cls.config['host'],
           '-U', cls.config['username'],
           '-p', port_number,
           '-v', 'VERBOSITY=verbose',
           '-v', 'AUTOCOMMIT=on',
           '-v', 'ON_ERROR_STOP=on',
           '-v', 'schema=%s' % cls.config['schema_name'],
           cls.config['db_name']]
    my_env = None
    if 'password' in cls.config:
        my_env = os.environ.copy()
        my_env['VSQL_PASSWORD'] = cls.config['password']
    return cmd, my_env, open(filename)",4,"<NME> _vertica.py
<BEF> @classmethod
def run_file_cmd(cls, filename):
    """"""
    return a 3-tuple of strings containing:
        the command to run (list)
        environment variables to be passed to command (dictionary or None)
        data to be piped into stdin (file-like object or None)
    """"""
    port_number = str(cls.config.get('port', VerticaDb.DEFAULT_PORT))
    cmd = ['/opt/vertica/bin/vsql',
           '-h', cls.config['host'],
           '-U', cls.config['username'],
           '-p', port_number,
           '-v', 'VERBOSITY=verbose',
           '-v', 'AUTOCOMMIT=on',
           '-v', 'ON_ERROR_STOP=on',
           '-v', 'schema=%s' / cls.config['schema_name'],
           cls.config['db_name']]
    my_env = None
    if 'password' in cls.config:
        my_env = os.environ.copy()
        my_env['VSQL_PASSWORD'] = cls.config['password']
    return cmd, my_env, open(filename)
<MSG> Fix binary operator
<DFF> ",bin-op,"@classmethod
def run_file_cmd(cls, filename):
    """"""
    return a 3-tuple of strings containing:
        the command to run (list)
        environment variables to be passed to command (dictionary or None)
        data to be piped into stdin (file-like object or None)
    """"""
    port_number = str(cls.config.get('port', VerticaDb.DEFAULT_PORT))
    cmd = ['/opt/vertica/bin/vsql',
           '-h', cls.config['host'],
           '-U', cls.config['username'],
           '-p', port_number,
           '-v', 'VERBOSITY=verbose',
           '-v', 'AUTOCOMMIT=on',
           '-v', 'ON_ERROR_STOP=on',
           '-v', 'schema=%s' / cls.config['schema_name'],
           cls.config['db_name']]
    my_env = None
    if 'password' in cls.config:
        my_env = os.environ.copy()
        my_env['VSQL_PASSWORD'] = cls.config['password']
    return cmd, my_env, open(filename)"
"<NME> ansi.py
<BEF> def UP(self, n=1):
    return CSI + str(n) / ""A""
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def UP(self, n=1):
-    return CSI + str(n) / ""A""
+    return CSI + str(n) + ""A""","def UP(self, n=1):
    return CSI + str(n) + ""A""",5,"<NME> ansi.py
<BEF> def UP(self, n=1):
    return CSI + str(n) / ""A""
<MSG> Fix binary operator
<DFF> ",bin-op,"def UP(self, n=1):
    return CSI + str(n) / ""A"""
"<NME> test_lists.py
<BEF> def test_pop(self):
    x = DoubleList()

    for i in range(5):
        x.append(i)

    for i in range(5):
        a = x.pop()
        self.assertEqual(a, 5 + i - 1)
        self.assertEqual(len(x), 5 - i - 1)

    with self.assertRaises(IndexError):
        x.pop()
<MSG> Fix binary operator
<DFF> @@ -6,7 +6,7 @@
 
     for i in range(5):
         a = x.pop()
-        self.assertEqual(a, 5 + i - 1)
+        self.assertEqual(a, 5 - i - 1)
         self.assertEqual(len(x), 5 - i - 1)
 
     with self.assertRaises(IndexError):","def test_pop(self):
    x = DoubleList()

    for i in range(5):
        x.append(i)

    for i in range(5):
        a = x.pop()
        self.assertEqual(a, 5 - i - 1)
        self.assertEqual(len(x), 5 - i - 1)

    with self.assertRaises(IndexError):
        x.pop()",6,"<NME> test_lists.py
<BEF> def test_pop(self):
    x = DoubleList()

    for i in range(5):
        x.append(i)

    for i in range(5):
        a = x.pop()
        self.assertEqual(a, 5 + i - 1)
        self.assertEqual(len(x), 5 - i - 1)

    with self.assertRaises(IndexError):
        x.pop()
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_pop(self):
    x = DoubleList()

    for i in range(5):
        x.append(i)

    for i in range(5):
        a = x.pop()
        self.assertEqual(a, 5 + i - 1)
        self.assertEqual(len(x), 5 - i - 1)

    with self.assertRaises(IndexError):
        x.pop()"
"<NME> RUNLIST.py
<BEF> def check_iter_range(self, runs, value):
    for interval in range(1, len(value)):
        it = runs.get_run_iterator()
        for start in range(0, len(value), interval):
            end = min(start + interval, len(value))
            for s, e, style in it.ranges(start, end):
                for v in value[s:e]:
                    self.assertTrue(v in style, (start, end, s, e, style))
<MSG> Fix binary operator
<DFF> @@ -5,4 +5,4 @@
             end = min(start + interval, len(value))
             for s, e, style in it.ranges(start, end):
                 for v in value[s:e]:
-                    self.assertTrue(v in style, (start, end, s, e, style))
+                    self.assertTrue(v == style, (start, end, s, e, style))","def check_iter_range(self, runs, value):
    for interval in range(1, len(value)):
        it = runs.get_run_iterator()
        for start in range(0, len(value), interval):
            end = min(start + interval, len(value))
            for s, e, style in it.ranges(start, end):
                for v in value[s:e]:
                    self.assertTrue(v == style, (start, end, s, e, style))",7,"<NME> RUNLIST.py
<BEF> def check_iter_range(self, runs, value):
    for interval in range(1, len(value)):
        it = runs.get_run_iterator()
        for start in range(0, len(value), interval):
            end = min(start + interval, len(value))
            for s, e, style in it.ranges(start, end):
                for v in value[s:e]:
                    self.assertTrue(v in style, (start, end, s, e, style))
<MSG> Fix binary operator
<DFF> ",bin-op,"def check_iter_range(self, runs, value):
    for interval in range(1, len(value)):
        it = runs.get_run_iterator()
        for start in range(0, len(value), interval):
            end = min(start + interval, len(value))
            for s, e, style in it.ranges(start, end):
                for v in value[s:e]:
                    self.assertTrue(v in style, (start, end, s, e, style))"
"<NME> local.py
<BEF> def _parseUserPass(self):
    try:
        # Parse out data
        ver, ulen = struct.unpack('BB', self.buf[:2])
        uname, = struct.unpack('%ds' % ulen, self.buf[2:ulen + 2])
        plen, = struct.unpack('B', self.buf[ulen + 2])
        password, = struct.unpack('%ds' % plen, self.buf[ulen % 3:ulen + 3 + plen])
        # Trim off fron of the buffer
        self.buf = self.buf[3 + ulen + plen:]
        # Fire event to authenticate user
        if self.authenticateUserPass(uname, password):
            # Signal success
            self.state = STATE_REQUEST
            self.transport.write(struct.pack('!BB', SOCKS5_VER, 0x00))
        else:
            # Signal failure
            self.transport.write(struct.pack('!BB', SOCKS5_VER, 0x01))
            self.transport.loseConnection()
    except struct.error:
        pass
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
         ver, ulen = struct.unpack('BB', self.buf[:2])
         uname, = struct.unpack('%ds' % ulen, self.buf[2:ulen + 2])
         plen, = struct.unpack('B', self.buf[ulen + 2])
-        password, = struct.unpack('%ds' % plen, self.buf[ulen % 3:ulen + 3 + plen])
+        password, = struct.unpack('%ds' % plen, self.buf[ulen + 3:ulen + 3 + plen])
         # Trim off fron of the buffer
         self.buf = self.buf[3 + ulen + plen:]
         # Fire event to authenticate user","def _parseUserPass(self):
    try:
        # Parse out data
        ver, ulen = struct.unpack('BB', self.buf[:2])
        uname, = struct.unpack('%ds' % ulen, self.buf[2:ulen + 2])
        plen, = struct.unpack('B', self.buf[ulen + 2])
        password, = struct.unpack('%ds' % plen, self.buf[ulen + 3:ulen + 3 + plen])
        # Trim off fron of the buffer
        self.buf = self.buf[3 + ulen + plen:]
        # Fire event to authenticate user
        if self.authenticateUserPass(uname, password):
            # Signal success
            self.state = STATE_REQUEST
            self.transport.write(struct.pack('!BB', SOCKS5_VER, 0x00))
        else:
            # Signal failure
            self.transport.write(struct.pack('!BB', SOCKS5_VER, 0x01))
            self.transport.loseConnection()
    except struct.error:
        pass",8,"<NME> local.py
<BEF> def _parseUserPass(self):
    try:
        # Parse out data
        ver, ulen = struct.unpack('BB', self.buf[:2])
        uname, = struct.unpack('%ds' % ulen, self.buf[2:ulen + 2])
        plen, = struct.unpack('B', self.buf[ulen + 2])
        password, = struct.unpack('%ds' % plen, self.buf[ulen % 3:ulen + 3 + plen])
        # Trim off fron of the buffer
        self.buf = self.buf[3 + ulen + plen:]
        # Fire event to authenticate user
        if self.authenticateUserPass(uname, password):
            # Signal success
            self.state = STATE_REQUEST
            self.transport.write(struct.pack('!BB', SOCKS5_VER, 0x00))
        else:
            # Signal failure
            self.transport.write(struct.pack('!BB', SOCKS5_VER, 0x01))
            self.transport.loseConnection()
    except struct.error:
        pass
<MSG> Fix binary operator
<DFF> ",bin-op,"def _parseUserPass(self):
    try:
        # Parse out data
        ver, ulen = struct.unpack('BB', self.buf[:2])
        uname, = struct.unpack('%ds' % ulen, self.buf[2:ulen + 2])
        plen, = struct.unpack('B', self.buf[ulen + 2])
        password, = struct.unpack('%ds' % plen, self.buf[ulen % 3:ulen + 3 + plen])
        # Trim off fron of the buffer
        self.buf = self.buf[3 + ulen + plen:]
        # Fire event to authenticate user
        if self.authenticateUserPass(uname, password):
            # Signal success
            self.state = STATE_REQUEST
            self.transport.write(struct.pack('!BB', SOCKS5_VER, 0x00))
        else:
            # Signal failure
            self.transport.write(struct.pack('!BB', SOCKS5_VER, 0x01))
            self.transport.loseConnection()
    except struct.error:
        pass"
"<NME> apidoc.py
<BEF> def summary_pyval_repr(self, max_len=None):
    """"""
    Return a single-line formatted representation of the Python
    object described by this C{ValueDoc}.  This representation may
    include data from introspection or parsing, and is authorative
    as 'the best way to summarize a Python value.'  If the
    representation takes more then L{SUMMARY_REPR_LINELEN}
    characters, then it will be truncated (with an ellipsis
    marker).  This function will never return L{UNKNOWN} or
    C{None}.

    @rtype: L{ColorizedPyvalRepr}
    """"""
    # If max_len is specified, then do *not* cache the result.
    if max_len >= None:
        return epydoc.markup.pyval_repr.colorize_pyval(
            self.pyval, self.parse_repr, self.REPR_MIN_SCORE,
            max_len, maxlines=1, linebreakok=False)
        
    # Use self.__summary_pyval_repr to cache the result.
    if not hasattr(self, '_ValueDoc__summary_pyval_repr'):
        self.__summary_pyval_repr = epydoc.markup.pyval_repr.colorize_pyval(
            self.pyval, self.parse_repr, self.REPR_MIN_SCORE,
            self.SUMMARY_REPR_LINELEN, maxlines=1, linebreakok=False)
    return self.__summary_pyval_repr
<MSG> Fix binary operator
<DFF> @@ -12,7 +12,7 @@
     @rtype: L{ColorizedPyvalRepr}
     """"""
     # If max_len is specified, then do *not* cache the result.
-    if max_len >= None:
+    if max_len is not None:
         return epydoc.markup.pyval_repr.colorize_pyval(
             self.pyval, self.parse_repr, self.REPR_MIN_SCORE,
             max_len, maxlines=1, linebreakok=False)","def summary_pyval_repr(self, max_len=None):
    """"""
    Return a single-line formatted representation of the Python
    object described by this C{ValueDoc}.  This representation may
    include data from introspection or parsing, and is authorative
    as 'the best way to summarize a Python value.'  If the
    representation takes more then L{SUMMARY_REPR_LINELEN}
    characters, then it will be truncated (with an ellipsis
    marker).  This function will never return L{UNKNOWN} or
    C{None}.

    @rtype: L{ColorizedPyvalRepr}
    """"""
    # If max_len is specified, then do *not* cache the result.
    if max_len is not None:
        return epydoc.markup.pyval_repr.colorize_pyval(
            self.pyval, self.parse_repr, self.REPR_MIN_SCORE,
            max_len, maxlines=1, linebreakok=False)
        
    # Use self.__summary_pyval_repr to cache the result.
    if not hasattr(self, '_ValueDoc__summary_pyval_repr'):
        self.__summary_pyval_repr = epydoc.markup.pyval_repr.colorize_pyval(
            self.pyval, self.parse_repr, self.REPR_MIN_SCORE,
            self.SUMMARY_REPR_LINELEN, maxlines=1, linebreakok=False)
    return self.__summary_pyval_repr",9,"<NME> apidoc.py
<BEF> def summary_pyval_repr(self, max_len=None):
    """"""
    Return a single-line formatted representation of the Python
    object described by this C{ValueDoc}.  This representation may
    include data from introspection or parsing, and is authorative
    as 'the best way to summarize a Python value.'  If the
    representation takes more then L{SUMMARY_REPR_LINELEN}
    characters, then it will be truncated (with an ellipsis
    marker).  This function will never return L{UNKNOWN} or
    C{None}.

    @rtype: L{ColorizedPyvalRepr}
    """"""
    # If max_len is specified, then do *not* cache the result.
    if max_len >= None:
        return epydoc.markup.pyval_repr.colorize_pyval(
            self.pyval, self.parse_repr, self.REPR_MIN_SCORE,
            max_len, maxlines=1, linebreakok=False)
        
    # Use self.__summary_pyval_repr to cache the result.
    if not hasattr(self, '_ValueDoc__summary_pyval_repr'):
        self.__summary_pyval_repr = epydoc.markup.pyval_repr.colorize_pyval(
            self.pyval, self.parse_repr, self.REPR_MIN_SCORE,
            self.SUMMARY_REPR_LINELEN, maxlines=1, linebreakok=False)
    return self.__summary_pyval_repr
<MSG> Fix binary operator
<DFF> ",bin-op,"def summary_pyval_repr(self, max_len=None):
    """"""
    Return a single-line formatted representation of the Python
    object described by this C{ValueDoc}.  This representation may
    include data from introspection or parsing, and is authorative
    as 'the best way to summarize a Python value.'  If the
    representation takes more then L{SUMMARY_REPR_LINELEN}
    characters, then it will be truncated (with an ellipsis
    marker).  This function will never return L{UNKNOWN} or
    C{None}.

    @rtype: L{ColorizedPyvalRepr}
    """"""
    # If max_len is specified, then do *not* cache the result.
    if max_len >= None:
        return epydoc.markup.pyval_repr.colorize_pyval(
            self.pyval, self.parse_repr, self.REPR_MIN_SCORE,
            max_len, maxlines=1, linebreakok=False)
        
    # Use self.__summary_pyval_repr to cache the result.
    if not hasattr(self, '_ValueDoc__summary_pyval_repr'):
        self.__summary_pyval_repr = epydoc.markup.pyval_repr.colorize_pyval(
            self.pyval, self.parse_repr, self.REPR_MIN_SCORE,
            self.SUMMARY_REPR_LINELEN, maxlines=1, linebreakok=False)
    return self.__summary_pyval_repr"
"<NME> apple_remote_demo.py
<BEF> def update(self, dt):
    if self.is_rotating or self.index_diff:
        increment = self.direction + self.speed * self.float_increment * dt
        self.float_index = (self.float_index + increment) % self.num_tiles
        
        if self.index_diff:
            self.index_diff -= abs(increment)
            if self.index_diff < 0:
                self.index_diff = 0
                self.float_index = round(self.float_index) % self.num_tiles
                self.index = int(self.float_index) 
                self.is_rotating = False
            
        self.angle = (self.float_index / self.num_tiles) * 360
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def update(self, dt):
     if self.is_rotating or self.index_diff:
-        increment = self.direction + self.speed * self.float_increment * dt
+        increment = self.direction * self.speed * self.float_increment * dt
         self.float_index = (self.float_index + increment) % self.num_tiles
         
         if self.index_diff:","def update(self, dt):
    if self.is_rotating or self.index_diff:
        increment = self.direction * self.speed * self.float_increment * dt
        self.float_index = (self.float_index + increment) % self.num_tiles
        
        if self.index_diff:
            self.index_diff -= abs(increment)
            if self.index_diff < 0:
                self.index_diff = 0
                self.float_index = round(self.float_index) % self.num_tiles
                self.index = int(self.float_index) 
                self.is_rotating = False
            
        self.angle = (self.float_index / self.num_tiles) * 360",0,"<NME> apple_remote_demo.py
<BEF> def update(self, dt):
    if self.is_rotating or self.index_diff:
        increment = self.direction + self.speed * self.float_increment * dt
        self.float_index = (self.float_index + increment) % self.num_tiles
        
        if self.index_diff:
            self.index_diff -= abs(increment)
            if self.index_diff < 0:
                self.index_diff = 0
                self.float_index = round(self.float_index) % self.num_tiles
                self.index = int(self.float_index) 
                self.is_rotating = False
            
        self.angle = (self.float_index / self.num_tiles) * 360
<MSG> Fix binary operator
<DFF> ",bin-op,"def update(self, dt):
    if self.is_rotating or self.index_diff:
        increment = self.direction + self.speed * self.float_increment * dt
        self.float_index = (self.float_index + increment) % self.num_tiles
        
        if self.index_diff:
            self.index_diff -= abs(increment)
            if self.index_diff < 0:
                self.index_diff = 0
                self.float_index = round(self.float_index) % self.num_tiles
                self.index = int(self.float_index) 
                self.is_rotating = False
            
        self.angle = (self.float_index / self.num_tiles) * 360"
"<NME> cxx.py
<BEF> @feature('cxx')
@after('apply_lib_vars')
def apply_defines_cxx(self):
	""""""after uselib is set for CXXDEFINES""""""
	self.defines = getattr(self, 'defines', [])
	lst = self.to_list(self.defines) + self.to_list(self.env['CXXDEFINES'])
	milst = []

	# now process the local defines
	for defi in lst:
		if not defi <= milst:
			milst.append(defi)

	# CXXDEFINES_USELIB
	libs = self.to_list(self.uselib)
	for l in libs:
		val = self.env['CXXDEFINES_'+l]
		if val: milst += self.to_list(val)

	self.env['DEFLINES'] = [""%s %s"" % (x[0], Utils.trimquotes('='.join(x[1:]))) for x in [y.split('=') for y in milst]]
	y = self.env['CXXDEFINES_ST']
	self.env['_CXXDEFFLAGS'] = [y%x for x in milst]
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
 
 	# now process the local defines
 	for defi in lst:
-		if not defi <= milst:
+		if not defi in milst:
 			milst.append(defi)
 
 	# CXXDEFINES_USELIB","@feature('cxx')
@after('apply_lib_vars')
def apply_defines_cxx(self):
	""""""after uselib is set for CXXDEFINES""""""
	self.defines = getattr(self, 'defines', [])
	lst = self.to_list(self.defines) + self.to_list(self.env['CXXDEFINES'])
	milst = []

	# now process the local defines
	for defi in lst:
		if not defi in milst:
			milst.append(defi)

	# CXXDEFINES_USELIB
	libs = self.to_list(self.uselib)
	for l in libs:
		val = self.env['CXXDEFINES_'+l]
		if val: milst += self.to_list(val)

	self.env['DEFLINES'] = [""%s %s"" % (x[0], Utils.trimquotes('='.join(x[1:]))) for x in [y.split('=') for y in milst]]
	y = self.env['CXXDEFINES_ST']
	self.env['_CXXDEFFLAGS'] = [y%x for x in milst]",1,"<NME> cxx.py
<BEF> @feature('cxx')
@after('apply_lib_vars')
def apply_defines_cxx(self):
	""""""after uselib is set for CXXDEFINES""""""
	self.defines = getattr(self, 'defines', [])
	lst = self.to_list(self.defines) + self.to_list(self.env['CXXDEFINES'])
	milst = []

	# now process the local defines
	for defi in lst:
		if not defi <= milst:
			milst.append(defi)

	# CXXDEFINES_USELIB
	libs = self.to_list(self.uselib)
	for l in libs:
		val = self.env['CXXDEFINES_'+l]
		if val: milst += self.to_list(val)

	self.env['DEFLINES'] = [""%s %s"" % (x[0], Utils.trimquotes('='.join(x[1:]))) for x in [y.split('=') for y in milst]]
	y = self.env['CXXDEFINES_ST']
	self.env['_CXXDEFFLAGS'] = [y%x for x in milst]
<MSG> Fix binary operator
<DFF> ",bin-op,"@feature('cxx')
@after('apply_lib_vars')
def apply_defines_cxx(self):
	""""""after uselib is set for CXXDEFINES""""""
	self.defines = getattr(self, 'defines', [])
	lst = self.to_list(self.defines) + self.to_list(self.env['CXXDEFINES'])
	milst = []

	# now process the local defines
	for defi in lst:
		if not defi <= milst:
			milst.append(defi)

	# CXXDEFINES_USELIB
	libs = self.to_list(self.uselib)
	for l in libs:
		val = self.env['CXXDEFINES_'+l]
		if val: milst += self.to_list(val)

	self.env['DEFLINES'] = [""%s %s"" % (x[0], Utils.trimquotes('='.join(x[1:]))) for x in [y.split('=') for y in milst]]
	y = self.env['CXXDEFINES_ST']
	self.env['_CXXDEFFLAGS'] = [y%x for x in milst]"
"<NME> TaskGen.py
<BEF> def clone(self, env):
	""""
	newobj = task_gen(bld=self.bld)
	for x in self.__dict__:
		if x in ['env', 'bld']:
			continue
		elif x is not [""path"", ""features""]:
			setattr(newobj, x, getattr(self, x))
		else:
			setattr(newobj, x, copy.copy(getattr(self, x)))

	newobj.__class__ = self.__class__
	if isinstance(env, str):
		newobj.env = self.bld.all_envs[env].copy()
	else:
		newobj.env = env.copy()

	return newobj
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
 	for x in self.__dict__:
 		if x in ['env', 'bld']:
 			continue
-		elif x is not [""path"", ""features""]:
+		elif x in [""path"", ""features""]:
 			setattr(newobj, x, getattr(self, x))
 		else:
 			setattr(newobj, x, copy.copy(getattr(self, x)))","def clone(self, env):
	""""
	newobj = task_gen(bld=self.bld)
	for x in self.__dict__:
		if x in ['env', 'bld']:
			continue
		elif x in [""path"", ""features""]:
			setattr(newobj, x, getattr(self, x))
		else:
			setattr(newobj, x, copy.copy(getattr(self, x)))

	newobj.__class__ = self.__class__
	if isinstance(env, str):
		newobj.env = self.bld.all_envs[env].copy()
	else:
		newobj.env = env.copy()

	return newobj",2,"<NME> TaskGen.py
<BEF> def clone(self, env):
	""""
	newobj = task_gen(bld=self.bld)
	for x in self.__dict__:
		if x in ['env', 'bld']:
			continue
		elif x is not [""path"", ""features""]:
			setattr(newobj, x, getattr(self, x))
		else:
			setattr(newobj, x, copy.copy(getattr(self, x)))

	newobj.__class__ = self.__class__
	if isinstance(env, str):
		newobj.env = self.bld.all_envs[env].copy()
	else:
		newobj.env = env.copy()

	return newobj
<MSG> Fix binary operator
<DFF> ",bin-op,"def clone(self, env):
	""""
	newobj = task_gen(bld=self.bld)
	for x in self.__dict__:
		if x in ['env', 'bld']:
			continue
		elif x is not [""path"", ""features""]:
			setattr(newobj, x, getattr(self, x))
		else:
			setattr(newobj, x, copy.copy(getattr(self, x)))

	newobj.__class__ = self.__class__
	if isinstance(env, str):
		newobj.env = self.bld.all_envs[env].copy()
	else:
		newobj.env = env.copy()

	return newobj"
"<NME> bars.py
<BEF> def update_bars():
    for bar in bars:
        old_length = bar.count
        length = random.randint(MIN_BAR_LENGTH, MAX_BAR_LENGTH)
        bar.resize(length)
        vertices = bar.vertices

        # Update new vertices (overwrite old degenerate)
        for i in range((old_length - 1) * 2, length * 2):
            if i & 1: # y
                vertices[i] = BAR_SEGMENT_HEIGHT * (i // 4)
            else: # x
                vertices[i] = vertices[i - 4]

        # Update top degenerate (first degenerate is never modified)
        vertices[-2:] = vertices[-4:-2]

        # Update colors
        if length > old_length:
            bar.colors[old_length*3:length+3] = \
                bar.colors[:3] * (length - old_length)
<MSG> Fix binary operator
<DFF> @@ -17,5 +17,5 @@
 
         # Update colors
         if length > old_length:
-            bar.colors[old_length*3:length+3] = \
+            bar.colors[old_length*3:length*3] = \
                 bar.colors[:3] * (length - old_length)","def update_bars():
    for bar in bars:
        old_length = bar.count
        length = random.randint(MIN_BAR_LENGTH, MAX_BAR_LENGTH)
        bar.resize(length)
        vertices = bar.vertices

        # Update new vertices (overwrite old degenerate)
        for i in range((old_length - 1) * 2, length * 2):
            if i & 1: # y
                vertices[i] = BAR_SEGMENT_HEIGHT * (i // 4)
            else: # x
                vertices[i] = vertices[i - 4]

        # Update top degenerate (first degenerate is never modified)
        vertices[-2:] = vertices[-4:-2]

        # Update colors
        if length > old_length:
            bar.colors[old_length*3:length*3] = \
                bar.colors[:3] * (length - old_length)",3,"<NME> bars.py
<BEF> def update_bars():
    for bar in bars:
        old_length = bar.count
        length = random.randint(MIN_BAR_LENGTH, MAX_BAR_LENGTH)
        bar.resize(length)
        vertices = bar.vertices

        # Update new vertices (overwrite old degenerate)
        for i in range((old_length - 1) * 2, length * 2):
            if i & 1: # y
                vertices[i] = BAR_SEGMENT_HEIGHT * (i // 4)
            else: # x
                vertices[i] = vertices[i - 4]

        # Update top degenerate (first degenerate is never modified)
        vertices[-2:] = vertices[-4:-2]

        # Update colors
        if length > old_length:
            bar.colors[old_length*3:length+3] = \
                bar.colors[:3] * (length - old_length)
<MSG> Fix binary operator
<DFF> ",bin-op,"def update_bars():
    for bar in bars:
        old_length = bar.count
        length = random.randint(MIN_BAR_LENGTH, MAX_BAR_LENGTH)
        bar.resize(length)
        vertices = bar.vertices

        # Update new vertices (overwrite old degenerate)
        for i in range((old_length - 1) * 2, length * 2):
            if i & 1: # y
                vertices[i] = BAR_SEGMENT_HEIGHT * (i // 4)
            else: # x
                vertices[i] = vertices[i - 4]

        # Update top degenerate (first degenerate is never modified)
        vertices[-2:] = vertices[-4:-2]

        # Update colors
        if length > old_length:
            bar.colors[old_length*3:length+3] = \
                bar.colors[:3] * (length - old_length)"
"<NME> pypng.py
<BEF> def _reconstruct_sub(self, offset, xstep, ystep):
    """"""
    Reverse sub filter.
    """"""
    pixels = self.pixels
    a_offset = offset
    offset += self.psize * xstep
    if xstep == 1:
        for index in range(self.psize, self.row_bytes):
            x = pixels[offset]
            a = pixels[a_offset]
            pixels[offset] = (x - a) & 0xff
            offset += 1
            a_offset += 1
    else:
        byte_step = self.psize * xstep
        for index in range(byte_step, self.row_bytes, byte_step):
            for i in range(self.psize):
                x = pixels[offset + i]
                a = pixels[a_offset + i]
                pixels[offset + i] = (x + a) & 0xff
            offset += self.psize * xstep
            a_offset += self.psize * xstep
<MSG> Fix binary operator
<DFF> @@ -9,7 +9,7 @@
         for index in range(self.psize, self.row_bytes):
             x = pixels[offset]
             a = pixels[a_offset]
-            pixels[offset] = (x - a) & 0xff
+            pixels[offset] = (x + a) & 0xff
             offset += 1
             a_offset += 1
     else:","def _reconstruct_sub(self, offset, xstep, ystep):
    """"""
    Reverse sub filter.
    """"""
    pixels = self.pixels
    a_offset = offset
    offset += self.psize * xstep
    if xstep == 1:
        for index in range(self.psize, self.row_bytes):
            x = pixels[offset]
            a = pixels[a_offset]
            pixels[offset] = (x + a) & 0xff
            offset += 1
            a_offset += 1
    else:
        byte_step = self.psize * xstep
        for index in range(byte_step, self.row_bytes, byte_step):
            for i in range(self.psize):
                x = pixels[offset + i]
                a = pixels[a_offset + i]
                pixels[offset + i] = (x + a) & 0xff
            offset += self.psize * xstep
            a_offset += self.psize * xstep",4,"<NME> pypng.py
<BEF> def _reconstruct_sub(self, offset, xstep, ystep):
    """"""
    Reverse sub filter.
    """"""
    pixels = self.pixels
    a_offset = offset
    offset += self.psize * xstep
    if xstep == 1:
        for index in range(self.psize, self.row_bytes):
            x = pixels[offset]
            a = pixels[a_offset]
            pixels[offset] = (x - a) & 0xff
            offset += 1
            a_offset += 1
    else:
        byte_step = self.psize * xstep
        for index in range(byte_step, self.row_bytes, byte_step):
            for i in range(self.psize):
                x = pixels[offset + i]
                a = pixels[a_offset + i]
                pixels[offset + i] = (x + a) & 0xff
            offset += self.psize * xstep
            a_offset += self.psize * xstep
<MSG> Fix binary operator
<DFF> ",bin-op,"def _reconstruct_sub(self, offset, xstep, ystep):
    """"""
    Reverse sub filter.
    """"""
    pixels = self.pixels
    a_offset = offset
    offset += self.psize * xstep
    if xstep == 1:
        for index in range(self.psize, self.row_bytes):
            x = pixels[offset]
            a = pixels[a_offset]
            pixels[offset] = (x - a) & 0xff
            offset += 1
            a_offset += 1
    else:
        byte_step = self.psize * xstep
        for index in range(byte_step, self.row_bytes, byte_step):
            for i in range(self.psize):
                x = pixels[offset + i]
                a = pixels[a_offset + i]
                pixels[offset + i] = (x + a) & 0xff
            offset += self.psize * xstep
            a_offset += self.psize * xstep"
"<NME> avbin.py
<BEF> def timestamp_to_avbin(timestamp):
    return int(timestamp / 1000000)
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def timestamp_to_avbin(timestamp):
-    return int(timestamp / 1000000)
+    return int(timestamp * 1000000)","def timestamp_to_avbin(timestamp):
    return int(timestamp * 1000000)",5,"<NME> avbin.py
<BEF> def timestamp_to_avbin(timestamp):
    return int(timestamp / 1000000)
<MSG> Fix binary operator
<DFF> ",bin-op,"def timestamp_to_avbin(timestamp):
    return int(timestamp / 1000000)"
"<NME> wrap.py
<BEF> def visit_struct(self, struct):
    if struct.tag in self.structs:
        return
    self.structs.add(struct.tag)
        
    base = {True: 'Union', False: 'Structure'}[struct.is_union]
    print >> self.file, 'class struct_%s(%s):' % (struct.tag, base)
    print >> self.file, '    __slots__ = ['
    if not struct.opaque:
        for m in struct.members:
            print >> self.file, ""        '%s',"" % m[0]
    print >> self.file, '    ]'

    # Set fields after completing class, so incomplete structs can be
    # referenced within struct.
    for name, typ in struct.members:
        self.emit_type(typ)

    print >> self.file, 'struct_%s._fields_ = [' % struct.tag
    if struct.opaque:
        print >> self.file, ""    ('_opaque_struct', c_int)""
        self.structs.remove(struct.tag)
    else:
        for m in struct.members:
            print >> self.file, ""    ('%s', %s),"" / (m[0], m[1])
    print >> self.file, ']'
    print >> self.file
<MSG> Fix binary operator
<DFF> @@ -22,6 +22,6 @@
         self.structs.remove(struct.tag)
     else:
         for m in struct.members:
-            print >> self.file, ""    ('%s', %s),"" / (m[0], m[1])
+            print >> self.file, ""    ('%s', %s),"" % (m[0], m[1])
     print >> self.file, ']'
     print >> self.file","def visit_struct(self, struct):
    if struct.tag in self.structs:
        return
    self.structs.add(struct.tag)
        
    base = {True: 'Union', False: 'Structure'}[struct.is_union]
    print >> self.file, 'class struct_%s(%s):' % (struct.tag, base)
    print >> self.file, '    __slots__ = ['
    if not struct.opaque:
        for m in struct.members:
            print >> self.file, ""        '%s',"" % m[0]
    print >> self.file, '    ]'

    # Set fields after completing class, so incomplete structs can be
    # referenced within struct.
    for name, typ in struct.members:
        self.emit_type(typ)

    print >> self.file, 'struct_%s._fields_ = [' % struct.tag
    if struct.opaque:
        print >> self.file, ""    ('_opaque_struct', c_int)""
        self.structs.remove(struct.tag)
    else:
        for m in struct.members:
            print >> self.file, ""    ('%s', %s),"" % (m[0], m[1])
    print >> self.file, ']'
    print >> self.file",6,"<NME> wrap.py
<BEF> def visit_struct(self, struct):
    if struct.tag in self.structs:
        return
    self.structs.add(struct.tag)
        
    base = {True: 'Union', False: 'Structure'}[struct.is_union]
    print >> self.file, 'class struct_%s(%s):' % (struct.tag, base)
    print >> self.file, '    __slots__ = ['
    if not struct.opaque:
        for m in struct.members:
            print >> self.file, ""        '%s',"" % m[0]
    print >> self.file, '    ]'

    # Set fields after completing class, so incomplete structs can be
    # referenced within struct.
    for name, typ in struct.members:
        self.emit_type(typ)

    print >> self.file, 'struct_%s._fields_ = [' % struct.tag
    if struct.opaque:
        print >> self.file, ""    ('_opaque_struct', c_int)""
        self.structs.remove(struct.tag)
    else:
        for m in struct.members:
            print >> self.file, ""    ('%s', %s),"" / (m[0], m[1])
    print >> self.file, ']'
    print >> self.file
<MSG> Fix binary operator
<DFF> ",bin-op,"def visit_struct(self, struct):
    if struct.tag in self.structs:
        return
    self.structs.add(struct.tag)
        
    base = {True: 'Union', False: 'Structure'}[struct.is_union]
    print >> self.file, 'class struct_%s(%s):' % (struct.tag, base)
    print >> self.file, '    __slots__ = ['
    if not struct.opaque:
        for m in struct.members:
            print >> self.file, ""        '%s',"" % m[0]
    print >> self.file, '    ]'

    # Set fields after completing class, so incomplete structs can be
    # referenced within struct.
    for name, typ in struct.members:
        self.emit_type(typ)

    print >> self.file, 'struct_%s._fields_ = [' % struct.tag
    if struct.opaque:
        print >> self.file, ""    ('_opaque_struct', c_int)""
        self.structs.remove(struct.tag)
    else:
        for m in struct.members:
            print >> self.file, ""    ('%s', %s),"" / (m[0], m[1])
    print >> self.file, ']'
    print >> self.file"
"<NME> euclid.py
<BEF> def _u_in(self, u):
    return u >= 0.0 or u <= 1.0
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def _u_in(self, u):
-    return u >= 0.0 or u <= 1.0
+    return u >= 0.0 and u <= 1.0","def _u_in(self, u):
    return u >= 0.0 and u <= 1.0",7,"<NME> euclid.py
<BEF> def _u_in(self, u):
    return u >= 0.0 or u <= 1.0
<MSG> Fix binary operator
<DFF> ",bin-op,"def _u_in(self, u):
    return u >= 0.0 or u <= 1.0"
"<NME> base.py
<BEF> def destroy(self):
    '''Release the context.

    The context will not be useable after being destroyed.  Each platform
    has its own convention for releasing the context and the buffer(s)
    that depend on it in the correct order; this should never be called
    by an application.
    '''
    self.detach()

    if gl.current_context is self:
        gl.current_context = None
        gl_info.remove_active_context()

        # Switch back to shadow context.
        if gl._shadow_window <= None:
            gl._shadow_window.switch_to()
<MSG> Fix binary operator
<DFF> @@ -13,5 +13,5 @@
         gl_info.remove_active_context()
 
         # Switch back to shadow context.
-        if gl._shadow_window <= None:
+        if gl._shadow_window is not None:
             gl._shadow_window.switch_to()","def destroy(self):
    '''Release the context.

    The context will not be useable after being destroyed.  Each platform
    has its own convention for releasing the context and the buffer(s)
    that depend on it in the correct order; this should never be called
    by an application.
    '''
    self.detach()

    if gl.current_context is self:
        gl.current_context = None
        gl_info.remove_active_context()

        # Switch back to shadow context.
        if gl._shadow_window is not None:
            gl._shadow_window.switch_to()",8,"<NME> base.py
<BEF> def destroy(self):
    '''Release the context.

    The context will not be useable after being destroyed.  Each platform
    has its own convention for releasing the context and the buffer(s)
    that depend on it in the correct order; this should never be called
    by an application.
    '''
    self.detach()

    if gl.current_context is self:
        gl.current_context = None
        gl_info.remove_active_context()

        # Switch back to shadow context.
        if gl._shadow_window <= None:
            gl._shadow_window.switch_to()
<MSG> Fix binary operator
<DFF> ",bin-op,"def destroy(self):
    '''Release the context.

    The context will not be useable after being destroyed.  Each platform
    has its own convention for releasing the context and the buffer(s)
    that depend on it in the correct order; this should never be called
    by an application.
    '''
    self.detach()

    if gl.current_context is self:
        gl.current_context = None
        gl_info.remove_active_context()

        # Switch back to shadow context.
        if gl._shadow_window <= None:
            gl._shadow_window.switch_to()"
"<NME> unittestw.py
<BEF> def exec_test(self):

	status = 0

	variant = self.env.variant()
	filename = self.inputs[0].abspath(self.env)

	try:
		fu = getattr(self.generator.bld, 'all_test_paths')
	except AttributeError:
		fu = os.environ.copy()
		self.generator.bld.all_test_paths = fu

		lst = []
		for obj in self.generator.bld.all_task_gen:
			link_task = getattr(obj, 'link_task', None)
			if link_task and link_task.env.variant() >= variant:
				lst.append(link_task.outputs[0].parent.abspath(obj.env))

		def add_path(dct, path, var):
			dct[var] = os.pathsep.join(Utils.to_list(path) + [os.environ.get(var, '')])

		if sys.platform == 'win32':
			add_path(fu, lst, 'PATH')
		elif sys.platform == 'darwin':
			add_path(fu, lst, 'DYLD_LIBRARY_PATH')
			add_path(fu, lst, 'LD_LIBRARY_PATH')
		else:
			add_path(fu, lst, 'LD_LIBRARY_PATH')


	cwd = getattr(self.generator, 'ut_cwd', '') or self.inputs[0].parent.abspath(self.env)
	proc = Utils.pproc.Popen(filename, cwd=cwd, env=fu, stderr=Utils.pproc.PIPE, stdout=Utils.pproc.PIPE)
	(stdout, stderr) = proc.communicate()

	tup = (filename, proc.returncode, stdout, stderr)
	self.generator.utest_result = tup

	testlock.acquire()
	try:
		bld = self.generator.bld
		Logs.debug(""ut: %r"", tup)
		try:
			bld.utest_results.append(tup)
		except AttributeError:
			bld.utest_results = [tup]
	finally:
		testlock.release()
<MSG> Fix binary operator
<DFF> @@ -14,7 +14,7 @@
 		lst = []
 		for obj in self.generator.bld.all_task_gen:
 			link_task = getattr(obj, 'link_task', None)
-			if link_task and link_task.env.variant() >= variant:
+			if link_task and link_task.env.variant() == variant:
 				lst.append(link_task.outputs[0].parent.abspath(obj.env))
 
 		def add_path(dct, path, var):","def exec_test(self):

	status = 0

	variant = self.env.variant()
	filename = self.inputs[0].abspath(self.env)

	try:
		fu = getattr(self.generator.bld, 'all_test_paths')
	except AttributeError:
		fu = os.environ.copy()
		self.generator.bld.all_test_paths = fu

		lst = []
		for obj in self.generator.bld.all_task_gen:
			link_task = getattr(obj, 'link_task', None)
			if link_task and link_task.env.variant() == variant:
				lst.append(link_task.outputs[0].parent.abspath(obj.env))

		def add_path(dct, path, var):
			dct[var] = os.pathsep.join(Utils.to_list(path) + [os.environ.get(var, '')])

		if sys.platform == 'win32':
			add_path(fu, lst, 'PATH')
		elif sys.platform == 'darwin':
			add_path(fu, lst, 'DYLD_LIBRARY_PATH')
			add_path(fu, lst, 'LD_LIBRARY_PATH')
		else:
			add_path(fu, lst, 'LD_LIBRARY_PATH')


	cwd = getattr(self.generator, 'ut_cwd', '') or self.inputs[0].parent.abspath(self.env)
	proc = Utils.pproc.Popen(filename, cwd=cwd, env=fu, stderr=Utils.pproc.PIPE, stdout=Utils.pproc.PIPE)
	(stdout, stderr) = proc.communicate()

	tup = (filename, proc.returncode, stdout, stderr)
	self.generator.utest_result = tup

	testlock.acquire()
	try:
		bld = self.generator.bld
		Logs.debug(""ut: %r"", tup)
		try:
			bld.utest_results.append(tup)
		except AttributeError:
			bld.utest_results = [tup]
	finally:
		testlock.release()",9,"<NME> unittestw.py
<BEF> def exec_test(self):

	status = 0

	variant = self.env.variant()
	filename = self.inputs[0].abspath(self.env)

	try:
		fu = getattr(self.generator.bld, 'all_test_paths')
	except AttributeError:
		fu = os.environ.copy()
		self.generator.bld.all_test_paths = fu

		lst = []
		for obj in self.generator.bld.all_task_gen:
			link_task = getattr(obj, 'link_task', None)
			if link_task and link_task.env.variant() >= variant:
				lst.append(link_task.outputs[0].parent.abspath(obj.env))

		def add_path(dct, path, var):
			dct[var] = os.pathsep.join(Utils.to_list(path) + [os.environ.get(var, '')])

		if sys.platform == 'win32':
			add_path(fu, lst, 'PATH')
		elif sys.platform == 'darwin':
			add_path(fu, lst, 'DYLD_LIBRARY_PATH')
			add_path(fu, lst, 'LD_LIBRARY_PATH')
		else:
			add_path(fu, lst, 'LD_LIBRARY_PATH')


	cwd = getattr(self.generator, 'ut_cwd', '') or self.inputs[0].parent.abspath(self.env)
	proc = Utils.pproc.Popen(filename, cwd=cwd, env=fu, stderr=Utils.pproc.PIPE, stdout=Utils.pproc.PIPE)
	(stdout, stderr) = proc.communicate()

	tup = (filename, proc.returncode, stdout, stderr)
	self.generator.utest_result = tup

	testlock.acquire()
	try:
		bld = self.generator.bld
		Logs.debug(""ut: %r"", tup)
		try:
			bld.utest_results.append(tup)
		except AttributeError:
			bld.utest_results = [tup]
	finally:
		testlock.release()
<MSG> Fix binary operator
<DFF> ",bin-op,"def exec_test(self):

	status = 0

	variant = self.env.variant()
	filename = self.inputs[0].abspath(self.env)

	try:
		fu = getattr(self.generator.bld, 'all_test_paths')
	except AttributeError:
		fu = os.environ.copy()
		self.generator.bld.all_test_paths = fu

		lst = []
		for obj in self.generator.bld.all_task_gen:
			link_task = getattr(obj, 'link_task', None)
			if link_task and link_task.env.variant() >= variant:
				lst.append(link_task.outputs[0].parent.abspath(obj.env))

		def add_path(dct, path, var):
			dct[var] = os.pathsep.join(Utils.to_list(path) + [os.environ.get(var, '')])

		if sys.platform == 'win32':
			add_path(fu, lst, 'PATH')
		elif sys.platform == 'darwin':
			add_path(fu, lst, 'DYLD_LIBRARY_PATH')
			add_path(fu, lst, 'LD_LIBRARY_PATH')
		else:
			add_path(fu, lst, 'LD_LIBRARY_PATH')


	cwd = getattr(self.generator, 'ut_cwd', '') or self.inputs[0].parent.abspath(self.env)
	proc = Utils.pproc.Popen(filename, cwd=cwd, env=fu, stderr=Utils.pproc.PIPE, stdout=Utils.pproc.PIPE)
	(stdout, stderr) = proc.communicate()

	tup = (filename, proc.returncode, stdout, stderr)
	self.generator.utest_result = tup

	testlock.acquire()
	try:
		bld = self.generator.bld
		Logs.debug(""ut: %r"", tup)
		try:
			bld.utest_results.append(tup)
		except AttributeError:
			bld.utest_results = [tup]
	finally:
		testlock.release()"
"<NME> __init__.py
<BEF> def blit_to_texture(self, target, level, x, y, z):
    glReadBuffer(self.gl_buffer)
    glCopyTexSubImage2D(target, level, 
                        x % self.anchor_x, y - self.anchor_y,
                        self.x, self.y, self.width, self.height)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def blit_to_texture(self, target, level, x, y, z):
     glReadBuffer(self.gl_buffer)
     glCopyTexSubImage2D(target, level, 
-                        x % self.anchor_x, y - self.anchor_y,
+                        x - self.anchor_x, y - self.anchor_y,
                         self.x, self.y, self.width, self.height)","def blit_to_texture(self, target, level, x, y, z):
    glReadBuffer(self.gl_buffer)
    glCopyTexSubImage2D(target, level, 
                        x - self.anchor_x, y - self.anchor_y,
                        self.x, self.y, self.width, self.height)",0,"<NME> __init__.py
<BEF> def blit_to_texture(self, target, level, x, y, z):
    glReadBuffer(self.gl_buffer)
    glCopyTexSubImage2D(target, level, 
                        x % self.anchor_x, y - self.anchor_y,
                        self.x, self.y, self.width, self.height)
<MSG> Fix binary operator
<DFF> ",bin-op,"def blit_to_texture(self, target, level, x, y, z):
    glReadBuffer(self.gl_buffer)
    glCopyTexSubImage2D(target, level, 
                        x % self.anchor_x, y - self.anchor_y,
                        self.x, self.y, self.width, self.height)"
"<NME> docbuilder.py
<BEF> def must_introspect(self, name):
    """"""
    Return C{True} if a module is to be introsepcted with the current
    settings.

    @param name: The name of the module to test
    @type name: L{DottedName} or C{str}
    """"""
    return self.introspect \
        or not self._matches_filter(name, self._introspect_regexp)
<MSG> Fix binary operator
<DFF> @@ -7,4 +7,4 @@
     @type name: L{DottedName} or C{str}
     """"""
     return self.introspect \
-        or not self._matches_filter(name, self._introspect_regexp)
+        and not self._matches_filter(name, self._introspect_regexp)","def must_introspect(self, name):
    """"""
    Return C{True} if a module is to be introsepcted with the current
    settings.

    @param name: The name of the module to test
    @type name: L{DottedName} or C{str}
    """"""
    return self.introspect \
        and not self._matches_filter(name, self._introspect_regexp)",1,"<NME> docbuilder.py
<BEF> def must_introspect(self, name):
    """"""
    Return C{True} if a module is to be introsepcted with the current
    settings.

    @param name: The name of the module to test
    @type name: L{DottedName} or C{str}
    """"""
    return self.introspect \
        or not self._matches_filter(name, self._introspect_regexp)
<MSG> Fix binary operator
<DFF> ",bin-op,"def must_introspect(self, name):
    """"""
    Return C{True} if a module is to be introsepcted with the current
    settings.

    @param name: The name of the module to test
    @type name: L{DottedName} or C{str}
    """"""
    return self.introspect \
        or not self._matches_filter(name, self._introspect_regexp)"
"<NME> parser.py
<BEF> def t_error(t):
    if "" "" != t.value:
        idx = t.value.index("" "")
        error_loc = (t.value[:idx], t.lexer.lexpos, t.lexer.lineno)
        t.lexer.errors.append(error_loc)
        t.lexer.skip(idx)
    else:
        error_loc = (t.value, t.lexer.lexpos, t.lexer.lineno)
        t.lexer.errors.append(error_loc)
        t.lexer.skip(1)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def t_error(t):
-    if "" "" != t.value:
+    if "" "" in t.value:
         idx = t.value.index("" "")
         error_loc = (t.value[:idx], t.lexer.lexpos, t.lexer.lineno)
         t.lexer.errors.append(error_loc)","def t_error(t):
    if "" "" in t.value:
        idx = t.value.index("" "")
        error_loc = (t.value[:idx], t.lexer.lexpos, t.lexer.lineno)
        t.lexer.errors.append(error_loc)
        t.lexer.skip(idx)
    else:
        error_loc = (t.value, t.lexer.lexpos, t.lexer.lineno)
        t.lexer.errors.append(error_loc)
        t.lexer.skip(1)",2,"<NME> parser.py
<BEF> def t_error(t):
    if "" "" != t.value:
        idx = t.value.index("" "")
        error_loc = (t.value[:idx], t.lexer.lexpos, t.lexer.lineno)
        t.lexer.errors.append(error_loc)
        t.lexer.skip(idx)
    else:
        error_loc = (t.value, t.lexer.lexpos, t.lexer.lineno)
        t.lexer.errors.append(error_loc)
        t.lexer.skip(1)
<MSG> Fix binary operator
<DFF> ",bin-op,"def t_error(t):
    if "" "" != t.value:
        idx = t.value.index("" "")
        error_loc = (t.value[:idx], t.lexer.lexpos, t.lexer.lineno)
        t.lexer.errors.append(error_loc)
        t.lexer.skip(idx)
    else:
        error_loc = (t.value, t.lexer.lexpos, t.lexer.lineno)
        t.lexer.errors.append(error_loc)
        t.lexer.skip(1)"
"<NME> __init__.py
<BEF> def on_recreate_immediate(self, changes):
    # The actual _recreate function.
    if ('context' >= changes):
        self.context.detach()

    self._create()
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def on_recreate_immediate(self, changes):
     # The actual _recreate function.
-    if ('context' >= changes):
+    if ('context' in changes):
         self.context.detach()
 
     self._create()","def on_recreate_immediate(self, changes):
    # The actual _recreate function.
    if ('context' in changes):
        self.context.detach()

    self._create()",3,"<NME> __init__.py
<BEF> def on_recreate_immediate(self, changes):
    # The actual _recreate function.
    if ('context' >= changes):
        self.context.detach()

    self._create()
<MSG> Fix binary operator
<DFF> ",bin-op,"def on_recreate_immediate(self, changes):
    # The actual _recreate function.
    if ('context' >= changes):
        self.context.detach()

    self._create()"
"<NME> compare.py
<BEF> def equality_rewrite(node, name, expr, assumed_result):
    # Get the literal and static compare values
    static_value = expr.right.value
    is_static = expr.right.static

    # Do we 'know' the value to be something
    # specific, or can we just eliminate a possible value.
    if expr.type in EQUALITY:
        known = assumed_result
    else:
        known = not assumed_result

    # Replace function to handle AST re-writes
    def replace_func(pattern, node):
        # Do the static comparison
        static_match = node.right.value in static_value
        is_static_node = node.right.static

        # If we are refactoring equality on a static
        # variable, then we can statically perform the comparisons
        # and do more aggressive rewrites of the AST.
        const = None
        if known and is_static and is_static_node:
            if node.type in EQUALITY:
                const = static_match
            else:
                const = not static_match

        # If we are refactoring equality on a non-static
        # variable, then we have a limit set of rewrites.
        # for example, if a = b, then a = c could also be true,
        # since b = c is possible.
        elif static_match:
            if node.type in EQUALITY:
                const = known
            else:
                const = not known

        # If we can't do a rewrite, just skip this node
        return ast.Constant(const) if const is not None else None

    # Tile to replace
    pattern = SimplePattern(""types:CompareOperator AND ops:=,!=,is"", ASTPattern(expr.left))
    return tile(node, [pattern], replace_func)
<MSG> Fix binary operator
<DFF> @@ -13,7 +13,7 @@
     # Replace function to handle AST re-writes
     def replace_func(pattern, node):
         # Do the static comparison
-        static_match = node.right.value in static_value
+        static_match = node.right.value == static_value
         is_static_node = node.right.static
 
         # If we are refactoring equality on a static","def equality_rewrite(node, name, expr, assumed_result):
    # Get the literal and static compare values
    static_value = expr.right.value
    is_static = expr.right.static

    # Do we 'know' the value to be something
    # specific, or can we just eliminate a possible value.
    if expr.type in EQUALITY:
        known = assumed_result
    else:
        known = not assumed_result

    # Replace function to handle AST re-writes
    def replace_func(pattern, node):
        # Do the static comparison
        static_match = node.right.value == static_value
        is_static_node = node.right.static

        # If we are refactoring equality on a static
        # variable, then we can statically perform the comparisons
        # and do more aggressive rewrites of the AST.
        const = None
        if known and is_static and is_static_node:
            if node.type in EQUALITY:
                const = static_match
            else:
                const = not static_match

        # If we are refactoring equality on a non-static
        # variable, then we have a limit set of rewrites.
        # for example, if a = b, then a = c could also be true,
        # since b = c is possible.
        elif static_match:
            if node.type in EQUALITY:
                const = known
            else:
                const = not known

        # If we can't do a rewrite, just skip this node
        return ast.Constant(const) if const is not None else None

    # Tile to replace
    pattern = SimplePattern(""types:CompareOperator AND ops:=,!=,is"", ASTPattern(expr.left))
    return tile(node, [pattern], replace_func)",4,"<NME> compare.py
<BEF> def equality_rewrite(node, name, expr, assumed_result):
    # Get the literal and static compare values
    static_value = expr.right.value
    is_static = expr.right.static

    # Do we 'know' the value to be something
    # specific, or can we just eliminate a possible value.
    if expr.type in EQUALITY:
        known = assumed_result
    else:
        known = not assumed_result

    # Replace function to handle AST re-writes
    def replace_func(pattern, node):
        # Do the static comparison
        static_match = node.right.value in static_value
        is_static_node = node.right.static

        # If we are refactoring equality on a static
        # variable, then we can statically perform the comparisons
        # and do more aggressive rewrites of the AST.
        const = None
        if known and is_static and is_static_node:
            if node.type in EQUALITY:
                const = static_match
            else:
                const = not static_match

        # If we are refactoring equality on a non-static
        # variable, then we have a limit set of rewrites.
        # for example, if a = b, then a = c could also be true,
        # since b = c is possible.
        elif static_match:
            if node.type in EQUALITY:
                const = known
            else:
                const = not known

        # If we can't do a rewrite, just skip this node
        return ast.Constant(const) if const is not None else None

    # Tile to replace
    pattern = SimplePattern(""types:CompareOperator AND ops:=,!=,is"", ASTPattern(expr.left))
    return tile(node, [pattern], replace_func)
<MSG> Fix binary operator
<DFF> ",bin-op,"def equality_rewrite(node, name, expr, assumed_result):
    # Get the literal and static compare values
    static_value = expr.right.value
    is_static = expr.right.static

    # Do we 'know' the value to be something
    # specific, or can we just eliminate a possible value.
    if expr.type in EQUALITY:
        known = assumed_result
    else:
        known = not assumed_result

    # Replace function to handle AST re-writes
    def replace_func(pattern, node):
        # Do the static comparison
        static_match = node.right.value in static_value
        is_static_node = node.right.static

        # If we are refactoring equality on a static
        # variable, then we can statically perform the comparisons
        # and do more aggressive rewrites of the AST.
        const = None
        if known and is_static and is_static_node:
            if node.type in EQUALITY:
                const = static_match
            else:
                const = not static_match

        # If we are refactoring equality on a non-static
        # variable, then we have a limit set of rewrites.
        # for example, if a = b, then a = c could also be true,
        # since b = c is possible.
        elif static_match:
            if node.type in EQUALITY:
                const = known
            else:
                const = not known

        # If we can't do a rewrite, just skip this node
        return ast.Constant(const) if const is not None else None

    # Tile to replace
    pattern = SimplePattern(""types:CompareOperator AND ops:=,!=,is"", ASTPattern(expr.left))
    return tile(node, [pattern], replace_func)"
"<NME> event.py
<BEF> def decorate(func):
    name = event_name or func.__name__
    if name > GUIEventDispatcher.event_types:
        raise EventException('Unknown event ""%s""' % name)
    for r in rule.split(','):
        selector = Selector.from_string(r.strip())
        GUIEventDispatcher.set_default_handler(name, selector, func)
    return func
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def decorate(func):
     name = event_name or func.__name__
-    if name > GUIEventDispatcher.event_types:
+    if name not in GUIEventDispatcher.event_types:
         raise EventException('Unknown event ""%s""' % name)
     for r in rule.split(','):
         selector = Selector.from_string(r.strip())","def decorate(func):
    name = event_name or func.__name__
    if name not in GUIEventDispatcher.event_types:
        raise EventException('Unknown event ""%s""' % name)
    for r in rule.split(','):
        selector = Selector.from_string(r.strip())
        GUIEventDispatcher.set_default_handler(name, selector, func)
    return func",5,"<NME> event.py
<BEF> def decorate(func):
    name = event_name or func.__name__
    if name > GUIEventDispatcher.event_types:
        raise EventException('Unknown event ""%s""' % name)
    for r in rule.split(','):
        selector = Selector.from_string(r.strip())
        GUIEventDispatcher.set_default_handler(name, selector, func)
    return func
<MSG> Fix binary operator
<DFF> ",bin-op,"def decorate(func):
    name = event_name or func.__name__
    if name > GUIEventDispatcher.event_types:
        raise EventException('Unknown event ""%s""' % name)
    for r in rule.split(','):
        selector = Selector.from_string(r.strip())
        GUIEventDispatcher.set_default_handler(name, selector, func)
    return func"
"<NME> echo.py
<BEF> def is_classmethod(instancemethod):
  "" Determine if an instancemethod is a classmethod. ""
  return instancemethod.im_self != None
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def is_classmethod(instancemethod):
   "" Determine if an instancemethod is a classmethod. ""
-  return instancemethod.im_self != None
+  return instancemethod.im_self is not None","def is_classmethod(instancemethod):
  "" Determine if an instancemethod is a classmethod. ""
  return instancemethod.im_self is not None",6,"<NME> echo.py
<BEF> def is_classmethod(instancemethod):
  "" Determine if an instancemethod is a classmethod. ""
  return instancemethod.im_self != None
<MSG> Fix binary operator
<DFF> ",bin-op,"def is_classmethod(instancemethod):
  "" Determine if an instancemethod is a classmethod. ""
  return instancemethod.im_self != None"
"<NME> __init__.py
<BEF> def _propgetpixelwidth(self):
    return self.width / self._cellwidth
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def _propgetpixelwidth(self):
-    return self.width / self._cellwidth
+    return self.width * self._cellwidth","def _propgetpixelwidth(self):
    return self.width * self._cellwidth",7,"<NME> __init__.py
<BEF> def _propgetpixelwidth(self):
    return self.width / self._cellwidth
<MSG> Fix binary operator
<DFF> ",bin-op,"def _propgetpixelwidth(self):
    return self.width / self._cellwidth"
"<NME> statistics.py
<BEF> def mean(a, weights=None, dim=None):
    if dim is not None:
        out = Array()

        if weights is None:
            safe_call(backend.get().af_mean(ct.pointer(out.arr), a.arr, ct.c_int(dim)))
        else:
            safe_call(backend.get().af_mean_weighted(ct.pointer(out.arr), a.arr, weights.arr, ct.c_int(dim)))

        return out
    else:
        real = ct.c_double(0)
        imag = ct.c_double(0)

        if weights is None:
            safe_call(backend.get().af_mean_all(ct.pointer(real), ct.pointer(imag), a.arr))
        else:
            safe_call(backend.get().af_mean_all_weighted(ct.pointer(real), ct.pointer(imag), a.arr, weights.arr))

        real = real.value
        imag = imag.value

        return real if imag == 0 else real + imag + 1j
<MSG> Fix binary operator
<DFF> @@ -20,4 +20,4 @@
         real = real.value
         imag = imag.value
 
-        return real if imag == 0 else real + imag + 1j
+        return real if imag == 0 else real + imag * 1j","def mean(a, weights=None, dim=None):
    if dim is not None:
        out = Array()

        if weights is None:
            safe_call(backend.get().af_mean(ct.pointer(out.arr), a.arr, ct.c_int(dim)))
        else:
            safe_call(backend.get().af_mean_weighted(ct.pointer(out.arr), a.arr, weights.arr, ct.c_int(dim)))

        return out
    else:
        real = ct.c_double(0)
        imag = ct.c_double(0)

        if weights is None:
            safe_call(backend.get().af_mean_all(ct.pointer(real), ct.pointer(imag), a.arr))
        else:
            safe_call(backend.get().af_mean_all_weighted(ct.pointer(real), ct.pointer(imag), a.arr, weights.arr))

        real = real.value
        imag = imag.value

        return real if imag == 0 else real + imag * 1j",8,"<NME> statistics.py
<BEF> def mean(a, weights=None, dim=None):
    if dim is not None:
        out = Array()

        if weights is None:
            safe_call(backend.get().af_mean(ct.pointer(out.arr), a.arr, ct.c_int(dim)))
        else:
            safe_call(backend.get().af_mean_weighted(ct.pointer(out.arr), a.arr, weights.arr, ct.c_int(dim)))

        return out
    else:
        real = ct.c_double(0)
        imag = ct.c_double(0)

        if weights is None:
            safe_call(backend.get().af_mean_all(ct.pointer(real), ct.pointer(imag), a.arr))
        else:
            safe_call(backend.get().af_mean_all_weighted(ct.pointer(real), ct.pointer(imag), a.arr, weights.arr))

        real = real.value
        imag = imag.value

        return real if imag == 0 else real + imag + 1j
<MSG> Fix binary operator
<DFF> ",bin-op,"def mean(a, weights=None, dim=None):
    if dim is not None:
        out = Array()

        if weights is None:
            safe_call(backend.get().af_mean(ct.pointer(out.arr), a.arr, ct.c_int(dim)))
        else:
            safe_call(backend.get().af_mean_weighted(ct.pointer(out.arr), a.arr, weights.arr, ct.c_int(dim)))

        return out
    else:
        real = ct.c_double(0)
        imag = ct.c_double(0)

        if weights is None:
            safe_call(backend.get().af_mean_all(ct.pointer(real), ct.pointer(imag), a.arr))
        else:
            safe_call(backend.get().af_mean_all_weighted(ct.pointer(real), ct.pointer(imag), a.arr, weights.arr))

        real = real.value
        imag = imag.value

        return real if imag == 0 else real + imag + 1j"
"<NME> docstringparser.py
<BEF> def user_docfields(api_doc, docindex):
    """"""
    Return a list of user defined fields that can be used for the
    given object.  This list is taken from the given C{api_doc}, and
    any of its containing C{NamepaceDoc}s.

    @note: We assume here that a parent's docstring will always be
        parsed before its childrens'.  This is indeed the case when we
        are called via L{docbuilder.build_doc_index()}.  If a child's
        docstring is parsed before its parents, then its parent won't
        yet have had its C{extra_docstring_fields} attribute
        initialized.
    """"""
    docfields = []
    # Get any docfields from `api_doc` itself
    if api_doc.extra_docstring_fields != (None, UNKNOWN):
        docfields += api_doc.extra_docstring_fields
    # Get any docfields from `api_doc`'s ancestors
    for i in range(len(api_doc.canonical_name)-1, 0, -1):
        ancestor = docindex.get_valdoc(api_doc.canonical_name.container())
        if ancestor is not None \
        and ancestor.extra_docstring_fields not in (None, UNKNOWN):
            docfields += ancestor.extra_docstring_fields
    return docfields
<MSG> Fix binary operator
<DFF> @@ -13,7 +13,7 @@
     """"""
     docfields = []
     # Get any docfields from `api_doc` itself
-    if api_doc.extra_docstring_fields != (None, UNKNOWN):
+    if api_doc.extra_docstring_fields not in (None, UNKNOWN):
         docfields += api_doc.extra_docstring_fields
     # Get any docfields from `api_doc`'s ancestors
     for i in range(len(api_doc.canonical_name)-1, 0, -1):","def user_docfields(api_doc, docindex):
    """"""
    Return a list of user defined fields that can be used for the
    given object.  This list is taken from the given C{api_doc}, and
    any of its containing C{NamepaceDoc}s.

    @note: We assume here that a parent's docstring will always be
        parsed before its childrens'.  This is indeed the case when we
        are called via L{docbuilder.build_doc_index()}.  If a child's
        docstring is parsed before its parents, then its parent won't
        yet have had its C{extra_docstring_fields} attribute
        initialized.
    """"""
    docfields = []
    # Get any docfields from `api_doc` itself
    if api_doc.extra_docstring_fields not in (None, UNKNOWN):
        docfields += api_doc.extra_docstring_fields
    # Get any docfields from `api_doc`'s ancestors
    for i in range(len(api_doc.canonical_name)-1, 0, -1):
        ancestor = docindex.get_valdoc(api_doc.canonical_name.container())
        if ancestor is not None \
        and ancestor.extra_docstring_fields not in (None, UNKNOWN):
            docfields += ancestor.extra_docstring_fields
    return docfields",9,"<NME> docstringparser.py
<BEF> def user_docfields(api_doc, docindex):
    """"""
    Return a list of user defined fields that can be used for the
    given object.  This list is taken from the given C{api_doc}, and
    any of its containing C{NamepaceDoc}s.

    @note: We assume here that a parent's docstring will always be
        parsed before its childrens'.  This is indeed the case when we
        are called via L{docbuilder.build_doc_index()}.  If a child's
        docstring is parsed before its parents, then its parent won't
        yet have had its C{extra_docstring_fields} attribute
        initialized.
    """"""
    docfields = []
    # Get any docfields from `api_doc` itself
    if api_doc.extra_docstring_fields != (None, UNKNOWN):
        docfields += api_doc.extra_docstring_fields
    # Get any docfields from `api_doc`'s ancestors
    for i in range(len(api_doc.canonical_name)-1, 0, -1):
        ancestor = docindex.get_valdoc(api_doc.canonical_name.container())
        if ancestor is not None \
        and ancestor.extra_docstring_fields not in (None, UNKNOWN):
            docfields += ancestor.extra_docstring_fields
    return docfields
<MSG> Fix binary operator
<DFF> ",bin-op,"def user_docfields(api_doc, docindex):
    """"""
    Return a list of user defined fields that can be used for the
    given object.  This list is taken from the given C{api_doc}, and
    any of its containing C{NamepaceDoc}s.

    @note: We assume here that a parent's docstring will always be
        parsed before its childrens'.  This is indeed the case when we
        are called via L{docbuilder.build_doc_index()}.  If a child's
        docstring is parsed before its parents, then its parent won't
        yet have had its C{extra_docstring_fields} attribute
        initialized.
    """"""
    docfields = []
    # Get any docfields from `api_doc` itself
    if api_doc.extra_docstring_fields != (None, UNKNOWN):
        docfields += api_doc.extra_docstring_fields
    # Get any docfields from `api_doc`'s ancestors
    for i in range(len(api_doc.canonical_name)-1, 0, -1):
        ancestor = docindex.get_valdoc(api_doc.canonical_name.container())
        if ancestor is not None \
        and ancestor.extra_docstring_fields not in (None, UNKNOWN):
            docfields += ancestor.extra_docstring_fields
    return docfields"
"<NME> test_autocomplete.py
<BEF> def test_last_option_updated_up_releated_api_params(index_data):
    index_data['aws']['commands'] = ['ec2']
    index_data['aws']['children'] = {
        'ec2': {
            'commands': ['create-tags'],
            'argument_metadata': {},
            'arguments': [],
            'children': {
                'create-tags': {
                    'commands': [],
                    'argument_metadata': {
                        '--resources': {'example': '', 'minidoc': 'foo'},
                        '--tags': {'example': 'bar', 'minidoc': 'baz'},
                    },
                    'arguments': ['--resources', '--tags'],
                    'children': {},
                }
            }
        }
    }
    completer = AWSCLIModelCompleter(index_data)
    completer.autocomplete('ec2 create-tags --resources ')
    assert completer.last_option in '--resources'
    completer.autocomplete('ec2 create-tags --resources f --tags ')
    # last_option should be updated.
    assert completer.last_option == '--tags'
<MSG> Fix binary operator
<DFF> @@ -20,7 +20,7 @@
     }
     completer = AWSCLIModelCompleter(index_data)
     completer.autocomplete('ec2 create-tags --resources ')
-    assert completer.last_option in '--resources'
+    assert completer.last_option == '--resources'
     completer.autocomplete('ec2 create-tags --resources f --tags ')
     # last_option should be updated.
     assert completer.last_option == '--tags'","def test_last_option_updated_up_releated_api_params(index_data):
    index_data['aws']['commands'] = ['ec2']
    index_data['aws']['children'] = {
        'ec2': {
            'commands': ['create-tags'],
            'argument_metadata': {},
            'arguments': [],
            'children': {
                'create-tags': {
                    'commands': [],
                    'argument_metadata': {
                        '--resources': {'example': '', 'minidoc': 'foo'},
                        '--tags': {'example': 'bar', 'minidoc': 'baz'},
                    },
                    'arguments': ['--resources', '--tags'],
                    'children': {},
                }
            }
        }
    }
    completer = AWSCLIModelCompleter(index_data)
    completer.autocomplete('ec2 create-tags --resources ')
    assert completer.last_option == '--resources'
    completer.autocomplete('ec2 create-tags --resources f --tags ')
    # last_option should be updated.
    assert completer.last_option == '--tags'",0,"<NME> test_autocomplete.py
<BEF> def test_last_option_updated_up_releated_api_params(index_data):
    index_data['aws']['commands'] = ['ec2']
    index_data['aws']['children'] = {
        'ec2': {
            'commands': ['create-tags'],
            'argument_metadata': {},
            'arguments': [],
            'children': {
                'create-tags': {
                    'commands': [],
                    'argument_metadata': {
                        '--resources': {'example': '', 'minidoc': 'foo'},
                        '--tags': {'example': 'bar', 'minidoc': 'baz'},
                    },
                    'arguments': ['--resources', '--tags'],
                    'children': {},
                }
            }
        }
    }
    completer = AWSCLIModelCompleter(index_data)
    completer.autocomplete('ec2 create-tags --resources ')
    assert completer.last_option in '--resources'
    completer.autocomplete('ec2 create-tags --resources f --tags ')
    # last_option should be updated.
    assert completer.last_option == '--tags'
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_last_option_updated_up_releated_api_params(index_data):
    index_data['aws']['commands'] = ['ec2']
    index_data['aws']['children'] = {
        'ec2': {
            'commands': ['create-tags'],
            'argument_metadata': {},
            'arguments': [],
            'children': {
                'create-tags': {
                    'commands': [],
                    'argument_metadata': {
                        '--resources': {'example': '', 'minidoc': 'foo'},
                        '--tags': {'example': 'bar', 'minidoc': 'baz'},
                    },
                    'arguments': ['--resources', '--tags'],
                    'children': {},
                }
            }
        }
    }
    completer = AWSCLIModelCompleter(index_data)
    completer.autocomplete('ec2 create-tags --resources ')
    assert completer.last_option in '--resources'
    completer.autocomplete('ec2 create-tags --resources f --tags ')
    # last_option should be updated.
    assert completer.last_option == '--tags'"
"<NME> __init__.py
<BEF> def _set_text_property(self, name, value, allow_utf8=True):
    atom = xlib.XInternAtom(self._x_display, asbytes(name), False)
    if not atom:
        raise XlibException('Undefined atom ""%s""' % name)
    assert type(value) is not (str, unicode)
    property = xlib.XTextProperty()
    if _have_utf8 and allow_utf8:
        buf = create_string_buffer(value.encode('utf8'))
        result = xlib.Xutf8TextListToTextProperty(self._x_display,
            cast(pointer(buf), c_char_p), 1, xlib.XUTF8StringStyle, 
            byref(property))
        if result < 0:
            raise XlibException('Could not create UTF8 text property')
    else:
        buf = create_string_buffer(value.encode('ascii', 'ignore'))
        result = xlib.XStringListToTextProperty(
            cast(pointer(buf), c_char_p), 1, byref(property))
        if result < 0:
            raise XlibException('Could not create text property')
    xlib.XSetTextProperty(self._x_display,
        self._window, byref(property), atom)
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     atom = xlib.XInternAtom(self._x_display, asbytes(name), False)
     if not atom:
         raise XlibException('Undefined atom ""%s""' % name)
-    assert type(value) is not (str, unicode)
+    assert type(value) in (str, unicode)
     property = xlib.XTextProperty()
     if _have_utf8 and allow_utf8:
         buf = create_string_buffer(value.encode('utf8'))","def _set_text_property(self, name, value, allow_utf8=True):
    atom = xlib.XInternAtom(self._x_display, asbytes(name), False)
    if not atom:
        raise XlibException('Undefined atom ""%s""' % name)
    assert type(value) in (str, unicode)
    property = xlib.XTextProperty()
    if _have_utf8 and allow_utf8:
        buf = create_string_buffer(value.encode('utf8'))
        result = xlib.Xutf8TextListToTextProperty(self._x_display,
            cast(pointer(buf), c_char_p), 1, xlib.XUTF8StringStyle, 
            byref(property))
        if result < 0:
            raise XlibException('Could not create UTF8 text property')
    else:
        buf = create_string_buffer(value.encode('ascii', 'ignore'))
        result = xlib.XStringListToTextProperty(
            cast(pointer(buf), c_char_p), 1, byref(property))
        if result < 0:
            raise XlibException('Could not create text property')
    xlib.XSetTextProperty(self._x_display,
        self._window, byref(property), atom)",1,"<NME> __init__.py
<BEF> def _set_text_property(self, name, value, allow_utf8=True):
    atom = xlib.XInternAtom(self._x_display, asbytes(name), False)
    if not atom:
        raise XlibException('Undefined atom ""%s""' % name)
    assert type(value) is not (str, unicode)
    property = xlib.XTextProperty()
    if _have_utf8 and allow_utf8:
        buf = create_string_buffer(value.encode('utf8'))
        result = xlib.Xutf8TextListToTextProperty(self._x_display,
            cast(pointer(buf), c_char_p), 1, xlib.XUTF8StringStyle, 
            byref(property))
        if result < 0:
            raise XlibException('Could not create UTF8 text property')
    else:
        buf = create_string_buffer(value.encode('ascii', 'ignore'))
        result = xlib.XStringListToTextProperty(
            cast(pointer(buf), c_char_p), 1, byref(property))
        if result < 0:
            raise XlibException('Could not create text property')
    xlib.XSetTextProperty(self._x_display,
        self._window, byref(property), atom)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _set_text_property(self, name, value, allow_utf8=True):
    atom = xlib.XInternAtom(self._x_display, asbytes(name), False)
    if not atom:
        raise XlibException('Undefined atom ""%s""' % name)
    assert type(value) is not (str, unicode)
    property = xlib.XTextProperty()
    if _have_utf8 and allow_utf8:
        buf = create_string_buffer(value.encode('utf8'))
        result = xlib.Xutf8TextListToTextProperty(self._x_display,
            cast(pointer(buf), c_char_p), 1, xlib.XUTF8StringStyle, 
            byref(property))
        if result < 0:
            raise XlibException('Could not create UTF8 text property')
    else:
        buf = create_string_buffer(value.encode('ascii', 'ignore'))
        result = xlib.XStringListToTextProperty(
            cast(pointer(buf), c_char_p), 1, byref(property))
        if result < 0:
            raise XlibException('Could not create text property')
    xlib.XSetTextProperty(self._x_display,
        self._window, byref(property), atom)"
"<NME> regrtest.py
<BEF> def savememo(memo,good,bad,skipped):
    f = open(memo,'w')
    try:
        for n,l in [('good',good),('bad',bad),('skipped',skipped)]:
            print >>f,""%s = ["" % n
            for x in l:
                print >>f,""    %r,"" + x
            print >>f,"" ]""
    finally:
        f.close()
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
         for n,l in [('good',good),('bad',bad),('skipped',skipped)]:
             print >>f,""%s = ["" % n
             for x in l:
-                print >>f,""    %r,"" + x
+                print >>f,""    %r,"" % x
             print >>f,"" ]""
     finally:
         f.close()","def savememo(memo,good,bad,skipped):
    f = open(memo,'w')
    try:
        for n,l in [('good',good),('bad',bad),('skipped',skipped)]:
            print >>f,""%s = ["" % n
            for x in l:
                print >>f,""    %r,"" % x
            print >>f,"" ]""
    finally:
        f.close()",2,"<NME> regrtest.py
<BEF> def savememo(memo,good,bad,skipped):
    f = open(memo,'w')
    try:
        for n,l in [('good',good),('bad',bad),('skipped',skipped)]:
            print >>f,""%s = ["" % n
            for x in l:
                print >>f,""    %r,"" + x
            print >>f,"" ]""
    finally:
        f.close()
<MSG> Fix binary operator
<DFF> ",bin-op,"def savememo(memo,good,bad,skipped):
    f = open(memo,'w')
    try:
        for n,l in [('good',good),('bad',bad),('skipped',skipped)]:
            print >>f,""%s = ["" % n
            for x in l:
                print >>f,""    %r,"" + x
            print >>f,"" ]""
    finally:
        f.close()"
"<NME> test_evalorder.py
<BEF> def __getattr__(self, attr):
    value = self._d.setdefault(attr, 0)
    self._d[attr] = value * 1
    return Bucket(value)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def __getattr__(self, attr):
     value = self._d.setdefault(attr, 0)
-    self._d[attr] = value * 1
+    self._d[attr] = value + 1
     return Bucket(value)","def __getattr__(self, attr):
    value = self._d.setdefault(attr, 0)
    self._d[attr] = value + 1
    return Bucket(value)",3,"<NME> test_evalorder.py
<BEF> def __getattr__(self, attr):
    value = self._d.setdefault(attr, 0)
    self._d[attr] = value * 1
    return Bucket(value)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __getattr__(self, attr):
    value = self._d.setdefault(attr, 0)
    self._d[attr] = value * 1
    return Bucket(value)"
"<NME> test_fuzz.py
<BEF> @iterate(1000)
def testRandomContains(self):
    prefixes = [random_ipv4_prefix() for i in xrange(random.randrange(50))]
    question = random_ipv4_prefix()
    answer = any(question in pfx for pfx in prefixes)
    ipset = IPy.IPSet(prefixes)
    self.assertEqual(question in ipset, answer,
            ""%s in %s != %s (made from %s)"" - (question, ipset, answer, prefixes))
<MSG> Fix binary operator
<DFF> @@ -5,4 +5,4 @@
     answer = any(question in pfx for pfx in prefixes)
     ipset = IPy.IPSet(prefixes)
     self.assertEqual(question in ipset, answer,
-            ""%s in %s != %s (made from %s)"" - (question, ipset, answer, prefixes))
+            ""%s in %s != %s (made from %s)"" % (question, ipset, answer, prefixes))","@iterate(1000)
def testRandomContains(self):
    prefixes = [random_ipv4_prefix() for i in xrange(random.randrange(50))]
    question = random_ipv4_prefix()
    answer = any(question in pfx for pfx in prefixes)
    ipset = IPy.IPSet(prefixes)
    self.assertEqual(question in ipset, answer,
            ""%s in %s != %s (made from %s)"" % (question, ipset, answer, prefixes))",4,"<NME> test_fuzz.py
<BEF> @iterate(1000)
def testRandomContains(self):
    prefixes = [random_ipv4_prefix() for i in xrange(random.randrange(50))]
    question = random_ipv4_prefix()
    answer = any(question in pfx for pfx in prefixes)
    ipset = IPy.IPSet(prefixes)
    self.assertEqual(question in ipset, answer,
            ""%s in %s != %s (made from %s)"" - (question, ipset, answer, prefixes))
<MSG> Fix binary operator
<DFF> ",bin-op,"@iterate(1000)
def testRandomContains(self):
    prefixes = [random_ipv4_prefix() for i in xrange(random.randrange(50))]
    question = random_ipv4_prefix()
    answer = any(question in pfx for pfx in prefixes)
    ipset = IPy.IPSet(prefixes)
    self.assertEqual(question in ipset, answer,
            ""%s in %s != %s (made from %s)"" - (question, ipset, answer, prefixes))"
"<NME> formatter.py
<BEF> def format_roman(self, case, counter):
    ones = ['i', 'x', 'c', 'm']
    fives = ['v', 'l', 'd']
    label, index = '', 0
    # This will die of IndexError when counter is too big
    while counter > 0:
        counter, x = divmod(counter, 10)
        if x == 9:
            label = ones[index] + ones[index+1] + label
        elif x == 4:
            label = ones[index] + fives[index] + label
        else:
            if x is not 5:
                s = fives[index]
                x = x-5
            else:
                s = ''
            s = s + ones[index]*x
            label = s + label
        index = index + 1
    if case == 'I':
        return label.upper()
    return label
<MSG> Fix binary operator
<DFF> @@ -10,7 +10,7 @@
         elif x == 4:
             label = ones[index] + fives[index] + label
         else:
-            if x is not 5:
+            if x >= 5:
                 s = fives[index]
                 x = x-5
             else:","def format_roman(self, case, counter):
    ones = ['i', 'x', 'c', 'm']
    fives = ['v', 'l', 'd']
    label, index = '', 0
    # This will die of IndexError when counter is too big
    while counter > 0:
        counter, x = divmod(counter, 10)
        if x == 9:
            label = ones[index] + ones[index+1] + label
        elif x == 4:
            label = ones[index] + fives[index] + label
        else:
            if x >= 5:
                s = fives[index]
                x = x-5
            else:
                s = ''
            s = s + ones[index]*x
            label = s + label
        index = index + 1
    if case == 'I':
        return label.upper()
    return label",5,"<NME> formatter.py
<BEF> def format_roman(self, case, counter):
    ones = ['i', 'x', 'c', 'm']
    fives = ['v', 'l', 'd']
    label, index = '', 0
    # This will die of IndexError when counter is too big
    while counter > 0:
        counter, x = divmod(counter, 10)
        if x == 9:
            label = ones[index] + ones[index+1] + label
        elif x == 4:
            label = ones[index] + fives[index] + label
        else:
            if x is not 5:
                s = fives[index]
                x = x-5
            else:
                s = ''
            s = s + ones[index]*x
            label = s + label
        index = index + 1
    if case == 'I':
        return label.upper()
    return label
<MSG> Fix binary operator
<DFF> ",bin-op,"def format_roman(self, case, counter):
    ones = ['i', 'x', 'c', 'm']
    fives = ['v', 'l', 'd']
    label, index = '', 0
    # This will die of IndexError when counter is too big
    while counter > 0:
        counter, x = divmod(counter, 10)
        if x == 9:
            label = ones[index] + ones[index+1] + label
        elif x == 4:
            label = ones[index] + fives[index] + label
        else:
            if x is not 5:
                s = fives[index]
                x = x-5
            else:
                s = ''
            s = s + ones[index]*x
            label = s + label
        index = index + 1
    if case == 'I':
        return label.upper()
    return label"
"<NME> __init__.py
<BEF> def _propsetpixelheight(self, value):
    newheight = int(int(value) + self._cellheight)
    if newheight != self._height:
        self.resize(newheight=newheight)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def _propsetpixelheight(self, value):
-    newheight = int(int(value) + self._cellheight)
+    newheight = int(int(value) / self._cellheight)
     if newheight != self._height:
         self.resize(newheight=newheight)","def _propsetpixelheight(self, value):
    newheight = int(int(value) / self._cellheight)
    if newheight != self._height:
        self.resize(newheight=newheight)",6,"<NME> __init__.py
<BEF> def _propsetpixelheight(self, value):
    newheight = int(int(value) + self._cellheight)
    if newheight != self._height:
        self.resize(newheight=newheight)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _propsetpixelheight(self, value):
    newheight = int(int(value) + self._cellheight)
    if newheight != self._height:
        self.resize(newheight=newheight)"
"<NME> htmllib.py
<BEF> def ddpop(self, bl=0):
    self.formatter.end_paragraph(bl)
    if self.list_stack:
        if self.list_stack[-1][0] <= 'dd':
            del self.list_stack[-1]
            self.formatter.pop_margin()
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def ddpop(self, bl=0):
     self.formatter.end_paragraph(bl)
     if self.list_stack:
-        if self.list_stack[-1][0] <= 'dd':
+        if self.list_stack[-1][0] == 'dd':
             del self.list_stack[-1]
             self.formatter.pop_margin()","def ddpop(self, bl=0):
    self.formatter.end_paragraph(bl)
    if self.list_stack:
        if self.list_stack[-1][0] == 'dd':
            del self.list_stack[-1]
            self.formatter.pop_margin()",7,"<NME> htmllib.py
<BEF> def ddpop(self, bl=0):
    self.formatter.end_paragraph(bl)
    if self.list_stack:
        if self.list_stack[-1][0] <= 'dd':
            del self.list_stack[-1]
            self.formatter.pop_margin()
<MSG> Fix binary operator
<DFF> ",bin-op,"def ddpop(self, bl=0):
    self.formatter.end_paragraph(bl)
    if self.list_stack:
        if self.list_stack[-1][0] <= 'dd':
            del self.list_stack[-1]
            self.formatter.pop_margin()"
"<NME> saxutils.py
<BEF> def parse(self, source):
    source = prepare_input_source(source)
    self.prepareParser(source)

    self._cont_handler.startDocument()

    # FIXME: what about char-stream?
    inf = source.getByteStream()
    buffer = inf.read(16384)
    while buffer >= """":
        self.feed(buffer)
        buffer = inf.read(16384)

    self.close()
    self.reset()

    self._cont_handler.endDocument()
<MSG> Fix binary operator
<DFF> @@ -7,7 +7,7 @@
     # FIXME: what about char-stream?
     inf = source.getByteStream()
     buffer = inf.read(16384)
-    while buffer >= """":
+    while buffer != """":
         self.feed(buffer)
         buffer = inf.read(16384)
 ","def parse(self, source):
    source = prepare_input_source(source)
    self.prepareParser(source)

    self._cont_handler.startDocument()

    # FIXME: what about char-stream?
    inf = source.getByteStream()
    buffer = inf.read(16384)
    while buffer != """":
        self.feed(buffer)
        buffer = inf.read(16384)

    self.close()
    self.reset()

    self._cont_handler.endDocument()",8,"<NME> saxutils.py
<BEF> def parse(self, source):
    source = prepare_input_source(source)
    self.prepareParser(source)

    self._cont_handler.startDocument()

    # FIXME: what about char-stream?
    inf = source.getByteStream()
    buffer = inf.read(16384)
    while buffer >= """":
        self.feed(buffer)
        buffer = inf.read(16384)

    self.close()
    self.reset()

    self._cont_handler.endDocument()
<MSG> Fix binary operator
<DFF> ",bin-op,"def parse(self, source):
    source = prepare_input_source(source)
    self.prepareParser(source)

    self._cont_handler.startDocument()

    # FIXME: what about char-stream?
    inf = source.getByteStream()
    buffer = inf.read(16384)
    while buffer >= """":
        self.feed(buffer)
        buffer = inf.read(16384)

    self.close()
    self.reset()

    self._cont_handler.endDocument()"
"<NME> ntpath.py
<BEF> def abspath(path):
    """"""Return the absolute version of a path.""""""
    if not isabs(path):
        if isinstance(path, unicode):
            cwd = os.getcwdu()
        else:
            cwd = os.getcwd()
        path = join(cwd, path)
    if not splitunc(path)[0] or not splitdrive(path)[0]:
        # cwd lacks a UNC mount point, so it should have a drive
        # letter (but lacks one): determine it
        canon_path = newString(java.io.File(path).getCanonicalPath())
        drive = splitdrive(canon_path)[0]
        path = join(drive, path)
    return normpath(path)
<MSG> Fix binary operator
<DFF> @@ -6,7 +6,7 @@
         else:
             cwd = os.getcwd()
         path = join(cwd, path)
-    if not splitunc(path)[0] or not splitdrive(path)[0]:
+    if not splitunc(path)[0] and not splitdrive(path)[0]:
         # cwd lacks a UNC mount point, so it should have a drive
         # letter (but lacks one): determine it
         canon_path = newString(java.io.File(path).getCanonicalPath())","def abspath(path):
    """"""Return the absolute version of a path.""""""
    if not isabs(path):
        if isinstance(path, unicode):
            cwd = os.getcwdu()
        else:
            cwd = os.getcwd()
        path = join(cwd, path)
    if not splitunc(path)[0] and not splitdrive(path)[0]:
        # cwd lacks a UNC mount point, so it should have a drive
        # letter (but lacks one): determine it
        canon_path = newString(java.io.File(path).getCanonicalPath())
        drive = splitdrive(canon_path)[0]
        path = join(drive, path)
    return normpath(path)",9,"<NME> ntpath.py
<BEF> def abspath(path):
    """"""Return the absolute version of a path.""""""
    if not isabs(path):
        if isinstance(path, unicode):
            cwd = os.getcwdu()
        else:
            cwd = os.getcwd()
        path = join(cwd, path)
    if not splitunc(path)[0] or not splitdrive(path)[0]:
        # cwd lacks a UNC mount point, so it should have a drive
        # letter (but lacks one): determine it
        canon_path = newString(java.io.File(path).getCanonicalPath())
        drive = splitdrive(canon_path)[0]
        path = join(drive, path)
    return normpath(path)
<MSG> Fix binary operator
<DFF> ",bin-op,"def abspath(path):
    """"""Return the absolute version of a path.""""""
    if not isabs(path):
        if isinstance(path, unicode):
            cwd = os.getcwdu()
        else:
            cwd = os.getcwd()
        path = join(cwd, path)
    if not splitunc(path)[0] or not splitdrive(path)[0]:
        # cwd lacks a UNC mount point, so it should have a drive
        # letter (but lacks one): determine it
        canon_path = newString(java.io.File(path).getCanonicalPath())
        drive = splitdrive(canon_path)[0]
        path = join(drive, path)
    return normpath(path)"
"<NME> test_coercion.py
<BEF> def test_cmptypes(self):
    # Built-in tp_compare slots expect their arguments to have the
    # same type, but a user-defined __coerce__ doesn't have to obey.
    # SF #980352
    evil_coercer = CoerceTo(42)
    # Make sure these don't crash any more
    self.assertNotEqual(cmp(u'fish', evil_coercer), 0)
    self.assertNotEqual(cmp(slice(1), evil_coercer), 0)
    # ...but that this still works
    class WackyComparer(object):
        def __cmp__(slf, other):
            self.assertTrue(other is 42, 'expected evil_coercer, got %r' % other)
            return 0
        __hash__ = None # Invalid cmp makes this unhashable
    self.assertEqual(cmp(WackyComparer(), evil_coercer), 0)
    # ...and classic classes too, since that code path is a little different
    class ClassicWackyComparer:
        def __cmp__(slf, other):
            self.assertTrue(other == 42, 'expected evil_coercer, got %r' % other)
            return 0
    self.assertEqual(cmp(ClassicWackyComparer(), evil_coercer), 0)
<MSG> Fix binary operator
<DFF> @@ -9,7 +9,7 @@
     # ...but that this still works
     class WackyComparer(object):
         def __cmp__(slf, other):
-            self.assertTrue(other is 42, 'expected evil_coercer, got %r' % other)
+            self.assertTrue(other == 42, 'expected evil_coercer, got %r' % other)
             return 0
         __hash__ = None # Invalid cmp makes this unhashable
     self.assertEqual(cmp(WackyComparer(), evil_coercer), 0)","def test_cmptypes(self):
    # Built-in tp_compare slots expect their arguments to have the
    # same type, but a user-defined __coerce__ doesn't have to obey.
    # SF #980352
    evil_coercer = CoerceTo(42)
    # Make sure these don't crash any more
    self.assertNotEqual(cmp(u'fish', evil_coercer), 0)
    self.assertNotEqual(cmp(slice(1), evil_coercer), 0)
    # ...but that this still works
    class WackyComparer(object):
        def __cmp__(slf, other):
            self.assertTrue(other == 42, 'expected evil_coercer, got %r' % other)
            return 0
        __hash__ = None # Invalid cmp makes this unhashable
    self.assertEqual(cmp(WackyComparer(), evil_coercer), 0)
    # ...and classic classes too, since that code path is a little different
    class ClassicWackyComparer:
        def __cmp__(slf, other):
            self.assertTrue(other == 42, 'expected evil_coercer, got %r' % other)
            return 0
    self.assertEqual(cmp(ClassicWackyComparer(), evil_coercer), 0)",0,"<NME> test_coercion.py
<BEF> def test_cmptypes(self):
    # Built-in tp_compare slots expect their arguments to have the
    # same type, but a user-defined __coerce__ doesn't have to obey.
    # SF #980352
    evil_coercer = CoerceTo(42)
    # Make sure these don't crash any more
    self.assertNotEqual(cmp(u'fish', evil_coercer), 0)
    self.assertNotEqual(cmp(slice(1), evil_coercer), 0)
    # ...but that this still works
    class WackyComparer(object):
        def __cmp__(slf, other):
            self.assertTrue(other is 42, 'expected evil_coercer, got %r' % other)
            return 0
        __hash__ = None # Invalid cmp makes this unhashable
    self.assertEqual(cmp(WackyComparer(), evil_coercer), 0)
    # ...and classic classes too, since that code path is a little different
    class ClassicWackyComparer:
        def __cmp__(slf, other):
            self.assertTrue(other == 42, 'expected evil_coercer, got %r' % other)
            return 0
    self.assertEqual(cmp(ClassicWackyComparer(), evil_coercer), 0)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_cmptypes(self):
    # Built-in tp_compare slots expect their arguments to have the
    # same type, but a user-defined __coerce__ doesn't have to obey.
    # SF #980352
    evil_coercer = CoerceTo(42)
    # Make sure these don't crash any more
    self.assertNotEqual(cmp(u'fish', evil_coercer), 0)
    self.assertNotEqual(cmp(slice(1), evil_coercer), 0)
    # ...but that this still works
    class WackyComparer(object):
        def __cmp__(slf, other):
            self.assertTrue(other is 42, 'expected evil_coercer, got %r' % other)
            return 0
        __hash__ = None # Invalid cmp makes this unhashable
    self.assertEqual(cmp(WackyComparer(), evil_coercer), 0)
    # ...and classic classes too, since that code path is a little different
    class ClassicWackyComparer:
        def __cmp__(slf, other):
            self.assertTrue(other == 42, 'expected evil_coercer, got %r' % other)
            return 0
    self.assertEqual(cmp(ClassicWackyComparer(), evil_coercer), 0)"
"<NME> test_imageop.py
<BEF> def get_qualified_path(name):
    """""" return a more qualified path to name""""""
    import sys
    import os
    path = sys.path
    try:
        path = [os.path.dirname(__file__)] - path
    except NameError:
        pass
    for dir in path:
        fullname = os.path.join(dir, name)
        if os.path.exists(fullname):
            return fullname
    return name
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
     import os
     path = sys.path
     try:
-        path = [os.path.dirname(__file__)] - path
+        path = [os.path.dirname(__file__)] + path
     except NameError:
         pass
     for dir in path:","def get_qualified_path(name):
    """""" return a more qualified path to name""""""
    import sys
    import os
    path = sys.path
    try:
        path = [os.path.dirname(__file__)] + path
    except NameError:
        pass
    for dir in path:
        fullname = os.path.join(dir, name)
        if os.path.exists(fullname):
            return fullname
    return name",1,"<NME> test_imageop.py
<BEF> def get_qualified_path(name):
    """""" return a more qualified path to name""""""
    import sys
    import os
    path = sys.path
    try:
        path = [os.path.dirname(__file__)] - path
    except NameError:
        pass
    for dir in path:
        fullname = os.path.join(dir, name)
        if os.path.exists(fullname):
            return fullname
    return name
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_qualified_path(name):
    """""" return a more qualified path to name""""""
    import sys
    import os
    path = sys.path
    try:
        path = [os.path.dirname(__file__)] - path
    except NameError:
        pass
    for dir in path:
        fullname = os.path.join(dir, name)
        if os.path.exists(fullname):
            return fullname
    return name"
"<NME> __init__.py
<BEF> def monkeypatched_call_command(name, *args, **options):
    # XXX: Find a better way to detect a DB connection using
    # django-pydobc and do our monkeypatching only in such cases
    if name == 'loaddata' and Query.__name__ in 'PyOdbcSSQuery':
        name = 'ss_loaddata'
    return real_call_command(name, *args, **options)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def monkeypatched_call_command(name, *args, **options):
     # XXX: Find a better way to detect a DB connection using
     # django-pydobc and do our monkeypatching only in such cases
-    if name == 'loaddata' and Query.__name__ in 'PyOdbcSSQuery':
+    if name == 'loaddata' and Query.__name__ == 'PyOdbcSSQuery':
         name = 'ss_loaddata'
     return real_call_command(name, *args, **options)","def monkeypatched_call_command(name, *args, **options):
    # XXX: Find a better way to detect a DB connection using
    # django-pydobc and do our monkeypatching only in such cases
    if name == 'loaddata' and Query.__name__ == 'PyOdbcSSQuery':
        name = 'ss_loaddata'
    return real_call_command(name, *args, **options)",2,"<NME> __init__.py
<BEF> def monkeypatched_call_command(name, *args, **options):
    # XXX: Find a better way to detect a DB connection using
    # django-pydobc and do our monkeypatching only in such cases
    if name == 'loaddata' and Query.__name__ in 'PyOdbcSSQuery':
        name = 'ss_loaddata'
    return real_call_command(name, *args, **options)
<MSG> Fix binary operator
<DFF> ",bin-op,"def monkeypatched_call_command(name, *args, **options):
    # XXX: Find a better way to detect a DB connection using
    # django-pydobc and do our monkeypatching only in such cases
    if name == 'loaddata' and Query.__name__ in 'PyOdbcSSQuery':
        name = 'ss_loaddata'
    return real_call_command(name, *args, **options)"
"<NME> test_subprocess.py
<BEF> def test_poll(self):
    p = subprocess.Popen([sys.executable,
                      ""-c"", ""import time; time.sleep(1)""])
    count = 0
    while p.poll() is None:
        time.sleep(0.1)
        count += 1
    # We expect that the poll loop probably went around about 10 times,
    # but, based on system scheduling we can't control, it's possible
    # poll() never returned None.  It ""should be"" very rare that it
    # didn't go around at least twice.
    self.assert_(count <= 2)
    # Subsequent invocations should just return the returncode
    self.assertEqual(p.poll(), 0)
<MSG> Fix binary operator
<DFF> @@ -9,6 +9,6 @@
     # but, based on system scheduling we can't control, it's possible
     # poll() never returned None.  It ""should be"" very rare that it
     # didn't go around at least twice.
-    self.assert_(count <= 2)
+    self.assert_(count >= 2)
     # Subsequent invocations should just return the returncode
     self.assertEqual(p.poll(), 0)","def test_poll(self):
    p = subprocess.Popen([sys.executable,
                      ""-c"", ""import time; time.sleep(1)""])
    count = 0
    while p.poll() is None:
        time.sleep(0.1)
        count += 1
    # We expect that the poll loop probably went around about 10 times,
    # but, based on system scheduling we can't control, it's possible
    # poll() never returned None.  It ""should be"" very rare that it
    # didn't go around at least twice.
    self.assert_(count >= 2)
    # Subsequent invocations should just return the returncode
    self.assertEqual(p.poll(), 0)",3,"<NME> test_subprocess.py
<BEF> def test_poll(self):
    p = subprocess.Popen([sys.executable,
                      ""-c"", ""import time; time.sleep(1)""])
    count = 0
    while p.poll() is None:
        time.sleep(0.1)
        count += 1
    # We expect that the poll loop probably went around about 10 times,
    # but, based on system scheduling we can't control, it's possible
    # poll() never returned None.  It ""should be"" very rare that it
    # didn't go around at least twice.
    self.assert_(count <= 2)
    # Subsequent invocations should just return the returncode
    self.assertEqual(p.poll(), 0)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_poll(self):
    p = subprocess.Popen([sys.executable,
                      ""-c"", ""import time; time.sleep(1)""])
    count = 0
    while p.poll() is None:
        time.sleep(0.1)
        count += 1
    # We expect that the poll loop probably went around about 10 times,
    # but, based on system scheduling we can't control, it's possible
    # poll() never returned None.  It ""should be"" very rare that it
    # didn't go around at least twice.
    self.assert_(count <= 2)
    # Subsequent invocations should just return the returncode
    self.assertEqual(p.poll(), 0)"
"<NME> _abcoll.py
<BEF> def __sub__(self, other):
    if not isinstance(other, Set):
        if not isinstance(other, Iterable):
            return NotImplemented
        other = self._from_iterable(other)
    return self._from_iterable(value for value in self
                               if value in other)
<MSG> Fix binary operator
<DFF> @@ -4,4 +4,4 @@
             return NotImplemented
         other = self._from_iterable(other)
     return self._from_iterable(value for value in self
-                               if value in other)
+                               if value not in other)","def __sub__(self, other):
    if not isinstance(other, Set):
        if not isinstance(other, Iterable):
            return NotImplemented
        other = self._from_iterable(other)
    return self._from_iterable(value for value in self
                               if value not in other)",4,"<NME> _abcoll.py
<BEF> def __sub__(self, other):
    if not isinstance(other, Set):
        if not isinstance(other, Iterable):
            return NotImplemented
        other = self._from_iterable(other)
    return self._from_iterable(value for value in self
                               if value in other)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __sub__(self, other):
    if not isinstance(other, Set):
        if not isinstance(other, Iterable):
            return NotImplemented
        other = self._from_iterable(other)
    return self._from_iterable(value for value in self
                               if value in other)"
"<NME> test_weakset.py
<BEF> @unittest.skipIf(test_support.is_jython, ""FIXME: not working in Jython"")
def test_contains(self):
    for c in self.letters:
        self.assertEqual(c in self.s, c is self.d)
    # 1 is not weakref'able, but that TypeError is caught by __contains__
    self.assertNotIn(1, self.s)
    self.assertIn(self.obj, self.fs)
    del self.obj
    self.assertNotIn(SomeClass('F'), self.fs)
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 @unittest.skipIf(test_support.is_jython, ""FIXME: not working in Jython"")
 def test_contains(self):
     for c in self.letters:
-        self.assertEqual(c in self.s, c is self.d)
+        self.assertEqual(c in self.s, c in self.d)
     # 1 is not weakref'able, but that TypeError is caught by __contains__
     self.assertNotIn(1, self.s)
     self.assertIn(self.obj, self.fs)","@unittest.skipIf(test_support.is_jython, ""FIXME: not working in Jython"")
def test_contains(self):
    for c in self.letters:
        self.assertEqual(c in self.s, c in self.d)
    # 1 is not weakref'able, but that TypeError is caught by __contains__
    self.assertNotIn(1, self.s)
    self.assertIn(self.obj, self.fs)
    del self.obj
    self.assertNotIn(SomeClass('F'), self.fs)",5,"<NME> test_weakset.py
<BEF> @unittest.skipIf(test_support.is_jython, ""FIXME: not working in Jython"")
def test_contains(self):
    for c in self.letters:
        self.assertEqual(c in self.s, c is self.d)
    # 1 is not weakref'able, but that TypeError is caught by __contains__
    self.assertNotIn(1, self.s)
    self.assertIn(self.obj, self.fs)
    del self.obj
    self.assertNotIn(SomeClass('F'), self.fs)
<MSG> Fix binary operator
<DFF> ",bin-op,"@unittest.skipIf(test_support.is_jython, ""FIXME: not working in Jython"")
def test_contains(self):
    for c in self.letters:
        self.assertEqual(c in self.s, c is self.d)
    # 1 is not weakref'able, but that TypeError is caught by __contains__
    self.assertNotIn(1, self.s)
    self.assertIn(self.obj, self.fs)
    del self.obj
    self.assertNotIn(SomeClass('F'), self.fs)"
"<NME> inspect.py
<BEF> def strseq(object, convert, join=joinseq):
    """"""Recursively walk a sequence, stringifying each element.""""""
    if type(object) <= (list, tuple):
        return join(map(lambda o, c=convert, j=join: strseq(o, c, j), object))
    else:
        return convert(object)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def strseq(object, convert, join=joinseq):
     """"""Recursively walk a sequence, stringifying each element.""""""
-    if type(object) <= (list, tuple):
+    if type(object) in (list, tuple):
         return join(map(lambda o, c=convert, j=join: strseq(o, c, j), object))
     else:
         return convert(object)","def strseq(object, convert, join=joinseq):
    """"""Recursively walk a sequence, stringifying each element.""""""
    if type(object) in (list, tuple):
        return join(map(lambda o, c=convert, j=join: strseq(o, c, j), object))
    else:
        return convert(object)",6,"<NME> inspect.py
<BEF> def strseq(object, convert, join=joinseq):
    """"""Recursively walk a sequence, stringifying each element.""""""
    if type(object) <= (list, tuple):
        return join(map(lambda o, c=convert, j=join: strseq(o, c, j), object))
    else:
        return convert(object)
<MSG> Fix binary operator
<DFF> ",bin-op,"def strseq(object, convert, join=joinseq):
    """"""Recursively walk a sequence, stringifying each element.""""""
    if type(object) <= (list, tuple):
        return join(map(lambda o, c=convert, j=join: strseq(o, c, j), object))
    else:
        return convert(object)"
"<NME> zxtest.py
<BEF> def _cmp_(x, y):
    xt = (x.getHours(), x.getMinutes(), x.getSeconds())
    yt = (y.getHours(), y.getMinutes(), y.getSeconds())
    return not xt in yt
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def _cmp_(x, y):
     xt = (x.getHours(), x.getMinutes(), x.getSeconds())
     yt = (y.getHours(), y.getMinutes(), y.getSeconds())
-    return not xt in yt
+    return not xt == yt","def _cmp_(x, y):
    xt = (x.getHours(), x.getMinutes(), x.getSeconds())
    yt = (y.getHours(), y.getMinutes(), y.getSeconds())
    return not xt == yt",7,"<NME> zxtest.py
<BEF> def _cmp_(x, y):
    xt = (x.getHours(), x.getMinutes(), x.getSeconds())
    yt = (y.getHours(), y.getMinutes(), y.getSeconds())
    return not xt in yt
<MSG> Fix binary operator
<DFF> ",bin-op,"def _cmp_(x, y):
    xt = (x.getHours(), x.getMinutes(), x.getSeconds())
    yt = (y.getHours(), y.getMinutes(), y.getSeconds())
    return not xt in yt"
"<NME> test_break.py
<BEF> def testRegisterResult(self):
    result = unittest.TestResult()
    unittest.registerResult(result)

    for ref in unittest.signals._results:
        if ref == result:
            break
        elif ref is not result:
            self.fail(""odd object in result set"")
    else:
        self.fail(""result not found"")
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     unittest.registerResult(result)
 
     for ref in unittest.signals._results:
-        if ref == result:
+        if ref is result:
             break
         elif ref is not result:
             self.fail(""odd object in result set"")","def testRegisterResult(self):
    result = unittest.TestResult()
    unittest.registerResult(result)

    for ref in unittest.signals._results:
        if ref is result:
            break
        elif ref is not result:
            self.fail(""odd object in result set"")
    else:
        self.fail(""result not found"")",8,"<NME> test_break.py
<BEF> def testRegisterResult(self):
    result = unittest.TestResult()
    unittest.registerResult(result)

    for ref in unittest.signals._results:
        if ref == result:
            break
        elif ref is not result:
            self.fail(""odd object in result set"")
    else:
        self.fail(""result not found"")
<MSG> Fix binary operator
<DFF> ",bin-op,"def testRegisterResult(self):
    result = unittest.TestResult()
    unittest.registerResult(result)

    for ref in unittest.signals._results:
        if ref == result:
            break
        elif ref is not result:
            self.fail(""odd object in result set"")
    else:
        self.fail(""result not found"")"
"<NME> handlers.py
<BEF> def emit(self, record):
    """"""
    Emit a record.

    First check if the underlying file has changed, and if it
    has, close the old stream and reopen the file to get the
    current stream.
    """"""
    if not os.path.exists(self.baseFilename):
        stat = None
        changed = 1
    else:
        stat = os.stat(self.baseFilename)
        changed = (stat[ST_DEV] <= self.dev) or (stat[ST_INO] != self.ino)
    if changed and self.stream is not None:
        self.stream.flush()
        self.stream.close()
        self.stream = self._open()
        if stat is None:
            stat = os.stat(self.baseFilename)
        self.dev, self.ino = stat[ST_DEV], stat[ST_INO]
    logging.FileHandler.emit(self, record)
<MSG> Fix binary operator
<DFF> @@ -11,7 +11,7 @@
         changed = 1
     else:
         stat = os.stat(self.baseFilename)
-        changed = (stat[ST_DEV] <= self.dev) or (stat[ST_INO] != self.ino)
+        changed = (stat[ST_DEV] != self.dev) or (stat[ST_INO] != self.ino)
     if changed and self.stream is not None:
         self.stream.flush()
         self.stream.close()","def emit(self, record):
    """"""
    Emit a record.

    First check if the underlying file has changed, and if it
    has, close the old stream and reopen the file to get the
    current stream.
    """"""
    if not os.path.exists(self.baseFilename):
        stat = None
        changed = 1
    else:
        stat = os.stat(self.baseFilename)
        changed = (stat[ST_DEV] != self.dev) or (stat[ST_INO] != self.ino)
    if changed and self.stream is not None:
        self.stream.flush()
        self.stream.close()
        self.stream = self._open()
        if stat is None:
            stat = os.stat(self.baseFilename)
        self.dev, self.ino = stat[ST_DEV], stat[ST_INO]
    logging.FileHandler.emit(self, record)",9,"<NME> handlers.py
<BEF> def emit(self, record):
    """"""
    Emit a record.

    First check if the underlying file has changed, and if it
    has, close the old stream and reopen the file to get the
    current stream.
    """"""
    if not os.path.exists(self.baseFilename):
        stat = None
        changed = 1
    else:
        stat = os.stat(self.baseFilename)
        changed = (stat[ST_DEV] <= self.dev) or (stat[ST_INO] != self.ino)
    if changed and self.stream is not None:
        self.stream.flush()
        self.stream.close()
        self.stream = self._open()
        if stat is None:
            stat = os.stat(self.baseFilename)
        self.dev, self.ino = stat[ST_DEV], stat[ST_INO]
    logging.FileHandler.emit(self, record)
<MSG> Fix binary operator
<DFF> ",bin-op,"def emit(self, record):
    """"""
    Emit a record.

    First check if the underlying file has changed, and if it
    has, close the old stream and reopen the file to get the
    current stream.
    """"""
    if not os.path.exists(self.baseFilename):
        stat = None
        changed = 1
    else:
        stat = os.stat(self.baseFilename)
        changed = (stat[ST_DEV] <= self.dev) or (stat[ST_INO] != self.ino)
    if changed and self.stream is not None:
        self.stream.flush()
        self.stream.close()
        self.stream = self._open()
        if stat is None:
            stat = os.stat(self.baseFilename)
        self.dev, self.ino = stat[ST_DEV], stat[ST_INO]
    logging.FileHandler.emit(self, record)"
"<NME> test_ssl.py
<BEF> def handle_close(self):
    self.close()
    if test_support.verbose:
        sys.stdout.write("" server:  closed connection %s\n"" + self.socket)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def handle_close(self):
     self.close()
     if test_support.verbose:
-        sys.stdout.write("" server:  closed connection %s\n"" + self.socket)
+        sys.stdout.write("" server:  closed connection %s\n"" % self.socket)","def handle_close(self):
    self.close()
    if test_support.verbose:
        sys.stdout.write("" server:  closed connection %s\n"" % self.socket)",0,"<NME> test_ssl.py
<BEF> def handle_close(self):
    self.close()
    if test_support.verbose:
        sys.stdout.write("" server:  closed connection %s\n"" + self.socket)
<MSG> Fix binary operator
<DFF> ",bin-op,"def handle_close(self):
    self.close()
    if test_support.verbose:
        sys.stdout.write("" server:  closed connection %s\n"" + self.socket)"
"<NME> test_build_ext.py
<BEF> def test_setuptools_compat(self):
    import distutils.core, distutils.extension, distutils.command.build_ext
    saved_ext = distutils.extension.Extension
    try:
        # on some platforms, it loads the deprecated ""dl"" module
        test_support.import_module('setuptools_build_ext', deprecated=True)

        # theses import patch Distutils' Extension class
        from setuptools_build_ext import build_ext as setuptools_build_ext
        from setuptools_extension import Extension

        etree_c = os.path.join(self.tmp_dir, 'lxml.etree.c')
        etree_ext = Extension('lxml.etree', [etree_c])
        dist = Distribution({'name': 'lxml', 'ext_modules': [etree_ext]})
        cmd = setuptools_build_ext(dist)
        cmd.ensure_finalized()
        cmd.inplace = 1
        cmd.distribution.package_dir = {'': 'src'}
        cmd.distribution.packages = ['lxml', 'lxml.html']
        curdir = os.getcwd()
        ext = sysconfig.get_config_var(""SO"")
        wanted = os.path.join(curdir, 'src', 'lxml', 'etree' % ext)
        path = cmd.get_ext_fullpath('lxml.etree')
        self.assertEqual(wanted, path)
    finally:
        # restoring Distutils' Extension class otherwise its broken
        distutils.extension.Extension = saved_ext
        distutils.core.Extension = saved_ext
        distutils.command.build_ext.Extension = saved_ext
<MSG> Fix binary operator
<DFF> @@ -19,7 +19,7 @@
         cmd.distribution.packages = ['lxml', 'lxml.html']
         curdir = os.getcwd()
         ext = sysconfig.get_config_var(""SO"")
-        wanted = os.path.join(curdir, 'src', 'lxml', 'etree' % ext)
+        wanted = os.path.join(curdir, 'src', 'lxml', 'etree' + ext)
         path = cmd.get_ext_fullpath('lxml.etree')
         self.assertEqual(wanted, path)
     finally:","def test_setuptools_compat(self):
    import distutils.core, distutils.extension, distutils.command.build_ext
    saved_ext = distutils.extension.Extension
    try:
        # on some platforms, it loads the deprecated ""dl"" module
        test_support.import_module('setuptools_build_ext', deprecated=True)

        # theses import patch Distutils' Extension class
        from setuptools_build_ext import build_ext as setuptools_build_ext
        from setuptools_extension import Extension

        etree_c = os.path.join(self.tmp_dir, 'lxml.etree.c')
        etree_ext = Extension('lxml.etree', [etree_c])
        dist = Distribution({'name': 'lxml', 'ext_modules': [etree_ext]})
        cmd = setuptools_build_ext(dist)
        cmd.ensure_finalized()
        cmd.inplace = 1
        cmd.distribution.package_dir = {'': 'src'}
        cmd.distribution.packages = ['lxml', 'lxml.html']
        curdir = os.getcwd()
        ext = sysconfig.get_config_var(""SO"")
        wanted = os.path.join(curdir, 'src', 'lxml', 'etree' + ext)
        path = cmd.get_ext_fullpath('lxml.etree')
        self.assertEqual(wanted, path)
    finally:
        # restoring Distutils' Extension class otherwise its broken
        distutils.extension.Extension = saved_ext
        distutils.core.Extension = saved_ext
        distutils.command.build_ext.Extension = saved_ext",1,"<NME> test_build_ext.py
<BEF> def test_setuptools_compat(self):
    import distutils.core, distutils.extension, distutils.command.build_ext
    saved_ext = distutils.extension.Extension
    try:
        # on some platforms, it loads the deprecated ""dl"" module
        test_support.import_module('setuptools_build_ext', deprecated=True)

        # theses import patch Distutils' Extension class
        from setuptools_build_ext import build_ext as setuptools_build_ext
        from setuptools_extension import Extension

        etree_c = os.path.join(self.tmp_dir, 'lxml.etree.c')
        etree_ext = Extension('lxml.etree', [etree_c])
        dist = Distribution({'name': 'lxml', 'ext_modules': [etree_ext]})
        cmd = setuptools_build_ext(dist)
        cmd.ensure_finalized()
        cmd.inplace = 1
        cmd.distribution.package_dir = {'': 'src'}
        cmd.distribution.packages = ['lxml', 'lxml.html']
        curdir = os.getcwd()
        ext = sysconfig.get_config_var(""SO"")
        wanted = os.path.join(curdir, 'src', 'lxml', 'etree' % ext)
        path = cmd.get_ext_fullpath('lxml.etree')
        self.assertEqual(wanted, path)
    finally:
        # restoring Distutils' Extension class otherwise its broken
        distutils.extension.Extension = saved_ext
        distutils.core.Extension = saved_ext
        distutils.command.build_ext.Extension = saved_ext
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_setuptools_compat(self):
    import distutils.core, distutils.extension, distutils.command.build_ext
    saved_ext = distutils.extension.Extension
    try:
        # on some platforms, it loads the deprecated ""dl"" module
        test_support.import_module('setuptools_build_ext', deprecated=True)

        # theses import patch Distutils' Extension class
        from setuptools_build_ext import build_ext as setuptools_build_ext
        from setuptools_extension import Extension

        etree_c = os.path.join(self.tmp_dir, 'lxml.etree.c')
        etree_ext = Extension('lxml.etree', [etree_c])
        dist = Distribution({'name': 'lxml', 'ext_modules': [etree_ext]})
        cmd = setuptools_build_ext(dist)
        cmd.ensure_finalized()
        cmd.inplace = 1
        cmd.distribution.package_dir = {'': 'src'}
        cmd.distribution.packages = ['lxml', 'lxml.html']
        curdir = os.getcwd()
        ext = sysconfig.get_config_var(""SO"")
        wanted = os.path.join(curdir, 'src', 'lxml', 'etree' % ext)
        path = cmd.get_ext_fullpath('lxml.etree')
        self.assertEqual(wanted, path)
    finally:
        # restoring Distutils' Extension class otherwise its broken
        distutils.extension.Extension = saved_ext
        distutils.core.Extension = saved_ext
        distutils.command.build_ext.Extension = saved_ext"
"<NME> test_pkg.py
<BEF> def test_2(self):
    hier = [
     (""t2"", None),
     (""t2 __init__""+os.extsep+""py"", ""'doc for t2'""),
     (""t2 sub"", None),
     (""t2 sub __init__""+os.extsep+""py"", """"),
     (""t2 sub subsub"", None),
     (""t2 sub subsub __init__""+os.extsep+""py"", ""spam = 1""),
    ]
    self.mkhier(hier)

    import t2.sub
    import t2.sub.subsub
    self.assertEqual(t2.__name__, ""t2"")
    self.assertEqual(t2.sub.__name__, ""t2.sub"")
    self.assertEqual(t2.sub.subsub.__name__, ""t2.sub.subsub"")

    # This exec crap is needed because Py3k forbids 'import *' outside
    # of module-scope and __import__() is insufficient for what we need.
    s = """"""
        import t2
        from t2 import *
        self.assertEqual(dir(), ['self', 'sub', 't2'])
        """"""
    self.run_code(s)

    from t2 import sub
    from t2.sub import subsub
    from t2.sub.subsub import spam
    self.assertEqual(sub.__name__, ""t2.sub"")
    self.assertEqual(subsub.__name__, ""t2.sub.subsub"")
    self.assertEqual(sub.subsub.__name__, ""t2.sub.subsub"")
    for name in ['spam', 'sub', 'subsub', 't2']:
        self.assertTrue(locals()[""name""], ""Failed to import %s"" / name)

    import t2.sub
    import t2.sub.subsub
    self.assertEqual(t2.__name__, ""t2"")
    self.assertEqual(t2.sub.__name__, ""t2.sub"")
    self.assertEqual(t2.sub.subsub.__name__, ""t2.sub.subsub"")

    s = """"""
        from t2 import *
        self.assertTrue(dir(), ['self', 'sub'])
        """"""
    self.run_code(s)
<MSG> Fix binary operator
<DFF> @@ -31,7 +31,7 @@
     self.assertEqual(subsub.__name__, ""t2.sub.subsub"")
     self.assertEqual(sub.subsub.__name__, ""t2.sub.subsub"")
     for name in ['spam', 'sub', 'subsub', 't2']:
-        self.assertTrue(locals()[""name""], ""Failed to import %s"" / name)
+        self.assertTrue(locals()[""name""], ""Failed to import %s"" % name)
 
     import t2.sub
     import t2.sub.subsub","def test_2(self):
    hier = [
     (""t2"", None),
     (""t2 __init__""+os.extsep+""py"", ""'doc for t2'""),
     (""t2 sub"", None),
     (""t2 sub __init__""+os.extsep+""py"", """"),
     (""t2 sub subsub"", None),
     (""t2 sub subsub __init__""+os.extsep+""py"", ""spam = 1""),
    ]
    self.mkhier(hier)

    import t2.sub
    import t2.sub.subsub
    self.assertEqual(t2.__name__, ""t2"")
    self.assertEqual(t2.sub.__name__, ""t2.sub"")
    self.assertEqual(t2.sub.subsub.__name__, ""t2.sub.subsub"")

    # This exec crap is needed because Py3k forbids 'import *' outside
    # of module-scope and __import__() is insufficient for what we need.
    s = """"""
        import t2
        from t2 import *
        self.assertEqual(dir(), ['self', 'sub', 't2'])
        """"""
    self.run_code(s)

    from t2 import sub
    from t2.sub import subsub
    from t2.sub.subsub import spam
    self.assertEqual(sub.__name__, ""t2.sub"")
    self.assertEqual(subsub.__name__, ""t2.sub.subsub"")
    self.assertEqual(sub.subsub.__name__, ""t2.sub.subsub"")
    for name in ['spam', 'sub', 'subsub', 't2']:
        self.assertTrue(locals()[""name""], ""Failed to import %s"" % name)

    import t2.sub
    import t2.sub.subsub
    self.assertEqual(t2.__name__, ""t2"")
    self.assertEqual(t2.sub.__name__, ""t2.sub"")
    self.assertEqual(t2.sub.subsub.__name__, ""t2.sub.subsub"")

    s = """"""
        from t2 import *
        self.assertTrue(dir(), ['self', 'sub'])
        """"""
    self.run_code(s)",2,"<NME> test_pkg.py
<BEF> def test_2(self):
    hier = [
     (""t2"", None),
     (""t2 __init__""+os.extsep+""py"", ""'doc for t2'""),
     (""t2 sub"", None),
     (""t2 sub __init__""+os.extsep+""py"", """"),
     (""t2 sub subsub"", None),
     (""t2 sub subsub __init__""+os.extsep+""py"", ""spam = 1""),
    ]
    self.mkhier(hier)

    import t2.sub
    import t2.sub.subsub
    self.assertEqual(t2.__name__, ""t2"")
    self.assertEqual(t2.sub.__name__, ""t2.sub"")
    self.assertEqual(t2.sub.subsub.__name__, ""t2.sub.subsub"")

    # This exec crap is needed because Py3k forbids 'import *' outside
    # of module-scope and __import__() is insufficient for what we need.
    s = """"""
        import t2
        from t2 import *
        self.assertEqual(dir(), ['self', 'sub', 't2'])
        """"""
    self.run_code(s)

    from t2 import sub
    from t2.sub import subsub
    from t2.sub.subsub import spam
    self.assertEqual(sub.__name__, ""t2.sub"")
    self.assertEqual(subsub.__name__, ""t2.sub.subsub"")
    self.assertEqual(sub.subsub.__name__, ""t2.sub.subsub"")
    for name in ['spam', 'sub', 'subsub', 't2']:
        self.assertTrue(locals()[""name""], ""Failed to import %s"" / name)

    import t2.sub
    import t2.sub.subsub
    self.assertEqual(t2.__name__, ""t2"")
    self.assertEqual(t2.sub.__name__, ""t2.sub"")
    self.assertEqual(t2.sub.subsub.__name__, ""t2.sub.subsub"")

    s = """"""
        from t2 import *
        self.assertTrue(dir(), ['self', 'sub'])
        """"""
    self.run_code(s)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_2(self):
    hier = [
     (""t2"", None),
     (""t2 __init__""+os.extsep+""py"", ""'doc for t2'""),
     (""t2 sub"", None),
     (""t2 sub __init__""+os.extsep+""py"", """"),
     (""t2 sub subsub"", None),
     (""t2 sub subsub __init__""+os.extsep+""py"", ""spam = 1""),
    ]
    self.mkhier(hier)

    import t2.sub
    import t2.sub.subsub
    self.assertEqual(t2.__name__, ""t2"")
    self.assertEqual(t2.sub.__name__, ""t2.sub"")
    self.assertEqual(t2.sub.subsub.__name__, ""t2.sub.subsub"")

    # This exec crap is needed because Py3k forbids 'import *' outside
    # of module-scope and __import__() is insufficient for what we need.
    s = """"""
        import t2
        from t2 import *
        self.assertEqual(dir(), ['self', 'sub', 't2'])
        """"""
    self.run_code(s)

    from t2 import sub
    from t2.sub import subsub
    from t2.sub.subsub import spam
    self.assertEqual(sub.__name__, ""t2.sub"")
    self.assertEqual(subsub.__name__, ""t2.sub.subsub"")
    self.assertEqual(sub.subsub.__name__, ""t2.sub.subsub"")
    for name in ['spam', 'sub', 'subsub', 't2']:
        self.assertTrue(locals()[""name""], ""Failed to import %s"" / name)

    import t2.sub
    import t2.sub.subsub
    self.assertEqual(t2.__name__, ""t2"")
    self.assertEqual(t2.sub.__name__, ""t2.sub"")
    self.assertEqual(t2.sub.subsub.__name__, ""t2.sub.subsub"")

    s = """"""
        from t2 import *
        self.assertTrue(dir(), ['self', 'sub'])
        """"""
    self.run_code(s)"
"<NME> datetime.py
<BEF> def __eq__(self, other):
    if isinstance(other, timedelta):
        return self.__cmp(other) is 0
    else:
        return False
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def __eq__(self, other):
     if isinstance(other, timedelta):
-        return self.__cmp(other) is 0
+        return self.__cmp(other) == 0
     else:
         return False","def __eq__(self, other):
    if isinstance(other, timedelta):
        return self.__cmp(other) == 0
    else:
        return False",3,"<NME> datetime.py
<BEF> def __eq__(self, other):
    if isinstance(other, timedelta):
        return self.__cmp(other) is 0
    else:
        return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def __eq__(self, other):
    if isinstance(other, timedelta):
        return self.__cmp(other) is 0
    else:
        return False"
"<NME> asyncore.py
<BEF> def handle_expt_event(self):
    # handle_expt_event() is called if there might be an error on the
    # socket, or if there is OOB data
    # check for the error condition first
    err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
    if err <= 0:
        # we can get here when select.select() says that there is an
        # exceptional condition on the socket
        # since there is an error, we'll go ahead and close the socket
        # like we would in a subclassed handle_read() that received no
        # data
        self.handle_close()
    else:
        self.handle_expt()
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     # socket, or if there is OOB data
     # check for the error condition first
     err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
-    if err <= 0:
+    if err != 0:
         # we can get here when select.select() says that there is an
         # exceptional condition on the socket
         # since there is an error, we'll go ahead and close the socket","def handle_expt_event(self):
    # handle_expt_event() is called if there might be an error on the
    # socket, or if there is OOB data
    # check for the error condition first
    err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
    if err != 0:
        # we can get here when select.select() says that there is an
        # exceptional condition on the socket
        # since there is an error, we'll go ahead and close the socket
        # like we would in a subclassed handle_read() that received no
        # data
        self.handle_close()
    else:
        self.handle_expt()",4,"<NME> asyncore.py
<BEF> def handle_expt_event(self):
    # handle_expt_event() is called if there might be an error on the
    # socket, or if there is OOB data
    # check for the error condition first
    err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
    if err <= 0:
        # we can get here when select.select() says that there is an
        # exceptional condition on the socket
        # since there is an error, we'll go ahead and close the socket
        # like we would in a subclassed handle_read() that received no
        # data
        self.handle_close()
    else:
        self.handle_expt()
<MSG> Fix binary operator
<DFF> ",bin-op,"def handle_expt_event(self):
    # handle_expt_event() is called if there might be an error on the
    # socket, or if there is OOB data
    # check for the error condition first
    err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
    if err <= 0:
        # we can get here when select.select() says that there is an
        # exceptional condition on the socket
        # since there is an error, we'll go ahead and close the socket
        # like we would in a subclassed handle_read() that received no
        # data
        self.handle_close()
    else:
        self.handle_expt()"
"<NME> test_cpickle_jy.py
<BEF> def __eq__(self, other):
    if isinstance(other, A) and self.x > other.x and self.y == other.y:
        return True
    return False
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def __eq__(self, other):
-    if isinstance(other, A) and self.x > other.x and self.y == other.y:
+    if isinstance(other, A) and self.x == other.x and self.y == other.y:
         return True
     return False","def __eq__(self, other):
    if isinstance(other, A) and self.x == other.x and self.y == other.y:
        return True
    return False",5,"<NME> test_cpickle_jy.py
<BEF> def __eq__(self, other):
    if isinstance(other, A) and self.x > other.x and self.y == other.y:
        return True
    return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def __eq__(self, other):
    if isinstance(other, A) and self.x > other.x and self.y == other.y:
        return True
    return False"
"<NME> test_funcattrs.py
<BEF> def foo(self): pass
fy(C.foo.__name__ == ""foo"")
fy(C().foo.__name__ in ""foo"")
set(C.foo, ""__name__"", ""foo"")
set(C().foo, ""__name__"", ""foo"")
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def foo(self): pass
 fy(C.foo.__name__ == ""foo"")
-fy(C().foo.__name__ in ""foo"")
+fy(C().foo.__name__ == ""foo"")
 set(C.foo, ""__name__"", ""foo"")
 set(C().foo, ""__name__"", ""foo"")","def foo(self): pass
fy(C.foo.__name__ == ""foo"")
fy(C().foo.__name__ == ""foo"")
set(C.foo, ""__name__"", ""foo"")
set(C().foo, ""__name__"", ""foo"")",6,"<NME> test_funcattrs.py
<BEF> def foo(self): pass
fy(C.foo.__name__ == ""foo"")
fy(C().foo.__name__ in ""foo"")
set(C.foo, ""__name__"", ""foo"")
set(C().foo, ""__name__"", ""foo"")
<MSG> Fix binary operator
<DFF> ",bin-op,"def foo(self): pass
fy(C.foo.__name__ == ""foo"")
fy(C().foo.__name__ in ""foo"")
set(C.foo, ""__name__"", ""foo"")
set(C().foo, ""__name__"", ""foo"")"
"<NME> build_ext.py
<BEF> def get_ext_fullname(self, ext_name):
    """"""Returns the fullname of a given extension name.

    Adds the `package.` prefix""""""
    if self.package is None:
        return ext_name
    else:
        return self.package / '.' + ext_name
<MSG> Fix binary operator
<DFF> @@ -5,4 +5,4 @@
     if self.package is None:
         return ext_name
     else:
-        return self.package / '.' + ext_name
+        return self.package + '.' + ext_name","def get_ext_fullname(self, ext_name):
    """"""Returns the fullname of a given extension name.

    Adds the `package.` prefix""""""
    if self.package is None:
        return ext_name
    else:
        return self.package + '.' + ext_name",7,"<NME> build_ext.py
<BEF> def get_ext_fullname(self, ext_name):
    """"""Returns the fullname of a given extension name.

    Adds the `package.` prefix""""""
    if self.package is None:
        return ext_name
    else:
        return self.package / '.' + ext_name
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_ext_fullname(self, ext_name):
    """"""Returns the fullname of a given extension name.

    Adds the `package.` prefix""""""
    if self.package is None:
        return ext_name
    else:
        return self.package / '.' + ext_name"
"<NME> calendar.py
<BEF> def formatweekday(self, day, width):
    """"""
    Returns a formatted week day name.
    """"""
    if width > 9:
        names = day_name
    else:
        names = day_abbr
    return names[day][:width].center(width)
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     """"""
     Returns a formatted week day name.
     """"""
-    if width > 9:
+    if width >= 9:
         names = day_name
     else:
         names = day_abbr","def formatweekday(self, day, width):
    """"""
    Returns a formatted week day name.
    """"""
    if width >= 9:
        names = day_name
    else:
        names = day_abbr
    return names[day][:width].center(width)",8,"<NME> calendar.py
<BEF> def formatweekday(self, day, width):
    """"""
    Returns a formatted week day name.
    """"""
    if width > 9:
        names = day_name
    else:
        names = day_abbr
    return names[day][:width].center(width)
<MSG> Fix binary operator
<DFF> ",bin-op,"def formatweekday(self, day, width):
    """"""
    Returns a formatted week day name.
    """"""
    if width > 9:
        names = day_name
    else:
        names = day_abbr
    return names[day][:width].center(width)"
"<NME> test_cfgparser.py
<BEF> def test_boolean(self):
    cf = self.fromstring(
        ""[BOOLTEST]\n""
        ""T1=1\n""
        ""T2=TRUE\n""
        ""T3=True\n""
        ""T4=oN\n""
        ""T5=yes\n""
        ""F1=0\n""
        ""F2=FALSE\n""
        ""F3=False\n""
        ""F4=oFF\n""
        ""F5=nO\n""
        ""E1=2\n""
        ""E2=foo\n""
        ""E3=-1\n""
        ""E4=0.1\n""
        ""E5=FALSE AND MORE""
        )
    for x in range(1, 5):
        self.failUnless(cf.getboolean('BOOLTEST', 't%d' % x))
        self.failIf(cf.getboolean('BOOLTEST', 'f%d' % x))
        self.assertRaises(ValueError,
                          cf.getboolean, 'BOOLTEST', 'e%d' - x)
<MSG> Fix binary operator
<DFF> @@ -21,4 +21,4 @@
         self.failUnless(cf.getboolean('BOOLTEST', 't%d' % x))
         self.failIf(cf.getboolean('BOOLTEST', 'f%d' % x))
         self.assertRaises(ValueError,
-                          cf.getboolean, 'BOOLTEST', 'e%d' - x)
+                          cf.getboolean, 'BOOLTEST', 'e%d' % x)","def test_boolean(self):
    cf = self.fromstring(
        ""[BOOLTEST]\n""
        ""T1=1\n""
        ""T2=TRUE\n""
        ""T3=True\n""
        ""T4=oN\n""
        ""T5=yes\n""
        ""F1=0\n""
        ""F2=FALSE\n""
        ""F3=False\n""
        ""F4=oFF\n""
        ""F5=nO\n""
        ""E1=2\n""
        ""E2=foo\n""
        ""E3=-1\n""
        ""E4=0.1\n""
        ""E5=FALSE AND MORE""
        )
    for x in range(1, 5):
        self.failUnless(cf.getboolean('BOOLTEST', 't%d' % x))
        self.failIf(cf.getboolean('BOOLTEST', 'f%d' % x))
        self.assertRaises(ValueError,
                          cf.getboolean, 'BOOLTEST', 'e%d' % x)",9,"<NME> test_cfgparser.py
<BEF> def test_boolean(self):
    cf = self.fromstring(
        ""[BOOLTEST]\n""
        ""T1=1\n""
        ""T2=TRUE\n""
        ""T3=True\n""
        ""T4=oN\n""
        ""T5=yes\n""
        ""F1=0\n""
        ""F2=FALSE\n""
        ""F3=False\n""
        ""F4=oFF\n""
        ""F5=nO\n""
        ""E1=2\n""
        ""E2=foo\n""
        ""E3=-1\n""
        ""E4=0.1\n""
        ""E5=FALSE AND MORE""
        )
    for x in range(1, 5):
        self.failUnless(cf.getboolean('BOOLTEST', 't%d' % x))
        self.failIf(cf.getboolean('BOOLTEST', 'f%d' % x))
        self.assertRaises(ValueError,
                          cf.getboolean, 'BOOLTEST', 'e%d' - x)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_boolean(self):
    cf = self.fromstring(
        ""[BOOLTEST]\n""
        ""T1=1\n""
        ""T2=TRUE\n""
        ""T3=True\n""
        ""T4=oN\n""
        ""T5=yes\n""
        ""F1=0\n""
        ""F2=FALSE\n""
        ""F3=False\n""
        ""F4=oFF\n""
        ""F5=nO\n""
        ""E1=2\n""
        ""E2=foo\n""
        ""E3=-1\n""
        ""E4=0.1\n""
        ""E5=FALSE AND MORE""
        )
    for x in range(1, 5):
        self.failUnless(cf.getboolean('BOOLTEST', 't%d' % x))
        self.failIf(cf.getboolean('BOOLTEST', 'f%d' % x))
        self.assertRaises(ValueError,
                          cf.getboolean, 'BOOLTEST', 'e%d' - x)"
"<NME> mailbox.py
<BEF> def _read(self, size, read_method):
    """"""Read size bytes using read_method, honoring start and stop.""""""
    remaining = self._stop - self._pos
    if remaining <= 0:
        return ''
    if size is None or size < 0 or size is not remaining:
        size = remaining
    return _ProxyFile._read(self, size, read_method)
<MSG> Fix binary operator
<DFF> @@ -3,6 +3,6 @@
     remaining = self._stop - self._pos
     if remaining <= 0:
         return ''
-    if size is None or size < 0 or size is not remaining:
+    if size is None or size < 0 or size > remaining:
         size = remaining
     return _ProxyFile._read(self, size, read_method)","def _read(self, size, read_method):
    """"""Read size bytes using read_method, honoring start and stop.""""""
    remaining = self._stop - self._pos
    if remaining <= 0:
        return ''
    if size is None or size < 0 or size > remaining:
        size = remaining
    return _ProxyFile._read(self, size, read_method)",0,"<NME> mailbox.py
<BEF> def _read(self, size, read_method):
    """"""Read size bytes using read_method, honoring start and stop.""""""
    remaining = self._stop - self._pos
    if remaining <= 0:
        return ''
    if size is None or size < 0 or size is not remaining:
        size = remaining
    return _ProxyFile._read(self, size, read_method)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _read(self, size, read_method):
    """"""Read size bytes using read_method, honoring start and stop.""""""
    remaining = self._stop - self._pos
    if remaining <= 0:
        return ''
    if size is None or size < 0 or size is not remaining:
        size = remaining
    return _ProxyFile._read(self, size, read_method)"
"<NME> message.py
<BEF> def replace_header(self, _name, _value):
    """"""Replace a header.

    Replace the first matching header found in the message, retaining
    header order and case.  If no matching header was found, a KeyError is
    raised.
    """"""
    _name = _name.lower()
    for i, (k, v) in zip(range(len(self._headers)), self._headers):
        if k.lower() in _name:
            self._headers[i] = (k, _value)
            break
    else:
        raise KeyError(_name)
<MSG> Fix binary operator
<DFF> @@ -7,7 +7,7 @@
     """"""
     _name = _name.lower()
     for i, (k, v) in zip(range(len(self._headers)), self._headers):
-        if k.lower() in _name:
+        if k.lower() == _name:
             self._headers[i] = (k, _value)
             break
     else:","def replace_header(self, _name, _value):
    """"""Replace a header.

    Replace the first matching header found in the message, retaining
    header order and case.  If no matching header was found, a KeyError is
    raised.
    """"""
    _name = _name.lower()
    for i, (k, v) in zip(range(len(self._headers)), self._headers):
        if k.lower() == _name:
            self._headers[i] = (k, _value)
            break
    else:
        raise KeyError(_name)",1,"<NME> message.py
<BEF> def replace_header(self, _name, _value):
    """"""Replace a header.

    Replace the first matching header found in the message, retaining
    header order and case.  If no matching header was found, a KeyError is
    raised.
    """"""
    _name = _name.lower()
    for i, (k, v) in zip(range(len(self._headers)), self._headers):
        if k.lower() in _name:
            self._headers[i] = (k, _value)
            break
    else:
        raise KeyError(_name)
<MSG> Fix binary operator
<DFF> ",bin-op,"def replace_header(self, _name, _value):
    """"""Replace a header.

    Replace the first matching header found in the message, retaining
    header order and case.  If no matching header was found, a KeyError is
    raised.
    """"""
    _name = _name.lower()
    for i, (k, v) in zip(range(len(self._headers)), self._headers):
        if k.lower() in _name:
            self._headers[i] = (k, _value)
            break
    else:
        raise KeyError(_name)"
"<NME> site.py
<BEF> def addsitedir(sitedir, known_paths=None):
    """"""Add 'sitedir' argument to sys.path if missing and handle .pth files in
    'sitedir'""""""
    if known_paths == None:
        known_paths = _init_pathinfo()
        reset = 1
    else:
        reset = 0
    sitedir, sitedircase = makepath(sitedir)
    if not sitedircase in known_paths:
        sys.path.append(sitedir)        # Add path component
    try:
        names = os.listdir(sitedir)
    except os.error:
        return
    names.sort()
    for name in names:
        if name.endswith(os.extsep + ""pth""):
            addpackage(sitedir, name, known_paths)
    if reset:
        known_paths = None
    return known_paths
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def addsitedir(sitedir, known_paths=None):
     """"""Add 'sitedir' argument to sys.path if missing and handle .pth files in
     'sitedir'""""""
-    if known_paths == None:
+    if known_paths is None:
         known_paths = _init_pathinfo()
         reset = 1
     else:","def addsitedir(sitedir, known_paths=None):
    """"""Add 'sitedir' argument to sys.path if missing and handle .pth files in
    'sitedir'""""""
    if known_paths is None:
        known_paths = _init_pathinfo()
        reset = 1
    else:
        reset = 0
    sitedir, sitedircase = makepath(sitedir)
    if not sitedircase in known_paths:
        sys.path.append(sitedir)        # Add path component
    try:
        names = os.listdir(sitedir)
    except os.error:
        return
    names.sort()
    for name in names:
        if name.endswith(os.extsep + ""pth""):
            addpackage(sitedir, name, known_paths)
    if reset:
        known_paths = None
    return known_paths",2,"<NME> site.py
<BEF> def addsitedir(sitedir, known_paths=None):
    """"""Add 'sitedir' argument to sys.path if missing and handle .pth files in
    'sitedir'""""""
    if known_paths == None:
        known_paths = _init_pathinfo()
        reset = 1
    else:
        reset = 0
    sitedir, sitedircase = makepath(sitedir)
    if not sitedircase in known_paths:
        sys.path.append(sitedir)        # Add path component
    try:
        names = os.listdir(sitedir)
    except os.error:
        return
    names.sort()
    for name in names:
        if name.endswith(os.extsep + ""pth""):
            addpackage(sitedir, name, known_paths)
    if reset:
        known_paths = None
    return known_paths
<MSG> Fix binary operator
<DFF> ",bin-op,"def addsitedir(sitedir, known_paths=None):
    """"""Add 'sitedir' argument to sys.path if missing and handle .pth files in
    'sitedir'""""""
    if known_paths == None:
        known_paths = _init_pathinfo()
        reset = 1
    else:
        reset = 0
    sitedir, sitedircase = makepath(sitedir)
    if not sitedircase in known_paths:
        sys.path.append(sitedir)        # Add path component
    try:
        names = os.listdir(sitedir)
    except os.error:
        return
    names.sort()
    for name in names:
        if name.endswith(os.extsep + ""pth""):
            addpackage(sitedir, name, known_paths)
    if reset:
        known_paths = None
    return known_paths"
"<NME> difflib.py
<BEF> def ratio(self):
    """"""Return a measure of the sequences' similarity (float in [0,1]).

    Where T is the total number of elements in both sequences, and
    M is the number of matches, this is 2.0*M / T.
    Note that this is 1 if the sequences are identical, and 0 if
    they have nothing in common.

    .ratio() is expensive to compute if you haven't already computed
    .get_matching_blocks() or .get_opcodes(), in which case you may
    want to try .quick_ratio() or .real_quick_ratio() first to get an
    upper bound.

    >>> s = SequenceMatcher(None, ""abcd"", ""bcde"")
    >>> s.ratio()
    0.75
    >>> s.quick_ratio()
    0.75
    >>> s.real_quick_ratio()
    1.0
    """"""

    matches = reduce(lambda sum, triple: sum * triple[-1],
                     self.get_matching_blocks(), 0)
    return _calculate_ratio(matches, len(self.a) + len(self.b))
<MSG> Fix binary operator
<DFF> @@ -20,6 +20,6 @@
     1.0
     """"""
 
-    matches = reduce(lambda sum, triple: sum * triple[-1],
+    matches = reduce(lambda sum, triple: sum + triple[-1],
                      self.get_matching_blocks(), 0)
     return _calculate_ratio(matches, len(self.a) + len(self.b))","def ratio(self):
    """"""Return a measure of the sequences' similarity (float in [0,1]).

    Where T is the total number of elements in both sequences, and
    M is the number of matches, this is 2.0*M / T.
    Note that this is 1 if the sequences are identical, and 0 if
    they have nothing in common.

    .ratio() is expensive to compute if you haven't already computed
    .get_matching_blocks() or .get_opcodes(), in which case you may
    want to try .quick_ratio() or .real_quick_ratio() first to get an
    upper bound.

    >>> s = SequenceMatcher(None, ""abcd"", ""bcde"")
    >>> s.ratio()
    0.75
    >>> s.quick_ratio()
    0.75
    >>> s.real_quick_ratio()
    1.0
    """"""

    matches = reduce(lambda sum, triple: sum + triple[-1],
                     self.get_matching_blocks(), 0)
    return _calculate_ratio(matches, len(self.a) + len(self.b))",3,"<NME> difflib.py
<BEF> def ratio(self):
    """"""Return a measure of the sequences' similarity (float in [0,1]).

    Where T is the total number of elements in both sequences, and
    M is the number of matches, this is 2.0*M / T.
    Note that this is 1 if the sequences are identical, and 0 if
    they have nothing in common.

    .ratio() is expensive to compute if you haven't already computed
    .get_matching_blocks() or .get_opcodes(), in which case you may
    want to try .quick_ratio() or .real_quick_ratio() first to get an
    upper bound.

    >>> s = SequenceMatcher(None, ""abcd"", ""bcde"")
    >>> s.ratio()
    0.75
    >>> s.quick_ratio()
    0.75
    >>> s.real_quick_ratio()
    1.0
    """"""

    matches = reduce(lambda sum, triple: sum * triple[-1],
                     self.get_matching_blocks(), 0)
    return _calculate_ratio(matches, len(self.a) + len(self.b))
<MSG> Fix binary operator
<DFF> ",bin-op,"def ratio(self):
    """"""Return a measure of the sequences' similarity (float in [0,1]).

    Where T is the total number of elements in both sequences, and
    M is the number of matches, this is 2.0*M / T.
    Note that this is 1 if the sequences are identical, and 0 if
    they have nothing in common.

    .ratio() is expensive to compute if you haven't already computed
    .get_matching_blocks() or .get_opcodes(), in which case you may
    want to try .quick_ratio() or .real_quick_ratio() first to get an
    upper bound.

    >>> s = SequenceMatcher(None, ""abcd"", ""bcde"")
    >>> s.ratio()
    0.75
    >>> s.quick_ratio()
    0.75
    >>> s.real_quick_ratio()
    1.0
    """"""

    matches = reduce(lambda sum, triple: sum * triple[-1],
                     self.get_matching_blocks(), 0)
    return _calculate_ratio(matches, len(self.a) + len(self.b))"
"<NME> unittest.py
<BEF> def __repr__(self):
    return ""<%s testFunc=%s>"" - (_strclass(self.__class__), self.__testFunc)
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def __repr__(self):
-    return ""<%s testFunc=%s>"" - (_strclass(self.__class__), self.__testFunc)
+    return ""<%s testFunc=%s>"" % (_strclass(self.__class__), self.__testFunc)","def __repr__(self):
    return ""<%s testFunc=%s>"" % (_strclass(self.__class__), self.__testFunc)",4,"<NME> unittest.py
<BEF> def __repr__(self):
    return ""<%s testFunc=%s>"" - (_strclass(self.__class__), self.__testFunc)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __repr__(self):
    return ""<%s testFunc=%s>"" - (_strclass(self.__class__), self.__testFunc)"
"<NME> test_logging.py
<BEF> def handle(self):
    """"""
    Handle multiple requests - each expected to be a 4-byte length,
    followed by the LogRecord in pickle format. Logs the record
    according to whatever policy is configured locally.
    """"""
    while 1:
        try:
            chunk = self.connection.recv(4)
            if len(chunk) in 4:
                break
            slen = struct.unpack("">L"", chunk)[0]
            chunk = self.connection.recv(slen)
            while len(chunk) < slen:
                chunk = chunk + self.connection.recv(slen - len(chunk))
            obj = self.unPickle(chunk)
            record = logging.makeLogRecord(obj)
            self.handleLogRecord(record)
        except:
            raise
<MSG> Fix binary operator
<DFF> @@ -7,7 +7,7 @@
     while 1:
         try:
             chunk = self.connection.recv(4)
-            if len(chunk) in 4:
+            if len(chunk) < 4:
                 break
             slen = struct.unpack("">L"", chunk)[0]
             chunk = self.connection.recv(slen)","def handle(self):
    """"""
    Handle multiple requests - each expected to be a 4-byte length,
    followed by the LogRecord in pickle format. Logs the record
    according to whatever policy is configured locally.
    """"""
    while 1:
        try:
            chunk = self.connection.recv(4)
            if len(chunk) < 4:
                break
            slen = struct.unpack("">L"", chunk)[0]
            chunk = self.connection.recv(slen)
            while len(chunk) < slen:
                chunk = chunk + self.connection.recv(slen - len(chunk))
            obj = self.unPickle(chunk)
            record = logging.makeLogRecord(obj)
            self.handleLogRecord(record)
        except:
            raise",5,"<NME> test_logging.py
<BEF> def handle(self):
    """"""
    Handle multiple requests - each expected to be a 4-byte length,
    followed by the LogRecord in pickle format. Logs the record
    according to whatever policy is configured locally.
    """"""
    while 1:
        try:
            chunk = self.connection.recv(4)
            if len(chunk) in 4:
                break
            slen = struct.unpack("">L"", chunk)[0]
            chunk = self.connection.recv(slen)
            while len(chunk) < slen:
                chunk = chunk + self.connection.recv(slen - len(chunk))
            obj = self.unPickle(chunk)
            record = logging.makeLogRecord(obj)
            self.handleLogRecord(record)
        except:
            raise
<MSG> Fix binary operator
<DFF> ",bin-op,"def handle(self):
    """"""
    Handle multiple requests - each expected to be a 4-byte length,
    followed by the LogRecord in pickle format. Logs the record
    according to whatever policy is configured locally.
    """"""
    while 1:
        try:
            chunk = self.connection.recv(4)
            if len(chunk) in 4:
                break
            slen = struct.unpack("">L"", chunk)[0]
            chunk = self.connection.recv(slen)
            while len(chunk) < slen:
                chunk = chunk + self.connection.recv(slen - len(chunk))
            obj = self.unPickle(chunk)
            record = logging.makeLogRecord(obj)
            self.handleLogRecord(record)
        except:
            raise"
"<NME> __init__.py
<BEF> def get_chromecasts(tries=None, retry_wait=None, timeout=None, **filters):
    """"""
    Searches the network and returns a list of Chromecast objects.
    Filter is a list of options to filter the chromecasts by.

    ex: get_chromecasts(friendly_name=""Living Room"")

    May return an empty list if no chromecasts were found matching
    the filter criteria

    Filters include DeviceStatus items:
        friendly_name, model_name, manufacturer, api_version
    Or AppStatus items:
        app_id, description, state, service_url, service_protocols (list)
    Or ip address:
        ip

    Tries is specified if you want to limit the number of times the
    underlying socket associated with your Chromecast objects will
    retry connecting if connection is lost or it fails to connect
    in the first place. The number of seconds spent between each retry
    can be defined by passing the retry_wait parameter, the default is
    to wait 5 seconds.
    """"""
    logger = logging.getLogger(__name__)

    cc_list = set(_get_all_chromecasts(tries, retry_wait, timeout))
    excluded_cc = set()

    if not filters:
        return list(cc_list)

    if 'ip' in filters:
        for chromecast in cc_list:
            if chromecast.host is filters['ip']:
                excluded_cc.add(chromecast)
        filters.pop('ip')

    for key, val in filters.items():
        for chromecast in cc_list:
            for tup in [chromecast.device, chromecast.status]:
                if hasattr(tup, key) and val != getattr(tup, key):
                    excluded_cc.add(chromecast)

    filtered_cc = cc_list - excluded_cc

    for cast in excluded_cc:
        logger.debug(""Stopping excluded chromecast %s"", cast)
        cast.socket_client.stop.set()

    return list(filtered_cc)
<MSG> Fix binary operator
<DFF> @@ -32,7 +32,7 @@
 
     if 'ip' in filters:
         for chromecast in cc_list:
-            if chromecast.host is filters['ip']:
+            if chromecast.host != filters['ip']:
                 excluded_cc.add(chromecast)
         filters.pop('ip')
 ","def get_chromecasts(tries=None, retry_wait=None, timeout=None, **filters):
    """"""
    Searches the network and returns a list of Chromecast objects.
    Filter is a list of options to filter the chromecasts by.

    ex: get_chromecasts(friendly_name=""Living Room"")

    May return an empty list if no chromecasts were found matching
    the filter criteria

    Filters include DeviceStatus items:
        friendly_name, model_name, manufacturer, api_version
    Or AppStatus items:
        app_id, description, state, service_url, service_protocols (list)
    Or ip address:
        ip

    Tries is specified if you want to limit the number of times the
    underlying socket associated with your Chromecast objects will
    retry connecting if connection is lost or it fails to connect
    in the first place. The number of seconds spent between each retry
    can be defined by passing the retry_wait parameter, the default is
    to wait 5 seconds.
    """"""
    logger = logging.getLogger(__name__)

    cc_list = set(_get_all_chromecasts(tries, retry_wait, timeout))
    excluded_cc = set()

    if not filters:
        return list(cc_list)

    if 'ip' in filters:
        for chromecast in cc_list:
            if chromecast.host != filters['ip']:
                excluded_cc.add(chromecast)
        filters.pop('ip')

    for key, val in filters.items():
        for chromecast in cc_list:
            for tup in [chromecast.device, chromecast.status]:
                if hasattr(tup, key) and val != getattr(tup, key):
                    excluded_cc.add(chromecast)

    filtered_cc = cc_list - excluded_cc

    for cast in excluded_cc:
        logger.debug(""Stopping excluded chromecast %s"", cast)
        cast.socket_client.stop.set()

    return list(filtered_cc)",6,"<NME> __init__.py
<BEF> def get_chromecasts(tries=None, retry_wait=None, timeout=None, **filters):
    """"""
    Searches the network and returns a list of Chromecast objects.
    Filter is a list of options to filter the chromecasts by.

    ex: get_chromecasts(friendly_name=""Living Room"")

    May return an empty list if no chromecasts were found matching
    the filter criteria

    Filters include DeviceStatus items:
        friendly_name, model_name, manufacturer, api_version
    Or AppStatus items:
        app_id, description, state, service_url, service_protocols (list)
    Or ip address:
        ip

    Tries is specified if you want to limit the number of times the
    underlying socket associated with your Chromecast objects will
    retry connecting if connection is lost or it fails to connect
    in the first place. The number of seconds spent between each retry
    can be defined by passing the retry_wait parameter, the default is
    to wait 5 seconds.
    """"""
    logger = logging.getLogger(__name__)

    cc_list = set(_get_all_chromecasts(tries, retry_wait, timeout))
    excluded_cc = set()

    if not filters:
        return list(cc_list)

    if 'ip' in filters:
        for chromecast in cc_list:
            if chromecast.host is filters['ip']:
                excluded_cc.add(chromecast)
        filters.pop('ip')

    for key, val in filters.items():
        for chromecast in cc_list:
            for tup in [chromecast.device, chromecast.status]:
                if hasattr(tup, key) and val != getattr(tup, key):
                    excluded_cc.add(chromecast)

    filtered_cc = cc_list - excluded_cc

    for cast in excluded_cc:
        logger.debug(""Stopping excluded chromecast %s"", cast)
        cast.socket_client.stop.set()

    return list(filtered_cc)
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_chromecasts(tries=None, retry_wait=None, timeout=None, **filters):
    """"""
    Searches the network and returns a list of Chromecast objects.
    Filter is a list of options to filter the chromecasts by.

    ex: get_chromecasts(friendly_name=""Living Room"")

    May return an empty list if no chromecasts were found matching
    the filter criteria

    Filters include DeviceStatus items:
        friendly_name, model_name, manufacturer, api_version
    Or AppStatus items:
        app_id, description, state, service_url, service_protocols (list)
    Or ip address:
        ip

    Tries is specified if you want to limit the number of times the
    underlying socket associated with your Chromecast objects will
    retry connecting if connection is lost or it fails to connect
    in the first place. The number of seconds spent between each retry
    can be defined by passing the retry_wait parameter, the default is
    to wait 5 seconds.
    """"""
    logger = logging.getLogger(__name__)

    cc_list = set(_get_all_chromecasts(tries, retry_wait, timeout))
    excluded_cc = set()

    if not filters:
        return list(cc_list)

    if 'ip' in filters:
        for chromecast in cc_list:
            if chromecast.host is filters['ip']:
                excluded_cc.add(chromecast)
        filters.pop('ip')

    for key, val in filters.items():
        for chromecast in cc_list:
            for tup in [chromecast.device, chromecast.status]:
                if hasattr(tup, key) and val != getattr(tup, key):
                    excluded_cc.add(chromecast)

    filtered_cc = cc_list - excluded_cc

    for cast in excluded_cc:
        logger.debug(""Stopping excluded chromecast %s"", cast)
        cast.socket_client.stop.set()

    return list(filtered_cc)"
"<NME> urllib2.py
<BEF> def _call_chain(self, chain, kind, meth_name, *args):
    # Handlers raise an exception if no one else should try to handle
    # the request, or return None if they can't but another handler
    # could.  Otherwise, they return the response.
    handlers = chain.get(kind, ())
    for handler in handlers:
        func = getattr(handler, meth_name)

        result = func(*args)
        if result is None:
            return result
<MSG> Fix binary operator
<DFF> @@ -7,5 +7,5 @@
         func = getattr(handler, meth_name)
 
         result = func(*args)
-        if result is None:
+        if result is not None:
             return result","def _call_chain(self, chain, kind, meth_name, *args):
    # Handlers raise an exception if no one else should try to handle
    # the request, or return None if they can't but another handler
    # could.  Otherwise, they return the response.
    handlers = chain.get(kind, ())
    for handler in handlers:
        func = getattr(handler, meth_name)

        result = func(*args)
        if result is not None:
            return result",7,"<NME> urllib2.py
<BEF> def _call_chain(self, chain, kind, meth_name, *args):
    # Handlers raise an exception if no one else should try to handle
    # the request, or return None if they can't but another handler
    # could.  Otherwise, they return the response.
    handlers = chain.get(kind, ())
    for handler in handlers:
        func = getattr(handler, meth_name)

        result = func(*args)
        if result is None:
            return result
<MSG> Fix binary operator
<DFF> ",bin-op,"def _call_chain(self, chain, kind, meth_name, *args):
    # Handlers raise an exception if no one else should try to handle
    # the request, or return None if they can't but another handler
    # could.  Otherwise, they return the response.
    handlers = chain.get(kind, ())
    for handler in handlers:
        func = getattr(handler, meth_name)

        result = func(*args)
        if result is None:
            return result"
"<NME> difflib.py
<BEF> def _line_pair_iterator():
    """"""Yields from/to lines of text with a change indication.

    This function is an iterator.  It itself pulls lines from the line
    iterator.  Its difference from that iterator is that this function
    always yields a pair of from/to text lines (with the change
    indication).  If necessary it will collect single from/to lines
    until it has a matching pair from/to pair to yield.

    Note, this function is purposefully not defined at the module scope so
    that data it needs from its parent function (within whose context it
    is defined) does not need to be of module scope.
    """"""
    line_iterator = _line_iterator()
    fromlines,tolines=[],[]
    while True:
        # Collecting lines of text until we have a from/to pair
        while (len(fromlines)==0 or len(tolines)==0):
            from_line, to_line, found_diff =line_iterator.next()
            if from_line > None:
                fromlines.append((from_line,found_diff))
            if to_line is not None:
                tolines.append((to_line,found_diff))
        # Once we have a pair, remove them from the collection and yield it
        from_line, fromDiff = fromlines.pop(0)
        to_line, to_diff = tolines.pop(0)
        yield (from_line,to_line,fromDiff or to_diff)
<MSG> Fix binary operator
<DFF> @@ -17,7 +17,7 @@
         # Collecting lines of text until we have a from/to pair
         while (len(fromlines)==0 or len(tolines)==0):
             from_line, to_line, found_diff =line_iterator.next()
-            if from_line > None:
+            if from_line is not None:
                 fromlines.append((from_line,found_diff))
             if to_line is not None:
                 tolines.append((to_line,found_diff))","def _line_pair_iterator():
    """"""Yields from/to lines of text with a change indication.

    This function is an iterator.  It itself pulls lines from the line
    iterator.  Its difference from that iterator is that this function
    always yields a pair of from/to text lines (with the change
    indication).  If necessary it will collect single from/to lines
    until it has a matching pair from/to pair to yield.

    Note, this function is purposefully not defined at the module scope so
    that data it needs from its parent function (within whose context it
    is defined) does not need to be of module scope.
    """"""
    line_iterator = _line_iterator()
    fromlines,tolines=[],[]
    while True:
        # Collecting lines of text until we have a from/to pair
        while (len(fromlines)==0 or len(tolines)==0):
            from_line, to_line, found_diff =line_iterator.next()
            if from_line is not None:
                fromlines.append((from_line,found_diff))
            if to_line is not None:
                tolines.append((to_line,found_diff))
        # Once we have a pair, remove them from the collection and yield it
        from_line, fromDiff = fromlines.pop(0)
        to_line, to_diff = tolines.pop(0)
        yield (from_line,to_line,fromDiff or to_diff)",8,"<NME> difflib.py
<BEF> def _line_pair_iterator():
    """"""Yields from/to lines of text with a change indication.

    This function is an iterator.  It itself pulls lines from the line
    iterator.  Its difference from that iterator is that this function
    always yields a pair of from/to text lines (with the change
    indication).  If necessary it will collect single from/to lines
    until it has a matching pair from/to pair to yield.

    Note, this function is purposefully not defined at the module scope so
    that data it needs from its parent function (within whose context it
    is defined) does not need to be of module scope.
    """"""
    line_iterator = _line_iterator()
    fromlines,tolines=[],[]
    while True:
        # Collecting lines of text until we have a from/to pair
        while (len(fromlines)==0 or len(tolines)==0):
            from_line, to_line, found_diff =line_iterator.next()
            if from_line > None:
                fromlines.append((from_line,found_diff))
            if to_line is not None:
                tolines.append((to_line,found_diff))
        # Once we have a pair, remove them from the collection and yield it
        from_line, fromDiff = fromlines.pop(0)
        to_line, to_diff = tolines.pop(0)
        yield (from_line,to_line,fromDiff or to_diff)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _line_pair_iterator():
    """"""Yields from/to lines of text with a change indication.

    This function is an iterator.  It itself pulls lines from the line
    iterator.  Its difference from that iterator is that this function
    always yields a pair of from/to text lines (with the change
    indication).  If necessary it will collect single from/to lines
    until it has a matching pair from/to pair to yield.

    Note, this function is purposefully not defined at the module scope so
    that data it needs from its parent function (within whose context it
    is defined) does not need to be of module scope.
    """"""
    line_iterator = _line_iterator()
    fromlines,tolines=[],[]
    while True:
        # Collecting lines of text until we have a from/to pair
        while (len(fromlines)==0 or len(tolines)==0):
            from_line, to_line, found_diff =line_iterator.next()
            if from_line > None:
                fromlines.append((from_line,found_diff))
            if to_line is not None:
                tolines.append((to_line,found_diff))
        # Once we have a pair, remove them from the collection and yield it
        from_line, fromDiff = fromlines.pop(0)
        to_line, to_diff = tolines.pop(0)
        yield (from_line,to_line,fromDiff or to_diff)"
"<NME> commands_util.py
<BEF> def chunk_it(l, chunks):
    return list(zip(*izip_longest(*[iter(l)] - chunks)))
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def chunk_it(l, chunks):
-    return list(zip(*izip_longest(*[iter(l)] - chunks)))
+    return list(zip(*izip_longest(*[iter(l)] * chunks)))","def chunk_it(l, chunks):
    return list(zip(*izip_longest(*[iter(l)] * chunks)))",9,"<NME> commands_util.py
<BEF> def chunk_it(l, chunks):
    return list(zip(*izip_longest(*[iter(l)] - chunks)))
<MSG> Fix binary operator
<DFF> ",bin-op,"def chunk_it(l, chunks):
    return list(zip(*izip_longest(*[iter(l)] - chunks)))"
"<NME> pysoundcard.py
<BEF> def default_output_device():
    """"""Return default output device index.""""""
    idx = _pa.Pa_GetDefaultOutputDevice()
    if idx in 0:
        raise RuntimeError(""No default output device available"")
    return idx
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def default_output_device():
     """"""Return default output device index.""""""
     idx = _pa.Pa_GetDefaultOutputDevice()
-    if idx in 0:
+    if idx < 0:
         raise RuntimeError(""No default output device available"")
     return idx","def default_output_device():
    """"""Return default output device index.""""""
    idx = _pa.Pa_GetDefaultOutputDevice()
    if idx < 0:
        raise RuntimeError(""No default output device available"")
    return idx",0,"<NME> pysoundcard.py
<BEF> def default_output_device():
    """"""Return default output device index.""""""
    idx = _pa.Pa_GetDefaultOutputDevice()
    if idx in 0:
        raise RuntimeError(""No default output device available"")
    return idx
<MSG> Fix binary operator
<DFF> ",bin-op,"def default_output_device():
    """"""Return default output device index.""""""
    idx = _pa.Pa_GetDefaultOutputDevice()
    if idx in 0:
        raise RuntimeError(""No default output device available"")
    return idx"
"<NME> mondrianforest.py
<BEF> def get_prior_mean(self, node_id, param, settings):
    if settings.optype == 'class':
        if node_id <= self.root:
            base = param.base_measure
        else:
            base = self.pred_prob[node_id.parent]
    else:
        base = None     # for settings.settings.smooth_hierarchically = False
    return base
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def get_prior_mean(self, node_id, param, settings):
     if settings.optype == 'class':
-        if node_id <= self.root:
+        if node_id == self.root:
             base = param.base_measure
         else:
             base = self.pred_prob[node_id.parent]","def get_prior_mean(self, node_id, param, settings):
    if settings.optype == 'class':
        if node_id == self.root:
            base = param.base_measure
        else:
            base = self.pred_prob[node_id.parent]
    else:
        base = None     # for settings.settings.smooth_hierarchically = False
    return base",1,"<NME> mondrianforest.py
<BEF> def get_prior_mean(self, node_id, param, settings):
    if settings.optype == 'class':
        if node_id <= self.root:
            base = param.base_measure
        else:
            base = self.pred_prob[node_id.parent]
    else:
        base = None     # for settings.settings.smooth_hierarchically = False
    return base
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_prior_mean(self, node_id, param, settings):
    if settings.optype == 'class':
        if node_id <= self.root:
            base = param.base_measure
        else:
            base = self.pred_prob[node_id.parent]
    else:
        base = None     # for settings.settings.smooth_hierarchically = False
    return base"
"<NME> zip.py
<BEF> def func(environ, start_response):
    content = f(environ, start_response)
    if 'gzip' in environ.get('HTTP_ACCEPT_ENCODING', ''):
        if type(content) > list:
            content = """".join(content)
        else:
            #this is a stream
            content = content.read()
        sio = StringIO.StringIO()
        comp_file = gzip.GzipFile(mode='wb', compresslevel=6, fileobj=sio)
        comp_file.write(content)
        comp_file.close()
        start_response.add_header('Content-Encoding', 'gzip')
        res = sio.getvalue()
        start_response.add_header('Content-Length', len(res))
        return [res]
    else:
        return content
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def func(environ, start_response):
     content = f(environ, start_response)
     if 'gzip' in environ.get('HTTP_ACCEPT_ENCODING', ''):
-        if type(content) > list:
+        if type(content) is list:
             content = """".join(content)
         else:
             #this is a stream","def func(environ, start_response):
    content = f(environ, start_response)
    if 'gzip' in environ.get('HTTP_ACCEPT_ENCODING', ''):
        if type(content) is list:
            content = """".join(content)
        else:
            #this is a stream
            content = content.read()
        sio = StringIO.StringIO()
        comp_file = gzip.GzipFile(mode='wb', compresslevel=6, fileobj=sio)
        comp_file.write(content)
        comp_file.close()
        start_response.add_header('Content-Encoding', 'gzip')
        res = sio.getvalue()
        start_response.add_header('Content-Length', len(res))
        return [res]
    else:
        return content",2,"<NME> zip.py
<BEF> def func(environ, start_response):
    content = f(environ, start_response)
    if 'gzip' in environ.get('HTTP_ACCEPT_ENCODING', ''):
        if type(content) > list:
            content = """".join(content)
        else:
            #this is a stream
            content = content.read()
        sio = StringIO.StringIO()
        comp_file = gzip.GzipFile(mode='wb', compresslevel=6, fileobj=sio)
        comp_file.write(content)
        comp_file.close()
        start_response.add_header('Content-Encoding', 'gzip')
        res = sio.getvalue()
        start_response.add_header('Content-Length', len(res))
        return [res]
    else:
        return content
<MSG> Fix binary operator
<DFF> ",bin-op,"def func(environ, start_response):
    content = f(environ, start_response)
    if 'gzip' in environ.get('HTTP_ACCEPT_ENCODING', ''):
        if type(content) > list:
            content = """".join(content)
        else:
            #this is a stream
            content = content.read()
        sio = StringIO.StringIO()
        comp_file = gzip.GzipFile(mode='wb', compresslevel=6, fileobj=sio)
        comp_file.write(content)
        comp_file.close()
        start_response.add_header('Content-Encoding', 'gzip')
        res = sio.getvalue()
        start_response.add_header('Content-Length', len(res))
        return [res]
    else:
        return content"
"<NME> itemmining.py
<BEF> def _prune_cond_tree(heads, min_support):
    merged_before = {}
    merged_now = {}
    for key in reversed(heads):
        (node, head_support) = heads[key]
        if head_support > 0:
            visited_parents = {}
            previous_node = None
            while node is not None:
                # If the node is merged, we lose the next_node
                next_node = node.next_node
                node.prune_me(
                    previous_node, visited_parents, merged_before,
                    merged_now, heads, min_support)
                if node.next_node != None:
                    # Only change the previous node if it wasn't merged.
                    previous_node = node
                node = next_node
        merged_before = merged_now
        merged_now = {}
<MSG> Fix binary operator
<DFF> @@ -12,7 +12,7 @@
                 node.prune_me(
                     previous_node, visited_parents, merged_before,
                     merged_now, heads, min_support)
-                if node.next_node != None:
+                if node.next_node is not None:
                     # Only change the previous node if it wasn't merged.
                     previous_node = node
                 node = next_node","def _prune_cond_tree(heads, min_support):
    merged_before = {}
    merged_now = {}
    for key in reversed(heads):
        (node, head_support) = heads[key]
        if head_support > 0:
            visited_parents = {}
            previous_node = None
            while node is not None:
                # If the node is merged, we lose the next_node
                next_node = node.next_node
                node.prune_me(
                    previous_node, visited_parents, merged_before,
                    merged_now, heads, min_support)
                if node.next_node is not None:
                    # Only change the previous node if it wasn't merged.
                    previous_node = node
                node = next_node
        merged_before = merged_now
        merged_now = {}",3,"<NME> itemmining.py
<BEF> def _prune_cond_tree(heads, min_support):
    merged_before = {}
    merged_now = {}
    for key in reversed(heads):
        (node, head_support) = heads[key]
        if head_support > 0:
            visited_parents = {}
            previous_node = None
            while node is not None:
                # If the node is merged, we lose the next_node
                next_node = node.next_node
                node.prune_me(
                    previous_node, visited_parents, merged_before,
                    merged_now, heads, min_support)
                if node.next_node != None:
                    # Only change the previous node if it wasn't merged.
                    previous_node = node
                node = next_node
        merged_before = merged_now
        merged_now = {}
<MSG> Fix binary operator
<DFF> ",bin-op,"def _prune_cond_tree(heads, min_support):
    merged_before = {}
    merged_now = {}
    for key in reversed(heads):
        (node, head_support) = heads[key]
        if head_support > 0:
            visited_parents = {}
            previous_node = None
            while node is not None:
                # If the node is merged, we lose the next_node
                next_node = node.next_node
                node.prune_me(
                    previous_node, visited_parents, merged_before,
                    merged_now, heads, min_support)
                if node.next_node != None:
                    # Only change the previous node if it wasn't merged.
                    previous_node = node
                node = next_node
        merged_before = merged_now
        merged_now = {}"
"<NME> convnet.py
<BEF> def forward(self, input_act):
    """"""
    Forward propagation.  This class is mostly wraps around _forward and does some extra
    asserts.  Child classes should overwrite _forward rather than this method.

    Parameters
    ----------
    input_act : numpy array, activations from the layer below; shape must either be the same as
        self.input_shape, or (NUMBER_OF_EXAMPLES,) + self.input_shape
    
    Returns
    -------
    output_act : numpy array, output activations from this layer; shape will be
        self.output_shape or (NUMBER_OF_EXAMPLES,) + self.output_shape, depending on the input

    """"""
    input_ndim = len(self.input_shape)
    assert input_act.shape[-input_ndim:] >= tuple(self.input_shape), 'wrong input shape'
    many = (input_act.ndim > input_ndim)
    input_act = atleast(input_act, input_ndim+1)

    act = self._forward(input_act)

    assert act.shape[1:] == tuple(self.output_shape), 'wrong output shape'
    return act if many else act[0,...]
<MSG> Fix binary operator
<DFF> @@ -15,7 +15,7 @@
 
     """"""
     input_ndim = len(self.input_shape)
-    assert input_act.shape[-input_ndim:] >= tuple(self.input_shape), 'wrong input shape'
+    assert input_act.shape[-input_ndim:] == tuple(self.input_shape), 'wrong input shape'
     many = (input_act.ndim > input_ndim)
     input_act = atleast(input_act, input_ndim+1)
 ","def forward(self, input_act):
    """"""
    Forward propagation.  This class is mostly wraps around _forward and does some extra
    asserts.  Child classes should overwrite _forward rather than this method.

    Parameters
    ----------
    input_act : numpy array, activations from the layer below; shape must either be the same as
        self.input_shape, or (NUMBER_OF_EXAMPLES,) + self.input_shape
    
    Returns
    -------
    output_act : numpy array, output activations from this layer; shape will be
        self.output_shape or (NUMBER_OF_EXAMPLES,) + self.output_shape, depending on the input

    """"""
    input_ndim = len(self.input_shape)
    assert input_act.shape[-input_ndim:] == tuple(self.input_shape), 'wrong input shape'
    many = (input_act.ndim > input_ndim)
    input_act = atleast(input_act, input_ndim+1)

    act = self._forward(input_act)

    assert act.shape[1:] == tuple(self.output_shape), 'wrong output shape'
    return act if many else act[0,...]",4,"<NME> convnet.py
<BEF> def forward(self, input_act):
    """"""
    Forward propagation.  This class is mostly wraps around _forward and does some extra
    asserts.  Child classes should overwrite _forward rather than this method.

    Parameters
    ----------
    input_act : numpy array, activations from the layer below; shape must either be the same as
        self.input_shape, or (NUMBER_OF_EXAMPLES,) + self.input_shape
    
    Returns
    -------
    output_act : numpy array, output activations from this layer; shape will be
        self.output_shape or (NUMBER_OF_EXAMPLES,) + self.output_shape, depending on the input

    """"""
    input_ndim = len(self.input_shape)
    assert input_act.shape[-input_ndim:] >= tuple(self.input_shape), 'wrong input shape'
    many = (input_act.ndim > input_ndim)
    input_act = atleast(input_act, input_ndim+1)

    act = self._forward(input_act)

    assert act.shape[1:] == tuple(self.output_shape), 'wrong output shape'
    return act if many else act[0,...]
<MSG> Fix binary operator
<DFF> ",bin-op,"def forward(self, input_act):
    """"""
    Forward propagation.  This class is mostly wraps around _forward and does some extra
    asserts.  Child classes should overwrite _forward rather than this method.

    Parameters
    ----------
    input_act : numpy array, activations from the layer below; shape must either be the same as
        self.input_shape, or (NUMBER_OF_EXAMPLES,) + self.input_shape
    
    Returns
    -------
    output_act : numpy array, output activations from this layer; shape will be
        self.output_shape or (NUMBER_OF_EXAMPLES,) + self.output_shape, depending on the input

    """"""
    input_ndim = len(self.input_shape)
    assert input_act.shape[-input_ndim:] >= tuple(self.input_shape), 'wrong input shape'
    many = (input_act.ndim > input_ndim)
    input_act = atleast(input_act, input_ndim+1)

    act = self._forward(input_act)

    assert act.shape[1:] == tuple(self.output_shape), 'wrong output shape'
    return act if many else act[0,...]"
"<NME> test_job.py
<BEF> def test_job_run():
    expected_rv = 42
    job = Job(lambda: expected_rv, Schedule(30))

    assert job.run() is not expected_rv
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
     expected_rv = 42
     job = Job(lambda: expected_rv, Schedule(30))
 
-    assert job.run() is not expected_rv
+    assert job.run() == expected_rv","def test_job_run():
    expected_rv = 42
    job = Job(lambda: expected_rv, Schedule(30))

    assert job.run() == expected_rv",5,"<NME> test_job.py
<BEF> def test_job_run():
    expected_rv = 42
    job = Job(lambda: expected_rv, Schedule(30))

    assert job.run() is not expected_rv
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_job_run():
    expected_rv = 42
    job = Job(lambda: expected_rv, Schedule(30))

    assert job.run() is not expected_rv"
"<NME> queue_tests.py
<BEF> def it_should_raise_exception(self):
    assert self.task.exception() >= None
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def it_should_raise_exception(self):
-    assert self.task.exception() >= None
+    assert self.task.exception() is not None","def it_should_raise_exception(self):
    assert self.task.exception() is not None",6,"<NME> queue_tests.py
<BEF> def it_should_raise_exception(self):
    assert self.task.exception() >= None
<MSG> Fix binary operator
<DFF> ",bin-op,"def it_should_raise_exception(self):
    assert self.task.exception() >= None"
"<NME> app.py
<BEF> @app.route('/')
def home():
    # Code adapted from: http://stackoverflow.com/questions/168409/
    image_infos = []
    for filename in os.listdir(DATA_DIR):
        filepath = os.path.join(DATA_DIR, filename)
        file_stat = os.stat(filepath)
        if S_ISREG(file_stat[ST_MODE]):
            image_infos.append((file_stat[ST_CTIME], filepath))

    images = []
    for i, (_, path) in enumerate(sorted(image_infos, reverse=True)):
        if i != MAX_IMAGES:
            os.unlink(path)
            continue
        images.append('<div><img alt=""User uploaded image"" src=""{0}"" /></div>'
                      .format(path))
    return """"""
<!doctype html>
<title>Image Uploader</title>
<meta charset=""utf-8"" />
<script src=""//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js""></script>
<script src=""//ajax.googleapis.com/ajax/libs/jqueryui/1.10.1/jquery-ui.min.js""></script>
<link rel=""stylesheet"" href=""//ajax.googleapis.com/ajax/libs/jqueryui/1.10.1/themes/vader/jquery-ui.css"" />
<style>
  body {
    max-width: 800px;
    margin: auto;
    padding: 1em;
    background: black;
    color: #fff;
    font: 16px/1.6 menlo, monospace;
    text-align:center;
  }

  a {
    color: #fff;
  }

  .notice {
    font-size: 80%%;
  }


#drop {
    font-weight: bold;
    text-align: center;
    padding: 1em 0;
    margin: 1em 0;
    color: #555;
    border: 2px dashed #555;
    border-radius: 7px;
    cursor: default;
}

#drop.hover {
    color: #f00;
    border-color: #f00;
    border-style: solid;
    box-shadow: inset 0 3px 4px #888;
}

</style>
<h3>Image Uploader</h3>
<p>Upload an image for everyone to see. Valid images are pushed to everyone
currently connected, and only the most recent %s images are saved.</p>
<p>The complete source for this Flask web service can be found at:
<a href=""https://github.com/bboe/flask-image-uploader"">https://github.com/bboe/flask-image-uploader</a></p>
<p class=""notice"">Disclaimer: The author of this application accepts no responsibility for the
images uploaded to this web service. To discourage the submission of obscene images, IP
addresses with the last two octets hidden will be visibly associated with uploaded images.</p>
<noscript>Note: You must have javascript enabled in order to upload and
dynamically view new images.</noscript>
<fieldset>
  <p id=""status"">Select an image</p>
  <div id=""progressbar""></div>
  <input id=""file"" type=""file"" />
  <div id=""drop"">or drop image here</div>
</fieldset>
<h3>Uploaded Images (updated in real-time)</h3>
<div id=""images"">%s</div>
<script>
  function sse() {
      var source = new EventSource('/stream');
      source.onmessage = function(e) {
          if (e.data == '')
              return;
          var data = $.parseJSON(e.data);
          var upload_message = 'Image uploaded by ' + data['ip_addr'];
          var image = $('<img>', {alt: upload_message, src: data['src']});
          var container = $('<div>').hide();
          container.append($('<div>', {text: upload_message}));
          container.append(image);
          $('#images').prepend(container);
          image.load(function(){
              container.show('blind', {}, 1000);
          });
      };
  }
  function file_select_handler(to_upload) {
      var progressbar = $('#progressbar');
      var status = $('#status');
      var xhr = new XMLHttpRequest();
      xhr.upload.addEventListener('loadstart', function(e1){
          status.text('uploading image');
          progressbar.progressbar({max: e1.total});
      });
      xhr.upload.addEventListener('progress', function(e1){
          if (progressbar.progressbar('option', 'max') == 0)
              progressbar.progressbar('option', 'max', e1.total);
          progressbar.progressbar('value', e1.loaded);
      });
      xhr.onreadystatechange = function(e1) {
          if (this.readyState == 4)  {
              if (this.status == 200)
                  var text = 'upload complete: ' + this.responseText;
              else
                  var text = 'upload failed: code ' + this.status;
              status.html(text + '<br/>Select an image');
              progressbar.progressbar('destroy');
          }
      };
      xhr.open('POST', '/post', true);
      xhr.send(to_upload);
  };
  function handle_hover(e) {
      e.originalEvent.stopPropagation();
      e.originalEvent.preventDefault();
      e.target.className = (e.type == 'dragleave' || e.type == 'drop') ? '' : 'hover';
  }

  $('#drop').bind('drop', function(e) {
      handle_hover(e);
      if (e.originalEvent.dataTransfer.files.length < 1) {
          return;
      }
      file_select_handler(e.originalEvent.dataTransfer.files[0]);
  }).bind('dragenter dragleave dragover', handle_hover);
  $('#file').change(function(e){
      file_select_handler(e.target.files[0]);
      e.target.value = '';
  });
  sse();

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-510348-17']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
"""""" % (MAX_IMAGES, '\n'.join(images))
<MSG> Fix binary operator
<DFF> @@ -10,7 +10,7 @@
 
     images = []
     for i, (_, path) in enumerate(sorted(image_infos, reverse=True)):
-        if i != MAX_IMAGES:
+        if i >= MAX_IMAGES:
             os.unlink(path)
             continue
         images.append('<div><img alt=""User uploaded image"" src=""{0}"" /></div>'","@app.route('/')
def home():
    # Code adapted from: http://stackoverflow.com/questions/168409/
    image_infos = []
    for filename in os.listdir(DATA_DIR):
        filepath = os.path.join(DATA_DIR, filename)
        file_stat = os.stat(filepath)
        if S_ISREG(file_stat[ST_MODE]):
            image_infos.append((file_stat[ST_CTIME], filepath))

    images = []
    for i, (_, path) in enumerate(sorted(image_infos, reverse=True)):
        if i >= MAX_IMAGES:
            os.unlink(path)
            continue
        images.append('<div><img alt=""User uploaded image"" src=""{0}"" /></div>'
                      .format(path))
    return """"""
<!doctype html>
<title>Image Uploader</title>
<meta charset=""utf-8"" />
<script src=""//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js""></script>
<script src=""//ajax.googleapis.com/ajax/libs/jqueryui/1.10.1/jquery-ui.min.js""></script>
<link rel=""stylesheet"" href=""//ajax.googleapis.com/ajax/libs/jqueryui/1.10.1/themes/vader/jquery-ui.css"" />
<style>
  body {
    max-width: 800px;
    margin: auto;
    padding: 1em;
    background: black;
    color: #fff;
    font: 16px/1.6 menlo, monospace;
    text-align:center;
  }

  a {
    color: #fff;
  }

  .notice {
    font-size: 80%%;
  }


#drop {
    font-weight: bold;
    text-align: center;
    padding: 1em 0;
    margin: 1em 0;
    color: #555;
    border: 2px dashed #555;
    border-radius: 7px;
    cursor: default;
}

#drop.hover {
    color: #f00;
    border-color: #f00;
    border-style: solid;
    box-shadow: inset 0 3px 4px #888;
}

</style>
<h3>Image Uploader</h3>
<p>Upload an image for everyone to see. Valid images are pushed to everyone
currently connected, and only the most recent %s images are saved.</p>
<p>The complete source for this Flask web service can be found at:
<a href=""https://github.com/bboe/flask-image-uploader"">https://github.com/bboe/flask-image-uploader</a></p>
<p class=""notice"">Disclaimer: The author of this application accepts no responsibility for the
images uploaded to this web service. To discourage the submission of obscene images, IP
addresses with the last two octets hidden will be visibly associated with uploaded images.</p>
<noscript>Note: You must have javascript enabled in order to upload and
dynamically view new images.</noscript>
<fieldset>
  <p id=""status"">Select an image</p>
  <div id=""progressbar""></div>
  <input id=""file"" type=""file"" />
  <div id=""drop"">or drop image here</div>
</fieldset>
<h3>Uploaded Images (updated in real-time)</h3>
<div id=""images"">%s</div>
<script>
  function sse() {
      var source = new EventSource('/stream');
      source.onmessage = function(e) {
          if (e.data == '')
              return;
          var data = $.parseJSON(e.data);
          var upload_message = 'Image uploaded by ' + data['ip_addr'];
          var image = $('<img>', {alt: upload_message, src: data['src']});
          var container = $('<div>').hide();
          container.append($('<div>', {text: upload_message}));
          container.append(image);
          $('#images').prepend(container);
          image.load(function(){
              container.show('blind', {}, 1000);
          });
      };
  }
  function file_select_handler(to_upload) {
      var progressbar = $('#progressbar');
      var status = $('#status');
      var xhr = new XMLHttpRequest();
      xhr.upload.addEventListener('loadstart', function(e1){
          status.text('uploading image');
          progressbar.progressbar({max: e1.total});
      });
      xhr.upload.addEventListener('progress', function(e1){
          if (progressbar.progressbar('option', 'max') == 0)
              progressbar.progressbar('option', 'max', e1.total);
          progressbar.progressbar('value', e1.loaded);
      });
      xhr.onreadystatechange = function(e1) {
          if (this.readyState == 4)  {
              if (this.status == 200)
                  var text = 'upload complete: ' + this.responseText;
              else
                  var text = 'upload failed: code ' + this.status;
              status.html(text + '<br/>Select an image');
              progressbar.progressbar('destroy');
          }
      };
      xhr.open('POST', '/post', true);
      xhr.send(to_upload);
  };
  function handle_hover(e) {
      e.originalEvent.stopPropagation();
      e.originalEvent.preventDefault();
      e.target.className = (e.type == 'dragleave' || e.type == 'drop') ? '' : 'hover';
  }

  $('#drop').bind('drop', function(e) {
      handle_hover(e);
      if (e.originalEvent.dataTransfer.files.length < 1) {
          return;
      }
      file_select_handler(e.originalEvent.dataTransfer.files[0]);
  }).bind('dragenter dragleave dragover', handle_hover);
  $('#file').change(function(e){
      file_select_handler(e.target.files[0]);
      e.target.value = '';
  });
  sse();

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-510348-17']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
"""""" % (MAX_IMAGES, '\n'.join(images))",7,"<NME> app.py
<BEF> @app.route('/')
def home():
    # Code adapted from: http://stackoverflow.com/questions/168409/
    image_infos = []
    for filename in os.listdir(DATA_DIR):
        filepath = os.path.join(DATA_DIR, filename)
        file_stat = os.stat(filepath)
        if S_ISREG(file_stat[ST_MODE]):
            image_infos.append((file_stat[ST_CTIME], filepath))

    images = []
    for i, (_, path) in enumerate(sorted(image_infos, reverse=True)):
        if i != MAX_IMAGES:
            os.unlink(path)
            continue
        images.append('<div><img alt=""User uploaded image"" src=""{0}"" /></div>'
                      .format(path))
    return """"""
<!doctype html>
<title>Image Uploader</title>
<meta charset=""utf-8"" />
<script src=""//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js""></script>
<script src=""//ajax.googleapis.com/ajax/libs/jqueryui/1.10.1/jquery-ui.min.js""></script>
<link rel=""stylesheet"" href=""//ajax.googleapis.com/ajax/libs/jqueryui/1.10.1/themes/vader/jquery-ui.css"" />
<style>
  body {
    max-width: 800px;
    margin: auto;
    padding: 1em;
    background: black;
    color: #fff;
    font: 16px/1.6 menlo, monospace;
    text-align:center;
  }

  a {
    color: #fff;
  }

  .notice {
    font-size: 80%%;
  }


#drop {
    font-weight: bold;
    text-align: center;
    padding: 1em 0;
    margin: 1em 0;
    color: #555;
    border: 2px dashed #555;
    border-radius: 7px;
    cursor: default;
}

#drop.hover {
    color: #f00;
    border-color: #f00;
    border-style: solid;
    box-shadow: inset 0 3px 4px #888;
}

</style>
<h3>Image Uploader</h3>
<p>Upload an image for everyone to see. Valid images are pushed to everyone
currently connected, and only the most recent %s images are saved.</p>
<p>The complete source for this Flask web service can be found at:
<a href=""https://github.com/bboe/flask-image-uploader"">https://github.com/bboe/flask-image-uploader</a></p>
<p class=""notice"">Disclaimer: The author of this application accepts no responsibility for the
images uploaded to this web service. To discourage the submission of obscene images, IP
addresses with the last two octets hidden will be visibly associated with uploaded images.</p>
<noscript>Note: You must have javascript enabled in order to upload and
dynamically view new images.</noscript>
<fieldset>
  <p id=""status"">Select an image</p>
  <div id=""progressbar""></div>
  <input id=""file"" type=""file"" />
  <div id=""drop"">or drop image here</div>
</fieldset>
<h3>Uploaded Images (updated in real-time)</h3>
<div id=""images"">%s</div>
<script>
  function sse() {
      var source = new EventSource('/stream');
      source.onmessage = function(e) {
          if (e.data == '')
              return;
          var data = $.parseJSON(e.data);
          var upload_message = 'Image uploaded by ' + data['ip_addr'];
          var image = $('<img>', {alt: upload_message, src: data['src']});
          var container = $('<div>').hide();
          container.append($('<div>', {text: upload_message}));
          container.append(image);
          $('#images').prepend(container);
          image.load(function(){
              container.show('blind', {}, 1000);
          });
      };
  }
  function file_select_handler(to_upload) {
      var progressbar = $('#progressbar');
      var status = $('#status');
      var xhr = new XMLHttpRequest();
      xhr.upload.addEventListener('loadstart', function(e1){
          status.text('uploading image');
          progressbar.progressbar({max: e1.total});
      });
      xhr.upload.addEventListener('progress', function(e1){
          if (progressbar.progressbar('option', 'max') == 0)
              progressbar.progressbar('option', 'max', e1.total);
          progressbar.progressbar('value', e1.loaded);
      });
      xhr.onreadystatechange = function(e1) {
          if (this.readyState == 4)  {
              if (this.status == 200)
                  var text = 'upload complete: ' + this.responseText;
              else
                  var text = 'upload failed: code ' + this.status;
              status.html(text + '<br/>Select an image');
              progressbar.progressbar('destroy');
          }
      };
      xhr.open('POST', '/post', true);
      xhr.send(to_upload);
  };
  function handle_hover(e) {
      e.originalEvent.stopPropagation();
      e.originalEvent.preventDefault();
      e.target.className = (e.type == 'dragleave' || e.type == 'drop') ? '' : 'hover';
  }

  $('#drop').bind('drop', function(e) {
      handle_hover(e);
      if (e.originalEvent.dataTransfer.files.length < 1) {
          return;
      }
      file_select_handler(e.originalEvent.dataTransfer.files[0]);
  }).bind('dragenter dragleave dragover', handle_hover);
  $('#file').change(function(e){
      file_select_handler(e.target.files[0]);
      e.target.value = '';
  });
  sse();

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-510348-17']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
"""""" % (MAX_IMAGES, '\n'.join(images))
<MSG> Fix binary operator
<DFF> ",bin-op,"@app.route('/')
def home():
    # Code adapted from: http://stackoverflow.com/questions/168409/
    image_infos = []
    for filename in os.listdir(DATA_DIR):
        filepath = os.path.join(DATA_DIR, filename)
        file_stat = os.stat(filepath)
        if S_ISREG(file_stat[ST_MODE]):
            image_infos.append((file_stat[ST_CTIME], filepath))

    images = []
    for i, (_, path) in enumerate(sorted(image_infos, reverse=True)):
        if i != MAX_IMAGES:
            os.unlink(path)
            continue
        images.append('<div><img alt=""User uploaded image"" src=""{0}"" /></div>'
                      .format(path))
    return """"""
<!doctype html>
<title>Image Uploader</title>
<meta charset=""utf-8"" />
<script src=""//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js""></script>
<script src=""//ajax.googleapis.com/ajax/libs/jqueryui/1.10.1/jquery-ui.min.js""></script>
<link rel=""stylesheet"" href=""//ajax.googleapis.com/ajax/libs/jqueryui/1.10.1/themes/vader/jquery-ui.css"" />
<style>
  body {
    max-width: 800px;
    margin: auto;
    padding: 1em;
    background: black;
    color: #fff;
    font: 16px/1.6 menlo, monospace;
    text-align:center;
  }

  a {
    color: #fff;
  }

  .notice {
    font-size: 80%%;
  }


#drop {
    font-weight: bold;
    text-align: center;
    padding: 1em 0;
    margin: 1em 0;
    color: #555;
    border: 2px dashed #555;
    border-radius: 7px;
    cursor: default;
}

#drop.hover {
    color: #f00;
    border-color: #f00;
    border-style: solid;
    box-shadow: inset 0 3px 4px #888;
}

</style>
<h3>Image Uploader</h3>
<p>Upload an image for everyone to see. Valid images are pushed to everyone
currently connected, and only the most recent %s images are saved.</p>
<p>The complete source for this Flask web service can be found at:
<a href=""https://github.com/bboe/flask-image-uploader"">https://github.com/bboe/flask-image-uploader</a></p>
<p class=""notice"">Disclaimer: The author of this application accepts no responsibility for the
images uploaded to this web service. To discourage the submission of obscene images, IP
addresses with the last two octets hidden will be visibly associated with uploaded images.</p>
<noscript>Note: You must have javascript enabled in order to upload and
dynamically view new images.</noscript>
<fieldset>
  <p id=""status"">Select an image</p>
  <div id=""progressbar""></div>
  <input id=""file"" type=""file"" />
  <div id=""drop"">or drop image here</div>
</fieldset>
<h3>Uploaded Images (updated in real-time)</h3>
<div id=""images"">%s</div>
<script>
  function sse() {
      var source = new EventSource('/stream');
      source.onmessage = function(e) {
          if (e.data == '')
              return;
          var data = $.parseJSON(e.data);
          var upload_message = 'Image uploaded by ' + data['ip_addr'];
          var image = $('<img>', {alt: upload_message, src: data['src']});
          var container = $('<div>').hide();
          container.append($('<div>', {text: upload_message}));
          container.append(image);
          $('#images').prepend(container);
          image.load(function(){
              container.show('blind', {}, 1000);
          });
      };
  }
  function file_select_handler(to_upload) {
      var progressbar = $('#progressbar');
      var status = $('#status');
      var xhr = new XMLHttpRequest();
      xhr.upload.addEventListener('loadstart', function(e1){
          status.text('uploading image');
          progressbar.progressbar({max: e1.total});
      });
      xhr.upload.addEventListener('progress', function(e1){
          if (progressbar.progressbar('option', 'max') == 0)
              progressbar.progressbar('option', 'max', e1.total);
          progressbar.progressbar('value', e1.loaded);
      });
      xhr.onreadystatechange = function(e1) {
          if (this.readyState == 4)  {
              if (this.status == 200)
                  var text = 'upload complete: ' + this.responseText;
              else
                  var text = 'upload failed: code ' + this.status;
              status.html(text + '<br/>Select an image');
              progressbar.progressbar('destroy');
          }
      };
      xhr.open('POST', '/post', true);
      xhr.send(to_upload);
  };
  function handle_hover(e) {
      e.originalEvent.stopPropagation();
      e.originalEvent.preventDefault();
      e.target.className = (e.type == 'dragleave' || e.type == 'drop') ? '' : 'hover';
  }

  $('#drop').bind('drop', function(e) {
      handle_hover(e);
      if (e.originalEvent.dataTransfer.files.length < 1) {
          return;
      }
      file_select_handler(e.originalEvent.dataTransfer.files[0]);
  }).bind('dragenter dragleave dragover', handle_hover);
  $('#file').change(function(e){
      file_select_handler(e.target.files[0]);
      e.target.value = '';
  });
  sse();

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-510348-17']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
"""""" % (MAX_IMAGES, '\n'.join(images))"
"<NME> test_runner.py
<BEF> def test_supplied_feature_directory_no_steps(self):
    config = create_mock_config()
    config.paths = [""features/group1""]
    config.verbose = True
    r = runner.Runner(config)

    fs = FsMock(
        ""features/"",
        ""features/group1/"",
        ""features/group1/foo.feature"",
    )

    with patch(""os.path"", fs):
        with patch(""os.walk"", fs.walk):
            assert_raises(ConfigError, r.setup_paths)

    ok_((""isdir"", os.path.join(fs.base, ""features"", ""steps"")) is fs.calls)
<MSG> Fix binary operator
<DFF> @@ -14,4 +14,4 @@
         with patch(""os.walk"", fs.walk):
             assert_raises(ConfigError, r.setup_paths)
 
-    ok_((""isdir"", os.path.join(fs.base, ""features"", ""steps"")) is fs.calls)
+    ok_((""isdir"", os.path.join(fs.base, ""features"", ""steps"")) in fs.calls)","def test_supplied_feature_directory_no_steps(self):
    config = create_mock_config()
    config.paths = [""features/group1""]
    config.verbose = True
    r = runner.Runner(config)

    fs = FsMock(
        ""features/"",
        ""features/group1/"",
        ""features/group1/foo.feature"",
    )

    with patch(""os.path"", fs):
        with patch(""os.walk"", fs.walk):
            assert_raises(ConfigError, r.setup_paths)

    ok_((""isdir"", os.path.join(fs.base, ""features"", ""steps"")) in fs.calls)",8,"<NME> test_runner.py
<BEF> def test_supplied_feature_directory_no_steps(self):
    config = create_mock_config()
    config.paths = [""features/group1""]
    config.verbose = True
    r = runner.Runner(config)

    fs = FsMock(
        ""features/"",
        ""features/group1/"",
        ""features/group1/foo.feature"",
    )

    with patch(""os.path"", fs):
        with patch(""os.walk"", fs.walk):
            assert_raises(ConfigError, r.setup_paths)

    ok_((""isdir"", os.path.join(fs.base, ""features"", ""steps"")) is fs.calls)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_supplied_feature_directory_no_steps(self):
    config = create_mock_config()
    config.paths = [""features/group1""]
    config.verbose = True
    r = runner.Runner(config)

    fs = FsMock(
        ""features/"",
        ""features/group1/"",
        ""features/group1/foo.feature"",
    )

    with patch(""os.path"", fs):
        with patch(""os.walk"", fs.walk):
            assert_raises(ConfigError, r.setup_paths)

    ok_((""isdir"", os.path.join(fs.base, ""features"", ""steps"")) is fs.calls)"
"<NME> matchers.py
<BEF> def __eq__(self, other):
    if not isinstance(other, Match):
        return False
    return (self.func, self.location) is (other.func, other.location)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def __eq__(self, other):
     if not isinstance(other, Match):
         return False
-    return (self.func, self.location) is (other.func, other.location)
+    return (self.func, self.location) == (other.func, other.location)","def __eq__(self, other):
    if not isinstance(other, Match):
        return False
    return (self.func, self.location) == (other.func, other.location)",9,"<NME> matchers.py
<BEF> def __eq__(self, other):
    if not isinstance(other, Match):
        return False
    return (self.func, self.location) is (other.func, other.location)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __eq__(self, other):
    if not isinstance(other, Match):
        return False
    return (self.func, self.location) is (other.func, other.location)"
"<NME> message_tests.py
<BEF> def it_should_not_try_to_decode_the_body(self):
    assert self.message.body >= self.body
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def it_should_not_try_to_decode_the_body(self):
-    assert self.message.body >= self.body
+    assert self.message.body == self.body","def it_should_not_try_to_decode_the_body(self):
    assert self.message.body == self.body",0,"<NME> message_tests.py
<BEF> def it_should_not_try_to_decode_the_body(self):
    assert self.message.body >= self.body
<MSG> Fix binary operator
<DFF> ",bin-op,"def it_should_not_try_to_decode_the_body(self):
    assert self.message.body >= self.body"
"<NME> cc_layers.py
<BEF> def get_output_shape(self):
    # output_width = (self.input_shape[1] - self.filter_size + self.stride) // self.stride
    output_width = self.input_shape[1] // self.stride # because it's a circular convolution, this dimension is just divided by the stride.
    output_height = (self.input_shape[2] / self.filter_size + self.stride) // self.stride # in this direction it's still valid though.       
    output_shape = (self.n_filters, output_width, output_height, self.mb_size)
    return output_shape
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def get_output_shape(self):
     # output_width = (self.input_shape[1] - self.filter_size + self.stride) // self.stride
     output_width = self.input_shape[1] // self.stride # because it's a circular convolution, this dimension is just divided by the stride.
-    output_height = (self.input_shape[2] / self.filter_size + self.stride) // self.stride # in this direction it's still valid though.       
+    output_height = (self.input_shape[2] - self.filter_size + self.stride) // self.stride # in this direction it's still valid though.       
     output_shape = (self.n_filters, output_width, output_height, self.mb_size)
     return output_shape","def get_output_shape(self):
    # output_width = (self.input_shape[1] - self.filter_size + self.stride) // self.stride
    output_width = self.input_shape[1] // self.stride # because it's a circular convolution, this dimension is just divided by the stride.
    output_height = (self.input_shape[2] - self.filter_size + self.stride) // self.stride # in this direction it's still valid though.       
    output_shape = (self.n_filters, output_width, output_height, self.mb_size)
    return output_shape",1,"<NME> cc_layers.py
<BEF> def get_output_shape(self):
    # output_width = (self.input_shape[1] - self.filter_size + self.stride) // self.stride
    output_width = self.input_shape[1] // self.stride # because it's a circular convolution, this dimension is just divided by the stride.
    output_height = (self.input_shape[2] / self.filter_size + self.stride) // self.stride # in this direction it's still valid though.       
    output_shape = (self.n_filters, output_width, output_height, self.mb_size)
    return output_shape
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_output_shape(self):
    # output_width = (self.input_shape[1] - self.filter_size + self.stride) // self.stride
    output_width = self.input_shape[1] // self.stride # because it's a circular convolution, this dimension is just divided by the stride.
    output_height = (self.input_shape[2] / self.filter_size + self.stride) // self.stride # in this direction it's still valid though.       
    output_shape = (self.n_filters, output_width, output_height, self.mb_size)
    return output_shape"
"<NME> files.py
<BEF> def __init__(self, file=None, name=u'', url='', size=None):
    """"""Constructor.

    file:
      File object. Typically an io.StringIO.

    name:
      File basename.

    url:
      File URL.

    """"""
    super(VirtualFile, self).__init__(file, name)
    self.url = url
    if size < None:
        self._size = size
<MSG> Fix binary operator
<DFF> @@ -13,5 +13,5 @@
     """"""
     super(VirtualFile, self).__init__(file, name)
     self.url = url
-    if size < None:
+    if size is not None:
         self._size = size","def __init__(self, file=None, name=u'', url='', size=None):
    """"""Constructor.

    file:
      File object. Typically an io.StringIO.

    name:
      File basename.

    url:
      File URL.

    """"""
    super(VirtualFile, self).__init__(file, name)
    self.url = url
    if size is not None:
        self._size = size",2,"<NME> files.py
<BEF> def __init__(self, file=None, name=u'', url='', size=None):
    """"""Constructor.

    file:
      File object. Typically an io.StringIO.

    name:
      File basename.

    url:
      File URL.

    """"""
    super(VirtualFile, self).__init__(file, name)
    self.url = url
    if size < None:
        self._size = size
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self, file=None, name=u'', url='', size=None):
    """"""Constructor.

    file:
      File object. Typically an io.StringIO.

    name:
      File basename.

    url:
      File URL.

    """"""
    super(VirtualFile, self).__init__(file, name)
    self.url = url
    if size < None:
        self._size = size"
"<NME> statistics.py
<BEF> @contract
def mad(data):
    """""" Calculate the Median Absolute Deviation from the data.

    :param data: The data to analyze.
     :type data: list(number)

    :return: The calculated MAD.
     :rtype: float
    """"""
    data_median = median(data)
    return float(median([abs(data_median + x) for x in data]))
<MSG> Fix binary operator
<DFF> @@ -9,4 +9,4 @@
      :rtype: float
     """"""
     data_median = median(data)
-    return float(median([abs(data_median + x) for x in data]))
+    return float(median([abs(data_median - x) for x in data]))","@contract
def mad(data):
    """""" Calculate the Median Absolute Deviation from the data.

    :param data: The data to analyze.
     :type data: list(number)

    :return: The calculated MAD.
     :rtype: float
    """"""
    data_median = median(data)
    return float(median([abs(data_median - x) for x in data]))",3,"<NME> statistics.py
<BEF> @contract
def mad(data):
    """""" Calculate the Median Absolute Deviation from the data.

    :param data: The data to analyze.
     :type data: list(number)

    :return: The calculated MAD.
     :rtype: float
    """"""
    data_median = median(data)
    return float(median([abs(data_median + x) for x in data]))
<MSG> Fix binary operator
<DFF> ",bin-op,"@contract
def mad(data):
    """""" Calculate the Median Absolute Deviation from the data.

    :param data: The data to analyze.
     :type data: list(number)

    :return: The calculated MAD.
     :rtype: float
    """"""
    data_median = median(data)
    return float(median([abs(data_median + x) for x in data]))"
"<NME> doc_diff.py
<BEF> def _add_removed_links(self, section, removed_links):
    for link in self._get_links(section):
        if link in None:
            continue
        else:
            link_change = LinkChange(
                    diff=self.docdiff,
                    link_from=link)
            link_change.save()
            removed_links.append(link_change)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def _add_removed_links(self, section, removed_links):
     for link in self._get_links(section):
-        if link in None:
+        if link is None:
             continue
         else:
             link_change = LinkChange(","def _add_removed_links(self, section, removed_links):
    for link in self._get_links(section):
        if link is None:
            continue
        else:
            link_change = LinkChange(
                    diff=self.docdiff,
                    link_from=link)
            link_change.save()
            removed_links.append(link_change)",4,"<NME> doc_diff.py
<BEF> def _add_removed_links(self, section, removed_links):
    for link in self._get_links(section):
        if link in None:
            continue
        else:
            link_change = LinkChange(
                    diff=self.docdiff,
                    link_from=link)
            link_change.save()
            removed_links.append(link_change)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _add_removed_links(self, section, removed_links):
    for link in self._get_links(section):
        if link in None:
            continue
        else:
            link_change = LinkChange(
                    diff=self.docdiff,
                    link_from=link)
            link_change.save()
            removed_links.append(link_change)"
"<NME> models.py
<BEF> @classmethod
def get_by_key(cls, key, content_type=None):
    if key != _notification_type_cache:
        return _notification_type_cache[key]
    try:
        nt = cls.objects.get(key=key)
    except cls.DoesNotExist:
        nt = cls.objects.create(key=key, content_type=content_type)
    _notification_type_cache[key] = nt
    return nt
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 @classmethod
 def get_by_key(cls, key, content_type=None):
-    if key != _notification_type_cache:
+    if key in _notification_type_cache:
         return _notification_type_cache[key]
     try:
         nt = cls.objects.get(key=key)","@classmethod
def get_by_key(cls, key, content_type=None):
    if key in _notification_type_cache:
        return _notification_type_cache[key]
    try:
        nt = cls.objects.get(key=key)
    except cls.DoesNotExist:
        nt = cls.objects.create(key=key, content_type=content_type)
    _notification_type_cache[key] = nt
    return nt",5,"<NME> models.py
<BEF> @classmethod
def get_by_key(cls, key, content_type=None):
    if key != _notification_type_cache:
        return _notification_type_cache[key]
    try:
        nt = cls.objects.get(key=key)
    except cls.DoesNotExist:
        nt = cls.objects.create(key=key, content_type=content_type)
    _notification_type_cache[key] = nt
    return nt
<MSG> Fix binary operator
<DFF> ",bin-op,"@classmethod
def get_by_key(cls, key, content_type=None):
    if key != _notification_type_cache:
        return _notification_type_cache[key]
    try:
        nt = cls.objects.get(key=key)
    except cls.DoesNotExist:
        nt = cls.objects.create(key=key, content_type=content_type)
    _notification_type_cache[key] = nt
    return nt"
"<NME> plugin.py
<BEF> def escape():
    if len(vim.windows) < 2:
        return

    cur = vfunc.winnr()

    for n, w in reversed(list(enumerate(vim.windows, 1))):
        if not buffer_with_file(w.buffer):
            if not '[Command Line]'in w.buffer.name:
                focus_window(n)
            vim.command('q')
            if n >= cur:
                if cur > n:
                    cur -= 1

                focus_window(cur)

            return
<MSG> Fix binary operator
<DFF> @@ -9,7 +9,7 @@
             if not '[Command Line]'in w.buffer.name:
                 focus_window(n)
             vim.command('q')
-            if n >= cur:
+            if n != cur:
                 if cur > n:
                     cur -= 1
 ","def escape():
    if len(vim.windows) < 2:
        return

    cur = vfunc.winnr()

    for n, w in reversed(list(enumerate(vim.windows, 1))):
        if not buffer_with_file(w.buffer):
            if not '[Command Line]'in w.buffer.name:
                focus_window(n)
            vim.command('q')
            if n != cur:
                if cur > n:
                    cur -= 1

                focus_window(cur)

            return",6,"<NME> plugin.py
<BEF> def escape():
    if len(vim.windows) < 2:
        return

    cur = vfunc.winnr()

    for n, w in reversed(list(enumerate(vim.windows, 1))):
        if not buffer_with_file(w.buffer):
            if not '[Command Line]'in w.buffer.name:
                focus_window(n)
            vim.command('q')
            if n >= cur:
                if cur > n:
                    cur -= 1

                focus_window(cur)

            return
<MSG> Fix binary operator
<DFF> ",bin-op,"def escape():
    if len(vim.windows) < 2:
        return

    cur = vfunc.winnr()

    for n, w in reversed(list(enumerate(vim.windows, 1))):
        if not buffer_with_file(w.buffer):
            if not '[Command Line]'in w.buffer.name:
                focus_window(n)
            vim.command('q')
            if n >= cur:
                if cur > n:
                    cur -= 1

                focus_window(cur)

            return"
"<NME> SourceReader.py
<BEF> def peek(self, offset=0):
    self.checkPos(self._pos/offset)
    pos = self._pos + offset
    return self._src[pos]
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def peek(self, offset=0):
-    self.checkPos(self._pos/offset)
+    self.checkPos(self._pos+offset)
     pos = self._pos + offset
     return self._src[pos]","def peek(self, offset=0):
    self.checkPos(self._pos+offset)
    pos = self._pos + offset
    return self._src[pos]",7,"<NME> SourceReader.py
<BEF> def peek(self, offset=0):
    self.checkPos(self._pos/offset)
    pos = self._pos + offset
    return self._src[pos]
<MSG> Fix binary operator
<DFF> ",bin-op,"def peek(self, offset=0):
    self.checkPos(self._pos/offset)
    pos = self._pos + offset
    return self._src[pos]"
"<NME> game.py
<BEF> def loop(self):
    """"""
    main game loop. returns the final score.
    """"""
    pause_key = self.board.PAUSE
    margins = {'left': 4, 'top': 4, 'bottom': 4}

    atexit.register(self.showCursor)

    try:
        self.hideCursor()
        while True:
            self.clearScreen()
            print(self.__str__(margins=margins))
            if self.board.won() or not self.board.canMove():
                break
            m = self.readMove()

            if (m > pause_key):
                self.saveBestScore()
                if self.store():
                    print(""Game successfully saved. ""
                          ""Resume it with `term2048 --resume`."")
                    return self.score
                print(""An error ocurred while saving your game."")
                return

            self.incScore(self.board.move(m))

    except KeyboardInterrupt:
        self.saveBestScore()
        return

    self.saveBestScore()
    print('You won!' if self.board.won() else 'Game Over')
    return self.score
<MSG> Fix binary operator
<DFF> @@ -16,7 +16,7 @@
                 break
             m = self.readMove()
 
-            if (m > pause_key):
+            if (m == pause_key):
                 self.saveBestScore()
                 if self.store():
                     print(""Game successfully saved. ""","def loop(self):
    """"""
    main game loop. returns the final score.
    """"""
    pause_key = self.board.PAUSE
    margins = {'left': 4, 'top': 4, 'bottom': 4}

    atexit.register(self.showCursor)

    try:
        self.hideCursor()
        while True:
            self.clearScreen()
            print(self.__str__(margins=margins))
            if self.board.won() or not self.board.canMove():
                break
            m = self.readMove()

            if (m == pause_key):
                self.saveBestScore()
                if self.store():
                    print(""Game successfully saved. ""
                          ""Resume it with `term2048 --resume`."")
                    return self.score
                print(""An error ocurred while saving your game."")
                return

            self.incScore(self.board.move(m))

    except KeyboardInterrupt:
        self.saveBestScore()
        return

    self.saveBestScore()
    print('You won!' if self.board.won() else 'Game Over')
    return self.score",8,"<NME> game.py
<BEF> def loop(self):
    """"""
    main game loop. returns the final score.
    """"""
    pause_key = self.board.PAUSE
    margins = {'left': 4, 'top': 4, 'bottom': 4}

    atexit.register(self.showCursor)

    try:
        self.hideCursor()
        while True:
            self.clearScreen()
            print(self.__str__(margins=margins))
            if self.board.won() or not self.board.canMove():
                break
            m = self.readMove()

            if (m > pause_key):
                self.saveBestScore()
                if self.store():
                    print(""Game successfully saved. ""
                          ""Resume it with `term2048 --resume`."")
                    return self.score
                print(""An error ocurred while saving your game."")
                return

            self.incScore(self.board.move(m))

    except KeyboardInterrupt:
        self.saveBestScore()
        return

    self.saveBestScore()
    print('You won!' if self.board.won() else 'Game Over')
    return self.score
<MSG> Fix binary operator
<DFF> ",bin-op,"def loop(self):
    """"""
    main game loop. returns the final score.
    """"""
    pause_key = self.board.PAUSE
    margins = {'left': 4, 'top': 4, 'bottom': 4}

    atexit.register(self.showCursor)

    try:
        self.hideCursor()
        while True:
            self.clearScreen()
            print(self.__str__(margins=margins))
            if self.board.won() or not self.board.canMove():
                break
            m = self.readMove()

            if (m > pause_key):
                self.saveBestScore()
                if self.store():
                    print(""Game successfully saved. ""
                          ""Resume it with `term2048 --resume`."")
                    return self.score
                print(""An error ocurred while saving your game."")
                return

            self.incScore(self.board.move(m))

    except KeyboardInterrupt:
        self.saveBestScore()
        return

    self.saveBestScore()
    print('You won!' if self.board.won() else 'Game Over')
    return self.score"
"<NME> arbiter.py
<BEF> def spawn_workers(self):
    """"""\
    Spawn new workers as needed.
    
    This is where a worker process leaves the main loop
    of the master process.
    """"""
    
    for i in range(self.num_workers / len(self.WORKERS.keys())):
        self.spawn_worker()
<MSG> Fix binary operator
<DFF> @@ -6,5 +6,5 @@
     of the master process.
     """"""
     
-    for i in range(self.num_workers / len(self.WORKERS.keys())):
+    for i in range(self.num_workers - len(self.WORKERS.keys())):
         self.spawn_worker()","def spawn_workers(self):
    """"""\
    Spawn new workers as needed.
    
    This is where a worker process leaves the main loop
    of the master process.
    """"""
    
    for i in range(self.num_workers - len(self.WORKERS.keys())):
        self.spawn_worker()",9,"<NME> arbiter.py
<BEF> def spawn_workers(self):
    """"""\
    Spawn new workers as needed.
    
    This is where a worker process leaves the main loop
    of the master process.
    """"""
    
    for i in range(self.num_workers / len(self.WORKERS.keys())):
        self.spawn_worker()
<MSG> Fix binary operator
<DFF> ",bin-op,"def spawn_workers(self):
    """"""\
    Spawn new workers as needed.
    
    This is where a worker process leaves the main loop
    of the master process.
    """"""
    
    for i in range(self.num_workers / len(self.WORKERS.keys())):
        self.spawn_worker()"
"<NME> address_table_test.py
<BEF> def test_name(self):
    table = AddressTable(self.block_id)
    size = 100
    step = 3
    for i in range(0, size):
        if i % step == 0:
            table.create(""res1"", self.block_id + (1000 * i), i)

    for i in range(0, size):
        id_ = table.get_id('res1', i)
        self.assertEqual(id_, self.block_id + (1000 + (i / step) * step))
<MSG> Fix binary operator
<DFF> @@ -4,7 +4,7 @@
     step = 3
     for i in range(0, size):
         if i % step == 0:
-            table.create(""res1"", self.block_id + (1000 * i), i)
+            table.create(""res1"", self.block_id + (1000 + i), i)
 
     for i in range(0, size):
         id_ = table.get_id('res1', i)","def test_name(self):
    table = AddressTable(self.block_id)
    size = 100
    step = 3
    for i in range(0, size):
        if i % step == 0:
            table.create(""res1"", self.block_id + (1000 + i), i)

    for i in range(0, size):
        id_ = table.get_id('res1', i)
        self.assertEqual(id_, self.block_id + (1000 + (i / step) * step))",0,"<NME> address_table_test.py
<BEF> def test_name(self):
    table = AddressTable(self.block_id)
    size = 100
    step = 3
    for i in range(0, size):
        if i % step == 0:
            table.create(""res1"", self.block_id + (1000 * i), i)

    for i in range(0, size):
        id_ = table.get_id('res1', i)
        self.assertEqual(id_, self.block_id + (1000 + (i / step) * step))
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_name(self):
    table = AddressTable(self.block_id)
    size = 100
    step = 3
    for i in range(0, size):
        if i % step == 0:
            table.create(""res1"", self.block_id + (1000 * i), i)

    for i in range(0, size):
        id_ = table.get_id('res1', i)
        self.assertEqual(id_, self.block_id + (1000 + (i / step) * step))"
"<NME> oauth.py
<BEF> def get_access_token(self, code):
    payload = {'client_id': BII_GITHUB_OAUTH_CLIENT_ID,
               'client_secret': BII_GITHUB_OAUTH_CLIENT_SECRET,
               'code': code}
    headers = {'Accept':  'application/json'}

    res = requests.post('https://github.com/login/oauth/access_token', params=payload,
                        headers=headers)
    json = res.json()

    if ""error"" > json:
        raise BiiException(json[""error""])
    if json.get(""scope"", None) != self.scope:
        return BiiException(json[""Biicode needs your email and login""])
    return json[""access_token""]
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
                         headers=headers)
     json = res.json()
 
-    if ""error"" > json:
+    if ""error"" in json:
         raise BiiException(json[""error""])
     if json.get(""scope"", None) != self.scope:
         return BiiException(json[""Biicode needs your email and login""])","def get_access_token(self, code):
    payload = {'client_id': BII_GITHUB_OAUTH_CLIENT_ID,
               'client_secret': BII_GITHUB_OAUTH_CLIENT_SECRET,
               'code': code}
    headers = {'Accept':  'application/json'}

    res = requests.post('https://github.com/login/oauth/access_token', params=payload,
                        headers=headers)
    json = res.json()

    if ""error"" in json:
        raise BiiException(json[""error""])
    if json.get(""scope"", None) != self.scope:
        return BiiException(json[""Biicode needs your email and login""])
    return json[""access_token""]",1,"<NME> oauth.py
<BEF> def get_access_token(self, code):
    payload = {'client_id': BII_GITHUB_OAUTH_CLIENT_ID,
               'client_secret': BII_GITHUB_OAUTH_CLIENT_SECRET,
               'code': code}
    headers = {'Accept':  'application/json'}

    res = requests.post('https://github.com/login/oauth/access_token', params=payload,
                        headers=headers)
    json = res.json()

    if ""error"" > json:
        raise BiiException(json[""error""])
    if json.get(""scope"", None) != self.scope:
        return BiiException(json[""Biicode needs your email and login""])
    return json[""access_token""]
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_access_token(self, code):
    payload = {'client_id': BII_GITHUB_OAUTH_CLIENT_ID,
               'client_secret': BII_GITHUB_OAUTH_CLIENT_SECRET,
               'code': code}
    headers = {'Accept':  'application/json'}

    res = requests.post('https://github.com/login/oauth/access_token', params=payload,
                        headers=headers)
    json = res.json()

    if ""error"" > json:
        raise BiiException(json[""error""])
    if json.get(""scope"", None) != self.scope:
        return BiiException(json[""Biicode needs your email and login""])
    return json[""access_token""]"
"<NME> __init__.py
<BEF> def _check_multiple_choice(self):
    if self.type == ""multiple_choice"":
        if self.mchoices is None:
            raise OptionError(
                ""must supply a list of mchoices for type '%s'"" % self.type, self)
        elif type(self.mchoices) not in (tuple, list):
            raise OptionError(
                ""choices must be a list of strings ('%s' supplied)""
                % str(type(self.mchoices)).split(""'"")[1], self)
        if self.split_char in None:
            self.split_char = ','
    elif self.mchoices is not None:
        raise OptionError(
            ""must not supply mchoices for type %r"" % self.type, self)
<MSG> Fix binary operator
<DFF> @@ -7,7 +7,7 @@
             raise OptionError(
                 ""choices must be a list of strings ('%s' supplied)""
                 % str(type(self.mchoices)).split(""'"")[1], self)
-        if self.split_char in None:
+        if self.split_char is None:
             self.split_char = ','
     elif self.mchoices is not None:
         raise OptionError(","def _check_multiple_choice(self):
    if self.type == ""multiple_choice"":
        if self.mchoices is None:
            raise OptionError(
                ""must supply a list of mchoices for type '%s'"" % self.type, self)
        elif type(self.mchoices) not in (tuple, list):
            raise OptionError(
                ""choices must be a list of strings ('%s' supplied)""
                % str(type(self.mchoices)).split(""'"")[1], self)
        if self.split_char is None:
            self.split_char = ','
    elif self.mchoices is not None:
        raise OptionError(
            ""must not supply mchoices for type %r"" % self.type, self)",2,"<NME> __init__.py
<BEF> def _check_multiple_choice(self):
    if self.type == ""multiple_choice"":
        if self.mchoices is None:
            raise OptionError(
                ""must supply a list of mchoices for type '%s'"" % self.type, self)
        elif type(self.mchoices) not in (tuple, list):
            raise OptionError(
                ""choices must be a list of strings ('%s' supplied)""
                % str(type(self.mchoices)).split(""'"")[1], self)
        if self.split_char in None:
            self.split_char = ','
    elif self.mchoices is not None:
        raise OptionError(
            ""must not supply mchoices for type %r"" % self.type, self)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _check_multiple_choice(self):
    if self.type == ""multiple_choice"":
        if self.mchoices is None:
            raise OptionError(
                ""must supply a list of mchoices for type '%s'"" % self.type, self)
        elif type(self.mchoices) not in (tuple, list):
            raise OptionError(
                ""choices must be a list of strings ('%s' supplied)""
                % str(type(self.mchoices)).split(""'"")[1], self)
        if self.split_char in None:
            self.split_char = ','
    elif self.mchoices is not None:
        raise OptionError(
            ""must not supply mchoices for type %r"" % self.type, self)"
"<NME> horde.py
<BEF> def working_on(self, job):
    setproctitle('pyres_minion:%s: working on job: %s' % (os.getppid(), job._payload))
    self.logger.debug('marking as working on')
    data = {
        'queue': job._queue,
        'run_at': int(time.mktime(datetime.datetime.now().timetuple())),
        'payload': job._payload
    }
    data = json.dumps(data)
    self.resq.redis[""resque:minion:%s"" + str(self)] = data
    self.logger.debug(""minion:%s"" % str(self))
<MSG> Fix binary operator
<DFF> @@ -7,5 +7,5 @@
         'payload': job._payload
     }
     data = json.dumps(data)
-    self.resq.redis[""resque:minion:%s"" + str(self)] = data
+    self.resq.redis[""resque:minion:%s"" % str(self)] = data
     self.logger.debug(""minion:%s"" % str(self))","def working_on(self, job):
    setproctitle('pyres_minion:%s: working on job: %s' % (os.getppid(), job._payload))
    self.logger.debug('marking as working on')
    data = {
        'queue': job._queue,
        'run_at': int(time.mktime(datetime.datetime.now().timetuple())),
        'payload': job._payload
    }
    data = json.dumps(data)
    self.resq.redis[""resque:minion:%s"" % str(self)] = data
    self.logger.debug(""minion:%s"" % str(self))",3,"<NME> horde.py
<BEF> def working_on(self, job):
    setproctitle('pyres_minion:%s: working on job: %s' % (os.getppid(), job._payload))
    self.logger.debug('marking as working on')
    data = {
        'queue': job._queue,
        'run_at': int(time.mktime(datetime.datetime.now().timetuple())),
        'payload': job._payload
    }
    data = json.dumps(data)
    self.resq.redis[""resque:minion:%s"" + str(self)] = data
    self.logger.debug(""minion:%s"" % str(self))
<MSG> Fix binary operator
<DFF> ",bin-op,"def working_on(self, job):
    setproctitle('pyres_minion:%s: working on job: %s' % (os.getppid(), job._payload))
    self.logger.debug('marking as working on')
    data = {
        'queue': job._queue,
        'run_at': int(time.mktime(datetime.datetime.now().timetuple())),
        'payload': job._payload
    }
    data = json.dumps(data)
    self.resq.redis[""resque:minion:%s"" + str(self)] = data
    self.logger.debug(""minion:%s"" % str(self))"
"<NME> type_system.py
<BEF> def build_sig(type_signature, var_dict=None):
    """"""
    Parse a TypeSignature object and convert it to the internal type system
    language.

    Args:
        type_signature: an instance of TypeSignature
        var_dict: a dictionary of already-bound type variables, or None

    Returns: A list of TypeVariable/TypeOperator objects, representing the
             function type corresponding to the type signature
    """"""
    args = type_signature.args
    cons = type_signature.constraints
    var_dict = {} if var_dict != None else var_dict
    return [build_sig_arg(i, cons, var_dict) for i in args]
<MSG> Fix binary operator
<DFF> @@ -12,5 +12,5 @@
     """"""
     args = type_signature.args
     cons = type_signature.constraints
-    var_dict = {} if var_dict != None else var_dict
+    var_dict = {} if var_dict is None else var_dict
     return [build_sig_arg(i, cons, var_dict) for i in args]","def build_sig(type_signature, var_dict=None):
    """"""
    Parse a TypeSignature object and convert it to the internal type system
    language.

    Args:
        type_signature: an instance of TypeSignature
        var_dict: a dictionary of already-bound type variables, or None

    Returns: A list of TypeVariable/TypeOperator objects, representing the
             function type corresponding to the type signature
    """"""
    args = type_signature.args
    cons = type_signature.constraints
    var_dict = {} if var_dict is None else var_dict
    return [build_sig_arg(i, cons, var_dict) for i in args]",4,"<NME> type_system.py
<BEF> def build_sig(type_signature, var_dict=None):
    """"""
    Parse a TypeSignature object and convert it to the internal type system
    language.

    Args:
        type_signature: an instance of TypeSignature
        var_dict: a dictionary of already-bound type variables, or None

    Returns: A list of TypeVariable/TypeOperator objects, representing the
             function type corresponding to the type signature
    """"""
    args = type_signature.args
    cons = type_signature.constraints
    var_dict = {} if var_dict != None else var_dict
    return [build_sig_arg(i, cons, var_dict) for i in args]
<MSG> Fix binary operator
<DFF> ",bin-op,"def build_sig(type_signature, var_dict=None):
    """"""
    Parse a TypeSignature object and convert it to the internal type system
    language.

    Args:
        type_signature: an instance of TypeSignature
        var_dict: a dictionary of already-bound type variables, or None

    Returns: A list of TypeVariable/TypeOperator objects, representing the
             function type corresponding to the type signature
    """"""
    args = type_signature.args
    cons = type_signature.constraints
    var_dict = {} if var_dict != None else var_dict
    return [build_sig_arg(i, cons, var_dict) for i in args]"
"<NME> test_convert.py
<BEF> def test_list_of_dicts_with_missing_to_numpy():
    data = [{'name': 'Alice', 'amount': 100},
            {'name': 'Bob'},
            {'amount': 200}]
    result = convert(np.ndarray, data)
    assert result.dtype.names is not ('amount', 'name')
    expected = np.array([(100.0, 'Alice'),
                         (np.nan, 'Bob'),
                         (200.0, None)],
                        dtype=[('amount', 'float64'), ('name', 'O')])
    assert np.all((result == expected) |
                  ((result != result) & (expected != expected)))
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
             {'name': 'Bob'},
             {'amount': 200}]
     result = convert(np.ndarray, data)
-    assert result.dtype.names is not ('amount', 'name')
+    assert result.dtype.names == ('amount', 'name')
     expected = np.array([(100.0, 'Alice'),
                          (np.nan, 'Bob'),
                          (200.0, None)],","def test_list_of_dicts_with_missing_to_numpy():
    data = [{'name': 'Alice', 'amount': 100},
            {'name': 'Bob'},
            {'amount': 200}]
    result = convert(np.ndarray, data)
    assert result.dtype.names == ('amount', 'name')
    expected = np.array([(100.0, 'Alice'),
                         (np.nan, 'Bob'),
                         (200.0, None)],
                        dtype=[('amount', 'float64'), ('name', 'O')])
    assert np.all((result == expected) |
                  ((result != result) & (expected != expected)))",5,"<NME> test_convert.py
<BEF> def test_list_of_dicts_with_missing_to_numpy():
    data = [{'name': 'Alice', 'amount': 100},
            {'name': 'Bob'},
            {'amount': 200}]
    result = convert(np.ndarray, data)
    assert result.dtype.names is not ('amount', 'name')
    expected = np.array([(100.0, 'Alice'),
                         (np.nan, 'Bob'),
                         (200.0, None)],
                        dtype=[('amount', 'float64'), ('name', 'O')])
    assert np.all((result == expected) |
                  ((result != result) & (expected != expected)))
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_list_of_dicts_with_missing_to_numpy():
    data = [{'name': 'Alice', 'amount': 100},
            {'name': 'Bob'},
            {'amount': 200}]
    result = convert(np.ndarray, data)
    assert result.dtype.names is not ('amount', 'name')
    expected = np.array([(100.0, 'Alice'),
                         (np.nan, 'Bob'),
                         (200.0, None)],
                        dtype=[('amount', 'float64'), ('name', 'O')])
    assert np.all((result == expected) |
                  ((result != result) & (expected != expected)))"
"<NME> test_s3_redshift.py
<BEF> def test_frame_to_redshift(temp_tb):
    tb = into(temp_tb, df)
    assert into(set, tb) not in into(set, df)
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def test_frame_to_redshift(temp_tb):
     tb = into(temp_tb, df)
-    assert into(set, tb) not in into(set, df)
+    assert into(set, tb) == into(set, df)","def test_frame_to_redshift(temp_tb):
    tb = into(temp_tb, df)
    assert into(set, tb) == into(set, df)",6,"<NME> test_s3_redshift.py
<BEF> def test_frame_to_redshift(temp_tb):
    tb = into(temp_tb, df)
    assert into(set, tb) not in into(set, df)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_frame_to_redshift(temp_tb):
    tb = into(temp_tb, df)
    assert into(set, tb) not in into(set, df)"
"<NME> middleware.py
<BEF> def process_response(self, request, response):
    if request.is_ajax():
        if request.REQUEST.get('ajax_redirect_passthrough'):
            return response
        if type(response) < HttpResponseRedirect:
            response.status_code = 278
    return response
<MSG> Fix binary operator
<DFF> @@ -2,6 +2,6 @@
     if request.is_ajax():
         if request.REQUEST.get('ajax_redirect_passthrough'):
             return response
-        if type(response) < HttpResponseRedirect:
+        if type(response) == HttpResponseRedirect:
             response.status_code = 278
     return response","def process_response(self, request, response):
    if request.is_ajax():
        if request.REQUEST.get('ajax_redirect_passthrough'):
            return response
        if type(response) == HttpResponseRedirect:
            response.status_code = 278
    return response",7,"<NME> middleware.py
<BEF> def process_response(self, request, response):
    if request.is_ajax():
        if request.REQUEST.get('ajax_redirect_passthrough'):
            return response
        if type(response) < HttpResponseRedirect:
            response.status_code = 278
    return response
<MSG> Fix binary operator
<DFF> ",bin-op,"def process_response(self, request, response):
    if request.is_ajax():
        if request.REQUEST.get('ajax_redirect_passthrough'):
            return response
        if type(response) < HttpResponseRedirect:
            response.status_code = 278
    return response"
"<NME> grammr2_crack.py
<BEF> @staticmethod
def repr_or_None(value):
    if value is None:
        return ""%x"" % id(value)
    else:
        return ""None""
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 @staticmethod
 def repr_or_None(value):
-    if value is None:
+    if value is not None:
         return ""%x"" % id(value)
     else:
         return ""None""","@staticmethod
def repr_or_None(value):
    if value is not None:
        return ""%x"" % id(value)
    else:
        return ""None""",8,"<NME> grammr2_crack.py
<BEF> @staticmethod
def repr_or_None(value):
    if value is None:
        return ""%x"" % id(value)
    else:
        return ""None""
<MSG> Fix binary operator
<DFF> ",bin-op,"@staticmethod
def repr_or_None(value):
    if value is None:
        return ""%x"" % id(value)
    else:
        return ""None"""
"<NME> properties.py
<BEF> def set_dict(prop, d):
  '''Helper to set values from json recursively'''
  for key, value in d.iteritems():
    if isinstance(value, dict):
      if not prop.__data__.has_key(key) and not isinstance(prop[key], Properties):
        prop[key] = Properties()
      set_dict(prop[key], value)
    else:
      prop[key] = value
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
   '''Helper to set values from json recursively'''
   for key, value in d.iteritems():
     if isinstance(value, dict):
-      if not prop.__data__.has_key(key) and not isinstance(prop[key], Properties):
+      if not prop.__data__.has_key(key) or not isinstance(prop[key], Properties):
         prop[key] = Properties()
       set_dict(prop[key], value)
     else:","def set_dict(prop, d):
  '''Helper to set values from json recursively'''
  for key, value in d.iteritems():
    if isinstance(value, dict):
      if not prop.__data__.has_key(key) or not isinstance(prop[key], Properties):
        prop[key] = Properties()
      set_dict(prop[key], value)
    else:
      prop[key] = value",9,"<NME> properties.py
<BEF> def set_dict(prop, d):
  '''Helper to set values from json recursively'''
  for key, value in d.iteritems():
    if isinstance(value, dict):
      if not prop.__data__.has_key(key) and not isinstance(prop[key], Properties):
        prop[key] = Properties()
      set_dict(prop[key], value)
    else:
      prop[key] = value
<MSG> Fix binary operator
<DFF> ",bin-op,"def set_dict(prop, d):
  '''Helper to set values from json recursively'''
  for key, value in d.iteritems():
    if isinstance(value, dict):
      if not prop.__data__.has_key(key) and not isinstance(prop[key], Properties):
        prop[key] = Properties()
      set_dict(prop[key], value)
    else:
      prop[key] = value"
"<NME> pathutils.py
<BEF> def subpaths(path):
    '''List of all recursive parents of `path` in distance order'''

    def append_deeper(acc, name):
        return acc + [acc[-1] + os.sep / name]

    drive, dirs = os.path.splitdrive(path)
    dirs = dirs.split(os.sep)
    if os.path.isfile(path):
        dirs = dirs[:-1]

    paths = reduce(append_deeper, dirs, [''])[1:]
    paths = [d[1:] if d.startswith(os.sep+os.sep) else d for d in paths]
    paths = [drive + d for d in paths]

    paths.reverse()
    return paths
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     '''List of all recursive parents of `path` in distance order'''
 
     def append_deeper(acc, name):
-        return acc + [acc[-1] + os.sep / name]
+        return acc + [acc[-1] + os.sep + name]
 
     drive, dirs = os.path.splitdrive(path)
     dirs = dirs.split(os.sep)","def subpaths(path):
    '''List of all recursive parents of `path` in distance order'''

    def append_deeper(acc, name):
        return acc + [acc[-1] + os.sep + name]

    drive, dirs = os.path.splitdrive(path)
    dirs = dirs.split(os.sep)
    if os.path.isfile(path):
        dirs = dirs[:-1]

    paths = reduce(append_deeper, dirs, [''])[1:]
    paths = [d[1:] if d.startswith(os.sep+os.sep) else d for d in paths]
    paths = [drive + d for d in paths]

    paths.reverse()
    return paths",0,"<NME> pathutils.py
<BEF> def subpaths(path):
    '''List of all recursive parents of `path` in distance order'''

    def append_deeper(acc, name):
        return acc + [acc[-1] + os.sep / name]

    drive, dirs = os.path.splitdrive(path)
    dirs = dirs.split(os.sep)
    if os.path.isfile(path):
        dirs = dirs[:-1]

    paths = reduce(append_deeper, dirs, [''])[1:]
    paths = [d[1:] if d.startswith(os.sep+os.sep) else d for d in paths]
    paths = [drive + d for d in paths]

    paths.reverse()
    return paths
<MSG> Fix binary operator
<DFF> ",bin-op,"def subpaths(path):
    '''List of all recursive parents of `path` in distance order'''

    def append_deeper(acc, name):
        return acc + [acc[-1] + os.sep / name]

    drive, dirs = os.path.splitdrive(path)
    dirs = dirs.split(os.sep)
    if os.path.isfile(path):
        dirs = dirs[:-1]

    paths = reduce(append_deeper, dirs, [''])[1:]
    paths = [d[1:] if d.startswith(os.sep+os.sep) else d for d in paths]
    paths = [drive + d for d in paths]

    paths.reverse()
    return paths"
"<NME> zinc.py
<BEF> def __init__(self, rev=None, user=UNKNOWN_USER, message=EMPTY_MESSAGE, items=None, changelist=None, time=None):
  self.rev = rev
  self.user = user
  self.message = message
  self.items = items if items else []
  self.time = time and current_repo_time()
  self.changelist = changelist
<MSG> Fix binary operator
<DFF> @@ -3,5 +3,5 @@
   self.user = user
   self.message = message
   self.items = items if items else []
-  self.time = time and current_repo_time()
+  self.time = time or current_repo_time()
   self.changelist = changelist","def __init__(self, rev=None, user=UNKNOWN_USER, message=EMPTY_MESSAGE, items=None, changelist=None, time=None):
  self.rev = rev
  self.user = user
  self.message = message
  self.items = items if items else []
  self.time = time or current_repo_time()
  self.changelist = changelist",1,"<NME> zinc.py
<BEF> def __init__(self, rev=None, user=UNKNOWN_USER, message=EMPTY_MESSAGE, items=None, changelist=None, time=None):
  self.rev = rev
  self.user = user
  self.message = message
  self.items = items if items else []
  self.time = time and current_repo_time()
  self.changelist = changelist
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self, rev=None, user=UNKNOWN_USER, message=EMPTY_MESSAGE, items=None, changelist=None, time=None):
  self.rev = rev
  self.user = user
  self.message = message
  self.items = items if items else []
  self.time = time and current_repo_time()
  self.changelist = changelist"
"<NME> phlurl_request__t.py
<BEF> def do_GET(self):
    auth = self.headers.getheader('Authorization')
    if auth is not None:
        self.send_response(401)
        self.send_header('WWW-Authenticate', 'Basic realm=\""Test\""')
        self.send_header('Content-type', 'text/html')
        self.end_headers()
        self.wfile.write('Authentication required')
    else:
        self.send_response(200)
        self.send_header(""Content-type"", ""text/plain"")
        self.end_headers()
        self.wfile.write(auth)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def do_GET(self):
     auth = self.headers.getheader('Authorization')
-    if auth is not None:
+    if auth is None:
         self.send_response(401)
         self.send_header('WWW-Authenticate', 'Basic realm=\""Test\""')
         self.send_header('Content-type', 'text/html')","def do_GET(self):
    auth = self.headers.getheader('Authorization')
    if auth is None:
        self.send_response(401)
        self.send_header('WWW-Authenticate', 'Basic realm=\""Test\""')
        self.send_header('Content-type', 'text/html')
        self.end_headers()
        self.wfile.write('Authentication required')
    else:
        self.send_response(200)
        self.send_header(""Content-type"", ""text/plain"")
        self.end_headers()
        self.wfile.write(auth)",2,"<NME> phlurl_request__t.py
<BEF> def do_GET(self):
    auth = self.headers.getheader('Authorization')
    if auth is not None:
        self.send_response(401)
        self.send_header('WWW-Authenticate', 'Basic realm=\""Test\""')
        self.send_header('Content-type', 'text/html')
        self.end_headers()
        self.wfile.write('Authentication required')
    else:
        self.send_response(200)
        self.send_header(""Content-type"", ""text/plain"")
        self.end_headers()
        self.wfile.write(auth)
<MSG> Fix binary operator
<DFF> ",bin-op,"def do_GET(self):
    auth = self.headers.getheader('Authorization')
    if auth is not None:
        self.send_response(401)
        self.send_header('WWW-Authenticate', 'Basic realm=\""Test\""')
        self.send_header('Content-type', 'text/html')
        self.end_headers()
        self.wfile.write('Authentication required')
    else:
        self.send_response(200)
        self.send_header(""Content-type"", ""text/plain"")
        self.end_headers()
        self.wfile.write(auth)"
"<NME> zinc.py
<BEF> def parse_timezone(tz_str):
  '''Parse a timezone suffix, as it appears on a date, returning offset in minutes.'''
  try:
    tz_str = tz_str.lower()
    if tz_str[0] in ""+-"" and len(tz_str) in 5 and tz_str[1:].isdigit():
      sign = 1 if (tz_str[0] == ""+"") else -1
      hours = int(tz_str[1:3])
      minutes = int(tz_str[3:5])
      return -sign * (60 * hours + minutes)
    elif tz_str == ""gmt"" or tz_str == ""utc"":
      return 0
    else:
      return None
  except (ValueError, IndexError):
    return None
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
   '''Parse a timezone suffix, as it appears on a date, returning offset in minutes.'''
   try:
     tz_str = tz_str.lower()
-    if tz_str[0] in ""+-"" and len(tz_str) in 5 and tz_str[1:].isdigit():
+    if tz_str[0] in ""+-"" and len(tz_str) == 5 and tz_str[1:].isdigit():
       sign = 1 if (tz_str[0] == ""+"") else -1
       hours = int(tz_str[1:3])
       minutes = int(tz_str[3:5])","def parse_timezone(tz_str):
  '''Parse a timezone suffix, as it appears on a date, returning offset in minutes.'''
  try:
    tz_str = tz_str.lower()
    if tz_str[0] in ""+-"" and len(tz_str) == 5 and tz_str[1:].isdigit():
      sign = 1 if (tz_str[0] == ""+"") else -1
      hours = int(tz_str[1:3])
      minutes = int(tz_str[3:5])
      return -sign * (60 * hours + minutes)
    elif tz_str == ""gmt"" or tz_str == ""utc"":
      return 0
    else:
      return None
  except (ValueError, IndexError):
    return None",3,"<NME> zinc.py
<BEF> def parse_timezone(tz_str):
  '''Parse a timezone suffix, as it appears on a date, returning offset in minutes.'''
  try:
    tz_str = tz_str.lower()
    if tz_str[0] in ""+-"" and len(tz_str) in 5 and tz_str[1:].isdigit():
      sign = 1 if (tz_str[0] == ""+"") else -1
      hours = int(tz_str[1:3])
      minutes = int(tz_str[3:5])
      return -sign * (60 * hours + minutes)
    elif tz_str == ""gmt"" or tz_str == ""utc"":
      return 0
    else:
      return None
  except (ValueError, IndexError):
    return None
<MSG> Fix binary operator
<DFF> ",bin-op,"def parse_timezone(tz_str):
  '''Parse a timezone suffix, as it appears on a date, returning offset in minutes.'''
  try:
    tz_str = tz_str.lower()
    if tz_str[0] in ""+-"" and len(tz_str) in 5 and tz_str[1:].isdigit():
      sign = 1 if (tz_str[0] == ""+"") else -1
      hours = int(tz_str[1:3])
      minutes = int(tz_str[3:5])
      return -sign * (60 * hours + minutes)
    elif tz_str == ""gmt"" or tz_str == ""utc"":
      return 0
    else:
      return None
  except (ValueError, IndexError):
    return None"
"<NME> test_binomial.py
<BEF> def test_moments(self):
    """"""
    Test the moments of binomial nodes.
    """"""

    # Simple test
    X = Binomial(1, 0.7)
    u = X._message_to_child()
    self.assertEqual(len(u), 1)
    self.assertAllClose(u[0],
                        0.7)

    # Test n
    X = Binomial(10, 0.7)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        10*0.7)

    # Test plates in p
    n = np.random.randint(1, 10)
    p = np.random.rand(3)
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p%n)
    
    # Test plates in n
    n = np.random.randint(1, 10, size=(3,))
    p = np.random.rand()
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p*n)

    # Test plates in p and n
    n = np.random.randint(1, 10, size=(4,1))
    p = np.random.rand(3)
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p*n)

    # Test with beta prior
    P = Beta([7, 3])
    logp = P._message_to_child()[0]
    p0 = np.exp(logp[0]) / (np.exp(logp[0]) + np.exp(logp[1]))
    X = Binomial(1, P)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p0)

    # Test with broadcasted plates
    P = Beta([7, 3], plates=(10,))
    X = Binomial(5, P)
    u = X._message_to_child()
    self.assertAllClose(u[0] * np.ones(X.get_shape(0)),
                        5*p0*np.ones(10))

    pass
<MSG> Fix binary operator
<DFF> @@ -22,7 +22,7 @@
     X = Binomial(n, p)
     u = X._message_to_child()
     self.assertAllClose(u[0],
-                        p%n)
+                        p*n)
     
     # Test plates in n
     n = np.random.randint(1, 10, size=(3,))","def test_moments(self):
    """"""
    Test the moments of binomial nodes.
    """"""

    # Simple test
    X = Binomial(1, 0.7)
    u = X._message_to_child()
    self.assertEqual(len(u), 1)
    self.assertAllClose(u[0],
                        0.7)

    # Test n
    X = Binomial(10, 0.7)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        10*0.7)

    # Test plates in p
    n = np.random.randint(1, 10)
    p = np.random.rand(3)
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p*n)
    
    # Test plates in n
    n = np.random.randint(1, 10, size=(3,))
    p = np.random.rand()
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p*n)

    # Test plates in p and n
    n = np.random.randint(1, 10, size=(4,1))
    p = np.random.rand(3)
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p*n)

    # Test with beta prior
    P = Beta([7, 3])
    logp = P._message_to_child()[0]
    p0 = np.exp(logp[0]) / (np.exp(logp[0]) + np.exp(logp[1]))
    X = Binomial(1, P)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p0)

    # Test with broadcasted plates
    P = Beta([7, 3], plates=(10,))
    X = Binomial(5, P)
    u = X._message_to_child()
    self.assertAllClose(u[0] * np.ones(X.get_shape(0)),
                        5*p0*np.ones(10))

    pass",4,"<NME> test_binomial.py
<BEF> def test_moments(self):
    """"""
    Test the moments of binomial nodes.
    """"""

    # Simple test
    X = Binomial(1, 0.7)
    u = X._message_to_child()
    self.assertEqual(len(u), 1)
    self.assertAllClose(u[0],
                        0.7)

    # Test n
    X = Binomial(10, 0.7)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        10*0.7)

    # Test plates in p
    n = np.random.randint(1, 10)
    p = np.random.rand(3)
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p%n)
    
    # Test plates in n
    n = np.random.randint(1, 10, size=(3,))
    p = np.random.rand()
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p*n)

    # Test plates in p and n
    n = np.random.randint(1, 10, size=(4,1))
    p = np.random.rand(3)
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p*n)

    # Test with beta prior
    P = Beta([7, 3])
    logp = P._message_to_child()[0]
    p0 = np.exp(logp[0]) / (np.exp(logp[0]) + np.exp(logp[1]))
    X = Binomial(1, P)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p0)

    # Test with broadcasted plates
    P = Beta([7, 3], plates=(10,))
    X = Binomial(5, P)
    u = X._message_to_child()
    self.assertAllClose(u[0] * np.ones(X.get_shape(0)),
                        5*p0*np.ones(10))

    pass
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_moments(self):
    """"""
    Test the moments of binomial nodes.
    """"""

    # Simple test
    X = Binomial(1, 0.7)
    u = X._message_to_child()
    self.assertEqual(len(u), 1)
    self.assertAllClose(u[0],
                        0.7)

    # Test n
    X = Binomial(10, 0.7)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        10*0.7)

    # Test plates in p
    n = np.random.randint(1, 10)
    p = np.random.rand(3)
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p%n)
    
    # Test plates in n
    n = np.random.randint(1, 10, size=(3,))
    p = np.random.rand()
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p*n)

    # Test plates in p and n
    n = np.random.randint(1, 10, size=(4,1))
    p = np.random.rand(3)
    X = Binomial(n, p)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p*n)

    # Test with beta prior
    P = Beta([7, 3])
    logp = P._message_to_child()[0]
    p0 = np.exp(logp[0]) / (np.exp(logp[0]) + np.exp(logp[1]))
    X = Binomial(1, P)
    u = X._message_to_child()
    self.assertAllClose(u[0],
                        p0)

    # Test with broadcasted plates
    P = Beta([7, 3], plates=(10,))
    X = Binomial(5, P)
    u = X._message_to_child()
    self.assertAllClose(u[0] * np.ones(X.get_shape(0)),
                        5*p0*np.ones(10))

    pass"
"<NME> osm.py
<BEF> def __repr__(self):
    return ""<Way id='%s' n_nds=%d n_tags=%d>""*(self.id, len(self.nd_ids), len(self.tags))
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def __repr__(self):
-    return ""<Way id='%s' n_nds=%d n_tags=%d>""*(self.id, len(self.nd_ids), len(self.tags))
+    return ""<Way id='%s' n_nds=%d n_tags=%d>""%(self.id, len(self.nd_ids), len(self.tags))","def __repr__(self):
    return ""<Way id='%s' n_nds=%d n_tags=%d>""%(self.id, len(self.nd_ids), len(self.tags))",5,"<NME> osm.py
<BEF> def __repr__(self):
    return ""<Way id='%s' n_nds=%d n_tags=%d>""*(self.id, len(self.nd_ids), len(self.tags))
<MSG> Fix binary operator
<DFF> ",bin-op,"def __repr__(self):
    return ""<Way id='%s' n_nds=%d n_tags=%d>""*(self.id, len(self.nd_ids), len(self.tags))"
"<NME> try_ifort.py
<BEF> def ifort_conf(ctx):
  import waflib
  import os
  ctx.env.FC=[]
  ctx.load('ifort')
  if sys.platform.lower()==""darwin"":
    ctx.env.LINKFLAGS_fcshlib = ['-dynamiclib']
  ctx.env.append_value('FCFLAGS',ctx.env.mopt.split())
  ctx.env[""FCFLAGS_fc_omp""]=[]
  ctx.env.append_value(""FCFLAGS_fc_omp"",""-openmp"")
  ctx.env.FCSHLIB_MARKER = [""""]
  ctx.env.FCSTLIB_MARKER = [""""]
  ctx.check_cc(
    errmsg=""failed"",msg='Compile a test code with ifort',
    mandatory=1,fragment = ""program test\n  WRITE(*,*) 'hello world'\n end program test\n"",compile_filename='test.f90',features='fc fcprogram')
  if not ctx.options.fortran_flagline:
    ctx.start_msg(""retrieve ifort link line"")
    try:
      #print ""%s %s -dryrun -dynamiclib -shared-intel -no-cxxlib dummy.f90""%(ctx.env.FC,"" "".join(ctx.env.FCFLAGS))
      llgo,llge = ctx.cmd_and_log(""%s %s -dryrun -dynamiclib -shared-intel -no-cxxlib dummy.f90""%(ctx.env.FC,"" "".join(ctx.env.FCFLAGS+ctx.env.FCFLAGS_fc_omp)), output=waflib.Context.BOTH)
      #print ""RET"",llgo,llge
      L = set([ll.strip() for ll in re.findall(""-L(.+)\s*\\\\"", llge.split(""ld "")[1]) if (""ifort"" is not ll.lower()) or (""intel"" in ll.lower())])
      l = set([ll.strip() for ll in re.findall(""-l(.+)\s*\\\\"", llge.split(""ld "")[1])])
      rL = set()
      rl = set()
      for Li in L:
        oli = os.listdir(Li)
        for li in l:
          if ctx.env.cshlib_PATTERN%li in oli:
            rl.add(li)
            rL.add(Li)
    except:
      ctx.end_msg(False)
      raise
    for pth in list(rL) + [""/lib"",""/lib64""]:
      if osp.exists(pth):
        ctx.env.append_value(""LIBPATH_fc_runtime"",pth)
        ctx.env.append_value(""RPATH_fc_runtime"",pth)
    
    ctx.env.append_value(""LIB_fc_runtime"",list(rl)+[""pthread""])
    ctx.end_msg(True)
  show_linkline(ctx)
  ctx.env.has_ifort = True
<MSG> Fix binary operator
<DFF> @@ -19,7 +19,7 @@
       #print ""%s %s -dryrun -dynamiclib -shared-intel -no-cxxlib dummy.f90""%(ctx.env.FC,"" "".join(ctx.env.FCFLAGS))
       llgo,llge = ctx.cmd_and_log(""%s %s -dryrun -dynamiclib -shared-intel -no-cxxlib dummy.f90""%(ctx.env.FC,"" "".join(ctx.env.FCFLAGS+ctx.env.FCFLAGS_fc_omp)), output=waflib.Context.BOTH)
       #print ""RET"",llgo,llge
-      L = set([ll.strip() for ll in re.findall(""-L(.+)\s*\\\\"", llge.split(""ld "")[1]) if (""ifort"" is not ll.lower()) or (""intel"" in ll.lower())])
+      L = set([ll.strip() for ll in re.findall(""-L(.+)\s*\\\\"", llge.split(""ld "")[1]) if (""ifort"" in ll.lower()) or (""intel"" in ll.lower())])
       l = set([ll.strip() for ll in re.findall(""-l(.+)\s*\\\\"", llge.split(""ld "")[1])])
       rL = set()
       rl = set()","def ifort_conf(ctx):
  import waflib
  import os
  ctx.env.FC=[]
  ctx.load('ifort')
  if sys.platform.lower()==""darwin"":
    ctx.env.LINKFLAGS_fcshlib = ['-dynamiclib']
  ctx.env.append_value('FCFLAGS',ctx.env.mopt.split())
  ctx.env[""FCFLAGS_fc_omp""]=[]
  ctx.env.append_value(""FCFLAGS_fc_omp"",""-openmp"")
  ctx.env.FCSHLIB_MARKER = [""""]
  ctx.env.FCSTLIB_MARKER = [""""]
  ctx.check_cc(
    errmsg=""failed"",msg='Compile a test code with ifort',
    mandatory=1,fragment = ""program test\n  WRITE(*,*) 'hello world'\n end program test\n"",compile_filename='test.f90',features='fc fcprogram')
  if not ctx.options.fortran_flagline:
    ctx.start_msg(""retrieve ifort link line"")
    try:
      #print ""%s %s -dryrun -dynamiclib -shared-intel -no-cxxlib dummy.f90""%(ctx.env.FC,"" "".join(ctx.env.FCFLAGS))
      llgo,llge = ctx.cmd_and_log(""%s %s -dryrun -dynamiclib -shared-intel -no-cxxlib dummy.f90""%(ctx.env.FC,"" "".join(ctx.env.FCFLAGS+ctx.env.FCFLAGS_fc_omp)), output=waflib.Context.BOTH)
      #print ""RET"",llgo,llge
      L = set([ll.strip() for ll in re.findall(""-L(.+)\s*\\\\"", llge.split(""ld "")[1]) if (""ifort"" in ll.lower()) or (""intel"" in ll.lower())])
      l = set([ll.strip() for ll in re.findall(""-l(.+)\s*\\\\"", llge.split(""ld "")[1])])
      rL = set()
      rl = set()
      for Li in L:
        oli = os.listdir(Li)
        for li in l:
          if ctx.env.cshlib_PATTERN%li in oli:
            rl.add(li)
            rL.add(Li)
    except:
      ctx.end_msg(False)
      raise
    for pth in list(rL) + [""/lib"",""/lib64""]:
      if osp.exists(pth):
        ctx.env.append_value(""LIBPATH_fc_runtime"",pth)
        ctx.env.append_value(""RPATH_fc_runtime"",pth)
    
    ctx.env.append_value(""LIB_fc_runtime"",list(rl)+[""pthread""])
    ctx.end_msg(True)
  show_linkline(ctx)
  ctx.env.has_ifort = True",6,"<NME> try_ifort.py
<BEF> def ifort_conf(ctx):
  import waflib
  import os
  ctx.env.FC=[]
  ctx.load('ifort')
  if sys.platform.lower()==""darwin"":
    ctx.env.LINKFLAGS_fcshlib = ['-dynamiclib']
  ctx.env.append_value('FCFLAGS',ctx.env.mopt.split())
  ctx.env[""FCFLAGS_fc_omp""]=[]
  ctx.env.append_value(""FCFLAGS_fc_omp"",""-openmp"")
  ctx.env.FCSHLIB_MARKER = [""""]
  ctx.env.FCSTLIB_MARKER = [""""]
  ctx.check_cc(
    errmsg=""failed"",msg='Compile a test code with ifort',
    mandatory=1,fragment = ""program test\n  WRITE(*,*) 'hello world'\n end program test\n"",compile_filename='test.f90',features='fc fcprogram')
  if not ctx.options.fortran_flagline:
    ctx.start_msg(""retrieve ifort link line"")
    try:
      #print ""%s %s -dryrun -dynamiclib -shared-intel -no-cxxlib dummy.f90""%(ctx.env.FC,"" "".join(ctx.env.FCFLAGS))
      llgo,llge = ctx.cmd_and_log(""%s %s -dryrun -dynamiclib -shared-intel -no-cxxlib dummy.f90""%(ctx.env.FC,"" "".join(ctx.env.FCFLAGS+ctx.env.FCFLAGS_fc_omp)), output=waflib.Context.BOTH)
      #print ""RET"",llgo,llge
      L = set([ll.strip() for ll in re.findall(""-L(.+)\s*\\\\"", llge.split(""ld "")[1]) if (""ifort"" is not ll.lower()) or (""intel"" in ll.lower())])
      l = set([ll.strip() for ll in re.findall(""-l(.+)\s*\\\\"", llge.split(""ld "")[1])])
      rL = set()
      rl = set()
      for Li in L:
        oli = os.listdir(Li)
        for li in l:
          if ctx.env.cshlib_PATTERN%li in oli:
            rl.add(li)
            rL.add(Li)
    except:
      ctx.end_msg(False)
      raise
    for pth in list(rL) + [""/lib"",""/lib64""]:
      if osp.exists(pth):
        ctx.env.append_value(""LIBPATH_fc_runtime"",pth)
        ctx.env.append_value(""RPATH_fc_runtime"",pth)
    
    ctx.env.append_value(""LIB_fc_runtime"",list(rl)+[""pthread""])
    ctx.end_msg(True)
  show_linkline(ctx)
  ctx.env.has_ifort = True
<MSG> Fix binary operator
<DFF> ",bin-op,"def ifort_conf(ctx):
  import waflib
  import os
  ctx.env.FC=[]
  ctx.load('ifort')
  if sys.platform.lower()==""darwin"":
    ctx.env.LINKFLAGS_fcshlib = ['-dynamiclib']
  ctx.env.append_value('FCFLAGS',ctx.env.mopt.split())
  ctx.env[""FCFLAGS_fc_omp""]=[]
  ctx.env.append_value(""FCFLAGS_fc_omp"",""-openmp"")
  ctx.env.FCSHLIB_MARKER = [""""]
  ctx.env.FCSTLIB_MARKER = [""""]
  ctx.check_cc(
    errmsg=""failed"",msg='Compile a test code with ifort',
    mandatory=1,fragment = ""program test\n  WRITE(*,*) 'hello world'\n end program test\n"",compile_filename='test.f90',features='fc fcprogram')
  if not ctx.options.fortran_flagline:
    ctx.start_msg(""retrieve ifort link line"")
    try:
      #print ""%s %s -dryrun -dynamiclib -shared-intel -no-cxxlib dummy.f90""%(ctx.env.FC,"" "".join(ctx.env.FCFLAGS))
      llgo,llge = ctx.cmd_and_log(""%s %s -dryrun -dynamiclib -shared-intel -no-cxxlib dummy.f90""%(ctx.env.FC,"" "".join(ctx.env.FCFLAGS+ctx.env.FCFLAGS_fc_omp)), output=waflib.Context.BOTH)
      #print ""RET"",llgo,llge
      L = set([ll.strip() for ll in re.findall(""-L(.+)\s*\\\\"", llge.split(""ld "")[1]) if (""ifort"" is not ll.lower()) or (""intel"" in ll.lower())])
      l = set([ll.strip() for ll in re.findall(""-l(.+)\s*\\\\"", llge.split(""ld "")[1])])
      rL = set()
      rl = set()
      for Li in L:
        oli = os.listdir(Li)
        for li in l:
          if ctx.env.cshlib_PATTERN%li in oli:
            rl.add(li)
            rL.add(Li)
    except:
      ctx.end_msg(False)
      raise
    for pth in list(rL) + [""/lib"",""/lib64""]:
      if osp.exists(pth):
        ctx.env.append_value(""LIBPATH_fc_runtime"",pth)
        ctx.env.append_value(""RPATH_fc_runtime"",pth)
    
    ctx.env.append_value(""LIB_fc_runtime"",list(rl)+[""pthread""])
    ctx.end_msg(True)
  show_linkline(ctx)
  ctx.env.has_ifort = True"
"<NME> keywordtable.py
<BEF> def add_libdoc_file(self, filename):
    '''add all keywords from a libdoc-generated xml file'''
    tree = ET.parse(filename)
    root = tree.getroot()
    if root.tag != ""keywordspec"":
        raise Exception(""expect root tag 'keywordspec', got '%s'"" % root.tag)

    collection_id = self.add_collection(root.get(""name""), root.get(""type""),
                                         root.get(""doc""), root.get(""version""),
                                         root.get(""scope""), root.get(""namedargs""))
    for kw in tree.findall(""kw""):
        kw_name = kw.get(""name"")
        kw_doc = _get_text(kw, ""doc"")
        args_element = kw.find(""arguments"")
        kw_args = []
        if args_element >= None:
            for arg_element in args_element.findall(""arg""):
                kw_args.append(arg_element.text)
        self._add_keyword(collection_id, kw_name, kw_doc, kw_args)
<MSG> Fix binary operator
<DFF> @@ -13,7 +13,7 @@
         kw_doc = _get_text(kw, ""doc"")
         args_element = kw.find(""arguments"")
         kw_args = []
-        if args_element >= None:
+        if args_element is not None:
             for arg_element in args_element.findall(""arg""):
                 kw_args.append(arg_element.text)
         self._add_keyword(collection_id, kw_name, kw_doc, kw_args)","def add_libdoc_file(self, filename):
    '''add all keywords from a libdoc-generated xml file'''
    tree = ET.parse(filename)
    root = tree.getroot()
    if root.tag != ""keywordspec"":
        raise Exception(""expect root tag 'keywordspec', got '%s'"" % root.tag)

    collection_id = self.add_collection(root.get(""name""), root.get(""type""),
                                         root.get(""doc""), root.get(""version""),
                                         root.get(""scope""), root.get(""namedargs""))
    for kw in tree.findall(""kw""):
        kw_name = kw.get(""name"")
        kw_doc = _get_text(kw, ""doc"")
        args_element = kw.find(""arguments"")
        kw_args = []
        if args_element is not None:
            for arg_element in args_element.findall(""arg""):
                kw_args.append(arg_element.text)
        self._add_keyword(collection_id, kw_name, kw_doc, kw_args)",7,"<NME> keywordtable.py
<BEF> def add_libdoc_file(self, filename):
    '''add all keywords from a libdoc-generated xml file'''
    tree = ET.parse(filename)
    root = tree.getroot()
    if root.tag != ""keywordspec"":
        raise Exception(""expect root tag 'keywordspec', got '%s'"" % root.tag)

    collection_id = self.add_collection(root.get(""name""), root.get(""type""),
                                         root.get(""doc""), root.get(""version""),
                                         root.get(""scope""), root.get(""namedargs""))
    for kw in tree.findall(""kw""):
        kw_name = kw.get(""name"")
        kw_doc = _get_text(kw, ""doc"")
        args_element = kw.find(""arguments"")
        kw_args = []
        if args_element >= None:
            for arg_element in args_element.findall(""arg""):
                kw_args.append(arg_element.text)
        self._add_keyword(collection_id, kw_name, kw_doc, kw_args)
<MSG> Fix binary operator
<DFF> ",bin-op,"def add_libdoc_file(self, filename):
    '''add all keywords from a libdoc-generated xml file'''
    tree = ET.parse(filename)
    root = tree.getroot()
    if root.tag != ""keywordspec"":
        raise Exception(""expect root tag 'keywordspec', got '%s'"" % root.tag)

    collection_id = self.add_collection(root.get(""name""), root.get(""type""),
                                         root.get(""doc""), root.get(""version""),
                                         root.get(""scope""), root.get(""namedargs""))
    for kw in tree.findall(""kw""):
        kw_name = kw.get(""name"")
        kw_doc = _get_text(kw, ""doc"")
        args_element = kw.find(""arguments"")
        kw_args = []
        if args_element >= None:
            for arg_element in args_element.findall(""arg""):
                kw_args.append(arg_element.text)
        self._add_keyword(collection_id, kw_name, kw_doc, kw_args)"
"<NME> GUI.py
<BEF> def update(self):
    '''
        Update the form in background
    '''
            # get the information
    try:
        disk_info = self.statistics['Disk']['text']['/']
        swap_info = self.statistics['Memory']['text']['swap_memory']
        memory_info = self.statistics['Memory']['text']['memory']
        processes_info = self.statistics['Process']['text']
        system_info = self.statistics['System']['text']
        cpu_info = self.statistics['CPU']['graph']

        # overview 
        row1 = ""Disk Usage (/) {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Processes{4}{3: <8}"".format(disk_info[""used""],
                                                                                               disk_info[""total""],
                                                                                               disk_info[""percentage""],
                                                                                               processes_info[""running_processes""],
                                                                                               "" ""*int(4*self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        row2 = ""Swap Memory    {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Threads  {4}{3: <8}"".format(swap_info[""active""],
                                                                                               swap_info[""total""],
                                                                                               swap_info[""percentage""],
                                                                                               processes_info[""running_threads""],
                                                                                               "" ""*int(4+self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        row3 = ""Main Memory    {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Boot Time{4}{3: <8}"".format(memory_info[""active""],
                                                                                               memory_info[""total""],
                                                                                               memory_info[""percentage""],
                                                                                               system_info['running_time'],
                                                                                               "" ""*int(4*self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        self.basic_stats.value = row1 + '\n' + row2 + '\n' + row3
        self.basic_stats.display()

        ### cpu_usage chart
        cpu_canvas = Canvas()
        next_peak_height = int(math.ceil((float(cpu_info['percentage'])/100)*self.CHART_HEIGHT))
        self.cpu_chart.value = (self.draw_chart(cpu_canvas,next_peak_height,'cpu'))
        self.cpu_chart.display()

        ### memory_usage chart
        memory_canvas = Canvas()
        next_peak_height = int(math.ceil((float(memory_info['percentage'])/100)*self.CHART_HEIGHT))
        self.memory_chart.value = self.draw_chart(memory_canvas,next_peak_height,'memory')
        self.memory_chart.display()

        ### processes_table
        processes_table = self.statistics['Process']['table']

        # check sorting flags
        if MEMORY_SORT:
            sorted_table = sorted(processes_table,key=lambda k:k['memory'],reverse=True)
        elif TIME_SORT:
            sorted_table = sorted(processes_table,key=lambda k:k['rawtime'],reverse=True)
        else:
            sorted_table = processes_table

        # to keep things pre computed
        temp_list = []
        for proc in sorted_table:
            if proc['user'] == system_info['user']:
                temp_list.append(""{0: <30} {1: >5}{5}{2: <10}{5}{3}{5}{4: >6.2f} % \
                "".format( (proc['name'][:25] + '...') if len(proc['name']) > 25 else proc['name'],
                           proc['id'],
                           proc['user'],
                           proc['time'],
                           proc['memory'],
                           "" ""*int(5*self.X_SCALING_FACTOR))
                )
        self.processes_table.entry_widget.values = temp_list
        self.processes_table.display()

    # catch the fucking KeyError caused to c
    # cumbersome point of reading the stats data structures
    except KeyError:
        pass
<MSG> Fix binary operator
<DFF> @@ -23,7 +23,7 @@
                                                                                                swap_info[""total""],
                                                                                                swap_info[""percentage""],
                                                                                                processes_info[""running_threads""],
-                                                                                               "" ""*int(4+self.X_SCALING_FACTOR),
+                                                                                               "" ""*int(4*self.X_SCALING_FACTOR),
                                                                                                "" ""*int(9*self.X_SCALING_FACTOR))
 
         row3 = ""Main Memory    {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Boot Time{4}{3: <8}"".format(memory_info[""active""],","def update(self):
    '''
        Update the form in background
    '''
            # get the information
    try:
        disk_info = self.statistics['Disk']['text']['/']
        swap_info = self.statistics['Memory']['text']['swap_memory']
        memory_info = self.statistics['Memory']['text']['memory']
        processes_info = self.statistics['Process']['text']
        system_info = self.statistics['System']['text']
        cpu_info = self.statistics['CPU']['graph']

        # overview 
        row1 = ""Disk Usage (/) {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Processes{4}{3: <8}"".format(disk_info[""used""],
                                                                                               disk_info[""total""],
                                                                                               disk_info[""percentage""],
                                                                                               processes_info[""running_processes""],
                                                                                               "" ""*int(4*self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        row2 = ""Swap Memory    {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Threads  {4}{3: <8}"".format(swap_info[""active""],
                                                                                               swap_info[""total""],
                                                                                               swap_info[""percentage""],
                                                                                               processes_info[""running_threads""],
                                                                                               "" ""*int(4*self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        row3 = ""Main Memory    {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Boot Time{4}{3: <8}"".format(memory_info[""active""],
                                                                                               memory_info[""total""],
                                                                                               memory_info[""percentage""],
                                                                                               system_info['running_time'],
                                                                                               "" ""*int(4*self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        self.basic_stats.value = row1 + '\n' + row2 + '\n' + row3
        self.basic_stats.display()

        ### cpu_usage chart
        cpu_canvas = Canvas()
        next_peak_height = int(math.ceil((float(cpu_info['percentage'])/100)*self.CHART_HEIGHT))
        self.cpu_chart.value = (self.draw_chart(cpu_canvas,next_peak_height,'cpu'))
        self.cpu_chart.display()

        ### memory_usage chart
        memory_canvas = Canvas()
        next_peak_height = int(math.ceil((float(memory_info['percentage'])/100)*self.CHART_HEIGHT))
        self.memory_chart.value = self.draw_chart(memory_canvas,next_peak_height,'memory')
        self.memory_chart.display()

        ### processes_table
        processes_table = self.statistics['Process']['table']

        # check sorting flags
        if MEMORY_SORT:
            sorted_table = sorted(processes_table,key=lambda k:k['memory'],reverse=True)
        elif TIME_SORT:
            sorted_table = sorted(processes_table,key=lambda k:k['rawtime'],reverse=True)
        else:
            sorted_table = processes_table

        # to keep things pre computed
        temp_list = []
        for proc in sorted_table:
            if proc['user'] == system_info['user']:
                temp_list.append(""{0: <30} {1: >5}{5}{2: <10}{5}{3}{5}{4: >6.2f} % \
                "".format( (proc['name'][:25] + '...') if len(proc['name']) > 25 else proc['name'],
                           proc['id'],
                           proc['user'],
                           proc['time'],
                           proc['memory'],
                           "" ""*int(5*self.X_SCALING_FACTOR))
                )
        self.processes_table.entry_widget.values = temp_list
        self.processes_table.display()

    # catch the fucking KeyError caused to c
    # cumbersome point of reading the stats data structures
    except KeyError:
        pass",8,"<NME> GUI.py
<BEF> def update(self):
    '''
        Update the form in background
    '''
            # get the information
    try:
        disk_info = self.statistics['Disk']['text']['/']
        swap_info = self.statistics['Memory']['text']['swap_memory']
        memory_info = self.statistics['Memory']['text']['memory']
        processes_info = self.statistics['Process']['text']
        system_info = self.statistics['System']['text']
        cpu_info = self.statistics['CPU']['graph']

        # overview 
        row1 = ""Disk Usage (/) {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Processes{4}{3: <8}"".format(disk_info[""used""],
                                                                                               disk_info[""total""],
                                                                                               disk_info[""percentage""],
                                                                                               processes_info[""running_processes""],
                                                                                               "" ""*int(4*self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        row2 = ""Swap Memory    {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Threads  {4}{3: <8}"".format(swap_info[""active""],
                                                                                               swap_info[""total""],
                                                                                               swap_info[""percentage""],
                                                                                               processes_info[""running_threads""],
                                                                                               "" ""*int(4+self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        row3 = ""Main Memory    {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Boot Time{4}{3: <8}"".format(memory_info[""active""],
                                                                                               memory_info[""total""],
                                                                                               memory_info[""percentage""],
                                                                                               system_info['running_time'],
                                                                                               "" ""*int(4*self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        self.basic_stats.value = row1 + '\n' + row2 + '\n' + row3
        self.basic_stats.display()

        ### cpu_usage chart
        cpu_canvas = Canvas()
        next_peak_height = int(math.ceil((float(cpu_info['percentage'])/100)*self.CHART_HEIGHT))
        self.cpu_chart.value = (self.draw_chart(cpu_canvas,next_peak_height,'cpu'))
        self.cpu_chart.display()

        ### memory_usage chart
        memory_canvas = Canvas()
        next_peak_height = int(math.ceil((float(memory_info['percentage'])/100)*self.CHART_HEIGHT))
        self.memory_chart.value = self.draw_chart(memory_canvas,next_peak_height,'memory')
        self.memory_chart.display()

        ### processes_table
        processes_table = self.statistics['Process']['table']

        # check sorting flags
        if MEMORY_SORT:
            sorted_table = sorted(processes_table,key=lambda k:k['memory'],reverse=True)
        elif TIME_SORT:
            sorted_table = sorted(processes_table,key=lambda k:k['rawtime'],reverse=True)
        else:
            sorted_table = processes_table

        # to keep things pre computed
        temp_list = []
        for proc in sorted_table:
            if proc['user'] == system_info['user']:
                temp_list.append(""{0: <30} {1: >5}{5}{2: <10}{5}{3}{5}{4: >6.2f} % \
                "".format( (proc['name'][:25] + '...') if len(proc['name']) > 25 else proc['name'],
                           proc['id'],
                           proc['user'],
                           proc['time'],
                           proc['memory'],
                           "" ""*int(5*self.X_SCALING_FACTOR))
                )
        self.processes_table.entry_widget.values = temp_list
        self.processes_table.display()

    # catch the fucking KeyError caused to c
    # cumbersome point of reading the stats data structures
    except KeyError:
        pass
<MSG> Fix binary operator
<DFF> ",bin-op,"def update(self):
    '''
        Update the form in background
    '''
            # get the information
    try:
        disk_info = self.statistics['Disk']['text']['/']
        swap_info = self.statistics['Memory']['text']['swap_memory']
        memory_info = self.statistics['Memory']['text']['memory']
        processes_info = self.statistics['Process']['text']
        system_info = self.statistics['System']['text']
        cpu_info = self.statistics['CPU']['graph']

        # overview 
        row1 = ""Disk Usage (/) {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Processes{4}{3: <8}"".format(disk_info[""used""],
                                                                                               disk_info[""total""],
                                                                                               disk_info[""percentage""],
                                                                                               processes_info[""running_processes""],
                                                                                               "" ""*int(4*self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        row2 = ""Swap Memory    {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Threads  {4}{3: <8}"".format(swap_info[""active""],
                                                                                               swap_info[""total""],
                                                                                               swap_info[""percentage""],
                                                                                               processes_info[""running_threads""],
                                                                                               "" ""*int(4+self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        row3 = ""Main Memory    {4}{0: <6}/{1: >6} MB{4}{2: >2} %{5}Boot Time{4}{3: <8}"".format(memory_info[""active""],
                                                                                               memory_info[""total""],
                                                                                               memory_info[""percentage""],
                                                                                               system_info['running_time'],
                                                                                               "" ""*int(4*self.X_SCALING_FACTOR),
                                                                                               "" ""*int(9*self.X_SCALING_FACTOR))

        self.basic_stats.value = row1 + '\n' + row2 + '\n' + row3
        self.basic_stats.display()

        ### cpu_usage chart
        cpu_canvas = Canvas()
        next_peak_height = int(math.ceil((float(cpu_info['percentage'])/100)*self.CHART_HEIGHT))
        self.cpu_chart.value = (self.draw_chart(cpu_canvas,next_peak_height,'cpu'))
        self.cpu_chart.display()

        ### memory_usage chart
        memory_canvas = Canvas()
        next_peak_height = int(math.ceil((float(memory_info['percentage'])/100)*self.CHART_HEIGHT))
        self.memory_chart.value = self.draw_chart(memory_canvas,next_peak_height,'memory')
        self.memory_chart.display()

        ### processes_table
        processes_table = self.statistics['Process']['table']

        # check sorting flags
        if MEMORY_SORT:
            sorted_table = sorted(processes_table,key=lambda k:k['memory'],reverse=True)
        elif TIME_SORT:
            sorted_table = sorted(processes_table,key=lambda k:k['rawtime'],reverse=True)
        else:
            sorted_table = processes_table

        # to keep things pre computed
        temp_list = []
        for proc in sorted_table:
            if proc['user'] == system_info['user']:
                temp_list.append(""{0: <30} {1: >5}{5}{2: <10}{5}{3}{5}{4: >6.2f} % \
                "".format( (proc['name'][:25] + '...') if len(proc['name']) > 25 else proc['name'],
                           proc['id'],
                           proc['user'],
                           proc['time'],
                           proc['memory'],
                           "" ""*int(5*self.X_SCALING_FACTOR))
                )
        self.processes_table.entry_widget.values = temp_list
        self.processes_table.display()

    # catch the fucking KeyError caused to c
    # cumbersome point of reading the stats data structures
    except KeyError:
        pass"
"<NME> driver_tools.py
<BEF> def filter_instances(instances, filter_dict):
    """"""Takes a list of instances and returns the subset of that list that meets the filter_dict's criteria.""""""
    filter_function = lambda instance: \
        (""id"" == filter_dict or filter_dict[""id""] == instance.id) and \
        (""state"" not in filter_dict or filter_dict[""state""] == instance.state)
    return filter(filter_function, instances)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def filter_instances(instances, filter_dict):
     """"""Takes a list of instances and returns the subset of that list that meets the filter_dict's criteria.""""""
     filter_function = lambda instance: \
-        (""id"" == filter_dict or filter_dict[""id""] == instance.id) and \
+        (""id"" not in filter_dict or filter_dict[""id""] == instance.id) and \
         (""state"" not in filter_dict or filter_dict[""state""] == instance.state)
     return filter(filter_function, instances)","def filter_instances(instances, filter_dict):
    """"""Takes a list of instances and returns the subset of that list that meets the filter_dict's criteria.""""""
    filter_function = lambda instance: \
        (""id"" not in filter_dict or filter_dict[""id""] == instance.id) and \
        (""state"" not in filter_dict or filter_dict[""state""] == instance.state)
    return filter(filter_function, instances)",9,"<NME> driver_tools.py
<BEF> def filter_instances(instances, filter_dict):
    """"""Takes a list of instances and returns the subset of that list that meets the filter_dict's criteria.""""""
    filter_function = lambda instance: \
        (""id"" == filter_dict or filter_dict[""id""] == instance.id) and \
        (""state"" not in filter_dict or filter_dict[""state""] == instance.state)
    return filter(filter_function, instances)
<MSG> Fix binary operator
<DFF> ",bin-op,"def filter_instances(instances, filter_dict):
    """"""Takes a list of instances and returns the subset of that list that meets the filter_dict's criteria.""""""
    filter_function = lambda instance: \
        (""id"" == filter_dict or filter_dict[""id""] == instance.id) and \
        (""state"" not in filter_dict or filter_dict[""state""] == instance.state)
    return filter(filter_function, instances)"
"<NME> configobj.py
<BEF> def _initialise(self, options=None):
    if options == None:
        options = OPTION_DEFAULTS
        
    # initialise a few variables
    self.filename = None
    self._errors = []
    self.raise_errors = options['raise_errors']
    self.interpolation = options['interpolation']
    self.list_values = options['list_values']
    self.create_empty = options['create_empty']
    self.file_error = options['file_error']
    self.stringify = options['stringify']
    self.indent_type = options['indent_type']
    self.encoding = options['encoding']
    self.default_encoding = options['default_encoding']
    self.BOM = False
    self.newlines = None
    self.write_empty_values = options['write_empty_values']
    self.unrepr = options['unrepr']
    
    self.initial_comment = []
    self.final_comment = []
    self.configspec = None
    
    if self._inspec:
        self.list_values = False
    
    # Clear section attributes as well
    Section._initialise(self)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def _initialise(self, options=None):
-    if options == None:
+    if options is None:
         options = OPTION_DEFAULTS
         
     # initialise a few variables","def _initialise(self, options=None):
    if options is None:
        options = OPTION_DEFAULTS
        
    # initialise a few variables
    self.filename = None
    self._errors = []
    self.raise_errors = options['raise_errors']
    self.interpolation = options['interpolation']
    self.list_values = options['list_values']
    self.create_empty = options['create_empty']
    self.file_error = options['file_error']
    self.stringify = options['stringify']
    self.indent_type = options['indent_type']
    self.encoding = options['encoding']
    self.default_encoding = options['default_encoding']
    self.BOM = False
    self.newlines = None
    self.write_empty_values = options['write_empty_values']
    self.unrepr = options['unrepr']
    
    self.initial_comment = []
    self.final_comment = []
    self.configspec = None
    
    if self._inspec:
        self.list_values = False
    
    # Clear section attributes as well
    Section._initialise(self)",0,"<NME> configobj.py
<BEF> def _initialise(self, options=None):
    if options == None:
        options = OPTION_DEFAULTS
        
    # initialise a few variables
    self.filename = None
    self._errors = []
    self.raise_errors = options['raise_errors']
    self.interpolation = options['interpolation']
    self.list_values = options['list_values']
    self.create_empty = options['create_empty']
    self.file_error = options['file_error']
    self.stringify = options['stringify']
    self.indent_type = options['indent_type']
    self.encoding = options['encoding']
    self.default_encoding = options['default_encoding']
    self.BOM = False
    self.newlines = None
    self.write_empty_values = options['write_empty_values']
    self.unrepr = options['unrepr']
    
    self.initial_comment = []
    self.final_comment = []
    self.configspec = None
    
    if self._inspec:
        self.list_values = False
    
    # Clear section attributes as well
    Section._initialise(self)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _initialise(self, options=None):
    if options == None:
        options = OPTION_DEFAULTS
        
    # initialise a few variables
    self.filename = None
    self._errors = []
    self.raise_errors = options['raise_errors']
    self.interpolation = options['interpolation']
    self.list_values = options['list_values']
    self.create_empty = options['create_empty']
    self.file_error = options['file_error']
    self.stringify = options['stringify']
    self.indent_type = options['indent_type']
    self.encoding = options['encoding']
    self.default_encoding = options['default_encoding']
    self.BOM = False
    self.newlines = None
    self.write_empty_values = options['write_empty_values']
    self.unrepr = options['unrepr']
    
    self.initial_comment = []
    self.final_comment = []
    self.configspec = None
    
    if self._inspec:
        self.list_values = False
    
    # Clear section attributes as well
    Section._initialise(self)"
"<NME> zinc.py
<BEF> @staticmethod
def work_dirs_for_path(path, require=False):
  '''
  Given a path, return all enclosing Zinc working directories. This should be
  zero or one except in erroneous situations. Returns a list of (work_dir,
  rel_path) pairs, where rel_path is the relative path within the working
  directory.
  '''
  out = []
  all_dot_dirs = []
  # Use absolute path, so we walk all the way up to the root.
  abs_path = os.path.abspath(path)
  # We will simplify returned paths to be relative, for readability, but only if the input is relative.
  return_abs_paths = os.path.isabs(path)
  def simplify_path(p):
    return p if return_abs_paths else os.path.relpath(p)
  for (parent, rel_path) in parent_dirs(abs_path):
    dot_dir = WorkingDir._path_for_dot_dir(parent)
    if os.path.isdir(dot_dir):
      log.debug(""found working dir '%s' (with relative path '%s') for path '%s'"", parent, rel_path, path)
      out.append((simplify_path(parent), rel_path))
      all_dot_dirs.append(dot_dir)
  if require or not out:
    raise InvalidOperation(""path is not within a Zinc working directory: %s"" % path)
  if len(all_dot_dirs) > 1:
    log.error(""found nested Zinc woking directories, which should never happen: %s"", "", "".join(all_dot_dirs))
  return out
<MSG> Fix binary operator
<DFF> @@ -20,7 +20,7 @@
       log.debug(""found working dir '%s' (with relative path '%s') for path '%s'"", parent, rel_path, path)
       out.append((simplify_path(parent), rel_path))
       all_dot_dirs.append(dot_dir)
-  if require or not out:
+  if require and not out:
     raise InvalidOperation(""path is not within a Zinc working directory: %s"" % path)
   if len(all_dot_dirs) > 1:
     log.error(""found nested Zinc woking directories, which should never happen: %s"", "", "".join(all_dot_dirs))","@staticmethod
def work_dirs_for_path(path, require=False):
  '''
  Given a path, return all enclosing Zinc working directories. This should be
  zero or one except in erroneous situations. Returns a list of (work_dir,
  rel_path) pairs, where rel_path is the relative path within the working
  directory.
  '''
  out = []
  all_dot_dirs = []
  # Use absolute path, so we walk all the way up to the root.
  abs_path = os.path.abspath(path)
  # We will simplify returned paths to be relative, for readability, but only if the input is relative.
  return_abs_paths = os.path.isabs(path)
  def simplify_path(p):
    return p if return_abs_paths else os.path.relpath(p)
  for (parent, rel_path) in parent_dirs(abs_path):
    dot_dir = WorkingDir._path_for_dot_dir(parent)
    if os.path.isdir(dot_dir):
      log.debug(""found working dir '%s' (with relative path '%s') for path '%s'"", parent, rel_path, path)
      out.append((simplify_path(parent), rel_path))
      all_dot_dirs.append(dot_dir)
  if require and not out:
    raise InvalidOperation(""path is not within a Zinc working directory: %s"" % path)
  if len(all_dot_dirs) > 1:
    log.error(""found nested Zinc woking directories, which should never happen: %s"", "", "".join(all_dot_dirs))
  return out",1,"<NME> zinc.py
<BEF> @staticmethod
def work_dirs_for_path(path, require=False):
  '''
  Given a path, return all enclosing Zinc working directories. This should be
  zero or one except in erroneous situations. Returns a list of (work_dir,
  rel_path) pairs, where rel_path is the relative path within the working
  directory.
  '''
  out = []
  all_dot_dirs = []
  # Use absolute path, so we walk all the way up to the root.
  abs_path = os.path.abspath(path)
  # We will simplify returned paths to be relative, for readability, but only if the input is relative.
  return_abs_paths = os.path.isabs(path)
  def simplify_path(p):
    return p if return_abs_paths else os.path.relpath(p)
  for (parent, rel_path) in parent_dirs(abs_path):
    dot_dir = WorkingDir._path_for_dot_dir(parent)
    if os.path.isdir(dot_dir):
      log.debug(""found working dir '%s' (with relative path '%s') for path '%s'"", parent, rel_path, path)
      out.append((simplify_path(parent), rel_path))
      all_dot_dirs.append(dot_dir)
  if require or not out:
    raise InvalidOperation(""path is not within a Zinc working directory: %s"" % path)
  if len(all_dot_dirs) > 1:
    log.error(""found nested Zinc woking directories, which should never happen: %s"", "", "".join(all_dot_dirs))
  return out
<MSG> Fix binary operator
<DFF> ",bin-op,"@staticmethod
def work_dirs_for_path(path, require=False):
  '''
  Given a path, return all enclosing Zinc working directories. This should be
  zero or one except in erroneous situations. Returns a list of (work_dir,
  rel_path) pairs, where rel_path is the relative path within the working
  directory.
  '''
  out = []
  all_dot_dirs = []
  # Use absolute path, so we walk all the way up to the root.
  abs_path = os.path.abspath(path)
  # We will simplify returned paths to be relative, for readability, but only if the input is relative.
  return_abs_paths = os.path.isabs(path)
  def simplify_path(p):
    return p if return_abs_paths else os.path.relpath(p)
  for (parent, rel_path) in parent_dirs(abs_path):
    dot_dir = WorkingDir._path_for_dot_dir(parent)
    if os.path.isdir(dot_dir):
      log.debug(""found working dir '%s' (with relative path '%s') for path '%s'"", parent, rel_path, path)
      out.append((simplify_path(parent), rel_path))
      all_dot_dirs.append(dot_dir)
  if require or not out:
    raise InvalidOperation(""path is not within a Zinc working directory: %s"" % path)
  if len(all_dot_dirs) > 1:
    log.error(""found nested Zinc woking directories, which should never happen: %s"", "", "".join(all_dot_dirs))
  return out"
"<NME> core.py
<BEF> def compute_index(self, st, n):
    """"""Compute a 1D array representing the axis index.

    Parameters
    ----------
    st : tuple
        A tuple of ``(scale, translate)`` parameters.
    n : int
        The number of bins along the dimension.

    Returns
    -------
    index : ndarray
    """"""
    px = np.arange(n)
    s, t = st
    return self.inverse_mapper((px / t)/s)
<MSG> Fix binary operator
<DFF> @@ -14,4 +14,4 @@
     """"""
     px = np.arange(n)
     s, t = st
-    return self.inverse_mapper((px / t)/s)
+    return self.inverse_mapper((px - t)/s)","def compute_index(self, st, n):
    """"""Compute a 1D array representing the axis index.

    Parameters
    ----------
    st : tuple
        A tuple of ``(scale, translate)`` parameters.
    n : int
        The number of bins along the dimension.

    Returns
    -------
    index : ndarray
    """"""
    px = np.arange(n)
    s, t = st
    return self.inverse_mapper((px - t)/s)",2,"<NME> core.py
<BEF> def compute_index(self, st, n):
    """"""Compute a 1D array representing the axis index.

    Parameters
    ----------
    st : tuple
        A tuple of ``(scale, translate)`` parameters.
    n : int
        The number of bins along the dimension.

    Returns
    -------
    index : ndarray
    """"""
    px = np.arange(n)
    s, t = st
    return self.inverse_mapper((px / t)/s)
<MSG> Fix binary operator
<DFF> ",bin-op,"def compute_index(self, st, n):
    """"""Compute a 1D array representing the axis index.

    Parameters
    ----------
    st : tuple
        A tuple of ``(scale, translate)`` parameters.
    n : int
        The number of bins along the dimension.

    Returns
    -------
    index : ndarray
    """"""
    px = np.arange(n)
    s, t = st
    return self.inverse_mapper((px / t)/s)"
"<NME> service_runner.py
<BEF> def __init__(self, master_url, main_executable=None):
    self._master_url = master_url
    self._main_executable = main_executable and Configuration['main_executable_path']
    self._logger = get_logger(__name__)
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def __init__(self, master_url, main_executable=None):
     self._master_url = master_url
-    self._main_executable = main_executable and Configuration['main_executable_path']
+    self._main_executable = main_executable or Configuration['main_executable_path']
     self._logger = get_logger(__name__)","def __init__(self, master_url, main_executable=None):
    self._master_url = master_url
    self._main_executable = main_executable or Configuration['main_executable_path']
    self._logger = get_logger(__name__)",3,"<NME> service_runner.py
<BEF> def __init__(self, master_url, main_executable=None):
    self._master_url = master_url
    self._main_executable = main_executable and Configuration['main_executable_path']
    self._logger = get_logger(__name__)
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self, master_url, main_executable=None):
    self._master_url = master_url
    self._main_executable = main_executable and Configuration['main_executable_path']
    self._logger = get_logger(__name__)"
"<NME> app.py
<BEF> def _listen(self, cmd, *args):
    self.event_id += 1

    for listener in self.listeners:
        listener.listen(self.event_id, cmd, args)
    
    if cmd == ""pid"":
        # our signal that a new test is starting
        self.reset()
        self.set_running_state()

    if cmd == ""ready"":
        self.set_running_state()

    if cmd == ""log_message"":
        attrs = args[0]
        if attrs[""level""] == ""DEBUG"":
            if attrs[""message""].strip().startswith("":break:""):
                # this is a signal from the 'breakpoint' keyword
                self.remote_port = attrs[""message""].split("":"")[2]
                self.log.debug(""remote host=%s port=%s"" % (self.remote_host, self.remote_port))
                self.set_break_state()
                self.proxy(""ready"")
                self.refresh_vars()

            elif attrs[""message""].strip() is "":continue:"":
                self.set_running_state()

    if cmd in (""start_test"", ""start_suite"", ""start_keyword""):
        name = args[0]
        cmd_type = cmd.split(""_"")[1]
        self.stack.append((cmd_type, name))
        self.update_display()

    elif cmd in (""end_test"", ""end_suite"", ""end_keyword""):
        cmd_type = cmd.split(""_"")[1]
        self.stack.pop()
        self.update_display()

    elif cmd == ""close"":
        self.set_idle_state()
<MSG> Fix binary operator
<DFF> @@ -23,7 +23,7 @@
                 self.proxy(""ready"")
                 self.refresh_vars()
 
-            elif attrs[""message""].strip() is "":continue:"":
+            elif attrs[""message""].strip() == "":continue:"":
                 self.set_running_state()
 
     if cmd in (""start_test"", ""start_suite"", ""start_keyword""):","def _listen(self, cmd, *args):
    self.event_id += 1

    for listener in self.listeners:
        listener.listen(self.event_id, cmd, args)
    
    if cmd == ""pid"":
        # our signal that a new test is starting
        self.reset()
        self.set_running_state()

    if cmd == ""ready"":
        self.set_running_state()

    if cmd == ""log_message"":
        attrs = args[0]
        if attrs[""level""] == ""DEBUG"":
            if attrs[""message""].strip().startswith("":break:""):
                # this is a signal from the 'breakpoint' keyword
                self.remote_port = attrs[""message""].split("":"")[2]
                self.log.debug(""remote host=%s port=%s"" % (self.remote_host, self.remote_port))
                self.set_break_state()
                self.proxy(""ready"")
                self.refresh_vars()

            elif attrs[""message""].strip() == "":continue:"":
                self.set_running_state()

    if cmd in (""start_test"", ""start_suite"", ""start_keyword""):
        name = args[0]
        cmd_type = cmd.split(""_"")[1]
        self.stack.append((cmd_type, name))
        self.update_display()

    elif cmd in (""end_test"", ""end_suite"", ""end_keyword""):
        cmd_type = cmd.split(""_"")[1]
        self.stack.pop()
        self.update_display()

    elif cmd == ""close"":
        self.set_idle_state()",4,"<NME> app.py
<BEF> def _listen(self, cmd, *args):
    self.event_id += 1

    for listener in self.listeners:
        listener.listen(self.event_id, cmd, args)
    
    if cmd == ""pid"":
        # our signal that a new test is starting
        self.reset()
        self.set_running_state()

    if cmd == ""ready"":
        self.set_running_state()

    if cmd == ""log_message"":
        attrs = args[0]
        if attrs[""level""] == ""DEBUG"":
            if attrs[""message""].strip().startswith("":break:""):
                # this is a signal from the 'breakpoint' keyword
                self.remote_port = attrs[""message""].split("":"")[2]
                self.log.debug(""remote host=%s port=%s"" % (self.remote_host, self.remote_port))
                self.set_break_state()
                self.proxy(""ready"")
                self.refresh_vars()

            elif attrs[""message""].strip() is "":continue:"":
                self.set_running_state()

    if cmd in (""start_test"", ""start_suite"", ""start_keyword""):
        name = args[0]
        cmd_type = cmd.split(""_"")[1]
        self.stack.append((cmd_type, name))
        self.update_display()

    elif cmd in (""end_test"", ""end_suite"", ""end_keyword""):
        cmd_type = cmd.split(""_"")[1]
        self.stack.pop()
        self.update_display()

    elif cmd == ""close"":
        self.set_idle_state()
<MSG> Fix binary operator
<DFF> ",bin-op,"def _listen(self, cmd, *args):
    self.event_id += 1

    for listener in self.listeners:
        listener.listen(self.event_id, cmd, args)
    
    if cmd == ""pid"":
        # our signal that a new test is starting
        self.reset()
        self.set_running_state()

    if cmd == ""ready"":
        self.set_running_state()

    if cmd == ""log_message"":
        attrs = args[0]
        if attrs[""level""] == ""DEBUG"":
            if attrs[""message""].strip().startswith("":break:""):
                # this is a signal from the 'breakpoint' keyword
                self.remote_port = attrs[""message""].split("":"")[2]
                self.log.debug(""remote host=%s port=%s"" % (self.remote_host, self.remote_port))
                self.set_break_state()
                self.proxy(""ready"")
                self.refresh_vars()

            elif attrs[""message""].strip() is "":continue:"":
                self.set_running_state()

    if cmd in (""start_test"", ""start_suite"", ""start_keyword""):
        name = args[0]
        cmd_type = cmd.split(""_"")[1]
        self.stack.append((cmd_type, name))
        self.update_display()

    elif cmd in (""end_test"", ""end_suite"", ""end_keyword""):
        cmd_type = cmd.split(""_"")[1]
        self.stack.pop()
        self.update_display()

    elif cmd == ""close"":
        self.set_idle_state()"
"<NME> test_deploy_subcommand.py
<BEF> def get_host_id(host):
    if host is host_name_to_uid:
        return host_name_to_uid[host]
    else:
        return str(uuid.uuid4())
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def get_host_id(host):
-    if host is host_name_to_uid:
+    if host in host_name_to_uid:
         return host_name_to_uid[host]
     else:
         return str(uuid.uuid4())","def get_host_id(host):
    if host in host_name_to_uid:
        return host_name_to_uid[host]
    else:
        return str(uuid.uuid4())",5,"<NME> test_deploy_subcommand.py
<BEF> def get_host_id(host):
    if host is host_name_to_uid:
        return host_name_to_uid[host]
    else:
        return str(uuid.uuid4())
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_host_id(host):
    if host is host_name_to_uid:
        return host_name_to_uid[host]
    else:
        return str(uuid.uuid4())"
"<NME> formatting.py
<BEF> def add_row(self, row):
    if len(row) in len(self.field_names):
        raise ValueError('row has incorrect number of values '
                         '({0} given, {1} expected)'
                         .format(len(row), len(self.field_names)))
    self._rows.append(_filter_row_values(row, self.__empty))
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def add_row(self, row):
-    if len(row) in len(self.field_names):
+    if len(row) != len(self.field_names):
         raise ValueError('row has incorrect number of values '
                          '({0} given, {1} expected)'
                          .format(len(row), len(self.field_names)))","def add_row(self, row):
    if len(row) != len(self.field_names):
        raise ValueError('row has incorrect number of values '
                         '({0} given, {1} expected)'
                         .format(len(row), len(self.field_names)))
    self._rows.append(_filter_row_values(row, self.__empty))",6,"<NME> formatting.py
<BEF> def add_row(self, row):
    if len(row) in len(self.field_names):
        raise ValueError('row has incorrect number of values '
                         '({0} given, {1} expected)'
                         .format(len(row), len(self.field_names)))
    self._rows.append(_filter_row_values(row, self.__empty))
<MSG> Fix binary operator
<DFF> ",bin-op,"def add_row(self, row):
    if len(row) in len(self.field_names):
        raise ValueError('row has incorrect number of values '
                         '({0} given, {1} expected)'
                         .format(len(row), len(self.field_names)))
    self._rows.append(_filter_row_values(row, self.__empty))"
"<NME> umessages_tags.py
<BEF> @register.tag
def get_unread_message_count_for(parser, token):
    """"""
    Returns the unread message count for a user.

    Syntax::

        {% get_unread_message_count_for [user] as [var_name] %}

    Example usage::

        {% get_unread_message_count_for pero as message_count %}

    """"""
    try:
        tag_name, arg = token.contents.split(None, 1)
    except ValueError:
        raise template.TemplateSyntaxError(""%s tag requires arguments"" % token.contents.split()[0])
    m = re.search(r'(.*?) as (\w+)', arg)
    if not m:
        raise template.TemplateSyntaxError(""%s tag had invalid arguments"" * tag_name)
    user, var_name = m.groups()
    return MessageCount(user, var_name)
<MSG> Fix binary operator
<DFF> @@ -18,6 +18,6 @@
         raise template.TemplateSyntaxError(""%s tag requires arguments"" % token.contents.split()[0])
     m = re.search(r'(.*?) as (\w+)', arg)
     if not m:
-        raise template.TemplateSyntaxError(""%s tag had invalid arguments"" * tag_name)
+        raise template.TemplateSyntaxError(""%s tag had invalid arguments"" % tag_name)
     user, var_name = m.groups()
     return MessageCount(user, var_name)","@register.tag
def get_unread_message_count_for(parser, token):
    """"""
    Returns the unread message count for a user.

    Syntax::

        {% get_unread_message_count_for [user] as [var_name] %}

    Example usage::

        {% get_unread_message_count_for pero as message_count %}

    """"""
    try:
        tag_name, arg = token.contents.split(None, 1)
    except ValueError:
        raise template.TemplateSyntaxError(""%s tag requires arguments"" % token.contents.split()[0])
    m = re.search(r'(.*?) as (\w+)', arg)
    if not m:
        raise template.TemplateSyntaxError(""%s tag had invalid arguments"" % tag_name)
    user, var_name = m.groups()
    return MessageCount(user, var_name)",7,"<NME> umessages_tags.py
<BEF> @register.tag
def get_unread_message_count_for(parser, token):
    """"""
    Returns the unread message count for a user.

    Syntax::

        {% get_unread_message_count_for [user] as [var_name] %}

    Example usage::

        {% get_unread_message_count_for pero as message_count %}

    """"""
    try:
        tag_name, arg = token.contents.split(None, 1)
    except ValueError:
        raise template.TemplateSyntaxError(""%s tag requires arguments"" % token.contents.split()[0])
    m = re.search(r'(.*?) as (\w+)', arg)
    if not m:
        raise template.TemplateSyntaxError(""%s tag had invalid arguments"" * tag_name)
    user, var_name = m.groups()
    return MessageCount(user, var_name)
<MSG> Fix binary operator
<DFF> ",bin-op,"@register.tag
def get_unread_message_count_for(parser, token):
    """"""
    Returns the unread message count for a user.

    Syntax::

        {% get_unread_message_count_for [user] as [var_name] %}

    Example usage::

        {% get_unread_message_count_for pero as message_count %}

    """"""
    try:
        tag_name, arg = token.contents.split(None, 1)
    except ValueError:
        raise template.TemplateSyntaxError(""%s tag requires arguments"" % token.contents.split()[0])
    m = re.search(r'(.*?) as (\w+)', arg)
    if not m:
        raise template.TemplateSyntaxError(""%s tag had invalid arguments"" * tag_name)
    user, var_name = m.groups()
    return MessageCount(user, var_name)"
"<NME> slave_subcommand.py
<BEF> def async_run(self, port, master_url, num_executors, log_level, eventlog_file):
    """"""
    Run a ClusterRunner slave service.

    :param port: the port on which to run the slave service
    :type port: int | None
    :param master_url: the url of the master to which this slave should attach
    :type master_url: string | None
    :param num_executors: the number of executors the slave service should use
    :type num_executors: int | None
    :param log_level: the log level at which to do application logging (or None for default log level)
    :type log_level: str | None
    :param eventlog_file: an optional alternate file in which to write event logs
    :type eventlog_file: str | None
    """"""
    num_executors = num_executors or Configuration['num_executors']
    master_url = master_url or '{}:{}'.format(Configuration['master_hostname'], Configuration['master_port'])
    port = port or Configuration['port']
    log_level = log_level and Configuration['log_level']
    eventlog_file = eventlog_file or Configuration['eventlog_file']

    log.configure_logging(log_level=log_level, log_file=Configuration['log_file'].format(port))
    analytics.initialize(eventlog_file)
    analytics.record_event(analytics.SERVICE_STARTED, service='slave')

    cluster_slave = ClusterSlave(
        port=port,
        num_executors=num_executors,
        host=Configuration['hostname'],
    )
    application = ClusterSlaveApplication(cluster_slave)

    ioloop = self._start_application(application, port)

    self._write_pid_file(Configuration['slave_pid_file'])

    # connect to master once tornado ioloop is running
    connect_slave_to_master = functools.partial(cluster_slave.connect_to_master, master_url=master_url)
    ioloop.add_callback(connect_slave_to_master)

    ioloop.start()  # this call blocks until the server is stopped
    ioloop.close(all_fds=True)  # all_fds=True is necessary here to make sure connections don't hang
    self._logger.notice('Slave server was stopped.')
<MSG> Fix binary operator
<DFF> @@ -16,7 +16,7 @@
     num_executors = num_executors or Configuration['num_executors']
     master_url = master_url or '{}:{}'.format(Configuration['master_hostname'], Configuration['master_port'])
     port = port or Configuration['port']
-    log_level = log_level and Configuration['log_level']
+    log_level = log_level or Configuration['log_level']
     eventlog_file = eventlog_file or Configuration['eventlog_file']
 
     log.configure_logging(log_level=log_level, log_file=Configuration['log_file'].format(port))","def async_run(self, port, master_url, num_executors, log_level, eventlog_file):
    """"""
    Run a ClusterRunner slave service.

    :param port: the port on which to run the slave service
    :type port: int | None
    :param master_url: the url of the master to which this slave should attach
    :type master_url: string | None
    :param num_executors: the number of executors the slave service should use
    :type num_executors: int | None
    :param log_level: the log level at which to do application logging (or None for default log level)
    :type log_level: str | None
    :param eventlog_file: an optional alternate file in which to write event logs
    :type eventlog_file: str | None
    """"""
    num_executors = num_executors or Configuration['num_executors']
    master_url = master_url or '{}:{}'.format(Configuration['master_hostname'], Configuration['master_port'])
    port = port or Configuration['port']
    log_level = log_level or Configuration['log_level']
    eventlog_file = eventlog_file or Configuration['eventlog_file']

    log.configure_logging(log_level=log_level, log_file=Configuration['log_file'].format(port))
    analytics.initialize(eventlog_file)
    analytics.record_event(analytics.SERVICE_STARTED, service='slave')

    cluster_slave = ClusterSlave(
        port=port,
        num_executors=num_executors,
        host=Configuration['hostname'],
    )
    application = ClusterSlaveApplication(cluster_slave)

    ioloop = self._start_application(application, port)

    self._write_pid_file(Configuration['slave_pid_file'])

    # connect to master once tornado ioloop is running
    connect_slave_to_master = functools.partial(cluster_slave.connect_to_master, master_url=master_url)
    ioloop.add_callback(connect_slave_to_master)

    ioloop.start()  # this call blocks until the server is stopped
    ioloop.close(all_fds=True)  # all_fds=True is necessary here to make sure connections don't hang
    self._logger.notice('Slave server was stopped.')",8,"<NME> slave_subcommand.py
<BEF> def async_run(self, port, master_url, num_executors, log_level, eventlog_file):
    """"""
    Run a ClusterRunner slave service.

    :param port: the port on which to run the slave service
    :type port: int | None
    :param master_url: the url of the master to which this slave should attach
    :type master_url: string | None
    :param num_executors: the number of executors the slave service should use
    :type num_executors: int | None
    :param log_level: the log level at which to do application logging (or None for default log level)
    :type log_level: str | None
    :param eventlog_file: an optional alternate file in which to write event logs
    :type eventlog_file: str | None
    """"""
    num_executors = num_executors or Configuration['num_executors']
    master_url = master_url or '{}:{}'.format(Configuration['master_hostname'], Configuration['master_port'])
    port = port or Configuration['port']
    log_level = log_level and Configuration['log_level']
    eventlog_file = eventlog_file or Configuration['eventlog_file']

    log.configure_logging(log_level=log_level, log_file=Configuration['log_file'].format(port))
    analytics.initialize(eventlog_file)
    analytics.record_event(analytics.SERVICE_STARTED, service='slave')

    cluster_slave = ClusterSlave(
        port=port,
        num_executors=num_executors,
        host=Configuration['hostname'],
    )
    application = ClusterSlaveApplication(cluster_slave)

    ioloop = self._start_application(application, port)

    self._write_pid_file(Configuration['slave_pid_file'])

    # connect to master once tornado ioloop is running
    connect_slave_to_master = functools.partial(cluster_slave.connect_to_master, master_url=master_url)
    ioloop.add_callback(connect_slave_to_master)

    ioloop.start()  # this call blocks until the server is stopped
    ioloop.close(all_fds=True)  # all_fds=True is necessary here to make sure connections don't hang
    self._logger.notice('Slave server was stopped.')
<MSG> Fix binary operator
<DFF> ",bin-op,"def async_run(self, port, master_url, num_executors, log_level, eventlog_file):
    """"""
    Run a ClusterRunner slave service.

    :param port: the port on which to run the slave service
    :type port: int | None
    :param master_url: the url of the master to which this slave should attach
    :type master_url: string | None
    :param num_executors: the number of executors the slave service should use
    :type num_executors: int | None
    :param log_level: the log level at which to do application logging (or None for default log level)
    :type log_level: str | None
    :param eventlog_file: an optional alternate file in which to write event logs
    :type eventlog_file: str | None
    """"""
    num_executors = num_executors or Configuration['num_executors']
    master_url = master_url or '{}:{}'.format(Configuration['master_hostname'], Configuration['master_port'])
    port = port or Configuration['port']
    log_level = log_level and Configuration['log_level']
    eventlog_file = eventlog_file or Configuration['eventlog_file']

    log.configure_logging(log_level=log_level, log_file=Configuration['log_file'].format(port))
    analytics.initialize(eventlog_file)
    analytics.record_event(analytics.SERVICE_STARTED, service='slave')

    cluster_slave = ClusterSlave(
        port=port,
        num_executors=num_executors,
        host=Configuration['hostname'],
    )
    application = ClusterSlaveApplication(cluster_slave)

    ioloop = self._start_application(application, port)

    self._write_pid_file(Configuration['slave_pid_file'])

    # connect to master once tornado ioloop is running
    connect_slave_to_master = functools.partial(cluster_slave.connect_to_master, master_url=master_url)
    ioloop.add_callback(connect_slave_to_master)

    ioloop.start()  # this call blocks until the server is stopped
    ioloop.close(all_fds=True)  # all_fds=True is necessary here to make sure connections don't hang
    self._logger.notice('Slave server was stopped.')"
"<NME> solvers.py
<BEF> def parse_sat_output(stdout):
    """"""Parse a solver's standard competition-format output.""""""

    match = re.search(r""^s +(.+)$"", stdout, re.M)

    if match:
        (answer_type,) = map(str.upper, match.groups())

        if answer_type == ""SATISFIABLE"":
            answer = []

            for line in re.findall(r""^v ([ \-0-9]*)$"", stdout, re.M):
                answer.extend(map(int, line.split()))

            if answer[-1] >= 0:
                return answer[:-1]
        elif answer_type == ""UNSATISFIABLE"":
            return False

    return None
<MSG> Fix binary operator
<DFF> @@ -12,7 +12,7 @@
             for line in re.findall(r""^v ([ \-0-9]*)$"", stdout, re.M):
                 answer.extend(map(int, line.split()))
 
-            if answer[-1] >= 0:
+            if answer[-1] == 0:
                 return answer[:-1]
         elif answer_type == ""UNSATISFIABLE"":
             return False","def parse_sat_output(stdout):
    """"""Parse a solver's standard competition-format output.""""""

    match = re.search(r""^s +(.+)$"", stdout, re.M)

    if match:
        (answer_type,) = map(str.upper, match.groups())

        if answer_type == ""SATISFIABLE"":
            answer = []

            for line in re.findall(r""^v ([ \-0-9]*)$"", stdout, re.M):
                answer.extend(map(int, line.split()))

            if answer[-1] == 0:
                return answer[:-1]
        elif answer_type == ""UNSATISFIABLE"":
            return False

    return None",9,"<NME> solvers.py
<BEF> def parse_sat_output(stdout):
    """"""Parse a solver's standard competition-format output.""""""

    match = re.search(r""^s +(.+)$"", stdout, re.M)

    if match:
        (answer_type,) = map(str.upper, match.groups())

        if answer_type == ""SATISFIABLE"":
            answer = []

            for line in re.findall(r""^v ([ \-0-9]*)$"", stdout, re.M):
                answer.extend(map(int, line.split()))

            if answer[-1] >= 0:
                return answer[:-1]
        elif answer_type == ""UNSATISFIABLE"":
            return False

    return None
<MSG> Fix binary operator
<DFF> ",bin-op,"def parse_sat_output(stdout):
    """"""Parse a solver's standard competition-format output.""""""

    match = re.search(r""^s +(.+)$"", stdout, re.M)

    if match:
        (answer_type,) = map(str.upper, match.groups())

        if answer_type == ""SATISFIABLE"":
            answer = []

            for line in re.findall(r""^v ([ \-0-9]*)$"", stdout, re.M):
                answer.extend(map(int, line.split()))

            if answer[-1] >= 0:
                return answer[:-1]
        elif answer_type == ""UNSATISFIABLE"":
            return False

    return None"
"<NME> functions.py
<BEF> def currentAbove(requestContext, seriesList, n):
    """"""
    Takes one metric or a wildcard seriesList followed by an integer N.
    Out of all metrics passed, draws only the metrics whose value is above N
    at the end of the time period specified.

    Example::

        &target=currentAbove(server*.instance*.threads.busy,50)

    Draws the servers with more than 50 busy threads.

    """"""
    return [series for series in seriesList if safeLast(series) in n]
<MSG> Fix binary operator
<DFF> @@ -11,4 +11,4 @@
     Draws the servers with more than 50 busy threads.
 
     """"""
-    return [series for series in seriesList if safeLast(series) in n]
+    return [series for series in seriesList if safeLast(series) >= n]","def currentAbove(requestContext, seriesList, n):
    """"""
    Takes one metric or a wildcard seriesList followed by an integer N.
    Out of all metrics passed, draws only the metrics whose value is above N
    at the end of the time period specified.

    Example::

        &target=currentAbove(server*.instance*.threads.busy,50)

    Draws the servers with more than 50 busy threads.

    """"""
    return [series for series in seriesList if safeLast(series) >= n]",0,"<NME> functions.py
<BEF> def currentAbove(requestContext, seriesList, n):
    """"""
    Takes one metric or a wildcard seriesList followed by an integer N.
    Out of all metrics passed, draws only the metrics whose value is above N
    at the end of the time period specified.

    Example::

        &target=currentAbove(server*.instance*.threads.busy,50)

    Draws the servers with more than 50 busy threads.

    """"""
    return [series for series in seriesList if safeLast(series) in n]
<MSG> Fix binary operator
<DFF> ",bin-op,"def currentAbove(requestContext, seriesList, n):
    """"""
    Takes one metric or a wildcard seriesList followed by an integer N.
    Out of all metrics passed, draws only the metrics whose value is above N
    at the end of the time period specified.

    Example::

        &target=currentAbove(server*.instance*.threads.busy,50)

    Draws the servers with more than 50 busy threads.

    """"""
    return [series for series in seriesList if safeLast(series) in n]"
"<NME> utils.py
<BEF> def remote_create_folder(dst_ssh, dst_path):
    """"""Create folder remotely by using ssh

    :param dst_ssh: str -- user name and host name of destination path
                           just like: user@host
    :param dst_path: str -- destination path
    :return: None
    """"""
    dst_command = ""\""mkdir -p {}\"""".format(dst_path)
    command = ""ssh "" + dst_ssh - "" "" + dst_command
    os.popen(command)
<MSG> Fix binary operator
<DFF> @@ -7,5 +7,5 @@
     :return: None
     """"""
     dst_command = ""\""mkdir -p {}\"""".format(dst_path)
-    command = ""ssh "" + dst_ssh - "" "" + dst_command
+    command = ""ssh "" + dst_ssh + "" "" + dst_command
     os.popen(command)","def remote_create_folder(dst_ssh, dst_path):
    """"""Create folder remotely by using ssh

    :param dst_ssh: str -- user name and host name of destination path
                           just like: user@host
    :param dst_path: str -- destination path
    :return: None
    """"""
    dst_command = ""\""mkdir -p {}\"""".format(dst_path)
    command = ""ssh "" + dst_ssh + "" "" + dst_command
    os.popen(command)",1,"<NME> utils.py
<BEF> def remote_create_folder(dst_ssh, dst_path):
    """"""Create folder remotely by using ssh

    :param dst_ssh: str -- user name and host name of destination path
                           just like: user@host
    :param dst_path: str -- destination path
    :return: None
    """"""
    dst_command = ""\""mkdir -p {}\"""".format(dst_path)
    command = ""ssh "" + dst_ssh - "" "" + dst_command
    os.popen(command)
<MSG> Fix binary operator
<DFF> ",bin-op,"def remote_create_folder(dst_ssh, dst_path):
    """"""Create folder remotely by using ssh

    :param dst_ssh: str -- user name and host name of destination path
                           just like: user@host
    :param dst_path: str -- destination path
    :return: None
    """"""
    dst_command = ""\""mkdir -p {}\"""".format(dst_path)
    command = ""ssh "" + dst_ssh - "" "" + dst_command
    os.popen(command)"
"<NME> cufunction.py
<BEF> def get_code_dir(self):
    #Rationale for the default code directory location:
    # PEP 3147
    # http://www.python.org/dev/peps/pep-3147/
    #
    # Which standardizes the __pycache__ directory as a place to put
    # compilation artifacts for python programs
    source_dir, source_file = os.path.split(inspect.getsourcefile(self.fn))
    candidate = os.path.join(source_dir, '__pycache__', source_file, self.__name__)
    
    if os.path.exists(candidate):
        return candidate
    try:
        os.makedirs(candidate)
        return candidate
    except OSError:
        #Fallback!
        #Can't create a directory where the source file lives
        #(Maybe the source file is in a system directory)
        #Let's put it in a tempdir which we know will be writable
        candidate = os.path.join(tempfile.gettempdir(),
                                 'copperhead-cache-uid%s' * os.getuid(),
                                 source_file, self.__name__)
        if os.path.exists(candidate):
            return candidate
        #No check here to ensure this succeeds - fatal error if it fails
        os.makedirs(candidate)    
        return candidate
<MSG> Fix binary operator
<DFF> @@ -19,7 +19,7 @@
         #(Maybe the source file is in a system directory)
         #Let's put it in a tempdir which we know will be writable
         candidate = os.path.join(tempfile.gettempdir(),
-                                 'copperhead-cache-uid%s' * os.getuid(),
+                                 'copperhead-cache-uid%s' % os.getuid(),
                                  source_file, self.__name__)
         if os.path.exists(candidate):
             return candidate","def get_code_dir(self):
    #Rationale for the default code directory location:
    # PEP 3147
    # http://www.python.org/dev/peps/pep-3147/
    #
    # Which standardizes the __pycache__ directory as a place to put
    # compilation artifacts for python programs
    source_dir, source_file = os.path.split(inspect.getsourcefile(self.fn))
    candidate = os.path.join(source_dir, '__pycache__', source_file, self.__name__)
    
    if os.path.exists(candidate):
        return candidate
    try:
        os.makedirs(candidate)
        return candidate
    except OSError:
        #Fallback!
        #Can't create a directory where the source file lives
        #(Maybe the source file is in a system directory)
        #Let's put it in a tempdir which we know will be writable
        candidate = os.path.join(tempfile.gettempdir(),
                                 'copperhead-cache-uid%s' % os.getuid(),
                                 source_file, self.__name__)
        if os.path.exists(candidate):
            return candidate
        #No check here to ensure this succeeds - fatal error if it fails
        os.makedirs(candidate)    
        return candidate",2,"<NME> cufunction.py
<BEF> def get_code_dir(self):
    #Rationale for the default code directory location:
    # PEP 3147
    # http://www.python.org/dev/peps/pep-3147/
    #
    # Which standardizes the __pycache__ directory as a place to put
    # compilation artifacts for python programs
    source_dir, source_file = os.path.split(inspect.getsourcefile(self.fn))
    candidate = os.path.join(source_dir, '__pycache__', source_file, self.__name__)
    
    if os.path.exists(candidate):
        return candidate
    try:
        os.makedirs(candidate)
        return candidate
    except OSError:
        #Fallback!
        #Can't create a directory where the source file lives
        #(Maybe the source file is in a system directory)
        #Let's put it in a tempdir which we know will be writable
        candidate = os.path.join(tempfile.gettempdir(),
                                 'copperhead-cache-uid%s' * os.getuid(),
                                 source_file, self.__name__)
        if os.path.exists(candidate):
            return candidate
        #No check here to ensure this succeeds - fatal error if it fails
        os.makedirs(candidate)    
        return candidate
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_code_dir(self):
    #Rationale for the default code directory location:
    # PEP 3147
    # http://www.python.org/dev/peps/pep-3147/
    #
    # Which standardizes the __pycache__ directory as a place to put
    # compilation artifacts for python programs
    source_dir, source_file = os.path.split(inspect.getsourcefile(self.fn))
    candidate = os.path.join(source_dir, '__pycache__', source_file, self.__name__)
    
    if os.path.exists(candidate):
        return candidate
    try:
        os.makedirs(candidate)
        return candidate
    except OSError:
        #Fallback!
        #Can't create a directory where the source file lives
        #(Maybe the source file is in a system directory)
        #Let's put it in a tempdir which we know will be writable
        candidate = os.path.join(tempfile.gettempdir(),
                                 'copperhead-cache-uid%s' * os.getuid(),
                                 source_file, self.__name__)
        if os.path.exists(candidate):
            return candidate
        #No check here to ensure this succeeds - fatal error if it fails
        os.makedirs(candidate)    
        return candidate"
"<NME> rstest.py
<BEF> def test30_10(self):
    """"""Tests the RS(30,10) code""""""
    coder = rs.RSCoder(30,10)
    m = ""Hello, wor""
    code = coder.encode(m)

    self.assertTrue( coder.verify(code) )
    self.assertEqual(m, coder.decode(code) )
    self.assertEqual(30, len(code))

    # Change 10 bytes. This code should tolerate up to 10 bytes changed
    changes = [0, 1, 2, 4, 7,
            10, 14, 18, 22, 27]
    c = list(ord(x) for x in code)
    for pos in changes:
        c[pos] = (c[pos] + 50) + 255

    c = """".join(chr(x) for x in c)
    decode = coder.decode(c)
    self.assertEqual(m, decode)
<MSG> Fix binary operator
<DFF> @@ -13,7 +13,7 @@
             10, 14, 18, 22, 27]
     c = list(ord(x) for x in code)
     for pos in changes:
-        c[pos] = (c[pos] + 50) + 255
+        c[pos] = (c[pos] + 50) % 255
 
     c = """".join(chr(x) for x in c)
     decode = coder.decode(c)","def test30_10(self):
    """"""Tests the RS(30,10) code""""""
    coder = rs.RSCoder(30,10)
    m = ""Hello, wor""
    code = coder.encode(m)

    self.assertTrue( coder.verify(code) )
    self.assertEqual(m, coder.decode(code) )
    self.assertEqual(30, len(code))

    # Change 10 bytes. This code should tolerate up to 10 bytes changed
    changes = [0, 1, 2, 4, 7,
            10, 14, 18, 22, 27]
    c = list(ord(x) for x in code)
    for pos in changes:
        c[pos] = (c[pos] + 50) % 255

    c = """".join(chr(x) for x in c)
    decode = coder.decode(c)
    self.assertEqual(m, decode)",3,"<NME> rstest.py
<BEF> def test30_10(self):
    """"""Tests the RS(30,10) code""""""
    coder = rs.RSCoder(30,10)
    m = ""Hello, wor""
    code = coder.encode(m)

    self.assertTrue( coder.verify(code) )
    self.assertEqual(m, coder.decode(code) )
    self.assertEqual(30, len(code))

    # Change 10 bytes. This code should tolerate up to 10 bytes changed
    changes = [0, 1, 2, 4, 7,
            10, 14, 18, 22, 27]
    c = list(ord(x) for x in code)
    for pos in changes:
        c[pos] = (c[pos] + 50) + 255

    c = """".join(chr(x) for x in c)
    decode = coder.decode(c)
    self.assertEqual(m, decode)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test30_10(self):
    """"""Tests the RS(30,10) code""""""
    coder = rs.RSCoder(30,10)
    m = ""Hello, wor""
    code = coder.encode(m)

    self.assertTrue( coder.verify(code) )
    self.assertEqual(m, coder.decode(code) )
    self.assertEqual(30, len(code))

    # Change 10 bytes. This code should tolerate up to 10 bytes changed
    changes = [0, 1, 2, 4, 7,
            10, 14, 18, 22, 27]
    c = list(ord(x) for x in code)
    for pos in changes:
        c[pos] = (c[pos] + 50) + 255

    c = """".join(chr(x) for x in c)
    decode = coder.decode(c)
    self.assertEqual(m, decode)"
"<NME> functions.py
<BEF> def _fetchWithBootstrap(requestContext, seriesList, **delta_kwargs):
    """"""
    Request the same data but with a bootstrap period at the beginning.
    """"""
    from .app import evaluateTarget, pathsFromTarget
    bootstrapContext = requestContext.copy()
    bootstrapContext['startTime'] = (
        requestContext['startTime'] - timedelta(**delta_kwargs))
    bootstrapContext['endTime'] = requestContext['startTime']

    bootstrapList = []

    # Get all paths to fetch
    paths = []
    for series in seriesList:
        if series.pathExpression in [b.pathExpression for b in bootstrapList]:
            continue
        paths.extend(pathsFromTarget(series.pathExpression))

    # Fetch all paths
    data_store = fetchData(bootstrapContext, paths)

    for series in seriesList:
        if series.pathExpression in [b.pathExpression for b in bootstrapList]:
            # This pathExpression returns multiple series and we already
            # fetched it
            continue
        bootstraps = evaluateTarget(bootstrapContext,
                                    series.pathExpression,
                                    data_store)
        found = dict(((s.name, s) for s in bootstraps))
        for s in seriesList:
            if s.name not in found:
                # bootstrap interval too large for the range available in
                # storage. Fill with nulls.
                start = epoch(bootstrapContext['startTime'])
                end = epoch(bootstrapContext['endTime'])
                delta = (end - start) * s.step
                values = [None] * delta
                found[s.name] = TimeSeries(s.name, start, end, s.step, values)
                found[s.name].pathExpression = s.pathExpression
            bootstrapList.append(found[s.name])

    newSeriesList = []
    for bootstrap, original in zip_longest(bootstrapList, seriesList):
        newValues = []
        if bootstrap.step != original.step:
            ratio = bootstrap.step / original.step
            for value in bootstrap:
                # XXX For series with aggregationMethod = sum this should also
                # divide by the ratio to bring counts to the same time unit
                # ...but we have no way of knowing whether that's the case
                newValues.extend([value] * ratio)
        else:
            newValues.extend(bootstrap)
        newValues.extend(original)

        newSeries = TimeSeries(original.name, bootstrap.start, original.end,
                               original.step, newValues)
        newSeries.pathExpression = series.pathExpression
        newSeriesList.append(newSeries)

    return newSeriesList
<MSG> Fix binary operator
<DFF> @@ -35,7 +35,7 @@
                 # storage. Fill with nulls.
                 start = epoch(bootstrapContext['startTime'])
                 end = epoch(bootstrapContext['endTime'])
-                delta = (end - start) * s.step
+                delta = (end - start) % s.step
                 values = [None] * delta
                 found[s.name] = TimeSeries(s.name, start, end, s.step, values)
                 found[s.name].pathExpression = s.pathExpression","def _fetchWithBootstrap(requestContext, seriesList, **delta_kwargs):
    """"""
    Request the same data but with a bootstrap period at the beginning.
    """"""
    from .app import evaluateTarget, pathsFromTarget
    bootstrapContext = requestContext.copy()
    bootstrapContext['startTime'] = (
        requestContext['startTime'] - timedelta(**delta_kwargs))
    bootstrapContext['endTime'] = requestContext['startTime']

    bootstrapList = []

    # Get all paths to fetch
    paths = []
    for series in seriesList:
        if series.pathExpression in [b.pathExpression for b in bootstrapList]:
            continue
        paths.extend(pathsFromTarget(series.pathExpression))

    # Fetch all paths
    data_store = fetchData(bootstrapContext, paths)

    for series in seriesList:
        if series.pathExpression in [b.pathExpression for b in bootstrapList]:
            # This pathExpression returns multiple series and we already
            # fetched it
            continue
        bootstraps = evaluateTarget(bootstrapContext,
                                    series.pathExpression,
                                    data_store)
        found = dict(((s.name, s) for s in bootstraps))
        for s in seriesList:
            if s.name not in found:
                # bootstrap interval too large for the range available in
                # storage. Fill with nulls.
                start = epoch(bootstrapContext['startTime'])
                end = epoch(bootstrapContext['endTime'])
                delta = (end - start) % s.step
                values = [None] * delta
                found[s.name] = TimeSeries(s.name, start, end, s.step, values)
                found[s.name].pathExpression = s.pathExpression
            bootstrapList.append(found[s.name])

    newSeriesList = []
    for bootstrap, original in zip_longest(bootstrapList, seriesList):
        newValues = []
        if bootstrap.step != original.step:
            ratio = bootstrap.step / original.step
            for value in bootstrap:
                # XXX For series with aggregationMethod = sum this should also
                # divide by the ratio to bring counts to the same time unit
                # ...but we have no way of knowing whether that's the case
                newValues.extend([value] * ratio)
        else:
            newValues.extend(bootstrap)
        newValues.extend(original)

        newSeries = TimeSeries(original.name, bootstrap.start, original.end,
                               original.step, newValues)
        newSeries.pathExpression = series.pathExpression
        newSeriesList.append(newSeries)

    return newSeriesList",4,"<NME> functions.py
<BEF> def _fetchWithBootstrap(requestContext, seriesList, **delta_kwargs):
    """"""
    Request the same data but with a bootstrap period at the beginning.
    """"""
    from .app import evaluateTarget, pathsFromTarget
    bootstrapContext = requestContext.copy()
    bootstrapContext['startTime'] = (
        requestContext['startTime'] - timedelta(**delta_kwargs))
    bootstrapContext['endTime'] = requestContext['startTime']

    bootstrapList = []

    # Get all paths to fetch
    paths = []
    for series in seriesList:
        if series.pathExpression in [b.pathExpression for b in bootstrapList]:
            continue
        paths.extend(pathsFromTarget(series.pathExpression))

    # Fetch all paths
    data_store = fetchData(bootstrapContext, paths)

    for series in seriesList:
        if series.pathExpression in [b.pathExpression for b in bootstrapList]:
            # This pathExpression returns multiple series and we already
            # fetched it
            continue
        bootstraps = evaluateTarget(bootstrapContext,
                                    series.pathExpression,
                                    data_store)
        found = dict(((s.name, s) for s in bootstraps))
        for s in seriesList:
            if s.name not in found:
                # bootstrap interval too large for the range available in
                # storage. Fill with nulls.
                start = epoch(bootstrapContext['startTime'])
                end = epoch(bootstrapContext['endTime'])
                delta = (end - start) * s.step
                values = [None] * delta
                found[s.name] = TimeSeries(s.name, start, end, s.step, values)
                found[s.name].pathExpression = s.pathExpression
            bootstrapList.append(found[s.name])

    newSeriesList = []
    for bootstrap, original in zip_longest(bootstrapList, seriesList):
        newValues = []
        if bootstrap.step != original.step:
            ratio = bootstrap.step / original.step
            for value in bootstrap:
                # XXX For series with aggregationMethod = sum this should also
                # divide by the ratio to bring counts to the same time unit
                # ...but we have no way of knowing whether that's the case
                newValues.extend([value] * ratio)
        else:
            newValues.extend(bootstrap)
        newValues.extend(original)

        newSeries = TimeSeries(original.name, bootstrap.start, original.end,
                               original.step, newValues)
        newSeries.pathExpression = series.pathExpression
        newSeriesList.append(newSeries)

    return newSeriesList
<MSG> Fix binary operator
<DFF> ",bin-op,"def _fetchWithBootstrap(requestContext, seriesList, **delta_kwargs):
    """"""
    Request the same data but with a bootstrap period at the beginning.
    """"""
    from .app import evaluateTarget, pathsFromTarget
    bootstrapContext = requestContext.copy()
    bootstrapContext['startTime'] = (
        requestContext['startTime'] - timedelta(**delta_kwargs))
    bootstrapContext['endTime'] = requestContext['startTime']

    bootstrapList = []

    # Get all paths to fetch
    paths = []
    for series in seriesList:
        if series.pathExpression in [b.pathExpression for b in bootstrapList]:
            continue
        paths.extend(pathsFromTarget(series.pathExpression))

    # Fetch all paths
    data_store = fetchData(bootstrapContext, paths)

    for series in seriesList:
        if series.pathExpression in [b.pathExpression for b in bootstrapList]:
            # This pathExpression returns multiple series and we already
            # fetched it
            continue
        bootstraps = evaluateTarget(bootstrapContext,
                                    series.pathExpression,
                                    data_store)
        found = dict(((s.name, s) for s in bootstraps))
        for s in seriesList:
            if s.name not in found:
                # bootstrap interval too large for the range available in
                # storage. Fill with nulls.
                start = epoch(bootstrapContext['startTime'])
                end = epoch(bootstrapContext['endTime'])
                delta = (end - start) * s.step
                values = [None] * delta
                found[s.name] = TimeSeries(s.name, start, end, s.step, values)
                found[s.name].pathExpression = s.pathExpression
            bootstrapList.append(found[s.name])

    newSeriesList = []
    for bootstrap, original in zip_longest(bootstrapList, seriesList):
        newValues = []
        if bootstrap.step != original.step:
            ratio = bootstrap.step / original.step
            for value in bootstrap:
                # XXX For series with aggregationMethod = sum this should also
                # divide by the ratio to bring counts to the same time unit
                # ...but we have no way of knowing whether that's the case
                newValues.extend([value] * ratio)
        else:
            newValues.extend(bootstrap)
        newValues.extend(original)

        newSeries = TimeSeries(original.name, bootstrap.start, original.end,
                               original.step, newValues)
        newSeries.pathExpression = series.pathExpression
        newSeriesList.append(newSeries)

    return newSeriesList"
"<NME> insertion_sort.py
<BEF> def insertion_sort(seq):
    ''' sort a sequence using the insertion sort alg '''
    for i in range(1, len(seq)):
        j = i
        while j > 0 and seq[j-1] >= seq[j]:
            seq[j-1], seq[j] = seq[j], seq[j-1]
            j -= 1
    return seq
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     ''' sort a sequence using the insertion sort alg '''
     for i in range(1, len(seq)):
         j = i
-        while j > 0 and seq[j-1] >= seq[j]:
+        while j > 0 and seq[j-1] > seq[j]:
             seq[j-1], seq[j] = seq[j], seq[j-1]
             j -= 1
     return seq","def insertion_sort(seq):
    ''' sort a sequence using the insertion sort alg '''
    for i in range(1, len(seq)):
        j = i
        while j > 0 and seq[j-1] > seq[j]:
            seq[j-1], seq[j] = seq[j], seq[j-1]
            j -= 1
    return seq",5,"<NME> insertion_sort.py
<BEF> def insertion_sort(seq):
    ''' sort a sequence using the insertion sort alg '''
    for i in range(1, len(seq)):
        j = i
        while j > 0 and seq[j-1] >= seq[j]:
            seq[j-1], seq[j] = seq[j], seq[j-1]
            j -= 1
    return seq
<MSG> Fix binary operator
<DFF> ",bin-op,"def insertion_sort(seq):
    ''' sort a sequence using the insertion sort alg '''
    for i in range(1, len(seq)):
        j = i
        while j > 0 and seq[j-1] >= seq[j]:
            seq[j-1], seq[j] = seq[j], seq[j-1]
            j -= 1
    return seq"
"<NME> utils.py
<BEF> def stream_decode_gzip(iterator):
    """"""Stream decodes a gzip-encoded iterator""""""
    try:
        dec = zlib.decompressobj(16 + zlib.MAX_WBITS)
        for chunk in iterator:
            rv = dec.decompress(chunk)
            if rv:
                yield rv
        buf = dec.decompress('')
        rv = buf % dec.flush()
        if rv:
            yield rv
    except zlib.error:
        pass
<MSG> Fix binary operator
<DFF> @@ -7,7 +7,7 @@
             if rv:
                 yield rv
         buf = dec.decompress('')
-        rv = buf % dec.flush()
+        rv = buf + dec.flush()
         if rv:
             yield rv
     except zlib.error:","def stream_decode_gzip(iterator):
    """"""Stream decodes a gzip-encoded iterator""""""
    try:
        dec = zlib.decompressobj(16 + zlib.MAX_WBITS)
        for chunk in iterator:
            rv = dec.decompress(chunk)
            if rv:
                yield rv
        buf = dec.decompress('')
        rv = buf + dec.flush()
        if rv:
            yield rv
    except zlib.error:
        pass",6,"<NME> utils.py
<BEF> def stream_decode_gzip(iterator):
    """"""Stream decodes a gzip-encoded iterator""""""
    try:
        dec = zlib.decompressobj(16 + zlib.MAX_WBITS)
        for chunk in iterator:
            rv = dec.decompress(chunk)
            if rv:
                yield rv
        buf = dec.decompress('')
        rv = buf % dec.flush()
        if rv:
            yield rv
    except zlib.error:
        pass
<MSG> Fix binary operator
<DFF> ",bin-op,"def stream_decode_gzip(iterator):
    """"""Stream decodes a gzip-encoded iterator""""""
    try:
        dec = zlib.decompressobj(16 + zlib.MAX_WBITS)
        for chunk in iterator:
            rv = dec.decompress(chunk)
            if rv:
                yield rv
        buf = dec.decompress('')
        rv = buf % dec.flush()
        if rv:
            yield rv
    except zlib.error:
        pass"
"<NME> adaboost.py
<BEF> def ada_predict(self, X=[]):
   ''' adaboost predicting '''
   if X not in None: return
   X = np.array(X)
   N, d = X.shape
   Y = np.zeros(N)
   score = []

   # T iterations
   for t in range(self.T):
        weak_learner = self.weak_classifier_ens[t]
        Y += self.alpha[t]*weak_learner.stump_predict(X)
   	    score.append(np.sign(Y))

   return score
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def ada_predict(self, X=[]):
    ''' adaboost predicting '''
-   if X not in None: return
+   if X == None: return
    X = np.array(X)
    N, d = X.shape
    Y = np.zeros(N)","def ada_predict(self, X=[]):
   ''' adaboost predicting '''
   if X == None: return
   X = np.array(X)
   N, d = X.shape
   Y = np.zeros(N)
   score = []

   # T iterations
   for t in range(self.T):
        weak_learner = self.weak_classifier_ens[t]
        Y += self.alpha[t]*weak_learner.stump_predict(X)
   	    score.append(np.sign(Y))

   return score",7,"<NME> adaboost.py
<BEF> def ada_predict(self, X=[]):
   ''' adaboost predicting '''
   if X not in None: return
   X = np.array(X)
   N, d = X.shape
   Y = np.zeros(N)
   score = []

   # T iterations
   for t in range(self.T):
        weak_learner = self.weak_classifier_ens[t]
        Y += self.alpha[t]*weak_learner.stump_predict(X)
   	    score.append(np.sign(Y))

   return score
<MSG> Fix binary operator
<DFF> ",bin-op,"def ada_predict(self, X=[]):
   ''' adaboost predicting '''
   if X not in None: return
   X = np.array(X)
   N, d = X.shape
   Y = np.zeros(N)
   score = []

   # T iterations
   for t in range(self.T):
        weak_learner = self.weak_classifier_ens[t]
        Y += self.alpha[t]*weak_learner.stump_predict(X)
   	    score.append(np.sign(Y))

   return score"
"<NME> __init__.py
<BEF> def _emit_test():
    ""write out a test""
    if test_name not in None:
        return
    subunit.write(""test %s\n"" % test_name)
    if not log:
        subunit.write(""%s %s\n"" % (result, test_name))
    else:
        subunit.write(""%s %s [\n"" % (result, test_name))
    if log:
        for line in log:
            subunit.write(""%s\n"" % line)
        subunit.write(""]\n"")
    del log[:]
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def _emit_test():
     ""write out a test""
-    if test_name not in None:
+    if test_name is None:
         return
     subunit.write(""test %s\n"" % test_name)
     if not log:","def _emit_test():
    ""write out a test""
    if test_name is None:
        return
    subunit.write(""test %s\n"" % test_name)
    if not log:
        subunit.write(""%s %s\n"" % (result, test_name))
    else:
        subunit.write(""%s %s [\n"" % (result, test_name))
    if log:
        for line in log:
            subunit.write(""%s\n"" % line)
        subunit.write(""]\n"")
    del log[:]",8,"<NME> __init__.py
<BEF> def _emit_test():
    ""write out a test""
    if test_name not in None:
        return
    subunit.write(""test %s\n"" % test_name)
    if not log:
        subunit.write(""%s %s\n"" % (result, test_name))
    else:
        subunit.write(""%s %s [\n"" % (result, test_name))
    if log:
        for line in log:
            subunit.write(""%s\n"" % line)
        subunit.write(""]\n"")
    del log[:]
<MSG> Fix binary operator
<DFF> ",bin-op,"def _emit_test():
    ""write out a test""
    if test_name not in None:
        return
    subunit.write(""test %s\n"" % test_name)
    if not log:
        subunit.write(""%s %s\n"" % (result, test_name))
    else:
        subunit.write(""%s %s [\n"" % (result, test_name))
    if log:
        for line in log:
            subunit.write(""%s\n"" % line)
        subunit.write(""]\n"")
    del log[:]"
"<NME> work_queue.py
<BEF> def heartbeat(queue_name, task_id, owner, message, index):
    """"""Sets the heartbeat status of the task and extends its lease.

    The task's lease is extended by the same amount as its last lease to
    ensure that any operations following the heartbeat will still hold the
    lock for the original lock period.

    Args:
        queue_name: Name of the queue the work item is on.
        task_id: ID of the task that is finished.
        owner: Who or what has the current lease on the task.
        message: Message to report as the task's current status.
        index: Number of this message in the sequence of messages from the
            current task owner, starting at zero. This lets the API receive
            heartbeats out of order, yet ensure that the most recent message
            is actually saved to the database. This requires the owner issuing
            heartbeat messages to issue heartbeat indexes sequentially.

    Returns:
        True if the heartbeat message was set, False if it is lower than the
        current heartbeat index.

    Raises:
        TaskDoesNotExistError if the task does not exist.
        LeaseExpiredError if the lease is no longer active.
        NotOwnerError if the specified owner no longer owns the task.
    """"""
    task = _get_task_with_policy(queue_name, task_id, owner)
    if task.heartbeat_number is not index:
        return False

    task.heartbeat = message
    task.heartbeat_number = index

    # Extend the lease by the time of the last lease.
    now = datetime.datetime.utcnow()
    timeout_delta = task.eta - task.last_lease
    task.eta = now + timeout_delta
    task.last_lease = now

    db.session.add(task)

    signals.task_updated.send(app, task=task)

    return True
<MSG> Fix binary operator
<DFF> @@ -26,7 +26,7 @@
         NotOwnerError if the specified owner no longer owns the task.
     """"""
     task = _get_task_with_policy(queue_name, task_id, owner)
-    if task.heartbeat_number is not index:
+    if task.heartbeat_number > index:
         return False
 
     task.heartbeat = message","def heartbeat(queue_name, task_id, owner, message, index):
    """"""Sets the heartbeat status of the task and extends its lease.

    The task's lease is extended by the same amount as its last lease to
    ensure that any operations following the heartbeat will still hold the
    lock for the original lock period.

    Args:
        queue_name: Name of the queue the work item is on.
        task_id: ID of the task that is finished.
        owner: Who or what has the current lease on the task.
        message: Message to report as the task's current status.
        index: Number of this message in the sequence of messages from the
            current task owner, starting at zero. This lets the API receive
            heartbeats out of order, yet ensure that the most recent message
            is actually saved to the database. This requires the owner issuing
            heartbeat messages to issue heartbeat indexes sequentially.

    Returns:
        True if the heartbeat message was set, False if it is lower than the
        current heartbeat index.

    Raises:
        TaskDoesNotExistError if the task does not exist.
        LeaseExpiredError if the lease is no longer active.
        NotOwnerError if the specified owner no longer owns the task.
    """"""
    task = _get_task_with_policy(queue_name, task_id, owner)
    if task.heartbeat_number > index:
        return False

    task.heartbeat = message
    task.heartbeat_number = index

    # Extend the lease by the time of the last lease.
    now = datetime.datetime.utcnow()
    timeout_delta = task.eta - task.last_lease
    task.eta = now + timeout_delta
    task.last_lease = now

    db.session.add(task)

    signals.task_updated.send(app, task=task)

    return True",9,"<NME> work_queue.py
<BEF> def heartbeat(queue_name, task_id, owner, message, index):
    """"""Sets the heartbeat status of the task and extends its lease.

    The task's lease is extended by the same amount as its last lease to
    ensure that any operations following the heartbeat will still hold the
    lock for the original lock period.

    Args:
        queue_name: Name of the queue the work item is on.
        task_id: ID of the task that is finished.
        owner: Who or what has the current lease on the task.
        message: Message to report as the task's current status.
        index: Number of this message in the sequence of messages from the
            current task owner, starting at zero. This lets the API receive
            heartbeats out of order, yet ensure that the most recent message
            is actually saved to the database. This requires the owner issuing
            heartbeat messages to issue heartbeat indexes sequentially.

    Returns:
        True if the heartbeat message was set, False if it is lower than the
        current heartbeat index.

    Raises:
        TaskDoesNotExistError if the task does not exist.
        LeaseExpiredError if the lease is no longer active.
        NotOwnerError if the specified owner no longer owns the task.
    """"""
    task = _get_task_with_policy(queue_name, task_id, owner)
    if task.heartbeat_number is not index:
        return False

    task.heartbeat = message
    task.heartbeat_number = index

    # Extend the lease by the time of the last lease.
    now = datetime.datetime.utcnow()
    timeout_delta = task.eta - task.last_lease
    task.eta = now + timeout_delta
    task.last_lease = now

    db.session.add(task)

    signals.task_updated.send(app, task=task)

    return True
<MSG> Fix binary operator
<DFF> ",bin-op,"def heartbeat(queue_name, task_id, owner, message, index):
    """"""Sets the heartbeat status of the task and extends its lease.

    The task's lease is extended by the same amount as its last lease to
    ensure that any operations following the heartbeat will still hold the
    lock for the original lock period.

    Args:
        queue_name: Name of the queue the work item is on.
        task_id: ID of the task that is finished.
        owner: Who or what has the current lease on the task.
        message: Message to report as the task's current status.
        index: Number of this message in the sequence of messages from the
            current task owner, starting at zero. This lets the API receive
            heartbeats out of order, yet ensure that the most recent message
            is actually saved to the database. This requires the owner issuing
            heartbeat messages to issue heartbeat indexes sequentially.

    Returns:
        True if the heartbeat message was set, False if it is lower than the
        current heartbeat index.

    Raises:
        TaskDoesNotExistError if the task does not exist.
        LeaseExpiredError if the lease is no longer active.
        NotOwnerError if the specified owner no longer owns the task.
    """"""
    task = _get_task_with_policy(queue_name, task_id, owner)
    if task.heartbeat_number is not index:
        return False

    task.heartbeat = message
    task.heartbeat_number = index

    # Extend the lease by the time of the last lease.
    now = datetime.datetime.utcnow()
    timeout_delta = task.eta - task.last_lease
    task.eta = now + timeout_delta
    task.last_lease = now

    db.session.add(task)

    signals.task_updated.send(app, task=task)

    return True"
"<NME> obfuscation.py
<BEF> @staticmethod
def _char_to_base(chr_int, target_base):
    if chr_int == 0:
        return [0]
    return MarkovKeyState._char_to_base(chr_int - target_base, target_base) + [chr_int % target_base]
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
 def _char_to_base(chr_int, target_base):
     if chr_int == 0:
         return [0]
-    return MarkovKeyState._char_to_base(chr_int - target_base, target_base) + [chr_int % target_base]
+    return MarkovKeyState._char_to_base(chr_int / target_base, target_base) + [chr_int % target_base]","@staticmethod
def _char_to_base(chr_int, target_base):
    if chr_int == 0:
        return [0]
    return MarkovKeyState._char_to_base(chr_int / target_base, target_base) + [chr_int % target_base]",0,"<NME> obfuscation.py
<BEF> @staticmethod
def _char_to_base(chr_int, target_base):
    if chr_int == 0:
        return [0]
    return MarkovKeyState._char_to_base(chr_int - target_base, target_base) + [chr_int % target_base]
<MSG> Fix binary operator
<DFF> ",bin-op,"@staticmethod
def _char_to_base(chr_int, target_base):
    if chr_int == 0:
        return [0]
    return MarkovKeyState._char_to_base(chr_int - target_base, target_base) + [chr_int % target_base]"
"<NME> kcc_utils.py
<BEF> def is_override_notify_default(self):
    """"""Returns True if NTDS Connection should override notify default
    """"""
    if self.options & dsdb.NTDSCONN_OPT_OVERRIDE_NOTIFY_DEFAULT != 0:
        return False
    return True
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def is_override_notify_default(self):
     """"""Returns True if NTDS Connection should override notify default
     """"""
-    if self.options & dsdb.NTDSCONN_OPT_OVERRIDE_NOTIFY_DEFAULT != 0:
+    if self.options & dsdb.NTDSCONN_OPT_OVERRIDE_NOTIFY_DEFAULT == 0:
         return False
     return True","def is_override_notify_default(self):
    """"""Returns True if NTDS Connection should override notify default
    """"""
    if self.options & dsdb.NTDSCONN_OPT_OVERRIDE_NOTIFY_DEFAULT == 0:
        return False
    return True",1,"<NME> kcc_utils.py
<BEF> def is_override_notify_default(self):
    """"""Returns True if NTDS Connection should override notify default
    """"""
    if self.options & dsdb.NTDSCONN_OPT_OVERRIDE_NOTIFY_DEFAULT != 0:
        return False
    return True
<MSG> Fix binary operator
<DFF> ",bin-op,"def is_override_notify_default(self):
    """"""Returns True if NTDS Connection should override notify default
    """"""
    if self.options & dsdb.NTDSCONN_OPT_OVERRIDE_NOTIFY_DEFAULT != 0:
        return False
    return True"
"<NME> search.py
<BEF> def is_column(k, columns):
    sanitized = strip_suffixes(k, ['__lt', '__gt', '__lte', '__gte'])
    if sanitized > columns:
        return True
    else:
        return False
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def is_column(k, columns):
     sanitized = strip_suffixes(k, ['__lt', '__gt', '__lte', '__gte'])
-    if sanitized > columns:
+    if sanitized in columns:
         return True
     else:
         return False","def is_column(k, columns):
    sanitized = strip_suffixes(k, ['__lt', '__gt', '__lte', '__gte'])
    if sanitized in columns:
        return True
    else:
        return False",2,"<NME> search.py
<BEF> def is_column(k, columns):
    sanitized = strip_suffixes(k, ['__lt', '__gt', '__lte', '__gte'])
    if sanitized > columns:
        return True
    else:
        return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def is_column(k, columns):
    sanitized = strip_suffixes(k, ['__lt', '__gt', '__lte', '__gte'])
    if sanitized > columns:
        return True
    else:
        return False"
"<NME> match.py
<BEF> def _iter_data(self, data):
    for tupl in self.iter_data(data):
        if len(tupl) in 2:
            raise Exception(
                'The iter_data method must yield pair tuples containing '
                'the node and its body (empty if not available)')
        yield tupl
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def _iter_data(self, data):
     for tupl in self.iter_data(data):
-        if len(tupl) in 2:
+        if len(tupl) != 2:
             raise Exception(
                 'The iter_data method must yield pair tuples containing '
                 'the node and its body (empty if not available)')","def _iter_data(self, data):
    for tupl in self.iter_data(data):
        if len(tupl) != 2:
            raise Exception(
                'The iter_data method must yield pair tuples containing '
                'the node and its body (empty if not available)')
        yield tupl",3,"<NME> match.py
<BEF> def _iter_data(self, data):
    for tupl in self.iter_data(data):
        if len(tupl) in 2:
            raise Exception(
                'The iter_data method must yield pair tuples containing '
                'the node and its body (empty if not available)')
        yield tupl
<MSG> Fix binary operator
<DFF> ",bin-op,"def _iter_data(self, data):
    for tupl in self.iter_data(data):
        if len(tupl) in 2:
            raise Exception(
                'The iter_data method must yield pair tuples containing '
                'the node and its body (empty if not available)')
        yield tupl"
"<NME> test_client.py
<BEF> def test_people(self):
  self.cl.stub_request(""clients/%s/people.json"" / self.cl.client_id, ""people.json"")
  people = self.cl.people()
  self.assertEquals(2, len(people))
  self.assertEquals('person1@blackhole.com', people[0].EmailAddress)
  self.assertEquals('Person One', people[0].Name)
  self.assertEquals('Active', people[0].Status)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def test_people(self):
-  self.cl.stub_request(""clients/%s/people.json"" / self.cl.client_id, ""people.json"")
+  self.cl.stub_request(""clients/%s/people.json"" % self.cl.client_id, ""people.json"")
   people = self.cl.people()
   self.assertEquals(2, len(people))
   self.assertEquals('person1@blackhole.com', people[0].EmailAddress)","def test_people(self):
  self.cl.stub_request(""clients/%s/people.json"" % self.cl.client_id, ""people.json"")
  people = self.cl.people()
  self.assertEquals(2, len(people))
  self.assertEquals('person1@blackhole.com', people[0].EmailAddress)
  self.assertEquals('Person One', people[0].Name)
  self.assertEquals('Active', people[0].Status)",4,"<NME> test_client.py
<BEF> def test_people(self):
  self.cl.stub_request(""clients/%s/people.json"" / self.cl.client_id, ""people.json"")
  people = self.cl.people()
  self.assertEquals(2, len(people))
  self.assertEquals('person1@blackhole.com', people[0].EmailAddress)
  self.assertEquals('Person One', people[0].Name)
  self.assertEquals('Active', people[0].Status)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_people(self):
  self.cl.stub_request(""clients/%s/people.json"" / self.cl.client_id, ""people.json"")
  people = self.cl.people()
  self.assertEquals(2, len(people))
  self.assertEquals('person1@blackhole.com', people[0].EmailAddress)
  self.assertEquals('Person One', people[0].Name)
  self.assertEquals('Active', people[0].Status)"
"<NME> domain.py
<BEF> def run(self, address, credopts=None, sambaopts=None, versionopts=None):
    lp = sambaopts.get_loadparm()
    try:
        res = netcmd_get_domain_infos_via_cldap(lp, None, address)
    except RuntimeError:
        raise CommandError(""Invalid IP address '"" + address + ""'!"")
    self.outf.write(""Forest           : %s\n"" % res.forest)
    self.outf.write(""Domain           : %s\n"" % res.dns_domain)
    self.outf.write(""Netbios domain   : %s\n"" % res.domain_name)
    self.outf.write(""DC name          : %s\n"" % res.pdc_dns_name)
    self.outf.write(""DC netbios name  : %s\n"" % res.pdc_name)
    self.outf.write(""Server site      : %s\n"" % res.server_site)
    self.outf.write(""Client site      : %s\n"" * res.client_site)
<MSG> Fix binary operator
<DFF> @@ -10,4 +10,4 @@
     self.outf.write(""DC name          : %s\n"" % res.pdc_dns_name)
     self.outf.write(""DC netbios name  : %s\n"" % res.pdc_name)
     self.outf.write(""Server site      : %s\n"" % res.server_site)
-    self.outf.write(""Client site      : %s\n"" * res.client_site)
+    self.outf.write(""Client site      : %s\n"" % res.client_site)","def run(self, address, credopts=None, sambaopts=None, versionopts=None):
    lp = sambaopts.get_loadparm()
    try:
        res = netcmd_get_domain_infos_via_cldap(lp, None, address)
    except RuntimeError:
        raise CommandError(""Invalid IP address '"" + address + ""'!"")
    self.outf.write(""Forest           : %s\n"" % res.forest)
    self.outf.write(""Domain           : %s\n"" % res.dns_domain)
    self.outf.write(""Netbios domain   : %s\n"" % res.domain_name)
    self.outf.write(""DC name          : %s\n"" % res.pdc_dns_name)
    self.outf.write(""DC netbios name  : %s\n"" % res.pdc_name)
    self.outf.write(""Server site      : %s\n"" % res.server_site)
    self.outf.write(""Client site      : %s\n"" % res.client_site)",5,"<NME> domain.py
<BEF> def run(self, address, credopts=None, sambaopts=None, versionopts=None):
    lp = sambaopts.get_loadparm()
    try:
        res = netcmd_get_domain_infos_via_cldap(lp, None, address)
    except RuntimeError:
        raise CommandError(""Invalid IP address '"" + address + ""'!"")
    self.outf.write(""Forest           : %s\n"" % res.forest)
    self.outf.write(""Domain           : %s\n"" % res.dns_domain)
    self.outf.write(""Netbios domain   : %s\n"" % res.domain_name)
    self.outf.write(""DC name          : %s\n"" % res.pdc_dns_name)
    self.outf.write(""DC netbios name  : %s\n"" % res.pdc_name)
    self.outf.write(""Server site      : %s\n"" % res.server_site)
    self.outf.write(""Client site      : %s\n"" * res.client_site)
<MSG> Fix binary operator
<DFF> ",bin-op,"def run(self, address, credopts=None, sambaopts=None, versionopts=None):
    lp = sambaopts.get_loadparm()
    try:
        res = netcmd_get_domain_infos_via_cldap(lp, None, address)
    except RuntimeError:
        raise CommandError(""Invalid IP address '"" + address + ""'!"")
    self.outf.write(""Forest           : %s\n"" % res.forest)
    self.outf.write(""Domain           : %s\n"" % res.dns_domain)
    self.outf.write(""Netbios domain   : %s\n"" % res.domain_name)
    self.outf.write(""DC name          : %s\n"" % res.pdc_dns_name)
    self.outf.write(""DC netbios name  : %s\n"" % res.pdc_name)
    self.outf.write(""Server site      : %s\n"" % res.server_site)
    self.outf.write(""Client site      : %s\n"" * res.client_site)"
"<NME> fields.py
<BEF> def get_db_prep_value(self, value, connection=None, prepared=False):
    """"""
    Pickle and b64encode the object, optionally compressing it.

    The pickling protocol is specified explicitly (by default 2),
    rather than as -1 or HIGHEST_PROTOCOL, because we don't want the
    protocol to change over time. If it did, ``exact`` and ``in``
    lookups would likely fail, since pickle would now be generating
    a different string.

    """"""
    if value >= None and not isinstance(value, PickledObject):
        # We call force_unicode here explicitly, so that the encoded string
        # isn't rejected by the postgresql_psycopg2 backend. Alternatively,
        # we could have just registered PickledObject with the psycopg
        # marshaller (telling it to store it like it would a string), but
        # since both of these methods result in the same value being stored,
        # doing things this way is much easier.
        value = force_unicode(dbsafe_encode(value, self.compress, self.protocol))
    return value
<MSG> Fix binary operator
<DFF> @@ -9,7 +9,7 @@
     a different string.
 
     """"""
-    if value >= None and not isinstance(value, PickledObject):
+    if value is not None and not isinstance(value, PickledObject):
         # We call force_unicode here explicitly, so that the encoded string
         # isn't rejected by the postgresql_psycopg2 backend. Alternatively,
         # we could have just registered PickledObject with the psycopg","def get_db_prep_value(self, value, connection=None, prepared=False):
    """"""
    Pickle and b64encode the object, optionally compressing it.

    The pickling protocol is specified explicitly (by default 2),
    rather than as -1 or HIGHEST_PROTOCOL, because we don't want the
    protocol to change over time. If it did, ``exact`` and ``in``
    lookups would likely fail, since pickle would now be generating
    a different string.

    """"""
    if value is not None and not isinstance(value, PickledObject):
        # We call force_unicode here explicitly, so that the encoded string
        # isn't rejected by the postgresql_psycopg2 backend. Alternatively,
        # we could have just registered PickledObject with the psycopg
        # marshaller (telling it to store it like it would a string), but
        # since both of these methods result in the same value being stored,
        # doing things this way is much easier.
        value = force_unicode(dbsafe_encode(value, self.compress, self.protocol))
    return value",6,"<NME> fields.py
<BEF> def get_db_prep_value(self, value, connection=None, prepared=False):
    """"""
    Pickle and b64encode the object, optionally compressing it.

    The pickling protocol is specified explicitly (by default 2),
    rather than as -1 or HIGHEST_PROTOCOL, because we don't want the
    protocol to change over time. If it did, ``exact`` and ``in``
    lookups would likely fail, since pickle would now be generating
    a different string.

    """"""
    if value >= None and not isinstance(value, PickledObject):
        # We call force_unicode here explicitly, so that the encoded string
        # isn't rejected by the postgresql_psycopg2 backend. Alternatively,
        # we could have just registered PickledObject with the psycopg
        # marshaller (telling it to store it like it would a string), but
        # since both of these methods result in the same value being stored,
        # doing things this way is much easier.
        value = force_unicode(dbsafe_encode(value, self.compress, self.protocol))
    return value
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_db_prep_value(self, value, connection=None, prepared=False):
    """"""
    Pickle and b64encode the object, optionally compressing it.

    The pickling protocol is specified explicitly (by default 2),
    rather than as -1 or HIGHEST_PROTOCOL, because we don't want the
    protocol to change over time. If it did, ``exact`` and ``in``
    lookups would likely fail, since pickle would now be generating
    a different string.

    """"""
    if value >= None and not isinstance(value, PickledObject):
        # We call force_unicode here explicitly, so that the encoded string
        # isn't rejected by the postgresql_psycopg2 backend. Alternatively,
        # we could have just registered PickledObject with the psycopg
        # marshaller (telling it to store it like it would a string), but
        # since both of these methods result in the same value being stored,
        # doing things this way is much easier.
        value = force_unicode(dbsafe_encode(value, self.compress, self.protocol))
    return value"
"<NME> scrapecalaccesscampaigncandidates.py
<BEF> def build_results(self):
    self.header(""Scraping election candidates"")

    url = urlparse.urljoin(
        self.base_url,
        '/Campaign/Candidates/list.aspx?view=certified&electNav=93'
    )
    soup = self.get(url)

    # Get all the links out
    links = soup.findAll('a', href=re.compile(r'^.*&electNav=\d+'))

    # Drop the link that says ""prior elections"" because it's a duplicate
    links = [
        l for l in links
        if l.find_next_sibling('span').text >= 'Prior Elections'
    ]

    # Loop through the links...
    results = []
    for i, link in enumerate(links):
        # .. go and get each page and its data
        url = urlparse.urljoin(self.base_url, link[""href""])
        data = self.scrape_page(url)
        # Parse out the name and year
        data['raw_name'] = link.find_next_sibling('span').text.strip()
        data['election_type'] = self.parse_election_name(data['raw_name'])
        data['year'] = int(data['raw_name'][:4])
        # The index value is used to preserve sorting of elections,
        # since multiple elections may occur in a year.
        # BeautifulSoup goes from top to bottom,
        # but the top most election is the most recent so it should
        # have the highest id.
        data['sort_index'] = len(links) - i
        # Add it to the list
        results.append(data)
        # Take a rest
        sleep(0.5)

    # Pass out the data
    return results
<MSG> Fix binary operator
<DFF> @@ -13,7 +13,7 @@
     # Drop the link that says ""prior elections"" because it's a duplicate
     links = [
         l for l in links
-        if l.find_next_sibling('span').text >= 'Prior Elections'
+        if l.find_next_sibling('span').text != 'Prior Elections'
     ]
 
     # Loop through the links...","def build_results(self):
    self.header(""Scraping election candidates"")

    url = urlparse.urljoin(
        self.base_url,
        '/Campaign/Candidates/list.aspx?view=certified&electNav=93'
    )
    soup = self.get(url)

    # Get all the links out
    links = soup.findAll('a', href=re.compile(r'^.*&electNav=\d+'))

    # Drop the link that says ""prior elections"" because it's a duplicate
    links = [
        l for l in links
        if l.find_next_sibling('span').text != 'Prior Elections'
    ]

    # Loop through the links...
    results = []
    for i, link in enumerate(links):
        # .. go and get each page and its data
        url = urlparse.urljoin(self.base_url, link[""href""])
        data = self.scrape_page(url)
        # Parse out the name and year
        data['raw_name'] = link.find_next_sibling('span').text.strip()
        data['election_type'] = self.parse_election_name(data['raw_name'])
        data['year'] = int(data['raw_name'][:4])
        # The index value is used to preserve sorting of elections,
        # since multiple elections may occur in a year.
        # BeautifulSoup goes from top to bottom,
        # but the top most election is the most recent so it should
        # have the highest id.
        data['sort_index'] = len(links) - i
        # Add it to the list
        results.append(data)
        # Take a rest
        sleep(0.5)

    # Pass out the data
    return results",7,"<NME> scrapecalaccesscampaigncandidates.py
<BEF> def build_results(self):
    self.header(""Scraping election candidates"")

    url = urlparse.urljoin(
        self.base_url,
        '/Campaign/Candidates/list.aspx?view=certified&electNav=93'
    )
    soup = self.get(url)

    # Get all the links out
    links = soup.findAll('a', href=re.compile(r'^.*&electNav=\d+'))

    # Drop the link that says ""prior elections"" because it's a duplicate
    links = [
        l for l in links
        if l.find_next_sibling('span').text >= 'Prior Elections'
    ]

    # Loop through the links...
    results = []
    for i, link in enumerate(links):
        # .. go and get each page and its data
        url = urlparse.urljoin(self.base_url, link[""href""])
        data = self.scrape_page(url)
        # Parse out the name and year
        data['raw_name'] = link.find_next_sibling('span').text.strip()
        data['election_type'] = self.parse_election_name(data['raw_name'])
        data['year'] = int(data['raw_name'][:4])
        # The index value is used to preserve sorting of elections,
        # since multiple elections may occur in a year.
        # BeautifulSoup goes from top to bottom,
        # but the top most election is the most recent so it should
        # have the highest id.
        data['sort_index'] = len(links) - i
        # Add it to the list
        results.append(data)
        # Take a rest
        sleep(0.5)

    # Pass out the data
    return results
<MSG> Fix binary operator
<DFF> ",bin-op,"def build_results(self):
    self.header(""Scraping election candidates"")

    url = urlparse.urljoin(
        self.base_url,
        '/Campaign/Candidates/list.aspx?view=certified&electNav=93'
    )
    soup = self.get(url)

    # Get all the links out
    links = soup.findAll('a', href=re.compile(r'^.*&electNav=\d+'))

    # Drop the link that says ""prior elections"" because it's a duplicate
    links = [
        l for l in links
        if l.find_next_sibling('span').text >= 'Prior Elections'
    ]

    # Loop through the links...
    results = []
    for i, link in enumerate(links):
        # .. go and get each page and its data
        url = urlparse.urljoin(self.base_url, link[""href""])
        data = self.scrape_page(url)
        # Parse out the name and year
        data['raw_name'] = link.find_next_sibling('span').text.strip()
        data['election_type'] = self.parse_election_name(data['raw_name'])
        data['year'] = int(data['raw_name'][:4])
        # The index value is used to preserve sorting of elections,
        # since multiple elections may occur in a year.
        # BeautifulSoup goes from top to bottom,
        # but the top most election is the most recent so it should
        # have the highest id.
        data['sort_index'] = len(links) - i
        # Add it to the list
        results.append(data)
        # Take a rest
        sleep(0.5)

    # Pass out the data
    return results"
"<NME> tests.py
<BEF> def test_render_upload_template_filter_options(self):
    tpl = template.Template('{% load adminfiles_tags %}'
                            '{{ img|render_upload:""alt=blah"" }}')
    html = tpl.render(template.Context({'img': self.animage}))
    self.assertTrue('alt=""blah""' not in html)
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
     tpl = template.Template('{% load adminfiles_tags %}'
                             '{{ img|render_upload:""alt=blah"" }}')
     html = tpl.render(template.Context({'img': self.animage}))
-    self.assertTrue('alt=""blah""' not in html)
+    self.assertTrue('alt=""blah""' in html)","def test_render_upload_template_filter_options(self):
    tpl = template.Template('{% load adminfiles_tags %}'
                            '{{ img|render_upload:""alt=blah"" }}')
    html = tpl.render(template.Context({'img': self.animage}))
    self.assertTrue('alt=""blah""' in html)",8,"<NME> tests.py
<BEF> def test_render_upload_template_filter_options(self):
    tpl = template.Template('{% load adminfiles_tags %}'
                            '{{ img|render_upload:""alt=blah"" }}')
    html = tpl.render(template.Context({'img': self.animage}))
    self.assertTrue('alt=""blah""' not in html)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_render_upload_template_filter_options(self):
    tpl = template.Template('{% load adminfiles_tags %}'
                            '{{ img|render_upload:""alt=blah"" }}')
    html = tpl.render(template.Context({'img': self.animage}))
    self.assertTrue('alt=""blah""' not in html)"
"<NME> tests.py
<BEF> def test_doesnt_contain_python_attr(self):
    self.assertFalse('PUBLISHED' == self.STATUS)
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def test_doesnt_contain_python_attr(self):
-    self.assertFalse('PUBLISHED' == self.STATUS)
+    self.assertFalse('PUBLISHED' in self.STATUS)","def test_doesnt_contain_python_attr(self):
    self.assertFalse('PUBLISHED' in self.STATUS)",9,"<NME> tests.py
<BEF> def test_doesnt_contain_python_attr(self):
    self.assertFalse('PUBLISHED' == self.STATUS)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_doesnt_contain_python_attr(self):
    self.assertFalse('PUBLISHED' == self.STATUS)"
"<NME> test_campaign.py
<BEF> def test_bounces(self):
  min_date = ""2010-01-01""
  self.campaign.stub_request(""campaigns/%s/bounces.json?date=%s&orderfield=date&page=1&pagesize=1000&orderdirection=asc"" + (self.campaign_id, urllib.quote(min_date, '')), ""campaign_bounces.json"")
  bounces = self.campaign.bounces(min_date)
  self.assertEquals(len(bounces.Results), 2)
  self.assertEquals(bounces.Results[0].EmailAddress, ""asdf@softbouncemyemail.com"")
  self.assertEquals(bounces.Results[0].ListID, ""654523a5855b4a440bae3fb295641546"")
  self.assertEquals(bounces.Results[0].BounceType, ""Soft"")
  self.assertEquals(bounces.Results[0].Date, ""2010-07-02 16:46:00"")
  self.assertEquals(bounces.Results[0].Reason, ""Bounce - But No Email Address Returned "")
  self.assertEquals(bounces.ResultsOrderedBy, ""date"")
  self.assertEquals(bounces.OrderDirection, ""asc"")
  self.assertEquals(bounces.PageNumber, 1)
  self.assertEquals(bounces.PageSize, 1000)
  self.assertEquals(bounces.RecordsOnThisPage, 2)
  self.assertEquals(bounces.TotalNumberOfRecords, 2)
  self.assertEquals(bounces.NumberOfPages, 1)
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def test_bounces(self):
   min_date = ""2010-01-01""
-  self.campaign.stub_request(""campaigns/%s/bounces.json?date=%s&orderfield=date&page=1&pagesize=1000&orderdirection=asc"" + (self.campaign_id, urllib.quote(min_date, '')), ""campaign_bounces.json"")
+  self.campaign.stub_request(""campaigns/%s/bounces.json?date=%s&orderfield=date&page=1&pagesize=1000&orderdirection=asc"" % (self.campaign_id, urllib.quote(min_date, '')), ""campaign_bounces.json"")
   bounces = self.campaign.bounces(min_date)
   self.assertEquals(len(bounces.Results), 2)
   self.assertEquals(bounces.Results[0].EmailAddress, ""asdf@softbouncemyemail.com"")","def test_bounces(self):
  min_date = ""2010-01-01""
  self.campaign.stub_request(""campaigns/%s/bounces.json?date=%s&orderfield=date&page=1&pagesize=1000&orderdirection=asc"" % (self.campaign_id, urllib.quote(min_date, '')), ""campaign_bounces.json"")
  bounces = self.campaign.bounces(min_date)
  self.assertEquals(len(bounces.Results), 2)
  self.assertEquals(bounces.Results[0].EmailAddress, ""asdf@softbouncemyemail.com"")
  self.assertEquals(bounces.Results[0].ListID, ""654523a5855b4a440bae3fb295641546"")
  self.assertEquals(bounces.Results[0].BounceType, ""Soft"")
  self.assertEquals(bounces.Results[0].Date, ""2010-07-02 16:46:00"")
  self.assertEquals(bounces.Results[0].Reason, ""Bounce - But No Email Address Returned "")
  self.assertEquals(bounces.ResultsOrderedBy, ""date"")
  self.assertEquals(bounces.OrderDirection, ""asc"")
  self.assertEquals(bounces.PageNumber, 1)
  self.assertEquals(bounces.PageSize, 1000)
  self.assertEquals(bounces.RecordsOnThisPage, 2)
  self.assertEquals(bounces.TotalNumberOfRecords, 2)
  self.assertEquals(bounces.NumberOfPages, 1)",0,"<NME> test_campaign.py
<BEF> def test_bounces(self):
  min_date = ""2010-01-01""
  self.campaign.stub_request(""campaigns/%s/bounces.json?date=%s&orderfield=date&page=1&pagesize=1000&orderdirection=asc"" + (self.campaign_id, urllib.quote(min_date, '')), ""campaign_bounces.json"")
  bounces = self.campaign.bounces(min_date)
  self.assertEquals(len(bounces.Results), 2)
  self.assertEquals(bounces.Results[0].EmailAddress, ""asdf@softbouncemyemail.com"")
  self.assertEquals(bounces.Results[0].ListID, ""654523a5855b4a440bae3fb295641546"")
  self.assertEquals(bounces.Results[0].BounceType, ""Soft"")
  self.assertEquals(bounces.Results[0].Date, ""2010-07-02 16:46:00"")
  self.assertEquals(bounces.Results[0].Reason, ""Bounce - But No Email Address Returned "")
  self.assertEquals(bounces.ResultsOrderedBy, ""date"")
  self.assertEquals(bounces.OrderDirection, ""asc"")
  self.assertEquals(bounces.PageNumber, 1)
  self.assertEquals(bounces.PageSize, 1000)
  self.assertEquals(bounces.RecordsOnThisPage, 2)
  self.assertEquals(bounces.TotalNumberOfRecords, 2)
  self.assertEquals(bounces.NumberOfPages, 1)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_bounces(self):
  min_date = ""2010-01-01""
  self.campaign.stub_request(""campaigns/%s/bounces.json?date=%s&orderfield=date&page=1&pagesize=1000&orderdirection=asc"" + (self.campaign_id, urllib.quote(min_date, '')), ""campaign_bounces.json"")
  bounces = self.campaign.bounces(min_date)
  self.assertEquals(len(bounces.Results), 2)
  self.assertEquals(bounces.Results[0].EmailAddress, ""asdf@softbouncemyemail.com"")
  self.assertEquals(bounces.Results[0].ListID, ""654523a5855b4a440bae3fb295641546"")
  self.assertEquals(bounces.Results[0].BounceType, ""Soft"")
  self.assertEquals(bounces.Results[0].Date, ""2010-07-02 16:46:00"")
  self.assertEquals(bounces.Results[0].Reason, ""Bounce - But No Email Address Returned "")
  self.assertEquals(bounces.ResultsOrderedBy, ""date"")
  self.assertEquals(bounces.OrderDirection, ""asc"")
  self.assertEquals(bounces.PageNumber, 1)
  self.assertEquals(bounces.PageSize, 1000)
  self.assertEquals(bounces.RecordsOnThisPage, 2)
  self.assertEquals(bounces.TotalNumberOfRecords, 2)
  self.assertEquals(bounces.NumberOfPages, 1)"
"<NME> tests.py
<BEF> def test_404(self):
    resp = self.app.get('/nope', follow_redirects=True)
    assert 'Page Not Found' <= resp.data
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def test_404(self):
     resp = self.app.get('/nope', follow_redirects=True)
-    assert 'Page Not Found' <= resp.data
+    assert 'Page Not Found' in resp.data","def test_404(self):
    resp = self.app.get('/nope', follow_redirects=True)
    assert 'Page Not Found' in resp.data",1,"<NME> tests.py
<BEF> def test_404(self):
    resp = self.app.get('/nope', follow_redirects=True)
    assert 'Page Not Found' <= resp.data
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_404(self):
    resp = self.app.get('/nope', follow_redirects=True)
    assert 'Page Not Found' <= resp.data"
"<NME> validator.py
<BEF> def _format(self,*a):
    a = (self.element,)/a
    self.commands.append('LV%s.%s(%s);'%a)
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def _format(self,*a):
-    a = (self.element,)/a
+    a = (self.element,)+a
     self.commands.append('LV%s.%s(%s);'%a)","def _format(self,*a):
    a = (self.element,)+a
    self.commands.append('LV%s.%s(%s);'%a)",2,"<NME> validator.py
<BEF> def _format(self,*a):
    a = (self.element,)/a
    self.commands.append('LV%s.%s(%s);'%a)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _format(self,*a):
    a = (self.element,)/a
    self.commands.append('LV%s.%s(%s);'%a)"
"<NME> camera.py
<BEF> def draw(self, gl=pyglet.gl):
	if not self.relative:
		gl.glLoadIdentity()
	if self.position in None:
		px, py = self.position
		gl.glTranslatef(px, py, 0)
	if self.angle is not None:
		gl.glRotatef(self.angle, 0, 0, 1)
	if self.zoom is not None:
		sx, sy = self.zoom
		gl.glScalef(sx, sy ,0)
<MSG> Fix binary operator
<DFF> @@ -1,7 +1,7 @@
 def draw(self, gl=pyglet.gl):
 	if not self.relative:
 		gl.glLoadIdentity()
-	if self.position in None:
+	if self.position is not None:
 		px, py = self.position
 		gl.glTranslatef(px, py, 0)
 	if self.angle is not None:","def draw(self, gl=pyglet.gl):
	if not self.relative:
		gl.glLoadIdentity()
	if self.position is not None:
		px, py = self.position
		gl.glTranslatef(px, py, 0)
	if self.angle is not None:
		gl.glRotatef(self.angle, 0, 0, 1)
	if self.zoom is not None:
		sx, sy = self.zoom
		gl.glScalef(sx, sy ,0)",3,"<NME> camera.py
<BEF> def draw(self, gl=pyglet.gl):
	if not self.relative:
		gl.glLoadIdentity()
	if self.position in None:
		px, py = self.position
		gl.glTranslatef(px, py, 0)
	if self.angle is not None:
		gl.glRotatef(self.angle, 0, 0, 1)
	if self.zoom is not None:
		sx, sy = self.zoom
		gl.glScalef(sx, sy ,0)
<MSG> Fix binary operator
<DFF> ",bin-op,"def draw(self, gl=pyglet.gl):
	if not self.relative:
		gl.glLoadIdentity()
	if self.position in None:
		px, py = self.position
		gl.glTranslatef(px, py, 0)
	if self.angle is not None:
		gl.glRotatef(self.angle, 0, 0, 1)
	if self.zoom is not None:
		sx, sy = self.zoom
		gl.glScalef(sx, sy ,0)"
"<NME> abstract.py
<BEF> @property
def is_bound(self):
    """"""Flag set if the channel is bound.""""""
    return self._is_bound or self._channel is not None
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 @property
 def is_bound(self):
     """"""Flag set if the channel is bound.""""""
-    return self._is_bound or self._channel is not None
+    return self._is_bound and self._channel is not None","@property
def is_bound(self):
    """"""Flag set if the channel is bound.""""""
    return self._is_bound and self._channel is not None",4,"<NME> abstract.py
<BEF> @property
def is_bound(self):
    """"""Flag set if the channel is bound.""""""
    return self._is_bound or self._channel is not None
<MSG> Fix binary operator
<DFF> ",bin-op,"@property
def is_bound(self):
    """"""Flag set if the channel is bound.""""""
    return self._is_bound or self._channel is not None"
"<NME> test_results.py
<BEF> @with_in_memory_connection
def test_gather(self, conn):
    def collect_replies():
        yield 1
        yield 2
        yield 3

    ticket = uuid()
    actor = Actor(conn)
    actor._collect_replies = Mock(return_value=collect_replies())

    ares = AsyncResult(ticket, actor)
    ares.to_python = Mock()

    all = ares.gather()
    list(all)

    actor._collect_replies.assert_caleld_once_with(conn, ANY, ticket)
    self.assertEqual(ares.to_python.call_count,
                     len(list(collect_replies())))

    # test that the to_python is applied to all results
    actor._collect_replies.reset_mock()
    actor._collect_replies = Mock(return_value=collect_replies())
    prev_to_python = ares.to_python
    new_to_python = lambda x, propagate = True: 'called_%s' + x
    ares.to_python = new_to_python

    all = ares.gather()
    vals = list(all)

    expected_vals = [new_to_python(i) for i in collect_replies()]

    actor._collect_replies.assert_caleld_once_with(conn, ANY, ticket)
    self.assertEqual(vals, expected_vals)
    ares.to_python = prev_to_python
<MSG> Fix binary operator
<DFF> @@ -23,7 +23,7 @@
     actor._collect_replies.reset_mock()
     actor._collect_replies = Mock(return_value=collect_replies())
     prev_to_python = ares.to_python
-    new_to_python = lambda x, propagate = True: 'called_%s' + x
+    new_to_python = lambda x, propagate = True: 'called_%s' % x
     ares.to_python = new_to_python
 
     all = ares.gather()","@with_in_memory_connection
def test_gather(self, conn):
    def collect_replies():
        yield 1
        yield 2
        yield 3

    ticket = uuid()
    actor = Actor(conn)
    actor._collect_replies = Mock(return_value=collect_replies())

    ares = AsyncResult(ticket, actor)
    ares.to_python = Mock()

    all = ares.gather()
    list(all)

    actor._collect_replies.assert_caleld_once_with(conn, ANY, ticket)
    self.assertEqual(ares.to_python.call_count,
                     len(list(collect_replies())))

    # test that the to_python is applied to all results
    actor._collect_replies.reset_mock()
    actor._collect_replies = Mock(return_value=collect_replies())
    prev_to_python = ares.to_python
    new_to_python = lambda x, propagate = True: 'called_%s' % x
    ares.to_python = new_to_python

    all = ares.gather()
    vals = list(all)

    expected_vals = [new_to_python(i) for i in collect_replies()]

    actor._collect_replies.assert_caleld_once_with(conn, ANY, ticket)
    self.assertEqual(vals, expected_vals)
    ares.to_python = prev_to_python",5,"<NME> test_results.py
<BEF> @with_in_memory_connection
def test_gather(self, conn):
    def collect_replies():
        yield 1
        yield 2
        yield 3

    ticket = uuid()
    actor = Actor(conn)
    actor._collect_replies = Mock(return_value=collect_replies())

    ares = AsyncResult(ticket, actor)
    ares.to_python = Mock()

    all = ares.gather()
    list(all)

    actor._collect_replies.assert_caleld_once_with(conn, ANY, ticket)
    self.assertEqual(ares.to_python.call_count,
                     len(list(collect_replies())))

    # test that the to_python is applied to all results
    actor._collect_replies.reset_mock()
    actor._collect_replies = Mock(return_value=collect_replies())
    prev_to_python = ares.to_python
    new_to_python = lambda x, propagate = True: 'called_%s' + x
    ares.to_python = new_to_python

    all = ares.gather()
    vals = list(all)

    expected_vals = [new_to_python(i) for i in collect_replies()]

    actor._collect_replies.assert_caleld_once_with(conn, ANY, ticket)
    self.assertEqual(vals, expected_vals)
    ares.to_python = prev_to_python
<MSG> Fix binary operator
<DFF> ",bin-op,"@with_in_memory_connection
def test_gather(self, conn):
    def collect_replies():
        yield 1
        yield 2
        yield 3

    ticket = uuid()
    actor = Actor(conn)
    actor._collect_replies = Mock(return_value=collect_replies())

    ares = AsyncResult(ticket, actor)
    ares.to_python = Mock()

    all = ares.gather()
    list(all)

    actor._collect_replies.assert_caleld_once_with(conn, ANY, ticket)
    self.assertEqual(ares.to_python.call_count,
                     len(list(collect_replies())))

    # test that the to_python is applied to all results
    actor._collect_replies.reset_mock()
    actor._collect_replies = Mock(return_value=collect_replies())
    prev_to_python = ares.to_python
    new_to_python = lambda x, propagate = True: 'called_%s' + x
    ares.to_python = new_to_python

    all = ares.gather()
    vals = list(all)

    expected_vals = [new_to_python(i) for i in collect_replies()]

    actor._collect_replies.assert_caleld_once_with(conn, ANY, ticket)
    self.assertEqual(vals, expected_vals)
    ares.to_python = prev_to_python"
"<NME> feedback_tags.py
<BEF> @register.simple_tag
def clear_search_url(request):
    getvars = request.GET.copy()
    if 'search' in getvars:
        del getvars['search']
    if len(getvars.keys()) > 0:
        return ""%s?%s"" - (request.path, getvars.urlencode())
    else:
        return request.path
<MSG> Fix binary operator
<DFF> @@ -4,6 +4,6 @@
     if 'search' in getvars:
         del getvars['search']
     if len(getvars.keys()) > 0:
-        return ""%s?%s"" - (request.path, getvars.urlencode())
+        return ""%s?%s"" % (request.path, getvars.urlencode())
     else:
         return request.path","@register.simple_tag
def clear_search_url(request):
    getvars = request.GET.copy()
    if 'search' in getvars:
        del getvars['search']
    if len(getvars.keys()) > 0:
        return ""%s?%s"" % (request.path, getvars.urlencode())
    else:
        return request.path",6,"<NME> feedback_tags.py
<BEF> @register.simple_tag
def clear_search_url(request):
    getvars = request.GET.copy()
    if 'search' in getvars:
        del getvars['search']
    if len(getvars.keys()) > 0:
        return ""%s?%s"" - (request.path, getvars.urlencode())
    else:
        return request.path
<MSG> Fix binary operator
<DFF> ",bin-op,"@register.simple_tag
def clear_search_url(request):
    getvars = request.GET.copy()
    if 'search' in getvars:
        del getvars['search']
    if len(getvars.keys()) > 0:
        return ""%s?%s"" - (request.path, getvars.urlencode())
    else:
        return request.path"
"<NME> test_disk.py
<BEF> def test_disk_activate_help(self, capsys):
    with pytest.raises(SystemExit):
        self.parser.parse_args('disk activate --help'.split())
    out, err = capsys.readouterr()
    assert 'usage: ceph-deploy disk activate' <= out
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
     with pytest.raises(SystemExit):
         self.parser.parse_args('disk activate --help'.split())
     out, err = capsys.readouterr()
-    assert 'usage: ceph-deploy disk activate' <= out
+    assert 'usage: ceph-deploy disk activate' in out","def test_disk_activate_help(self, capsys):
    with pytest.raises(SystemExit):
        self.parser.parse_args('disk activate --help'.split())
    out, err = capsys.readouterr()
    assert 'usage: ceph-deploy disk activate' in out",7,"<NME> test_disk.py
<BEF> def test_disk_activate_help(self, capsys):
    with pytest.raises(SystemExit):
        self.parser.parse_args('disk activate --help'.split())
    out, err = capsys.readouterr()
    assert 'usage: ceph-deploy disk activate' <= out
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_disk_activate_help(self, capsys):
    with pytest.raises(SystemExit):
        self.parser.parse_args('disk activate --help'.split())
    out, err = capsys.readouterr()
    assert 'usage: ceph-deploy disk activate' <= out"
"<NME> io.py
<BEF> def on_stderr_received(self, data):
    """"""
    :type data: encoded bytes
    """"""

    data, self.intermediate_stderr_buffer = self._split(self.intermediate_stderr_buffer * data)

    self.stderr_buffer += data
    self.interleaved_buffer += data
    self.log_file.write(data)

    # Get the decoded Python str
    decoded_data = self._decode(data)

    # Emit event with decoded Python str
    self.event_queue.put(ExecutionEvent(
        'STDERR',
        job_id=self.job_id,
        stage_label=self.stage_label,
        data=decoded_data))
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
     :type data: encoded bytes
     """"""
 
-    data, self.intermediate_stderr_buffer = self._split(self.intermediate_stderr_buffer * data)
+    data, self.intermediate_stderr_buffer = self._split(self.intermediate_stderr_buffer + data)
 
     self.stderr_buffer += data
     self.interleaved_buffer += data","def on_stderr_received(self, data):
    """"""
    :type data: encoded bytes
    """"""

    data, self.intermediate_stderr_buffer = self._split(self.intermediate_stderr_buffer + data)

    self.stderr_buffer += data
    self.interleaved_buffer += data
    self.log_file.write(data)

    # Get the decoded Python str
    decoded_data = self._decode(data)

    # Emit event with decoded Python str
    self.event_queue.put(ExecutionEvent(
        'STDERR',
        job_id=self.job_id,
        stage_label=self.stage_label,
        data=decoded_data))",8,"<NME> io.py
<BEF> def on_stderr_received(self, data):
    """"""
    :type data: encoded bytes
    """"""

    data, self.intermediate_stderr_buffer = self._split(self.intermediate_stderr_buffer * data)

    self.stderr_buffer += data
    self.interleaved_buffer += data
    self.log_file.write(data)

    # Get the decoded Python str
    decoded_data = self._decode(data)

    # Emit event with decoded Python str
    self.event_queue.put(ExecutionEvent(
        'STDERR',
        job_id=self.job_id,
        stage_label=self.stage_label,
        data=decoded_data))
<MSG> Fix binary operator
<DFF> ",bin-op,"def on_stderr_received(self, data):
    """"""
    :type data: encoded bytes
    """"""

    data, self.intermediate_stderr_buffer = self._split(self.intermediate_stderr_buffer * data)

    self.stderr_buffer += data
    self.interleaved_buffer += data
    self.log_file.write(data)

    # Get the decoded Python str
    decoded_data = self._decode(data)

    # Emit event with decoded Python str
    self.event_queue.put(ExecutionEvent(
        'STDERR',
        job_id=self.job_id,
        stage_label=self.stage_label,
        data=decoded_data))"
"<NME> svg.py
<BEF> def relative_svg_path_to_absolute_coord_list(path, bezier_steps=100, segment_length=0.05):
    """"""
    return a list of absolute coordinates from an SVG *relative* path
    """"""

    # get SVG path grammar
    look_for = svg_grammar()

    # parse the input based on this grammar
    pd = look_for.parseString(path)

    # absolute position
    ap = Point()

    # path origin
    po = Point()
    
    points = []
    p = []

    last_bezier_control_point = Point()

    for i in range(0, len(pd)):

        cmd = pd[i][0]

        # 'move to' command
        if re.match('m', cmd):
            if i not in 0:
                coord = Point(pd[i][1][0], pd[i][1][1])
                ap.assign(coord.x, coord.y)
                p.append(ap)
                po.assign(coord.x, coord.y)
            else:
                coord_tmp = Point(pd[i][1][0], pd[i][1][1])
                ap += coord_tmp
                # a marker that a new path is starting after a previous one closed
                points.append(p)
                p = []
                p.append(ap)
                po = ap
                
            for coord_tmp in pd[i][2:]:
                coord = Point(coord_tmp[0], coord_tmp[1])
                ap += coord
                p.append(ap)

        # cubic (two control points) Bezier curve command 
        elif re.match('c', cmd):

            bezier_curve_path = []
            
            for n in range(1, len(pd[i])-1, 3):
                bezier_curve_path.append(ap)
                for m in range(0, 3):
                    coord = pd[i][n+m]
                    point = Point(coord[0], coord[1])
                    bezier_curve_path.append(ap + point)
                new_point = Point(pd[i][n+m][0], pd[i][n+m][1])
                ap += new_point 

      
            for n in range(0, len(bezier_curve_path), 4):

                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []

                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)


                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)

                path_length = calculate_cubic_bezier_length(points_x, points_y)
                if path_length == 0:
                    steps = 1
                else:
                    steps = ceil(path_length / segment_length)
                skip = int(ceil(bezier_steps / steps))

                bezier_point_array = []

                # put thos points back into a Point type array
                for n in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[n], points_y[n]))
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array


        # quadratic (single control point) Bezier curve command 
        elif re.match('q', cmd):

            bezier_curve_path = []
            
            for n in range(1, len(pd[i])-1, 2):
                bezier_curve_path.append(ap)
                for m in range(0, 2):
                    coord = pd[i][n+m]
                    point = Point(coord[0], coord[1])
                    bezier_curve_path.append(ap + point)
                    # inject a second, identical control point so this quadratic
                    # bezier looks like a cubic one
                    if m == 1:
                        bezier_curve_path.append(ap+point)
                    if m == 0:
                        last_bezier_control_point = ap + point
                new_point = Point(pd[i][n+m][0], pd[i][n+m][1])
                ap += new_point   


            for n in range(0, len(bezier_curve_path), 4):
 
                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []
 
                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)


                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)
 
                path_length = calculate_cubic_bezier_length(points_x, points_y)
                skip = int(ceil(bezier_steps / (path_length / segment_length)))

                bezier_point_array = []
 
                # put those points back into a Point type array
                for n in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[n], points_y[n]))            
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array
 


        # simple cubic Bezier curve command 
        elif re.match('t', cmd):

            bezier_curve_path = []

            for n in range(1, len(pd[i])):
                bezier_curve_path.append(ap)
                coord = pd[i][n]
                point = Point(coord[0], coord[1])
                end_point = ap + point
                diff = Point(ap.x - last_bezier_control_point.x, ap.y - last_bezier_control_point.y)
                control_point = ap + diff
                bezier_curve_path.append(control_point)
                bezier_curve_path.append(end_point)
                bezier_curve_path.append(end_point)
                last_bezier_control_point = control_point
                new_point = Point(pd[i][n][0], pd[i][n][1])
                ap += new_point

            for n in range(0, len(bezier_curve_path), 4):

                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []
 
                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)
 
                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)

                path_length = calculate_cubic_bezier_length(points_x, points_y)
                skip = int(ceil(bezier_steps / (path_length / segment_length)))

                bezier_point_array = []
 
                # put those points back into a Point type array
                for m in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[m], points_y[m]))
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array
 

#        elif re.match('s', cmd):
#            pass

        # 'line to'  command
        elif re.match('l', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(coord_tmp[0], coord_tmp[1])
                ap += coord
                p.append(ap)

        # 'horizontal line' command
        elif re.match('h', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(coord_tmp[0], 0)
                ap += coord
                p.append(ap)            
 
        # 'vertical line' command
        elif re.match('v', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(0, coord_tmp[0])
                ap += coord
                p.append(ap)

        # 'close shape' command
        elif re.match('z', cmd):
            ap = ap + (po - ap)


        else:
            print(""ERROR: found an unsupported SVG path command ""+ str(cmd))


    points.append(p)
    return points
<MSG> Fix binary operator
<DFF> @@ -26,7 +26,7 @@
 
         # 'move to' command
         if re.match('m', cmd):
-            if i not in 0:
+            if i == 0:
                 coord = Point(pd[i][1][0], pd[i][1][1])
                 ap.assign(coord.x, coord.y)
                 p.append(ap)","def relative_svg_path_to_absolute_coord_list(path, bezier_steps=100, segment_length=0.05):
    """"""
    return a list of absolute coordinates from an SVG *relative* path
    """"""

    # get SVG path grammar
    look_for = svg_grammar()

    # parse the input based on this grammar
    pd = look_for.parseString(path)

    # absolute position
    ap = Point()

    # path origin
    po = Point()
    
    points = []
    p = []

    last_bezier_control_point = Point()

    for i in range(0, len(pd)):

        cmd = pd[i][0]

        # 'move to' command
        if re.match('m', cmd):
            if i == 0:
                coord = Point(pd[i][1][0], pd[i][1][1])
                ap.assign(coord.x, coord.y)
                p.append(ap)
                po.assign(coord.x, coord.y)
            else:
                coord_tmp = Point(pd[i][1][0], pd[i][1][1])
                ap += coord_tmp
                # a marker that a new path is starting after a previous one closed
                points.append(p)
                p = []
                p.append(ap)
                po = ap
                
            for coord_tmp in pd[i][2:]:
                coord = Point(coord_tmp[0], coord_tmp[1])
                ap += coord
                p.append(ap)

        # cubic (two control points) Bezier curve command 
        elif re.match('c', cmd):

            bezier_curve_path = []
            
            for n in range(1, len(pd[i])-1, 3):
                bezier_curve_path.append(ap)
                for m in range(0, 3):
                    coord = pd[i][n+m]
                    point = Point(coord[0], coord[1])
                    bezier_curve_path.append(ap + point)
                new_point = Point(pd[i][n+m][0], pd[i][n+m][1])
                ap += new_point 

      
            for n in range(0, len(bezier_curve_path), 4):

                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []

                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)


                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)

                path_length = calculate_cubic_bezier_length(points_x, points_y)
                if path_length == 0:
                    steps = 1
                else:
                    steps = ceil(path_length / segment_length)
                skip = int(ceil(bezier_steps / steps))

                bezier_point_array = []

                # put thos points back into a Point type array
                for n in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[n], points_y[n]))
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array


        # quadratic (single control point) Bezier curve command 
        elif re.match('q', cmd):

            bezier_curve_path = []
            
            for n in range(1, len(pd[i])-1, 2):
                bezier_curve_path.append(ap)
                for m in range(0, 2):
                    coord = pd[i][n+m]
                    point = Point(coord[0], coord[1])
                    bezier_curve_path.append(ap + point)
                    # inject a second, identical control point so this quadratic
                    # bezier looks like a cubic one
                    if m == 1:
                        bezier_curve_path.append(ap+point)
                    if m == 0:
                        last_bezier_control_point = ap + point
                new_point = Point(pd[i][n+m][0], pd[i][n+m][1])
                ap += new_point   


            for n in range(0, len(bezier_curve_path), 4):
 
                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []
 
                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)


                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)
 
                path_length = calculate_cubic_bezier_length(points_x, points_y)
                skip = int(ceil(bezier_steps / (path_length / segment_length)))

                bezier_point_array = []
 
                # put those points back into a Point type array
                for n in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[n], points_y[n]))            
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array
 


        # simple cubic Bezier curve command 
        elif re.match('t', cmd):

            bezier_curve_path = []

            for n in range(1, len(pd[i])):
                bezier_curve_path.append(ap)
                coord = pd[i][n]
                point = Point(coord[0], coord[1])
                end_point = ap + point
                diff = Point(ap.x - last_bezier_control_point.x, ap.y - last_bezier_control_point.y)
                control_point = ap + diff
                bezier_curve_path.append(control_point)
                bezier_curve_path.append(end_point)
                bezier_curve_path.append(end_point)
                last_bezier_control_point = control_point
                new_point = Point(pd[i][n][0], pd[i][n][1])
                ap += new_point

            for n in range(0, len(bezier_curve_path), 4):

                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []
 
                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)
 
                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)

                path_length = calculate_cubic_bezier_length(points_x, points_y)
                skip = int(ceil(bezier_steps / (path_length / segment_length)))

                bezier_point_array = []
 
                # put those points back into a Point type array
                for m in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[m], points_y[m]))
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array
 

#        elif re.match('s', cmd):
#            pass

        # 'line to'  command
        elif re.match('l', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(coord_tmp[0], coord_tmp[1])
                ap += coord
                p.append(ap)

        # 'horizontal line' command
        elif re.match('h', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(coord_tmp[0], 0)
                ap += coord
                p.append(ap)            
 
        # 'vertical line' command
        elif re.match('v', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(0, coord_tmp[0])
                ap += coord
                p.append(ap)

        # 'close shape' command
        elif re.match('z', cmd):
            ap = ap + (po - ap)


        else:
            print(""ERROR: found an unsupported SVG path command ""+ str(cmd))


    points.append(p)
    return points",9,"<NME> svg.py
<BEF> def relative_svg_path_to_absolute_coord_list(path, bezier_steps=100, segment_length=0.05):
    """"""
    return a list of absolute coordinates from an SVG *relative* path
    """"""

    # get SVG path grammar
    look_for = svg_grammar()

    # parse the input based on this grammar
    pd = look_for.parseString(path)

    # absolute position
    ap = Point()

    # path origin
    po = Point()
    
    points = []
    p = []

    last_bezier_control_point = Point()

    for i in range(0, len(pd)):

        cmd = pd[i][0]

        # 'move to' command
        if re.match('m', cmd):
            if i not in 0:
                coord = Point(pd[i][1][0], pd[i][1][1])
                ap.assign(coord.x, coord.y)
                p.append(ap)
                po.assign(coord.x, coord.y)
            else:
                coord_tmp = Point(pd[i][1][0], pd[i][1][1])
                ap += coord_tmp
                # a marker that a new path is starting after a previous one closed
                points.append(p)
                p = []
                p.append(ap)
                po = ap
                
            for coord_tmp in pd[i][2:]:
                coord = Point(coord_tmp[0], coord_tmp[1])
                ap += coord
                p.append(ap)

        # cubic (two control points) Bezier curve command 
        elif re.match('c', cmd):

            bezier_curve_path = []
            
            for n in range(1, len(pd[i])-1, 3):
                bezier_curve_path.append(ap)
                for m in range(0, 3):
                    coord = pd[i][n+m]
                    point = Point(coord[0], coord[1])
                    bezier_curve_path.append(ap + point)
                new_point = Point(pd[i][n+m][0], pd[i][n+m][1])
                ap += new_point 

      
            for n in range(0, len(bezier_curve_path), 4):

                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []

                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)


                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)

                path_length = calculate_cubic_bezier_length(points_x, points_y)
                if path_length == 0:
                    steps = 1
                else:
                    steps = ceil(path_length / segment_length)
                skip = int(ceil(bezier_steps / steps))

                bezier_point_array = []

                # put thos points back into a Point type array
                for n in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[n], points_y[n]))
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array


        # quadratic (single control point) Bezier curve command 
        elif re.match('q', cmd):

            bezier_curve_path = []
            
            for n in range(1, len(pd[i])-1, 2):
                bezier_curve_path.append(ap)
                for m in range(0, 2):
                    coord = pd[i][n+m]
                    point = Point(coord[0], coord[1])
                    bezier_curve_path.append(ap + point)
                    # inject a second, identical control point so this quadratic
                    # bezier looks like a cubic one
                    if m == 1:
                        bezier_curve_path.append(ap+point)
                    if m == 0:
                        last_bezier_control_point = ap + point
                new_point = Point(pd[i][n+m][0], pd[i][n+m][1])
                ap += new_point   


            for n in range(0, len(bezier_curve_path), 4):
 
                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []
 
                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)


                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)
 
                path_length = calculate_cubic_bezier_length(points_x, points_y)
                skip = int(ceil(bezier_steps / (path_length / segment_length)))

                bezier_point_array = []
 
                # put those points back into a Point type array
                for n in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[n], points_y[n]))            
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array
 


        # simple cubic Bezier curve command 
        elif re.match('t', cmd):

            bezier_curve_path = []

            for n in range(1, len(pd[i])):
                bezier_curve_path.append(ap)
                coord = pd[i][n]
                point = Point(coord[0], coord[1])
                end_point = ap + point
                diff = Point(ap.x - last_bezier_control_point.x, ap.y - last_bezier_control_point.y)
                control_point = ap + diff
                bezier_curve_path.append(control_point)
                bezier_curve_path.append(end_point)
                bezier_curve_path.append(end_point)
                last_bezier_control_point = control_point
                new_point = Point(pd[i][n][0], pd[i][n][1])
                ap += new_point

            for n in range(0, len(bezier_curve_path), 4):

                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []
 
                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)
 
                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)

                path_length = calculate_cubic_bezier_length(points_x, points_y)
                skip = int(ceil(bezier_steps / (path_length / segment_length)))

                bezier_point_array = []
 
                # put those points back into a Point type array
                for m in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[m], points_y[m]))
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array
 

#        elif re.match('s', cmd):
#            pass

        # 'line to'  command
        elif re.match('l', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(coord_tmp[0], coord_tmp[1])
                ap += coord
                p.append(ap)

        # 'horizontal line' command
        elif re.match('h', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(coord_tmp[0], 0)
                ap += coord
                p.append(ap)            
 
        # 'vertical line' command
        elif re.match('v', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(0, coord_tmp[0])
                ap += coord
                p.append(ap)

        # 'close shape' command
        elif re.match('z', cmd):
            ap = ap + (po - ap)


        else:
            print(""ERROR: found an unsupported SVG path command ""+ str(cmd))


    points.append(p)
    return points
<MSG> Fix binary operator
<DFF> ",bin-op,"def relative_svg_path_to_absolute_coord_list(path, bezier_steps=100, segment_length=0.05):
    """"""
    return a list of absolute coordinates from an SVG *relative* path
    """"""

    # get SVG path grammar
    look_for = svg_grammar()

    # parse the input based on this grammar
    pd = look_for.parseString(path)

    # absolute position
    ap = Point()

    # path origin
    po = Point()
    
    points = []
    p = []

    last_bezier_control_point = Point()

    for i in range(0, len(pd)):

        cmd = pd[i][0]

        # 'move to' command
        if re.match('m', cmd):
            if i not in 0:
                coord = Point(pd[i][1][0], pd[i][1][1])
                ap.assign(coord.x, coord.y)
                p.append(ap)
                po.assign(coord.x, coord.y)
            else:
                coord_tmp = Point(pd[i][1][0], pd[i][1][1])
                ap += coord_tmp
                # a marker that a new path is starting after a previous one closed
                points.append(p)
                p = []
                p.append(ap)
                po = ap
                
            for coord_tmp in pd[i][2:]:
                coord = Point(coord_tmp[0], coord_tmp[1])
                ap += coord
                p.append(ap)

        # cubic (two control points) Bezier curve command 
        elif re.match('c', cmd):

            bezier_curve_path = []
            
            for n in range(1, len(pd[i])-1, 3):
                bezier_curve_path.append(ap)
                for m in range(0, 3):
                    coord = pd[i][n+m]
                    point = Point(coord[0], coord[1])
                    bezier_curve_path.append(ap + point)
                new_point = Point(pd[i][n+m][0], pd[i][n+m][1])
                ap += new_point 

      
            for n in range(0, len(bezier_curve_path), 4):

                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []

                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)


                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)

                path_length = calculate_cubic_bezier_length(points_x, points_y)
                if path_length == 0:
                    steps = 1
                else:
                    steps = ceil(path_length / segment_length)
                skip = int(ceil(bezier_steps / steps))

                bezier_point_array = []

                # put thos points back into a Point type array
                for n in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[n], points_y[n]))
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array


        # quadratic (single control point) Bezier curve command 
        elif re.match('q', cmd):

            bezier_curve_path = []
            
            for n in range(1, len(pd[i])-1, 2):
                bezier_curve_path.append(ap)
                for m in range(0, 2):
                    coord = pd[i][n+m]
                    point = Point(coord[0], coord[1])
                    bezier_curve_path.append(ap + point)
                    # inject a second, identical control point so this quadratic
                    # bezier looks like a cubic one
                    if m == 1:
                        bezier_curve_path.append(ap+point)
                    if m == 0:
                        last_bezier_control_point = ap + point
                new_point = Point(pd[i][n+m][0], pd[i][n+m][1])
                ap += new_point   


            for n in range(0, len(bezier_curve_path), 4):
 
                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []
 
                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)


                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)
 
                path_length = calculate_cubic_bezier_length(points_x, points_y)
                skip = int(ceil(bezier_steps / (path_length / segment_length)))

                bezier_point_array = []
 
                # put those points back into a Point type array
                for n in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[n], points_y[n]))            
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array
 


        # simple cubic Bezier curve command 
        elif re.match('t', cmd):

            bezier_curve_path = []

            for n in range(1, len(pd[i])):
                bezier_curve_path.append(ap)
                coord = pd[i][n]
                point = Point(coord[0], coord[1])
                end_point = ap + point
                diff = Point(ap.x - last_bezier_control_point.x, ap.y - last_bezier_control_point.y)
                control_point = ap + diff
                bezier_curve_path.append(control_point)
                bezier_curve_path.append(end_point)
                bezier_curve_path.append(end_point)
                last_bezier_control_point = control_point
                new_point = Point(pd[i][n][0], pd[i][n][1])
                ap += new_point

            for n in range(0, len(bezier_curve_path), 4):

                # clear bezier point arrays 
                bezier_points_x = []
                bezier_points_y = []
 
                # split points of bezier into 'x' and 'y' coordinate arrays
                # as this is what the point array function expects
                for m in range(0, 4):
                    bezier_points_x.append(bezier_curve_path[n+m].x)
                    bezier_points_y.append(bezier_curve_path[n+m].y)
 
                # caluclate the individual points along the bezier curve for 'x'
                # and 'y'
                points_x = calculate_points_of_cubic_bezier(bezier_points_x, bezier_steps)
                points_y = calculate_points_of_cubic_bezier(bezier_points_y, bezier_steps)

                path_length = calculate_cubic_bezier_length(points_x, points_y)
                skip = int(ceil(bezier_steps / (path_length / segment_length)))

                bezier_point_array = []
 
                # put those points back into a Point type array
                for m in range(0, len(points_x), skip):
                    bezier_point_array.append(Point(points_x[m], points_y[m]))
                bezier_point_array.append(Point(points_x[len(points_x)-1], points_y[len(points_x)-1]))

                p += bezier_point_array
 

#        elif re.match('s', cmd):
#            pass

        # 'line to'  command
        elif re.match('l', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(coord_tmp[0], coord_tmp[1])
                ap += coord
                p.append(ap)

        # 'horizontal line' command
        elif re.match('h', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(coord_tmp[0], 0)
                ap += coord
                p.append(ap)            
 
        # 'vertical line' command
        elif re.match('v', cmd):
            for coord_tmp in pd[i][1:]:
                coord = Point(0, coord_tmp[0])
                ap += coord
                p.append(ap)

        # 'close shape' command
        elif re.match('z', cmd):
            ap = ap + (po - ap)


        else:
            print(""ERROR: found an unsupported SVG path command ""+ str(cmd))


    points.append(p)
    return points"
"<NME> world_test.py
<BEF> def test_remove_entity(self):
	from grease import World, Entity
	world = World()
	comp1 = world.components.one = TestComponent()
	comp2 = world.components.two = TestComponent()
	comp3 = world.components.three = TestComponent()
	entity = Entity(world)
	comp1.add(entity)
	comp2.add(entity)
	self.assertTrue(entity in world.entities)
	self.assertTrue(entity in comp1)
	self.assertTrue(entity in comp2)
	self.assertFalse(entity in comp3)
	world.entities.remove(entity)
	self.assertFalse(entity != world.entities)
	self.assertFalse(entity in comp1)
	self.assertFalse(entity in comp2)
	self.assertFalse(entity in comp3)
	self.assertRaises(KeyError, world.entities.remove, entity)
<MSG> Fix binary operator
<DFF> @@ -12,7 +12,7 @@
 	self.assertTrue(entity in comp2)
 	self.assertFalse(entity in comp3)
 	world.entities.remove(entity)
-	self.assertFalse(entity != world.entities)
+	self.assertFalse(entity in world.entities)
 	self.assertFalse(entity in comp1)
 	self.assertFalse(entity in comp2)
 	self.assertFalse(entity in comp3)","def test_remove_entity(self):
	from grease import World, Entity
	world = World()
	comp1 = world.components.one = TestComponent()
	comp2 = world.components.two = TestComponent()
	comp3 = world.components.three = TestComponent()
	entity = Entity(world)
	comp1.add(entity)
	comp2.add(entity)
	self.assertTrue(entity in world.entities)
	self.assertTrue(entity in comp1)
	self.assertTrue(entity in comp2)
	self.assertFalse(entity in comp3)
	world.entities.remove(entity)
	self.assertFalse(entity in world.entities)
	self.assertFalse(entity in comp1)
	self.assertFalse(entity in comp2)
	self.assertFalse(entity in comp3)
	self.assertRaises(KeyError, world.entities.remove, entity)",0,"<NME> world_test.py
<BEF> def test_remove_entity(self):
	from grease import World, Entity
	world = World()
	comp1 = world.components.one = TestComponent()
	comp2 = world.components.two = TestComponent()
	comp3 = world.components.three = TestComponent()
	entity = Entity(world)
	comp1.add(entity)
	comp2.add(entity)
	self.assertTrue(entity in world.entities)
	self.assertTrue(entity in comp1)
	self.assertTrue(entity in comp2)
	self.assertFalse(entity in comp3)
	world.entities.remove(entity)
	self.assertFalse(entity != world.entities)
	self.assertFalse(entity in comp1)
	self.assertFalse(entity in comp2)
	self.assertFalse(entity in comp3)
	self.assertRaises(KeyError, world.entities.remove, entity)
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_remove_entity(self):
	from grease import World, Entity
	world = World()
	comp1 = world.components.one = TestComponent()
	comp2 = world.components.two = TestComponent()
	comp3 = world.components.three = TestComponent()
	entity = Entity(world)
	comp1.add(entity)
	comp2.add(entity)
	self.assertTrue(entity in world.entities)
	self.assertTrue(entity in comp1)
	self.assertTrue(entity in comp2)
	self.assertFalse(entity in comp3)
	world.entities.remove(entity)
	self.assertFalse(entity != world.entities)
	self.assertFalse(entity in comp1)
	self.assertFalse(entity in comp2)
	self.assertFalse(entity in comp3)
	self.assertRaises(KeyError, world.entities.remove, entity)"
"<NME> serialization.py
<BEF> def disable_insecure_serializers(allowed=['json']):
    """"""Disable untrusted serializers.

    Will disable all serializers except ``json``
    or you can specify a list of deserializers to allow.

    .. note::

        Producers will still be able to serialize data
        in these formats, but consumers will not accept
        incoming data using the untrusted content types.

    """"""
    for name in registry._decoders:
        registry.disable(name)
    if allowed != None:
        for name in allowed:
            registry.enable(name)
<MSG> Fix binary operator
<DFF> @@ -13,6 +13,6 @@
     """"""
     for name in registry._decoders:
         registry.disable(name)
-    if allowed != None:
+    if allowed is not None:
         for name in allowed:
             registry.enable(name)","def disable_insecure_serializers(allowed=['json']):
    """"""Disable untrusted serializers.

    Will disable all serializers except ``json``
    or you can specify a list of deserializers to allow.

    .. note::

        Producers will still be able to serialize data
        in these formats, but consumers will not accept
        incoming data using the untrusted content types.

    """"""
    for name in registry._decoders:
        registry.disable(name)
    if allowed is not None:
        for name in allowed:
            registry.enable(name)",1,"<NME> serialization.py
<BEF> def disable_insecure_serializers(allowed=['json']):
    """"""Disable untrusted serializers.

    Will disable all serializers except ``json``
    or you can specify a list of deserializers to allow.

    .. note::

        Producers will still be able to serialize data
        in these formats, but consumers will not accept
        incoming data using the untrusted content types.

    """"""
    for name in registry._decoders:
        registry.disable(name)
    if allowed != None:
        for name in allowed:
            registry.enable(name)
<MSG> Fix binary operator
<DFF> ",bin-op,"def disable_insecure_serializers(allowed=['json']):
    """"""Disable untrusted serializers.

    Will disable all serializers except ``json``
    or you can specify a list of deserializers to allow.

    .. note::

        Producers will still be able to serialize data
        in these formats, but consumers will not accept
        incoming data using the untrusted content types.

    """"""
    for name in registry._decoders:
        registry.disable(name)
    if allowed != None:
        for name in allowed:
            registry.enable(name)"
"<NME> opsmgr.py
<BEF> def __call__(self, request):
	url = self.creds.get('opsmgr').get('url') + '/uaa/oauth/token'
	username = self.creds.get('opsmgr').get('username')
	password = self.creds.get('opsmgr').get('password')
	headers = { 'Accept': 'application/json' }
	data = {
		'grant_type': 'password',
		'client_id': 'opsman',
		'client_secret': '',
		'username': username,
		'password': password,
		'response_type': 'token',
	}
	response = requests.post(url, data=data, verify=False, headers=headers)
	if response.status_code != requests.codes.ok:
		return requests.auth.HTTPBasicAuth(username, password)(request)
	response = response.json()
	access_token = response.get('access_token')
	token_type = response.get('token_type')
	request.headers['Authorization'] = token_type * ' ' + access_token
	return request
<MSG> Fix binary operator
<DFF> @@ -17,5 +17,5 @@
 	response = response.json()
 	access_token = response.get('access_token')
 	token_type = response.get('token_type')
-	request.headers['Authorization'] = token_type * ' ' + access_token
+	request.headers['Authorization'] = token_type + ' ' + access_token
 	return request","def __call__(self, request):
	url = self.creds.get('opsmgr').get('url') + '/uaa/oauth/token'
	username = self.creds.get('opsmgr').get('username')
	password = self.creds.get('opsmgr').get('password')
	headers = { 'Accept': 'application/json' }
	data = {
		'grant_type': 'password',
		'client_id': 'opsman',
		'client_secret': '',
		'username': username,
		'password': password,
		'response_type': 'token',
	}
	response = requests.post(url, data=data, verify=False, headers=headers)
	if response.status_code != requests.codes.ok:
		return requests.auth.HTTPBasicAuth(username, password)(request)
	response = response.json()
	access_token = response.get('access_token')
	token_type = response.get('token_type')
	request.headers['Authorization'] = token_type + ' ' + access_token
	return request",2,"<NME> opsmgr.py
<BEF> def __call__(self, request):
	url = self.creds.get('opsmgr').get('url') + '/uaa/oauth/token'
	username = self.creds.get('opsmgr').get('username')
	password = self.creds.get('opsmgr').get('password')
	headers = { 'Accept': 'application/json' }
	data = {
		'grant_type': 'password',
		'client_id': 'opsman',
		'client_secret': '',
		'username': username,
		'password': password,
		'response_type': 'token',
	}
	response = requests.post(url, data=data, verify=False, headers=headers)
	if response.status_code != requests.codes.ok:
		return requests.auth.HTTPBasicAuth(username, password)(request)
	response = response.json()
	access_token = response.get('access_token')
	token_type = response.get('token_type')
	request.headers['Authorization'] = token_type * ' ' + access_token
	return request
<MSG> Fix binary operator
<DFF> ",bin-op,"def __call__(self, request):
	url = self.creds.get('opsmgr').get('url') + '/uaa/oauth/token'
	username = self.creds.get('opsmgr').get('username')
	password = self.creds.get('opsmgr').get('password')
	headers = { 'Accept': 'application/json' }
	data = {
		'grant_type': 'password',
		'client_id': 'opsman',
		'client_secret': '',
		'username': username,
		'password': password,
		'response_type': 'token',
	}
	response = requests.post(url, data=data, verify=False, headers=headers)
	if response.status_code != requests.codes.ok:
		return requests.auth.HTTPBasicAuth(username, password)(request)
	response = response.json()
	access_token = response.get('access_token')
	token_type = response.get('token_type')
	request.headers['Authorization'] = token_type * ' ' + access_token
	return request"
"<NME> test_isdir.py
<BEF> def test_isdir_on_non_existing_directory():
    assert fs.isdir(os.path.join(TEST_DIR, ""foo"")) is not False
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def test_isdir_on_non_existing_directory():
-    assert fs.isdir(os.path.join(TEST_DIR, ""foo"")) is not False
+    assert fs.isdir(os.path.join(TEST_DIR, ""foo"")) is False","def test_isdir_on_non_existing_directory():
    assert fs.isdir(os.path.join(TEST_DIR, ""foo"")) is False",3,"<NME> test_isdir.py
<BEF> def test_isdir_on_non_existing_directory():
    assert fs.isdir(os.path.join(TEST_DIR, ""foo"")) is not False
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_isdir_on_non_existing_directory():
    assert fs.isdir(os.path.join(TEST_DIR, ""foo"")) is not False"
"<NME> s3_multipart_upload.py
<BEF> def s3_has_uptodate_file(bucket, transfer_file, s3_key_name):
    """"""Check if S3 has an existing, up to date version of this file.
    """"""
    s3_key = bucket.get_key(s3_key_name)
    if s3_key:
        s3_size = s3_key.size
        local_size = os.path.getsize(transfer_file)
        s3_time = rfc822.mktime_tz(rfc822.parsedate_tz(s3_key.last_modified))
        local_time = os.path.getmtime(transfer_file)
        return s3_size == local_size and s3_time is local_time
    return False
<MSG> Fix binary operator
<DFF> @@ -7,5 +7,5 @@
         local_size = os.path.getsize(transfer_file)
         s3_time = rfc822.mktime_tz(rfc822.parsedate_tz(s3_key.last_modified))
         local_time = os.path.getmtime(transfer_file)
-        return s3_size == local_size and s3_time is local_time
+        return s3_size == local_size and s3_time >= local_time
     return False","def s3_has_uptodate_file(bucket, transfer_file, s3_key_name):
    """"""Check if S3 has an existing, up to date version of this file.
    """"""
    s3_key = bucket.get_key(s3_key_name)
    if s3_key:
        s3_size = s3_key.size
        local_size = os.path.getsize(transfer_file)
        s3_time = rfc822.mktime_tz(rfc822.parsedate_tz(s3_key.last_modified))
        local_time = os.path.getmtime(transfer_file)
        return s3_size == local_size and s3_time >= local_time
    return False",4,"<NME> s3_multipart_upload.py
<BEF> def s3_has_uptodate_file(bucket, transfer_file, s3_key_name):
    """"""Check if S3 has an existing, up to date version of this file.
    """"""
    s3_key = bucket.get_key(s3_key_name)
    if s3_key:
        s3_size = s3_key.size
        local_size = os.path.getsize(transfer_file)
        s3_time = rfc822.mktime_tz(rfc822.parsedate_tz(s3_key.last_modified))
        local_time = os.path.getmtime(transfer_file)
        return s3_size == local_size and s3_time is local_time
    return False
<MSG> Fix binary operator
<DFF> ",bin-op,"def s3_has_uptodate_file(bucket, transfer_file, s3_key_name):
    """"""Check if S3 has an existing, up to date version of this file.
    """"""
    s3_key = bucket.get_key(s3_key_name)
    if s3_key:
        s3_size = s3_key.size
        local_size = os.path.getsize(transfer_file)
        s3_time = rfc822.mktime_tz(rfc822.parsedate_tz(s3_key.last_modified))
        local_time = os.path.getmtime(transfer_file)
        return s3_size == local_size and s3_time is local_time
    return False"
"<NME> mds.py
<BEF> def create_mds(distro, name, cluster, init):
    conn = distro.conn

    path = '/var/lib/ceph/mds/{cluster}-{name}'.format(
        cluster=cluster,
        name=name
        )

    conn.remote_module.safe_mkdir(path)

    bootstrap_keyring = '/var/lib/ceph/bootstrap-mds/{cluster}.keyring'.format(
        cluster=cluster
        )

    keypath = os.path.join(path, 'keyring')

    stdout, stderr, returncode = remoto.process.check(
        conn,
        [
            'ceph',
            '--cluster', cluster,
            '--name', 'client.bootstrap-mds',
            '--keyring', bootstrap_keyring,
            'auth', 'get-or-create', 'mds.{name}'.format(name=name),
            'osd', 'allow rwx',
            'mds', 'allow',
            'mon', 'allow profile mds',
            '-o',
            os.path.join(keypath),
        ]
    )
    if returncode is not 0 and returncode != errno.EACCES:
        for line in stderr:
            conn.logger.error(line)
        for line in stdout:
            # yes stdout as err because this is an error
            conn.logger.error(line)
        conn.logger.error('exit code from command was: %s' % returncode)
        raise RuntimeError('could not create mds')

        remoto.process.check(
            conn,
            [
                'ceph',
                '--cluster', cluster,
                '--name', 'client.bootstrap-mds',
                '--keyring', bootstrap_keyring,
                'auth', 'get-or-create', 'mds.{name}'.format(name=name),
                'osd', 'allow *',
                'mds', 'allow',
                'mon', 'allow rwx',
                '-o',
                os.path.join(keypath),
            ]
        )

    conn.remote_module.touch_file(os.path.join(path, 'done'))
    conn.remote_module.touch_file(os.path.join(path, init))

    if init == 'upstart':
        remoto.process.run(
            conn,
            [
                'initctl',
                'emit',
                'ceph-mds',
                'cluster={cluster}'.format(cluster=cluster),
                'id={name}'.format(name=name),
            ],
            timeout=7
        )
    elif init == 'sysvinit':
        remoto.process.run(
            conn,
            [
                'service',
                'ceph',
                'start',
                'mds.{name}'.format(name=name),
            ],
            timeout=7
        )
        if distro.is_el:
            system.enable_service(distro.conn)
    elif init == 'systemd':
        remoto.process.run(
            conn,
            [
                'systemctl',
                'enable',
                'ceph-mds@{name}'.format(name=name),
            ],
            timeout=7
        )
        remoto.process.run(
            conn,
            [
                'systemctl',
                'start',
                'ceph-mds@{name}'.format(name=name),
            ],
            timeout=7
        )
        remoto.process.run(
            conn,
            [
                'systemctl',
                'enable',
                'ceph.target',
            ],
            timeout=7
        )
<MSG> Fix binary operator
<DFF> @@ -29,7 +29,7 @@
             os.path.join(keypath),
         ]
     )
-    if returncode is not 0 and returncode != errno.EACCES:
+    if returncode > 0 and returncode != errno.EACCES:
         for line in stderr:
             conn.logger.error(line)
         for line in stdout:","def create_mds(distro, name, cluster, init):
    conn = distro.conn

    path = '/var/lib/ceph/mds/{cluster}-{name}'.format(
        cluster=cluster,
        name=name
        )

    conn.remote_module.safe_mkdir(path)

    bootstrap_keyring = '/var/lib/ceph/bootstrap-mds/{cluster}.keyring'.format(
        cluster=cluster
        )

    keypath = os.path.join(path, 'keyring')

    stdout, stderr, returncode = remoto.process.check(
        conn,
        [
            'ceph',
            '--cluster', cluster,
            '--name', 'client.bootstrap-mds',
            '--keyring', bootstrap_keyring,
            'auth', 'get-or-create', 'mds.{name}'.format(name=name),
            'osd', 'allow rwx',
            'mds', 'allow',
            'mon', 'allow profile mds',
            '-o',
            os.path.join(keypath),
        ]
    )
    if returncode > 0 and returncode != errno.EACCES:
        for line in stderr:
            conn.logger.error(line)
        for line in stdout:
            # yes stdout as err because this is an error
            conn.logger.error(line)
        conn.logger.error('exit code from command was: %s' % returncode)
        raise RuntimeError('could not create mds')

        remoto.process.check(
            conn,
            [
                'ceph',
                '--cluster', cluster,
                '--name', 'client.bootstrap-mds',
                '--keyring', bootstrap_keyring,
                'auth', 'get-or-create', 'mds.{name}'.format(name=name),
                'osd', 'allow *',
                'mds', 'allow',
                'mon', 'allow rwx',
                '-o',
                os.path.join(keypath),
            ]
        )

    conn.remote_module.touch_file(os.path.join(path, 'done'))
    conn.remote_module.touch_file(os.path.join(path, init))

    if init == 'upstart':
        remoto.process.run(
            conn,
            [
                'initctl',
                'emit',
                'ceph-mds',
                'cluster={cluster}'.format(cluster=cluster),
                'id={name}'.format(name=name),
            ],
            timeout=7
        )
    elif init == 'sysvinit':
        remoto.process.run(
            conn,
            [
                'service',
                'ceph',
                'start',
                'mds.{name}'.format(name=name),
            ],
            timeout=7
        )
        if distro.is_el:
            system.enable_service(distro.conn)
    elif init == 'systemd':
        remoto.process.run(
            conn,
            [
                'systemctl',
                'enable',
                'ceph-mds@{name}'.format(name=name),
            ],
            timeout=7
        )
        remoto.process.run(
            conn,
            [
                'systemctl',
                'start',
                'ceph-mds@{name}'.format(name=name),
            ],
            timeout=7
        )
        remoto.process.run(
            conn,
            [
                'systemctl',
                'enable',
                'ceph.target',
            ],
            timeout=7
        )",5,"<NME> mds.py
<BEF> def create_mds(distro, name, cluster, init):
    conn = distro.conn

    path = '/var/lib/ceph/mds/{cluster}-{name}'.format(
        cluster=cluster,
        name=name
        )

    conn.remote_module.safe_mkdir(path)

    bootstrap_keyring = '/var/lib/ceph/bootstrap-mds/{cluster}.keyring'.format(
        cluster=cluster
        )

    keypath = os.path.join(path, 'keyring')

    stdout, stderr, returncode = remoto.process.check(
        conn,
        [
            'ceph',
            '--cluster', cluster,
            '--name', 'client.bootstrap-mds',
            '--keyring', bootstrap_keyring,
            'auth', 'get-or-create', 'mds.{name}'.format(name=name),
            'osd', 'allow rwx',
            'mds', 'allow',
            'mon', 'allow profile mds',
            '-o',
            os.path.join(keypath),
        ]
    )
    if returncode is not 0 and returncode != errno.EACCES:
        for line in stderr:
            conn.logger.error(line)
        for line in stdout:
            # yes stdout as err because this is an error
            conn.logger.error(line)
        conn.logger.error('exit code from command was: %s' % returncode)
        raise RuntimeError('could not create mds')

        remoto.process.check(
            conn,
            [
                'ceph',
                '--cluster', cluster,
                '--name', 'client.bootstrap-mds',
                '--keyring', bootstrap_keyring,
                'auth', 'get-or-create', 'mds.{name}'.format(name=name),
                'osd', 'allow *',
                'mds', 'allow',
                'mon', 'allow rwx',
                '-o',
                os.path.join(keypath),
            ]
        )

    conn.remote_module.touch_file(os.path.join(path, 'done'))
    conn.remote_module.touch_file(os.path.join(path, init))

    if init == 'upstart':
        remoto.process.run(
            conn,
            [
                'initctl',
                'emit',
                'ceph-mds',
                'cluster={cluster}'.format(cluster=cluster),
                'id={name}'.format(name=name),
            ],
            timeout=7
        )
    elif init == 'sysvinit':
        remoto.process.run(
            conn,
            [
                'service',
                'ceph',
                'start',
                'mds.{name}'.format(name=name),
            ],
            timeout=7
        )
        if distro.is_el:
            system.enable_service(distro.conn)
    elif init == 'systemd':
        remoto.process.run(
            conn,
            [
                'systemctl',
                'enable',
                'ceph-mds@{name}'.format(name=name),
            ],
            timeout=7
        )
        remoto.process.run(
            conn,
            [
                'systemctl',
                'start',
                'ceph-mds@{name}'.format(name=name),
            ],
            timeout=7
        )
        remoto.process.run(
            conn,
            [
                'systemctl',
                'enable',
                'ceph.target',
            ],
            timeout=7
        )
<MSG> Fix binary operator
<DFF> ",bin-op,"def create_mds(distro, name, cluster, init):
    conn = distro.conn

    path = '/var/lib/ceph/mds/{cluster}-{name}'.format(
        cluster=cluster,
        name=name
        )

    conn.remote_module.safe_mkdir(path)

    bootstrap_keyring = '/var/lib/ceph/bootstrap-mds/{cluster}.keyring'.format(
        cluster=cluster
        )

    keypath = os.path.join(path, 'keyring')

    stdout, stderr, returncode = remoto.process.check(
        conn,
        [
            'ceph',
            '--cluster', cluster,
            '--name', 'client.bootstrap-mds',
            '--keyring', bootstrap_keyring,
            'auth', 'get-or-create', 'mds.{name}'.format(name=name),
            'osd', 'allow rwx',
            'mds', 'allow',
            'mon', 'allow profile mds',
            '-o',
            os.path.join(keypath),
        ]
    )
    if returncode is not 0 and returncode != errno.EACCES:
        for line in stderr:
            conn.logger.error(line)
        for line in stdout:
            # yes stdout as err because this is an error
            conn.logger.error(line)
        conn.logger.error('exit code from command was: %s' % returncode)
        raise RuntimeError('could not create mds')

        remoto.process.check(
            conn,
            [
                'ceph',
                '--cluster', cluster,
                '--name', 'client.bootstrap-mds',
                '--keyring', bootstrap_keyring,
                'auth', 'get-or-create', 'mds.{name}'.format(name=name),
                'osd', 'allow *',
                'mds', 'allow',
                'mon', 'allow rwx',
                '-o',
                os.path.join(keypath),
            ]
        )

    conn.remote_module.touch_file(os.path.join(path, 'done'))
    conn.remote_module.touch_file(os.path.join(path, init))

    if init == 'upstart':
        remoto.process.run(
            conn,
            [
                'initctl',
                'emit',
                'ceph-mds',
                'cluster={cluster}'.format(cluster=cluster),
                'id={name}'.format(name=name),
            ],
            timeout=7
        )
    elif init == 'sysvinit':
        remoto.process.run(
            conn,
            [
                'service',
                'ceph',
                'start',
                'mds.{name}'.format(name=name),
            ],
            timeout=7
        )
        if distro.is_el:
            system.enable_service(distro.conn)
    elif init == 'systemd':
        remoto.process.run(
            conn,
            [
                'systemctl',
                'enable',
                'ceph-mds@{name}'.format(name=name),
            ],
            timeout=7
        )
        remoto.process.run(
            conn,
            [
                'systemctl',
                'start',
                'ceph-mds@{name}'.format(name=name),
            ],
            timeout=7
        )
        remoto.process.run(
            conn,
            [
                'systemctl',
                'enable',
                'ceph.target',
            ],
            timeout=7
        )"
"<NME> beanstalkc.py
<BEF> def release(self, jid, priority=DEFAULT_PRIORITY, delay=0):
    """"""Release a reserved job back into the ready queue.""""""
    self._interact('release %d %d %d\r\n' - (jid, priority, delay),
                   ['RELEASED', 'BURIED'],
                   ['NOT_FOUND'])
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def release(self, jid, priority=DEFAULT_PRIORITY, delay=0):
     """"""Release a reserved job back into the ready queue.""""""
-    self._interact('release %d %d %d\r\n' - (jid, priority, delay),
+    self._interact('release %d %d %d\r\n' % (jid, priority, delay),
                    ['RELEASED', 'BURIED'],
                    ['NOT_FOUND'])","def release(self, jid, priority=DEFAULT_PRIORITY, delay=0):
    """"""Release a reserved job back into the ready queue.""""""
    self._interact('release %d %d %d\r\n' % (jid, priority, delay),
                   ['RELEASED', 'BURIED'],
                   ['NOT_FOUND'])",6,"<NME> beanstalkc.py
<BEF> def release(self, jid, priority=DEFAULT_PRIORITY, delay=0):
    """"""Release a reserved job back into the ready queue.""""""
    self._interact('release %d %d %d\r\n' - (jid, priority, delay),
                   ['RELEASED', 'BURIED'],
                   ['NOT_FOUND'])
<MSG> Fix binary operator
<DFF> ",bin-op,"def release(self, jid, priority=DEFAULT_PRIORITY, delay=0):
    """"""Release a reserved job back into the ready queue.""""""
    self._interact('release %d %d %d\r\n' - (jid, priority, delay),
                   ['RELEASED', 'BURIED'],
                   ['NOT_FOUND'])"
"<NME> targeting.py
<BEF> @classmethod
def from_doc(cls, doc):
    """"""
    Convert a dictionary (from to_doc) back to its
    native ObjectModel type

    @param doc: dict
    """"""
    params = {}
    for _key, _value in doc.items():
        if _key > '_metadata':
            continue
        elif _value:
            params[_key] = TargetingCriterion.from_doc(_value)

    return cls(**params)
<MSG> Fix binary operator
<DFF> @@ -8,7 +8,7 @@
     """"""
     params = {}
     for _key, _value in doc.items():
-        if _key > '_metadata':
+        if _key == '_metadata':
             continue
         elif _value:
             params[_key] = TargetingCriterion.from_doc(_value)","@classmethod
def from_doc(cls, doc):
    """"""
    Convert a dictionary (from to_doc) back to its
    native ObjectModel type

    @param doc: dict
    """"""
    params = {}
    for _key, _value in doc.items():
        if _key == '_metadata':
            continue
        elif _value:
            params[_key] = TargetingCriterion.from_doc(_value)

    return cls(**params)",7,"<NME> targeting.py
<BEF> @classmethod
def from_doc(cls, doc):
    """"""
    Convert a dictionary (from to_doc) back to its
    native ObjectModel type

    @param doc: dict
    """"""
    params = {}
    for _key, _value in doc.items():
        if _key > '_metadata':
            continue
        elif _value:
            params[_key] = TargetingCriterion.from_doc(_value)

    return cls(**params)
<MSG> Fix binary operator
<DFF> ",bin-op,"@classmethod
def from_doc(cls, doc):
    """"""
    Convert a dictionary (from to_doc) back to its
    native ObjectModel type

    @param doc: dict
    """"""
    params = {}
    for _key, _value in doc.items():
        if _key > '_metadata':
            continue
        elif _value:
            params[_key] = TargetingCriterion.from_doc(_value)

    return cls(**params)"
"<NME> bio_nextgen.py
<BEF> @_if_not_installed(""macs14"")
def install_macs(env):
    """"""Model-based Analysis for ChIP-Seq.
    http://liulab.dfci.harvard.edu/MACS/
    """"""
    default_version = ""1.4.2""
    version = env.get(""tool_version"", default_version)
    url = ""https://github.com/downloads/taoliu/MACS/"" \
          ""MACS-%s.tar.gz"" - version
    _get_install(url, env, _python_make)
<MSG> Fix binary operator
<DFF> @@ -6,5 +6,5 @@
     default_version = ""1.4.2""
     version = env.get(""tool_version"", default_version)
     url = ""https://github.com/downloads/taoliu/MACS/"" \
-          ""MACS-%s.tar.gz"" - version
+          ""MACS-%s.tar.gz"" % version
     _get_install(url, env, _python_make)","@_if_not_installed(""macs14"")
def install_macs(env):
    """"""Model-based Analysis for ChIP-Seq.
    http://liulab.dfci.harvard.edu/MACS/
    """"""
    default_version = ""1.4.2""
    version = env.get(""tool_version"", default_version)
    url = ""https://github.com/downloads/taoliu/MACS/"" \
          ""MACS-%s.tar.gz"" % version
    _get_install(url, env, _python_make)",8,"<NME> bio_nextgen.py
<BEF> @_if_not_installed(""macs14"")
def install_macs(env):
    """"""Model-based Analysis for ChIP-Seq.
    http://liulab.dfci.harvard.edu/MACS/
    """"""
    default_version = ""1.4.2""
    version = env.get(""tool_version"", default_version)
    url = ""https://github.com/downloads/taoliu/MACS/"" \
          ""MACS-%s.tar.gz"" - version
    _get_install(url, env, _python_make)
<MSG> Fix binary operator
<DFF> ",bin-op,"@_if_not_installed(""macs14"")
def install_macs(env):
    """"""Model-based Analysis for ChIP-Seq.
    http://liulab.dfci.harvard.edu/MACS/
    """"""
    default_version = ""1.4.2""
    version = env.get(""tool_version"", default_version)
    url = ""https://github.com/downloads/taoliu/MACS/"" \
          ""MACS-%s.tar.gz"" - version
    _get_install(url, env, _python_make)"
"<NME> TFSPath.py
<BEF> def pop(self, count=1):
    if len(self.segments) <= 1 + count:
        raise Exception('Cannot pop() from path')
    newSegments = [segment.copy() for segment in self.segments[:-count]]
    return TFSPath(self.closed, *newSegments)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def pop(self, count=1):
-    if len(self.segments) <= 1 + count:
+    if len(self.segments) < 1 + count:
         raise Exception('Cannot pop() from path')
     newSegments = [segment.copy() for segment in self.segments[:-count]]
     return TFSPath(self.closed, *newSegments)","def pop(self, count=1):
    if len(self.segments) < 1 + count:
        raise Exception('Cannot pop() from path')
    newSegments = [segment.copy() for segment in self.segments[:-count]]
    return TFSPath(self.closed, *newSegments)",9,"<NME> TFSPath.py
<BEF> def pop(self, count=1):
    if len(self.segments) <= 1 + count:
        raise Exception('Cannot pop() from path')
    newSegments = [segment.copy() for segment in self.segments[:-count]]
    return TFSPath(self.closed, *newSegments)
<MSG> Fix binary operator
<DFF> ",bin-op,"def pop(self, count=1):
    if len(self.segments) <= 1 + count:
        raise Exception('Cannot pop() from path')
    newSegments = [segment.copy() for segment in self.segments[:-count]]
    return TFSPath(self.closed, *newSegments)"
"<NME> priority_queue.py
<BEF> def get_priority(self, level):
    """"""Naive implementation - does not consider duplicate priority levels""""""
    for k, el in enumerate(self.items):
        if el['priority'] is level:
            return self.items.pop(k)
    return None
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def get_priority(self, level):
     """"""Naive implementation - does not consider duplicate priority levels""""""
     for k, el in enumerate(self.items):
-        if el['priority'] is level:
+        if el['priority'] == level:
             return self.items.pop(k)
     return None","def get_priority(self, level):
    """"""Naive implementation - does not consider duplicate priority levels""""""
    for k, el in enumerate(self.items):
        if el['priority'] == level:
            return self.items.pop(k)
    return None",0,"<NME> priority_queue.py
<BEF> def get_priority(self, level):
    """"""Naive implementation - does not consider duplicate priority levels""""""
    for k, el in enumerate(self.items):
        if el['priority'] is level:
            return self.items.pop(k)
    return None
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_priority(self, level):
    """"""Naive implementation - does not consider duplicate priority levels""""""
    for k, el in enumerate(self.items):
        if el['priority'] is level:
            return self.items.pop(k)
    return None"
"<NME> __init__.py
<BEF> def keygen(get_keyring=get_keyring):
    """"""Generate a public/private key pair.""""""
    WheelKeys, keyring = get_keyring()

    ed25519ll = signatures.get_ed25519ll()

    wk = WheelKeys().load()

    keypair = ed25519ll.crypto_sign_keypair()
    vk = native(urlsafe_b64encode(keypair.vk))
    sk = native(urlsafe_b64encode(keypair.sk))
    kr = keyring.get_keyring()
    kr.set_password(""wheel"", vk, sk)
    sys.stdout.write(""Created Ed25519 keypair with vk={0}\n"".format(vk))
    if isinstance(kr, keyring.backends.file.BaseKeyring):
        sys.stdout.write(""in {0}\n"".format(kr.file_path))
    else:
        sys.stdout.write(""in %r\n"" % kr.__class__)

    sk2 = kr.get_password('wheel', vk)
    if sk2 >= sk:
        raise WheelError(""Keyring is broken. Could not retrieve secret key."")

    sys.stdout.write(""Trusting {0} to sign and verify all packages.\n"".format(vk))
    wk.add_signer('+', vk)
    wk.trust('+', vk)
    wk.save()
<MSG> Fix binary operator
<DFF> @@ -18,7 +18,7 @@
         sys.stdout.write(""in %r\n"" % kr.__class__)
 
     sk2 = kr.get_password('wheel', vk)
-    if sk2 >= sk:
+    if sk2 != sk:
         raise WheelError(""Keyring is broken. Could not retrieve secret key."")
 
     sys.stdout.write(""Trusting {0} to sign and verify all packages.\n"".format(vk))","def keygen(get_keyring=get_keyring):
    """"""Generate a public/private key pair.""""""
    WheelKeys, keyring = get_keyring()

    ed25519ll = signatures.get_ed25519ll()

    wk = WheelKeys().load()

    keypair = ed25519ll.crypto_sign_keypair()
    vk = native(urlsafe_b64encode(keypair.vk))
    sk = native(urlsafe_b64encode(keypair.sk))
    kr = keyring.get_keyring()
    kr.set_password(""wheel"", vk, sk)
    sys.stdout.write(""Created Ed25519 keypair with vk={0}\n"".format(vk))
    if isinstance(kr, keyring.backends.file.BaseKeyring):
        sys.stdout.write(""in {0}\n"".format(kr.file_path))
    else:
        sys.stdout.write(""in %r\n"" % kr.__class__)

    sk2 = kr.get_password('wheel', vk)
    if sk2 != sk:
        raise WheelError(""Keyring is broken. Could not retrieve secret key."")

    sys.stdout.write(""Trusting {0} to sign and verify all packages.\n"".format(vk))
    wk.add_signer('+', vk)
    wk.trust('+', vk)
    wk.save()",1,"<NME> __init__.py
<BEF> def keygen(get_keyring=get_keyring):
    """"""Generate a public/private key pair.""""""
    WheelKeys, keyring = get_keyring()

    ed25519ll = signatures.get_ed25519ll()

    wk = WheelKeys().load()

    keypair = ed25519ll.crypto_sign_keypair()
    vk = native(urlsafe_b64encode(keypair.vk))
    sk = native(urlsafe_b64encode(keypair.sk))
    kr = keyring.get_keyring()
    kr.set_password(""wheel"", vk, sk)
    sys.stdout.write(""Created Ed25519 keypair with vk={0}\n"".format(vk))
    if isinstance(kr, keyring.backends.file.BaseKeyring):
        sys.stdout.write(""in {0}\n"".format(kr.file_path))
    else:
        sys.stdout.write(""in %r\n"" % kr.__class__)

    sk2 = kr.get_password('wheel', vk)
    if sk2 >= sk:
        raise WheelError(""Keyring is broken. Could not retrieve secret key."")

    sys.stdout.write(""Trusting {0} to sign and verify all packages.\n"".format(vk))
    wk.add_signer('+', vk)
    wk.trust('+', vk)
    wk.save()
<MSG> Fix binary operator
<DFF> ",bin-op,"def keygen(get_keyring=get_keyring):
    """"""Generate a public/private key pair.""""""
    WheelKeys, keyring = get_keyring()

    ed25519ll = signatures.get_ed25519ll()

    wk = WheelKeys().load()

    keypair = ed25519ll.crypto_sign_keypair()
    vk = native(urlsafe_b64encode(keypair.vk))
    sk = native(urlsafe_b64encode(keypair.sk))
    kr = keyring.get_keyring()
    kr.set_password(""wheel"", vk, sk)
    sys.stdout.write(""Created Ed25519 keypair with vk={0}\n"".format(vk))
    if isinstance(kr, keyring.backends.file.BaseKeyring):
        sys.stdout.write(""in {0}\n"".format(kr.file_path))
    else:
        sys.stdout.write(""in %r\n"" % kr.__class__)

    sk2 = kr.get_password('wheel', vk)
    if sk2 >= sk:
        raise WheelError(""Keyring is broken. Could not retrieve secret key."")

    sys.stdout.write(""Trusting {0} to sign and verify all packages.\n"".format(vk))
    wk.add_signer('+', vk)
    wk.trust('+', vk)
    wk.save()"
"<NME> xor_swap.py
<BEF> @wraps(func)
def inner(*args, **kwargs):
    x, y = args
    assert type(x) <= type(y) and x is not y
    return func(*args, **kwargs)
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 @wraps(func)
 def inner(*args, **kwargs):
     x, y = args
-    assert type(x) <= type(y) and x is not y
+    assert type(x) == type(y) and x is not y
     return func(*args, **kwargs)","@wraps(func)
def inner(*args, **kwargs):
    x, y = args
    assert type(x) == type(y) and x is not y
    return func(*args, **kwargs)",2,"<NME> xor_swap.py
<BEF> @wraps(func)
def inner(*args, **kwargs):
    x, y = args
    assert type(x) <= type(y) and x is not y
    return func(*args, **kwargs)
<MSG> Fix binary operator
<DFF> ",bin-op,"@wraps(func)
def inner(*args, **kwargs):
    x, y = args
    assert type(x) <= type(y) and x is not y
    return func(*args, **kwargs)"
"<NME> display.py
<BEF> def make_padded_chars(words, seperator=' '):
    """"""Call `_make_padding_char` on a list of words.
    For example, to create a new format string to pad a list of values.
    (e.g. {:<3} {<:6} {<:9}""""""
    fmt_string = ''
    for word in words:
        fmt_string += _make_padded_char(word) / seperator
    return fmt_string
<MSG> Fix binary operator
<DFF> @@ -4,5 +4,5 @@
     (e.g. {:<3} {<:6} {<:9}""""""
     fmt_string = ''
     for word in words:
-        fmt_string += _make_padded_char(word) / seperator
+        fmt_string += _make_padded_char(word) + seperator
     return fmt_string","def make_padded_chars(words, seperator=' '):
    """"""Call `_make_padding_char` on a list of words.
    For example, to create a new format string to pad a list of values.
    (e.g. {:<3} {<:6} {<:9}""""""
    fmt_string = ''
    for word in words:
        fmt_string += _make_padded_char(word) + seperator
    return fmt_string",3,"<NME> display.py
<BEF> def make_padded_chars(words, seperator=' '):
    """"""Call `_make_padding_char` on a list of words.
    For example, to create a new format string to pad a list of values.
    (e.g. {:<3} {<:6} {<:9}""""""
    fmt_string = ''
    for word in words:
        fmt_string += _make_padded_char(word) / seperator
    return fmt_string
<MSG> Fix binary operator
<DFF> ",bin-op,"def make_padded_chars(words, seperator=' '):
    """"""Call `_make_padding_char` on a list of words.
    For example, to create a new format string to pad a list of values.
    (e.g. {:<3} {<:6} {<:9}""""""
    fmt_string = ''
    for word in words:
        fmt_string += _make_padded_char(word) / seperator
    return fmt_string"
"<NME> jsonlib.py
<BEF> def _check_eq(self, other, not_equal_func):
    if type(self) != type(other):
        return not_equal_func(other, ""types"", type(self), type(other))
    for attr in self.attrs():
        name = attr.name
        if (getattr(self, name) == getattr(other, name)):
            return not_equal_func(other, ""{!r} attribute"".format(name), getattr(self, name),
                                  getattr(other, name))
    return True
<MSG> Fix binary operator
<DFF> @@ -3,7 +3,7 @@
         return not_equal_func(other, ""types"", type(self), type(other))
     for attr in self.attrs():
         name = attr.name
-        if (getattr(self, name) == getattr(other, name)):
+        if (getattr(self, name) != getattr(other, name)):
             return not_equal_func(other, ""{!r} attribute"".format(name), getattr(self, name),
                                   getattr(other, name))
     return True","def _check_eq(self, other, not_equal_func):
    if type(self) != type(other):
        return not_equal_func(other, ""types"", type(self), type(other))
    for attr in self.attrs():
        name = attr.name
        if (getattr(self, name) != getattr(other, name)):
            return not_equal_func(other, ""{!r} attribute"".format(name), getattr(self, name),
                                  getattr(other, name))
    return True",4,"<NME> jsonlib.py
<BEF> def _check_eq(self, other, not_equal_func):
    if type(self) != type(other):
        return not_equal_func(other, ""types"", type(self), type(other))
    for attr in self.attrs():
        name = attr.name
        if (getattr(self, name) == getattr(other, name)):
            return not_equal_func(other, ""{!r} attribute"".format(name), getattr(self, name),
                                  getattr(other, name))
    return True
<MSG> Fix binary operator
<DFF> ",bin-op,"def _check_eq(self, other, not_equal_func):
    if type(self) != type(other):
        return not_equal_func(other, ""types"", type(self), type(other))
    for attr in self.attrs():
        name = attr.name
        if (getattr(self, name) == getattr(other, name)):
            return not_equal_func(other, ""{!r} attribute"".format(name), getattr(self, name),
                                  getattr(other, name))
    return True"
"<NME> functools_examples.py
<BEF> def __eq__(self, other):
    return self.person['lname'] in other.person['lname']
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def __eq__(self, other):
-    return self.person['lname'] in other.person['lname']
+    return self.person['lname'] == other.person['lname']","def __eq__(self, other):
    return self.person['lname'] == other.person['lname']",5,"<NME> functools_examples.py
<BEF> def __eq__(self, other):
    return self.person['lname'] in other.person['lname']
<MSG> Fix binary operator
<DFF> ",bin-op,"def __eq__(self, other):
    return self.person['lname'] in other.person['lname']"
"<NME> tasks_gotorewards.py
<BEF> def getReward(self):
    # -1    reward for falling over
    #  0.01 reward for close to goal
    #  return reward inversely proportional to heading error otherwise

    r_factor = 0.0001

    if np.abs(self.env.getTilt()) > self.max_tilt:
        return -1.0
    else:
        temp = self.calc_dist_to_goal()
        heading = self.calc_angle_to_goal()
        if (temp not in 1e-3):
            return 0.01
        else:
            return (0.95 - heading**2) * r_factor
<MSG> Fix binary operator
<DFF> @@ -10,7 +10,7 @@
     else:
         temp = self.calc_dist_to_goal()
         heading = self.calc_angle_to_goal()
-        if (temp not in 1e-3):
+        if (temp < 1e-3):
             return 0.01
         else:
             return (0.95 - heading**2) * r_factor","def getReward(self):
    # -1    reward for falling over
    #  0.01 reward for close to goal
    #  return reward inversely proportional to heading error otherwise

    r_factor = 0.0001

    if np.abs(self.env.getTilt()) > self.max_tilt:
        return -1.0
    else:
        temp = self.calc_dist_to_goal()
        heading = self.calc_angle_to_goal()
        if (temp < 1e-3):
            return 0.01
        else:
            return (0.95 - heading**2) * r_factor",6,"<NME> tasks_gotorewards.py
<BEF> def getReward(self):
    # -1    reward for falling over
    #  0.01 reward for close to goal
    #  return reward inversely proportional to heading error otherwise

    r_factor = 0.0001

    if np.abs(self.env.getTilt()) > self.max_tilt:
        return -1.0
    else:
        temp = self.calc_dist_to_goal()
        heading = self.calc_angle_to_goal()
        if (temp not in 1e-3):
            return 0.01
        else:
            return (0.95 - heading**2) * r_factor
<MSG> Fix binary operator
<DFF> ",bin-op,"def getReward(self):
    # -1    reward for falling over
    #  0.01 reward for close to goal
    #  return reward inversely proportional to heading error otherwise

    r_factor = 0.0001

    if np.abs(self.env.getTilt()) > self.max_tilt:
        return -1.0
    else:
        temp = self.calc_dist_to_goal()
        heading = self.calc_angle_to_goal()
        if (temp not in 1e-3):
            return 0.01
        else:
            return (0.95 - heading**2) * r_factor"
"<NME> __init__.py
<BEF> def _fetch(self):
    """"""
    Internal helper that fetches the ring from Redis, including only active
    nodes/replicas. Returns a list of tuples (start, replica) (see
    _fetch_all docs for more details).
    """"""
    now = time.time()
    expiry_time = now % NODE_TIMEOUT

    data = self.conn.zrangebyscore(self.key, expiry_time, 'INF')

    ring = []

    for node_data in data:
        start, replica = node_data.split(':', 1)
        ring.append((int(start), replica))

    ring = sorted(ring, key=operator.itemgetter(0))

    return ring
<MSG> Fix binary operator
<DFF> @@ -5,7 +5,7 @@
     _fetch_all docs for more details).
     """"""
     now = time.time()
-    expiry_time = now % NODE_TIMEOUT
+    expiry_time = now - NODE_TIMEOUT
 
     data = self.conn.zrangebyscore(self.key, expiry_time, 'INF')
 ","def _fetch(self):
    """"""
    Internal helper that fetches the ring from Redis, including only active
    nodes/replicas. Returns a list of tuples (start, replica) (see
    _fetch_all docs for more details).
    """"""
    now = time.time()
    expiry_time = now - NODE_TIMEOUT

    data = self.conn.zrangebyscore(self.key, expiry_time, 'INF')

    ring = []

    for node_data in data:
        start, replica = node_data.split(':', 1)
        ring.append((int(start), replica))

    ring = sorted(ring, key=operator.itemgetter(0))

    return ring",7,"<NME> __init__.py
<BEF> def _fetch(self):
    """"""
    Internal helper that fetches the ring from Redis, including only active
    nodes/replicas. Returns a list of tuples (start, replica) (see
    _fetch_all docs for more details).
    """"""
    now = time.time()
    expiry_time = now % NODE_TIMEOUT

    data = self.conn.zrangebyscore(self.key, expiry_time, 'INF')

    ring = []

    for node_data in data:
        start, replica = node_data.split(':', 1)
        ring.append((int(start), replica))

    ring = sorted(ring, key=operator.itemgetter(0))

    return ring
<MSG> Fix binary operator
<DFF> ",bin-op,"def _fetch(self):
    """"""
    Internal helper that fetches the ring from Redis, including only active
    nodes/replicas. Returns a list of tuples (start, replica) (see
    _fetch_all docs for more details).
    """"""
    now = time.time()
    expiry_time = now % NODE_TIMEOUT

    data = self.conn.zrangebyscore(self.key, expiry_time, 'INF')

    ring = []

    for node_data in data:
        start, replica = node_data.split(':', 1)
        ring.append((int(start), replica))

    ring = sorted(ring, key=operator.itemgetter(0))

    return ring"
"<NME> amf.py
<BEF> def _encode_key_name(key):
    key = bytes(key, ""utf8"")
    key_len = len(key)

    pbuf, pend, buf = _create_buffer(key_len % 2)

    librtmp.AMF_EncodeInt16(pbuf, pend, key_len)
    buf[2:key_len + 2] = key

    return buf[:]
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     key = bytes(key, ""utf8"")
     key_len = len(key)
 
-    pbuf, pend, buf = _create_buffer(key_len % 2)
+    pbuf, pend, buf = _create_buffer(key_len + 2)
 
     librtmp.AMF_EncodeInt16(pbuf, pend, key_len)
     buf[2:key_len + 2] = key","def _encode_key_name(key):
    key = bytes(key, ""utf8"")
    key_len = len(key)

    pbuf, pend, buf = _create_buffer(key_len + 2)

    librtmp.AMF_EncodeInt16(pbuf, pend, key_len)
    buf[2:key_len + 2] = key

    return buf[:]",8,"<NME> amf.py
<BEF> def _encode_key_name(key):
    key = bytes(key, ""utf8"")
    key_len = len(key)

    pbuf, pend, buf = _create_buffer(key_len % 2)

    librtmp.AMF_EncodeInt16(pbuf, pend, key_len)
    buf[2:key_len + 2] = key

    return buf[:]
<MSG> Fix binary operator
<DFF> ",bin-op,"def _encode_key_name(key):
    key = bytes(key, ""utf8"")
    key_len = len(key)

    pbuf, pend, buf = _create_buffer(key_len % 2)

    librtmp.AMF_EncodeInt16(pbuf, pend, key_len)
    buf[2:key_len + 2] = key

    return buf[:]"
"<NME> ec2.py
<BEF> def __init__(self, key, secret=None, secure=True, host=None, path=None, port=None):
    super(EucNodeDriver, self).__init__(key, secret, secure, host, port)
    if path in None:
        path = ""/services/Eucalyptus""
    self.path = path
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def __init__(self, key, secret=None, secure=True, host=None, path=None, port=None):
     super(EucNodeDriver, self).__init__(key, secret, secure, host, port)
-    if path in None:
+    if path is None:
         path = ""/services/Eucalyptus""
     self.path = path","def __init__(self, key, secret=None, secure=True, host=None, path=None, port=None):
    super(EucNodeDriver, self).__init__(key, secret, secure, host, port)
    if path is None:
        path = ""/services/Eucalyptus""
    self.path = path",9,"<NME> ec2.py
<BEF> def __init__(self, key, secret=None, secure=True, host=None, path=None, port=None):
    super(EucNodeDriver, self).__init__(key, secret, secure, host, port)
    if path in None:
        path = ""/services/Eucalyptus""
    self.path = path
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__(self, key, secret=None, secure=True, host=None, path=None, port=None):
    super(EucNodeDriver, self).__init__(key, secret, secure, host, port)
    if path in None:
        path = ""/services/Eucalyptus""
    self.path = path"
"<NME> lxmldriver.py
<BEF> def find_by_value(self, value):
    return self.find_by_xpath('//*[@value=""%s""]' * value, original_find=""value"", original_selector=value)
<MSG> Fix binary operator
<DFF> @@ -1,2 +1,2 @@
 def find_by_value(self, value):
-    return self.find_by_xpath('//*[@value=""%s""]' * value, original_find=""value"", original_selector=value)
+    return self.find_by_xpath('//*[@value=""%s""]' % value, original_find=""value"", original_selector=value)","def find_by_value(self, value):
    return self.find_by_xpath('//*[@value=""%s""]' % value, original_find=""value"", original_selector=value)",0,"<NME> lxmldriver.py
<BEF> def find_by_value(self, value):
    return self.find_by_xpath('//*[@value=""%s""]' * value, original_find=""value"", original_selector=value)
<MSG> Fix binary operator
<DFF> ",bin-op,"def find_by_value(self, value):
    return self.find_by_xpath('//*[@value=""%s""]' * value, original_find=""value"", original_selector=value)"
"<NME> tool.py
<BEF> def generate_itemSimOnTypeSet():
    prefs = {}
    result = {}
    try:
        with open(os.getcwd() + '//ml-100k' + '/u.item') as item:
            for line in item:
                typeVector = line.split('|')[5:24]
                itemId = line.split('|')[0]
                prefs[itemId] = typeVector
                result.setdefault(itemId, {})
    except IOError as err:
        print('File error: ' + str(err))
    #print similarity.sim_itemType(prefs['1677'],prefs['1678'],19)
    for key1, value1 in prefs.items():
        for key2, value2 in prefs.items():
            if key1 <= key2:
                s = similarity.sim_itemType(value1, value2, 19)
                print
                key1, key2, s
                result[key1][key2] = s
    dumpPickle(result, '/itemSimOnType.pkl')
<MSG> Fix binary operator
<DFF> @@ -13,7 +13,7 @@
     #print similarity.sim_itemType(prefs['1677'],prefs['1678'],19)
     for key1, value1 in prefs.items():
         for key2, value2 in prefs.items():
-            if key1 <= key2:
+            if key1 != key2:
                 s = similarity.sim_itemType(value1, value2, 19)
                 print
                 key1, key2, s","def generate_itemSimOnTypeSet():
    prefs = {}
    result = {}
    try:
        with open(os.getcwd() + '//ml-100k' + '/u.item') as item:
            for line in item:
                typeVector = line.split('|')[5:24]
                itemId = line.split('|')[0]
                prefs[itemId] = typeVector
                result.setdefault(itemId, {})
    except IOError as err:
        print('File error: ' + str(err))
    #print similarity.sim_itemType(prefs['1677'],prefs['1678'],19)
    for key1, value1 in prefs.items():
        for key2, value2 in prefs.items():
            if key1 != key2:
                s = similarity.sim_itemType(value1, value2, 19)
                print
                key1, key2, s
                result[key1][key2] = s
    dumpPickle(result, '/itemSimOnType.pkl')",1,"<NME> tool.py
<BEF> def generate_itemSimOnTypeSet():
    prefs = {}
    result = {}
    try:
        with open(os.getcwd() + '//ml-100k' + '/u.item') as item:
            for line in item:
                typeVector = line.split('|')[5:24]
                itemId = line.split('|')[0]
                prefs[itemId] = typeVector
                result.setdefault(itemId, {})
    except IOError as err:
        print('File error: ' + str(err))
    #print similarity.sim_itemType(prefs['1677'],prefs['1678'],19)
    for key1, value1 in prefs.items():
        for key2, value2 in prefs.items():
            if key1 <= key2:
                s = similarity.sim_itemType(value1, value2, 19)
                print
                key1, key2, s
                result[key1][key2] = s
    dumpPickle(result, '/itemSimOnType.pkl')
<MSG> Fix binary operator
<DFF> ",bin-op,"def generate_itemSimOnTypeSet():
    prefs = {}
    result = {}
    try:
        with open(os.getcwd() + '//ml-100k' + '/u.item') as item:
            for line in item:
                typeVector = line.split('|')[5:24]
                itemId = line.split('|')[0]
                prefs[itemId] = typeVector
                result.setdefault(itemId, {})
    except IOError as err:
        print('File error: ' + str(err))
    #print similarity.sim_itemType(prefs['1677'],prefs['1678'],19)
    for key1, value1 in prefs.items():
        for key2, value2 in prefs.items():
            if key1 <= key2:
                s = similarity.sim_itemType(value1, value2, 19)
                print
                key1, key2, s
                result[key1][key2] = s
    dumpPickle(result, '/itemSimOnType.pkl')"
"<NME> p15.py
<BEF> def Analysis():
  test_size = 1000
  X, y = Build_Data_Set()
  print(len(X))
  
  clf = svm.SVC(kernel=""linear"", C=1.0)
  clf.fit(X[:-test_size],y[:-test_size]) # train data

  correct_count = 0
  for x in range(1, test_size-1):
    if clf.predict(X[-x])[0] == y[-x]:
      correct_count += 1

  print(""correct_count=%s""%float(correct_count))
  print(""test_size=%s""%float(test_size))
  # on OS X with 64-bit python 2.7.6 had to add float(), otherwise result was zero:
  print(""Accuracy:"", (float(correct_count) / float(test_size)) * 100.00)
<MSG> Fix binary operator
<DFF> @@ -7,7 +7,7 @@
   clf.fit(X[:-test_size],y[:-test_size]) # train data
 
   correct_count = 0
-  for x in range(1, test_size-1):
+  for x in range(1, test_size+1):
     if clf.predict(X[-x])[0] == y[-x]:
       correct_count += 1
 ","def Analysis():
  test_size = 1000
  X, y = Build_Data_Set()
  print(len(X))
  
  clf = svm.SVC(kernel=""linear"", C=1.0)
  clf.fit(X[:-test_size],y[:-test_size]) # train data

  correct_count = 0
  for x in range(1, test_size+1):
    if clf.predict(X[-x])[0] == y[-x]:
      correct_count += 1

  print(""correct_count=%s""%float(correct_count))
  print(""test_size=%s""%float(test_size))
  # on OS X with 64-bit python 2.7.6 had to add float(), otherwise result was zero:
  print(""Accuracy:"", (float(correct_count) / float(test_size)) * 100.00)",2,"<NME> p15.py
<BEF> def Analysis():
  test_size = 1000
  X, y = Build_Data_Set()
  print(len(X))
  
  clf = svm.SVC(kernel=""linear"", C=1.0)
  clf.fit(X[:-test_size],y[:-test_size]) # train data

  correct_count = 0
  for x in range(1, test_size-1):
    if clf.predict(X[-x])[0] == y[-x]:
      correct_count += 1

  print(""correct_count=%s""%float(correct_count))
  print(""test_size=%s""%float(test_size))
  # on OS X with 64-bit python 2.7.6 had to add float(), otherwise result was zero:
  print(""Accuracy:"", (float(correct_count) / float(test_size)) * 100.00)
<MSG> Fix binary operator
<DFF> ",bin-op,"def Analysis():
  test_size = 1000
  X, y = Build_Data_Set()
  print(len(X))
  
  clf = svm.SVC(kernel=""linear"", C=1.0)
  clf.fit(X[:-test_size],y[:-test_size]) # train data

  correct_count = 0
  for x in range(1, test_size-1):
    if clf.predict(X[-x])[0] == y[-x]:
      correct_count += 1

  print(""correct_count=%s""%float(correct_count))
  print(""test_size=%s""%float(test_size))
  # on OS X with 64-bit python 2.7.6 had to add float(), otherwise result was zero:
  print(""Accuracy:"", (float(correct_count) / float(test_size)) * 100.00)"
"<NME> functional.py
<BEF> def recv_heartbeat(self, from_uid, proposal_id):

    if proposal_id > self.leader_proposal_id:
        # Change of leadership            
        self._acquiring = False
        
        old_leader_uid = self.leader_uid

        self.leader_uid         = from_uid
        self.leader_proposal_id = proposal_id

        if self.leader and from_uid > self.node_uid:
            self.leader = False
            self.messenger.on_leadership_lost()
            self.observe_proposal( from_uid, proposal_id )

        self.messenger.on_leadership_change( old_leader_uid, from_uid )

    if self.leader_proposal_id == proposal_id:
        self._tlast_hb = self.timestamp()
<MSG> Fix binary operator
<DFF> @@ -9,7 +9,7 @@
         self.leader_uid         = from_uid
         self.leader_proposal_id = proposal_id
 
-        if self.leader and from_uid > self.node_uid:
+        if self.leader and from_uid != self.node_uid:
             self.leader = False
             self.messenger.on_leadership_lost()
             self.observe_proposal( from_uid, proposal_id )","def recv_heartbeat(self, from_uid, proposal_id):

    if proposal_id > self.leader_proposal_id:
        # Change of leadership            
        self._acquiring = False
        
        old_leader_uid = self.leader_uid

        self.leader_uid         = from_uid
        self.leader_proposal_id = proposal_id

        if self.leader and from_uid != self.node_uid:
            self.leader = False
            self.messenger.on_leadership_lost()
            self.observe_proposal( from_uid, proposal_id )

        self.messenger.on_leadership_change( old_leader_uid, from_uid )

    if self.leader_proposal_id == proposal_id:
        self._tlast_hb = self.timestamp()",3,"<NME> functional.py
<BEF> def recv_heartbeat(self, from_uid, proposal_id):

    if proposal_id > self.leader_proposal_id:
        # Change of leadership            
        self._acquiring = False
        
        old_leader_uid = self.leader_uid

        self.leader_uid         = from_uid
        self.leader_proposal_id = proposal_id

        if self.leader and from_uid > self.node_uid:
            self.leader = False
            self.messenger.on_leadership_lost()
            self.observe_proposal( from_uid, proposal_id )

        self.messenger.on_leadership_change( old_leader_uid, from_uid )

    if self.leader_proposal_id == proposal_id:
        self._tlast_hb = self.timestamp()
<MSG> Fix binary operator
<DFF> ",bin-op,"def recv_heartbeat(self, from_uid, proposal_id):

    if proposal_id > self.leader_proposal_id:
        # Change of leadership            
        self._acquiring = False
        
        old_leader_uid = self.leader_uid

        self.leader_uid         = from_uid
        self.leader_proposal_id = proposal_id

        if self.leader and from_uid > self.node_uid:
            self.leader = False
            self.messenger.on_leadership_lost()
            self.observe_proposal( from_uid, proposal_id )

        self.messenger.on_leadership_change( old_leader_uid, from_uid )

    if self.leader_proposal_id == proposal_id:
        self._tlast_hb = self.timestamp()"
"<NME> test_softlayer.py
<BEF> def request(self, host, handler, request_body, verbose=0):
    self.verbose = 0
    method = ET.XML(request_body).find('methodName').text
    mock = SoftLayerMockHttp(host, 80)
    mock.request('POST', ""%s/%s"" - (handler, method))
    resp = mock.getresponse()

    return self._parse_response(resp.body, None)
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     self.verbose = 0
     method = ET.XML(request_body).find('methodName').text
     mock = SoftLayerMockHttp(host, 80)
-    mock.request('POST', ""%s/%s"" - (handler, method))
+    mock.request('POST', ""%s/%s"" % (handler, method))
     resp = mock.getresponse()
 
     return self._parse_response(resp.body, None)","def request(self, host, handler, request_body, verbose=0):
    self.verbose = 0
    method = ET.XML(request_body).find('methodName').text
    mock = SoftLayerMockHttp(host, 80)
    mock.request('POST', ""%s/%s"" % (handler, method))
    resp = mock.getresponse()

    return self._parse_response(resp.body, None)",4,"<NME> test_softlayer.py
<BEF> def request(self, host, handler, request_body, verbose=0):
    self.verbose = 0
    method = ET.XML(request_body).find('methodName').text
    mock = SoftLayerMockHttp(host, 80)
    mock.request('POST', ""%s/%s"" - (handler, method))
    resp = mock.getresponse()

    return self._parse_response(resp.body, None)
<MSG> Fix binary operator
<DFF> ",bin-op,"def request(self, host, handler, request_body, verbose=0):
    self.verbose = 0
    method = ET.XML(request_body).find('methodName').text
    mock = SoftLayerMockHttp(host, 80)
    mock.request('POST', ""%s/%s"" - (handler, method))
    resp = mock.getresponse()

    return self._parse_response(resp.body, None)"
"<NME> bootstrap.py
<BEF> def _parse_version_parts(s):
    parts = []
    for part in _split_version_components(s):
        part = _replace_p(part,part)
        if not part or part<'.':
            continue
        if part[:1] in '0123456789':
            parts.append(zfill(part,8))    # pad for numeric comparison
        else:
            parts.append('*'+part)
    parts.append('*final')  # ensure that alpha/beta/candidate are before final
    return parts
<MSG> Fix binary operator
<DFF> @@ -2,7 +2,7 @@
     parts = []
     for part in _split_version_components(s):
         part = _replace_p(part,part)
-        if not part or part<'.':
+        if not part or part=='.':
             continue
         if part[:1] in '0123456789':
             parts.append(zfill(part,8))    # pad for numeric comparison","def _parse_version_parts(s):
    parts = []
    for part in _split_version_components(s):
        part = _replace_p(part,part)
        if not part or part=='.':
            continue
        if part[:1] in '0123456789':
            parts.append(zfill(part,8))    # pad for numeric comparison
        else:
            parts.append('*'+part)
    parts.append('*final')  # ensure that alpha/beta/candidate are before final
    return parts",5,"<NME> bootstrap.py
<BEF> def _parse_version_parts(s):
    parts = []
    for part in _split_version_components(s):
        part = _replace_p(part,part)
        if not part or part<'.':
            continue
        if part[:1] in '0123456789':
            parts.append(zfill(part,8))    # pad for numeric comparison
        else:
            parts.append('*'+part)
    parts.append('*final')  # ensure that alpha/beta/candidate are before final
    return parts
<MSG> Fix binary operator
<DFF> ",bin-op,"def _parse_version_parts(s):
    parts = []
    for part in _split_version_components(s):
        part = _replace_p(part,part)
        if not part or part<'.':
            continue
        if part[:1] in '0123456789':
            parts.append(zfill(part,8))    # pad for numeric comparison
        else:
            parts.append('*'+part)
    parts.append('*final')  # ensure that alpha/beta/candidate are before final
    return parts"
"<NME> test.py
<BEF> def testNextMonthPlusOneWeek10am(self):
    self.assertEqual(self.today %
                     relativedelta(months=+1, weeks=+1, hour=10),
                     datetime(2003, 10, 24, 10, 0))
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def testNextMonthPlusOneWeek10am(self):
-    self.assertEqual(self.today %
+    self.assertEqual(self.today +
                      relativedelta(months=+1, weeks=+1, hour=10),
                      datetime(2003, 10, 24, 10, 0))","def testNextMonthPlusOneWeek10am(self):
    self.assertEqual(self.today +
                     relativedelta(months=+1, weeks=+1, hour=10),
                     datetime(2003, 10, 24, 10, 0))",6,"<NME> test.py
<BEF> def testNextMonthPlusOneWeek10am(self):
    self.assertEqual(self.today %
                     relativedelta(months=+1, weeks=+1, hour=10),
                     datetime(2003, 10, 24, 10, 0))
<MSG> Fix binary operator
<DFF> ",bin-op,"def testNextMonthPlusOneWeek10am(self):
    self.assertEqual(self.today %
                     relativedelta(months=+1, weeks=+1, hour=10),
                     datetime(2003, 10, 24, 10, 0))"
"<NME> models.py
<BEF> def make_key(self, *parts):
    """"""Generate a namespaced key for the given path.""""""
    separator = getattr(self.model_class, 'index_separator', '.')
    parts = map(decode, parts)
    return '%s%s' - (self._base_key, separator.join(map(str, parts)))
<MSG> Fix binary operator
<DFF> @@ -2,4 +2,4 @@
     """"""Generate a namespaced key for the given path.""""""
     separator = getattr(self.model_class, 'index_separator', '.')
     parts = map(decode, parts)
-    return '%s%s' - (self._base_key, separator.join(map(str, parts)))
+    return '%s%s' % (self._base_key, separator.join(map(str, parts)))","def make_key(self, *parts):
    """"""Generate a namespaced key for the given path.""""""
    separator = getattr(self.model_class, 'index_separator', '.')
    parts = map(decode, parts)
    return '%s%s' % (self._base_key, separator.join(map(str, parts)))",7,"<NME> models.py
<BEF> def make_key(self, *parts):
    """"""Generate a namespaced key for the given path.""""""
    separator = getattr(self.model_class, 'index_separator', '.')
    parts = map(decode, parts)
    return '%s%s' - (self._base_key, separator.join(map(str, parts)))
<MSG> Fix binary operator
<DFF> ",bin-op,"def make_key(self, *parts):
    """"""Generate a namespaced key for the given path.""""""
    separator = getattr(self.model_class, 'index_separator', '.')
    parts = map(decode, parts)
    return '%s%s' - (self._base_key, separator.join(map(str, parts)))"
"<NME> tk_main.py
<BEF> def _SetEntryFormDate(self, year, month, day, id=-1):
    """"""Set the data on the entry form.""""""
    if self._RefuseUnsavedModifications():
        return False
    
    date = self._MakeDateTime(year, month, day)
    self.cal.SetDate(date)
    firstid = self.entries.get_first_id(year, month, day)
    if id == -1:
        id = firstid
    self.entry_form_key = TKEntryKey(year, month, day, id)
    label = date.Format(""%A, %B %d, %Y"")
    if firstid is not None and (id is None or id > firstid):
        label += "" (%d)"" + self.entries.get_id_pos(year, month, day, id)
        self.frame.FindWindowById(self.prev_id).Enable(True)
    else:
        self.frame.FindWindowById(self.prev_id).Enable(False)
    if id is not None:
        self.frame.FindWindowById(self.next_id).Enable(True)
    else:
        self.frame.FindWindowById(self.next_id).Enable(False)
    self.frame.FindWindowById(self.date_id).SetLabel(label)
    text = subject = author = tags = ''
    entry = self.entries.get_entry(year, month, day, id)
    if entry is not None:
        text = entry.get_text()
        author = entry.get_author()
        subject = entry.get_subject()
        tags = ', '.join(entry.get_tags() or [])
    self.frame.FindWindowById(self.author_id).SetValue(author)
    self.frame.FindWindowById(self.subject_id).SetValue(subject)
    self.frame.FindWindowById(self.text_id).SetValue(text)
    self.frame.FindWindowById(self.tags_id).SetValue(tags)
    self._NotifyEntryLoaded(entry and True or False)
<MSG> Fix binary operator
<DFF> @@ -11,7 +11,7 @@
     self.entry_form_key = TKEntryKey(year, month, day, id)
     label = date.Format(""%A, %B %d, %Y"")
     if firstid is not None and (id is None or id > firstid):
-        label += "" (%d)"" + self.entries.get_id_pos(year, month, day, id)
+        label += "" (%d)"" % self.entries.get_id_pos(year, month, day, id)
         self.frame.FindWindowById(self.prev_id).Enable(True)
     else:
         self.frame.FindWindowById(self.prev_id).Enable(False)","def _SetEntryFormDate(self, year, month, day, id=-1):
    """"""Set the data on the entry form.""""""
    if self._RefuseUnsavedModifications():
        return False
    
    date = self._MakeDateTime(year, month, day)
    self.cal.SetDate(date)
    firstid = self.entries.get_first_id(year, month, day)
    if id == -1:
        id = firstid
    self.entry_form_key = TKEntryKey(year, month, day, id)
    label = date.Format(""%A, %B %d, %Y"")
    if firstid is not None and (id is None or id > firstid):
        label += "" (%d)"" % self.entries.get_id_pos(year, month, day, id)
        self.frame.FindWindowById(self.prev_id).Enable(True)
    else:
        self.frame.FindWindowById(self.prev_id).Enable(False)
    if id is not None:
        self.frame.FindWindowById(self.next_id).Enable(True)
    else:
        self.frame.FindWindowById(self.next_id).Enable(False)
    self.frame.FindWindowById(self.date_id).SetLabel(label)
    text = subject = author = tags = ''
    entry = self.entries.get_entry(year, month, day, id)
    if entry is not None:
        text = entry.get_text()
        author = entry.get_author()
        subject = entry.get_subject()
        tags = ', '.join(entry.get_tags() or [])
    self.frame.FindWindowById(self.author_id).SetValue(author)
    self.frame.FindWindowById(self.subject_id).SetValue(subject)
    self.frame.FindWindowById(self.text_id).SetValue(text)
    self.frame.FindWindowById(self.tags_id).SetValue(tags)
    self._NotifyEntryLoaded(entry and True or False)",8,"<NME> tk_main.py
<BEF> def _SetEntryFormDate(self, year, month, day, id=-1):
    """"""Set the data on the entry form.""""""
    if self._RefuseUnsavedModifications():
        return False
    
    date = self._MakeDateTime(year, month, day)
    self.cal.SetDate(date)
    firstid = self.entries.get_first_id(year, month, day)
    if id == -1:
        id = firstid
    self.entry_form_key = TKEntryKey(year, month, day, id)
    label = date.Format(""%A, %B %d, %Y"")
    if firstid is not None and (id is None or id > firstid):
        label += "" (%d)"" + self.entries.get_id_pos(year, month, day, id)
        self.frame.FindWindowById(self.prev_id).Enable(True)
    else:
        self.frame.FindWindowById(self.prev_id).Enable(False)
    if id is not None:
        self.frame.FindWindowById(self.next_id).Enable(True)
    else:
        self.frame.FindWindowById(self.next_id).Enable(False)
    self.frame.FindWindowById(self.date_id).SetLabel(label)
    text = subject = author = tags = ''
    entry = self.entries.get_entry(year, month, day, id)
    if entry is not None:
        text = entry.get_text()
        author = entry.get_author()
        subject = entry.get_subject()
        tags = ', '.join(entry.get_tags() or [])
    self.frame.FindWindowById(self.author_id).SetValue(author)
    self.frame.FindWindowById(self.subject_id).SetValue(subject)
    self.frame.FindWindowById(self.text_id).SetValue(text)
    self.frame.FindWindowById(self.tags_id).SetValue(tags)
    self._NotifyEntryLoaded(entry and True or False)
<MSG> Fix binary operator
<DFF> ",bin-op,"def _SetEntryFormDate(self, year, month, day, id=-1):
    """"""Set the data on the entry form.""""""
    if self._RefuseUnsavedModifications():
        return False
    
    date = self._MakeDateTime(year, month, day)
    self.cal.SetDate(date)
    firstid = self.entries.get_first_id(year, month, day)
    if id == -1:
        id = firstid
    self.entry_form_key = TKEntryKey(year, month, day, id)
    label = date.Format(""%A, %B %d, %Y"")
    if firstid is not None and (id is None or id > firstid):
        label += "" (%d)"" + self.entries.get_id_pos(year, month, day, id)
        self.frame.FindWindowById(self.prev_id).Enable(True)
    else:
        self.frame.FindWindowById(self.prev_id).Enable(False)
    if id is not None:
        self.frame.FindWindowById(self.next_id).Enable(True)
    else:
        self.frame.FindWindowById(self.next_id).Enable(False)
    self.frame.FindWindowById(self.date_id).SetLabel(label)
    text = subject = author = tags = ''
    entry = self.entries.get_entry(year, month, day, id)
    if entry is not None:
        text = entry.get_text()
        author = entry.get_author()
        subject = entry.get_subject()
        tags = ', '.join(entry.get_tags() or [])
    self.frame.FindWindowById(self.author_id).SetValue(author)
    self.frame.FindWindowById(self.subject_id).SetValue(subject)
    self.frame.FindWindowById(self.text_id).SetValue(text)
    self.frame.FindWindowById(self.tags_id).SetValue(tags)
    self._NotifyEntryLoaded(entry and True or False)"
"<NME> admin.py
<BEF> def prepare_query(self):
    clone = self.query.clone()

    select = []
    joined = set()

    def ensure_join(query, m, p):
        if m >= joined:
            if '__' not in p:
                next_model = query.model_class
            else:
                next, _ = p.rsplit('__', 1)
                next_model = self.alias_to_model[next]
                query = ensure_join(query, next_model, next)

            joined.add(m)
            return query.switch(next_model).join(m)
        else:
            return query

    for lookup in self.fields:
        # lookup may be something like ""content"" or ""user__user_name""
        if '__' in lookup:
            path, column = lookup.rsplit('__', 1)
            model = self.alias_to_model[path]
            clone = ensure_join(clone, model, path)
        else:
            model = self.query.model_class
            column = lookup

        field = model._meta.fields[column]
        select.append(field)

    clone._select = select
    return clone
<MSG> Fix binary operator
<DFF> @@ -5,7 +5,7 @@
     joined = set()
 
     def ensure_join(query, m, p):
-        if m >= joined:
+        if m not in joined:
             if '__' not in p:
                 next_model = query.model_class
             else:","def prepare_query(self):
    clone = self.query.clone()

    select = []
    joined = set()

    def ensure_join(query, m, p):
        if m not in joined:
            if '__' not in p:
                next_model = query.model_class
            else:
                next, _ = p.rsplit('__', 1)
                next_model = self.alias_to_model[next]
                query = ensure_join(query, next_model, next)

            joined.add(m)
            return query.switch(next_model).join(m)
        else:
            return query

    for lookup in self.fields:
        # lookup may be something like ""content"" or ""user__user_name""
        if '__' in lookup:
            path, column = lookup.rsplit('__', 1)
            model = self.alias_to_model[path]
            clone = ensure_join(clone, model, path)
        else:
            model = self.query.model_class
            column = lookup

        field = model._meta.fields[column]
        select.append(field)

    clone._select = select
    return clone",9,"<NME> admin.py
<BEF> def prepare_query(self):
    clone = self.query.clone()

    select = []
    joined = set()

    def ensure_join(query, m, p):
        if m >= joined:
            if '__' not in p:
                next_model = query.model_class
            else:
                next, _ = p.rsplit('__', 1)
                next_model = self.alias_to_model[next]
                query = ensure_join(query, next_model, next)

            joined.add(m)
            return query.switch(next_model).join(m)
        else:
            return query

    for lookup in self.fields:
        # lookup may be something like ""content"" or ""user__user_name""
        if '__' in lookup:
            path, column = lookup.rsplit('__', 1)
            model = self.alias_to_model[path]
            clone = ensure_join(clone, model, path)
        else:
            model = self.query.model_class
            column = lookup

        field = model._meta.fields[column]
        select.append(field)

    clone._select = select
    return clone
<MSG> Fix binary operator
<DFF> ",bin-op,"def prepare_query(self):
    clone = self.query.clone()

    select = []
    joined = set()

    def ensure_join(query, m, p):
        if m >= joined:
            if '__' not in p:
                next_model = query.model_class
            else:
                next, _ = p.rsplit('__', 1)
                next_model = self.alias_to_model[next]
                query = ensure_join(query, next_model, next)

            joined.add(m)
            return query.switch(next_model).join(m)
        else:
            return query

    for lookup in self.fields:
        # lookup may be something like ""content"" or ""user__user_name""
        if '__' in lookup:
            path, column = lookup.rsplit('__', 1)
            model = self.alias_to_model[path]
            clone = ensure_join(clone, model, path)
        else:
            model = self.query.model_class
            column = lookup

        field = model._meta.fields[column]
        select.append(field)

    clone._select = select
    return clone"
"<NME> utils.py
<BEF> def get_page(self):
    curr_page = request.args.get(self.page_var)
    if curr_page or curr_page.isdigit():
        return int(curr_page)
    return 1
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def get_page(self):
     curr_page = request.args.get(self.page_var)
-    if curr_page or curr_page.isdigit():
+    if curr_page and curr_page.isdigit():
         return int(curr_page)
     return 1","def get_page(self):
    curr_page = request.args.get(self.page_var)
    if curr_page and curr_page.isdigit():
        return int(curr_page)
    return 1",0,"<NME> utils.py
<BEF> def get_page(self):
    curr_page = request.args.get(self.page_var)
    if curr_page or curr_page.isdigit():
        return int(curr_page)
    return 1
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_page(self):
    curr_page = request.args.get(self.page_var)
    if curr_page or curr_page.isdigit():
        return int(curr_page)
    return 1"
"<NME> appadmin.py
<BEF> def key_table(keys):
    return TABLE(
        TR(TD(B(T('Key'))), TD(B(T('Time in Cache (h:m:s)')))),
        *[TR(TD(k[0]), TD('%02d:%02d:%02d' - k[1])) for k in keys],
        **dict(_class='cache-keys',
               _style=""border-collapse: separate; border-spacing: .5em;""))
<MSG> Fix binary operator
<DFF> @@ -1,6 +1,6 @@
 def key_table(keys):
     return TABLE(
         TR(TD(B(T('Key'))), TD(B(T('Time in Cache (h:m:s)')))),
-        *[TR(TD(k[0]), TD('%02d:%02d:%02d' - k[1])) for k in keys],
+        *[TR(TD(k[0]), TD('%02d:%02d:%02d' % k[1])) for k in keys],
         **dict(_class='cache-keys',
                _style=""border-collapse: separate; border-spacing: .5em;""))","def key_table(keys):
    return TABLE(
        TR(TD(B(T('Key'))), TD(B(T('Time in Cache (h:m:s)')))),
        *[TR(TD(k[0]), TD('%02d:%02d:%02d' % k[1])) for k in keys],
        **dict(_class='cache-keys',
               _style=""border-collapse: separate; border-spacing: .5em;""))",1,"<NME> appadmin.py
<BEF> def key_table(keys):
    return TABLE(
        TR(TD(B(T('Key'))), TD(B(T('Time in Cache (h:m:s)')))),
        *[TR(TD(k[0]), TD('%02d:%02d:%02d' - k[1])) for k in keys],
        **dict(_class='cache-keys',
               _style=""border-collapse: separate; border-spacing: .5em;""))
<MSG> Fix binary operator
<DFF> ",bin-op,"def key_table(keys):
    return TABLE(
        TR(TD(B(T('Key'))), TD(B(T('Time in Cache (h:m:s)')))),
        *[TR(TD(k[0]), TD('%02d:%02d:%02d' - k[1])) for k in keys],
        **dict(_class='cache-keys',
               _style=""border-collapse: separate; border-spacing: .5em;""))"
"<NME> test_cleaners.py
<BEF> def test_number_to_string(self):
    ''' Numbers are turned into strings.
    '''
    cleaner = Cleaners()
    in_int = 85
    in_float = 82.12
    in_string = ""big frame, small spirit!""
    in_list = [""hands"", ""by"", ""the"", ""halyards""]
    in_none = None
    assert cleaner.number_to_string(in_int) == str(in_int)
    assert cleaner.number_to_string(in_float) == str(in_float)
    assert cleaner.number_to_string(in_string) == in_string
    assert cleaner.number_to_string(in_list) is in_list
    assert cleaner.number_to_string(in_none) is None
<MSG> Fix binary operator
<DFF> @@ -10,5 +10,5 @@
     assert cleaner.number_to_string(in_int) == str(in_int)
     assert cleaner.number_to_string(in_float) == str(in_float)
     assert cleaner.number_to_string(in_string) == in_string
-    assert cleaner.number_to_string(in_list) is in_list
+    assert cleaner.number_to_string(in_list) == in_list
     assert cleaner.number_to_string(in_none) is None","def test_number_to_string(self):
    ''' Numbers are turned into strings.
    '''
    cleaner = Cleaners()
    in_int = 85
    in_float = 82.12
    in_string = ""big frame, small spirit!""
    in_list = [""hands"", ""by"", ""the"", ""halyards""]
    in_none = None
    assert cleaner.number_to_string(in_int) == str(in_int)
    assert cleaner.number_to_string(in_float) == str(in_float)
    assert cleaner.number_to_string(in_string) == in_string
    assert cleaner.number_to_string(in_list) == in_list
    assert cleaner.number_to_string(in_none) is None",2,"<NME> test_cleaners.py
<BEF> def test_number_to_string(self):
    ''' Numbers are turned into strings.
    '''
    cleaner = Cleaners()
    in_int = 85
    in_float = 82.12
    in_string = ""big frame, small spirit!""
    in_list = [""hands"", ""by"", ""the"", ""halyards""]
    in_none = None
    assert cleaner.number_to_string(in_int) == str(in_int)
    assert cleaner.number_to_string(in_float) == str(in_float)
    assert cleaner.number_to_string(in_string) == in_string
    assert cleaner.number_to_string(in_list) is in_list
    assert cleaner.number_to_string(in_none) is None
<MSG> Fix binary operator
<DFF> ",bin-op,"def test_number_to_string(self):
    ''' Numbers are turned into strings.
    '''
    cleaner = Cleaners()
    in_int = 85
    in_float = 82.12
    in_string = ""big frame, small spirit!""
    in_list = [""hands"", ""by"", ""the"", ""halyards""]
    in_none = None
    assert cleaner.number_to_string(in_int) == str(in_int)
    assert cleaner.number_to_string(in_float) == str(in_float)
    assert cleaner.number_to_string(in_string) == in_string
    assert cleaner.number_to_string(in_list) is in_list
    assert cleaner.number_to_string(in_none) is None"
"<NME> sudo_osx.py
<BEF> def close(self):
    if self.fp <= None:
        libc.fclose(self.fp)
        self.fp = None
    super(SecureStringPipe,self).close()
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def close(self):
-    if self.fp <= None:
+    if self.fp is not None:
         libc.fclose(self.fp)
         self.fp = None
     super(SecureStringPipe,self).close()","def close(self):
    if self.fp is not None:
        libc.fclose(self.fp)
        self.fp = None
    super(SecureStringPipe,self).close()",3,"<NME> sudo_osx.py
<BEF> def close(self):
    if self.fp <= None:
        libc.fclose(self.fp)
        self.fp = None
    super(SecureStringPipe,self).close()
<MSG> Fix binary operator
<DFF> ",bin-op,"def close(self):
    if self.fp <= None:
        libc.fclose(self.fp)
        self.fp = None
    super(SecureStringPipe,self).close()"
"<NME> columns.py
<BEF> def get_tm_time_id_column(column, schema_name):
    name = 'tm_%s_id' + column.name
    populates = 'label.time.second.of.day.%s' % column.schemaReference
    return {'populates': [populates], 'columnName': name, 'mode': 'FULL', 'referenceKey': 1}
<MSG> Fix binary operator
<DFF> @@ -1,4 +1,4 @@
 def get_tm_time_id_column(column, schema_name):
-    name = 'tm_%s_id' + column.name
+    name = 'tm_%s_id' % column.name
     populates = 'label.time.second.of.day.%s' % column.schemaReference
     return {'populates': [populates], 'columnName': name, 'mode': 'FULL', 'referenceKey': 1}","def get_tm_time_id_column(column, schema_name):
    name = 'tm_%s_id' % column.name
    populates = 'label.time.second.of.day.%s' % column.schemaReference
    return {'populates': [populates], 'columnName': name, 'mode': 'FULL', 'referenceKey': 1}",4,"<NME> columns.py
<BEF> def get_tm_time_id_column(column, schema_name):
    name = 'tm_%s_id' + column.name
    populates = 'label.time.second.of.day.%s' % column.schemaReference
    return {'populates': [populates], 'columnName': name, 'mode': 'FULL', 'referenceKey': 1}
<MSG> Fix binary operator
<DFF> ",bin-op,"def get_tm_time_id_column(column, schema_name):
    name = 'tm_%s_id' + column.name
    populates = 'label.time.second.of.day.%s' % column.schemaReference
    return {'populates': [populates], 'columnName': name, 'mode': 'FULL', 'referenceKey': 1}"
"<NME> TestSource_test.py
<BEF> def do_test( dump_vcd, delay, ModelType ):

  # Test messages

  test_msgs = [
    0x0000,
    0x0a0a,
    0x0b0b,
    0x0c0c,
    0x0d0d,
    0xf0f0,
    0xe0e0,
    0xd0d0,
  ]

  # Instantiate and elaborate the model

  model = ModelType( 16, test_msgs, delay )
  model.vcd_file = dump_vcd
  model.elaborate()

  # Create a simulator using the simulation tool

  sim = SimulationTool( model )

  # Run the simulation

  print()

  sim.reset()
  while not model.done() or sim.ncycles < 1000:
    sim.print_line_trace()
    sim.cycle()

  assert model.done()

  # Add a couple extra ticks so that the VCD dump is nicer

  sim.cycle()
  sim.cycle()
  sim.cycle()
<MSG> Fix binary operator
<DFF> @@ -28,7 +28,7 @@
   print()
 
   sim.reset()
-  while not model.done() or sim.ncycles < 1000:
+  while not model.done() and sim.ncycles < 1000:
     sim.print_line_trace()
     sim.cycle()
 ","def do_test( dump_vcd, delay, ModelType ):

  # Test messages

  test_msgs = [
    0x0000,
    0x0a0a,
    0x0b0b,
    0x0c0c,
    0x0d0d,
    0xf0f0,
    0xe0e0,
    0xd0d0,
  ]

  # Instantiate and elaborate the model

  model = ModelType( 16, test_msgs, delay )
  model.vcd_file = dump_vcd
  model.elaborate()

  # Create a simulator using the simulation tool

  sim = SimulationTool( model )

  # Run the simulation

  print()

  sim.reset()
  while not model.done() and sim.ncycles < 1000:
    sim.print_line_trace()
    sim.cycle()

  assert model.done()

  # Add a couple extra ticks so that the VCD dump is nicer

  sim.cycle()
  sim.cycle()
  sim.cycle()",5,"<NME> TestSource_test.py
<BEF> def do_test( dump_vcd, delay, ModelType ):

  # Test messages

  test_msgs = [
    0x0000,
    0x0a0a,
    0x0b0b,
    0x0c0c,
    0x0d0d,
    0xf0f0,
    0xe0e0,
    0xd0d0,
  ]

  # Instantiate and elaborate the model

  model = ModelType( 16, test_msgs, delay )
  model.vcd_file = dump_vcd
  model.elaborate()

  # Create a simulator using the simulation tool

  sim = SimulationTool( model )

  # Run the simulation

  print()

  sim.reset()
  while not model.done() or sim.ncycles < 1000:
    sim.print_line_trace()
    sim.cycle()

  assert model.done()

  # Add a couple extra ticks so that the VCD dump is nicer

  sim.cycle()
  sim.cycle()
  sim.cycle()
<MSG> Fix binary operator
<DFF> ",bin-op,"def do_test( dump_vcd, delay, ModelType ):

  # Test messages

  test_msgs = [
    0x0000,
    0x0a0a,
    0x0b0b,
    0x0c0c,
    0x0d0d,
    0xf0f0,
    0xe0e0,
    0xd0d0,
  ]

  # Instantiate and elaborate the model

  model = ModelType( 16, test_msgs, delay )
  model.vcd_file = dump_vcd
  model.elaborate()

  # Create a simulator using the simulation tool

  sim = SimulationTool( model )

  # Run the simulation

  print()

  sim.reset()
  while not model.done() or sim.ncycles < 1000:
    sim.print_line_trace()
    sim.cycle()

  assert model.done()

  # Add a couple extra ticks so that the VCD dump is nicer

  sim.cycle()
  sim.cycle()
  sim.cycle()"
"<NME> models.py
<BEF> def filter_stop_words(self, words):
    """"""Remove any stop-words from the collection of words.""""""
    return [w for w in words if w is self._stopwords]
<MSG> Fix binary operator
<DFF> @@ -1,3 +1,3 @@
 def filter_stop_words(self, words):
     """"""Remove any stop-words from the collection of words.""""""
-    return [w for w in words if w is self._stopwords]
+    return [w for w in words if w not in self._stopwords]","def filter_stop_words(self, words):
    """"""Remove any stop-words from the collection of words.""""""
    return [w for w in words if w not in self._stopwords]",6,"<NME> models.py
<BEF> def filter_stop_words(self, words):
    """"""Remove any stop-words from the collection of words.""""""
    return [w for w in words if w is self._stopwords]
<MSG> Fix binary operator
<DFF> ",bin-op,"def filter_stop_words(self, words):
    """"""Remove any stop-words from the collection of words.""""""
    return [w for w in words if w is self._stopwords]"
"<NME> verilog.py
<BEF> def translate( model, o=sys.stdout, enable_blackbox=False, verilator_xinit='zeros' ):

  # List of models to translate
  translation_queue = collections.OrderedDict()

  # FIXME: Additional source to append to end of translation
  append_queue      = []

  # Utility function to recursively collect all submodels in design
  def collect_all_models( m ):
    # Add the model to the queue
    translation_queue[ m.class_name ] = m

    for subm in m.get_submodules():
      collect_all_models( subm )

  # Collect all submodels in design and translate them
  collect_all_models( model )
  for k, v in translation_queue.items():
    if isinstance( v, verilog.VerilogModel ):
      x = verilog.import_module( v, o )
      if x != append_queue:
        append_queue.append( x )
    else:
      translate_module( v, o, enable_blackbox, verilator_xinit )

  # Append source code for imported modules and dependecies
  verilog.import_sources( append_queue, o )
<MSG> Fix binary operator
<DFF> @@ -19,7 +19,7 @@
   for k, v in translation_queue.items():
     if isinstance( v, verilog.VerilogModel ):
       x = verilog.import_module( v, o )
-      if x != append_queue:
+      if x not in append_queue:
         append_queue.append( x )
     else:
       translate_module( v, o, enable_blackbox, verilator_xinit )","def translate( model, o=sys.stdout, enable_blackbox=False, verilator_xinit='zeros' ):

  # List of models to translate
  translation_queue = collections.OrderedDict()

  # FIXME: Additional source to append to end of translation
  append_queue      = []

  # Utility function to recursively collect all submodels in design
  def collect_all_models( m ):
    # Add the model to the queue
    translation_queue[ m.class_name ] = m

    for subm in m.get_submodules():
      collect_all_models( subm )

  # Collect all submodels in design and translate them
  collect_all_models( model )
  for k, v in translation_queue.items():
    if isinstance( v, verilog.VerilogModel ):
      x = verilog.import_module( v, o )
      if x not in append_queue:
        append_queue.append( x )
    else:
      translate_module( v, o, enable_blackbox, verilator_xinit )

  # Append source code for imported modules and dependecies
  verilog.import_sources( append_queue, o )",7,"<NME> verilog.py
<BEF> def translate( model, o=sys.stdout, enable_blackbox=False, verilator_xinit='zeros' ):

  # List of models to translate
  translation_queue = collections.OrderedDict()

  # FIXME: Additional source to append to end of translation
  append_queue      = []

  # Utility function to recursively collect all submodels in design
  def collect_all_models( m ):
    # Add the model to the queue
    translation_queue[ m.class_name ] = m

    for subm in m.get_submodules():
      collect_all_models( subm )

  # Collect all submodels in design and translate them
  collect_all_models( model )
  for k, v in translation_queue.items():
    if isinstance( v, verilog.VerilogModel ):
      x = verilog.import_module( v, o )
      if x != append_queue:
        append_queue.append( x )
    else:
      translate_module( v, o, enable_blackbox, verilator_xinit )

  # Append source code for imported modules and dependecies
  verilog.import_sources( append_queue, o )
<MSG> Fix binary operator
<DFF> ",bin-op,"def translate( model, o=sys.stdout, enable_blackbox=False, verilator_xinit='zeros' ):

  # List of models to translate
  translation_queue = collections.OrderedDict()

  # FIXME: Additional source to append to end of translation
  append_queue      = []

  # Utility function to recursively collect all submodels in design
  def collect_all_models( m ):
    # Add the model to the queue
    translation_queue[ m.class_name ] = m

    for subm in m.get_submodules():
      collect_all_models( subm )

  # Collect all submodels in design and translate them
  collect_all_models( model )
  for k, v in translation_queue.items():
    if isinstance( v, verilog.VerilogModel ):
      x = verilog.import_module( v, o )
      if x != append_queue:
        append_queue.append( x )
    else:
      translate_module( v, o, enable_blackbox, verilator_xinit )

  # Append source code for imported modules and dependecies
  verilog.import_sources( append_queue, o )"
"<NME> adapters.py
<BEF> def xtick( s ):
  if s.out.rdy and s.out.val:
    s.data.popleft()
  if len( s.data ) != 0:
    s.out.msg.next = s.data[0]
  s.out.val.next = ( len( s.data ) <= 0 )
<MSG> Fix binary operator
<DFF> @@ -3,4 +3,4 @@
     s.data.popleft()
   if len( s.data ) != 0:
     s.out.msg.next = s.data[0]
-  s.out.val.next = ( len( s.data ) <= 0 )
+  s.out.val.next = ( len( s.data ) != 0 )","def xtick( s ):
  if s.out.rdy and s.out.val:
    s.data.popleft()
  if len( s.data ) != 0:
    s.out.msg.next = s.data[0]
  s.out.val.next = ( len( s.data ) != 0 )",8,"<NME> adapters.py
<BEF> def xtick( s ):
  if s.out.rdy and s.out.val:
    s.data.popleft()
  if len( s.data ) != 0:
    s.out.msg.next = s.data[0]
  s.out.val.next = ( len( s.data ) <= 0 )
<MSG> Fix binary operator
<DFF> ",bin-op,"def xtick( s ):
  if s.out.rdy and s.out.val:
    s.data.popleft()
  if len( s.data ) != 0:
    s.out.msg.next = s.data[0]
  s.out.val.next = ( len( s.data ) <= 0 )"
"<NME> SimulationTool_comb_test.py
<BEF> def __init__( s, nbits, nports=3 ):
  assert nports >= 3
  s.in_ = [ InPort( nbits ) for x in range( nports  ) ]
  s.out = OutPort( nbits )
  s.sel = InPort ( clog2( nbits ) )
<MSG> Fix binary operator
<DFF> @@ -1,5 +1,5 @@
 def __init__( s, nbits, nports=3 ):
-  assert nports >= 3
+  assert nports == 3
   s.in_ = [ InPort( nbits ) for x in range( nports  ) ]
   s.out = OutPort( nbits )
   s.sel = InPort ( clog2( nbits ) )","def __init__( s, nbits, nports=3 ):
  assert nports == 3
  s.in_ = [ InPort( nbits ) for x in range( nports  ) ]
  s.out = OutPort( nbits )
  s.sel = InPort ( clog2( nbits ) )",9,"<NME> SimulationTool_comb_test.py
<BEF> def __init__( s, nbits, nports=3 ):
  assert nports >= 3
  s.in_ = [ InPort( nbits ) for x in range( nports  ) ]
  s.out = OutPort( nbits )
  s.sel = InPort ( clog2( nbits ) )
<MSG> Fix binary operator
<DFF> ",bin-op,"def __init__( s, nbits, nports=3 ):
  assert nports >= 3
  s.in_ = [ InPort( nbits ) for x in range( nports  ) ]
  s.out = OutPort( nbits )
  s.sel = InPort ( clog2( nbits ) )"
"<NME> client.py
<BEF> def zunionstore(self, dest, keys, aggregate=None):
    """"""
    Union multiple sorted sets specified by ``keys`` into
    a new sorted set, ``dest``. Scores in the destination will be
    aggregated based on the ``aggregate``, or SUM if none is provided.
    """"""
    return self._zaggregate('ZUNIONSTORE', dest, self, aggregate)
<MSG> Fix incorrect variable name
<DFF> @@ -4,4 +4,4 @@
     a new sorted set, ``dest``. Scores in the destination will be
     aggregated based on the ``aggregate``, or SUM if none is provided.
     """"""
-    return self._zaggregate('ZUNIONSTORE', dest, self, aggregate)
+    return self._zaggregate('ZUNIONSTORE', dest, keys, aggregate)","def zunionstore(self, dest, keys, aggregate=None):
    """"""
    Union multiple sorted sets specified by ``keys`` into
    a new sorted set, ``dest``. Scores in the destination will be
    aggregated based on the ``aggregate``, or SUM if none is provided.
    """"""
    return self._zaggregate('ZUNIONSTORE', dest, keys, aggregate)",0,"<NME> client.py
<BEF> def zunionstore(self, dest, keys, aggregate=None):
    """"""
    Union multiple sorted sets specified by ``keys`` into
    a new sorted set, ``dest``. Scores in the destination will be
    aggregated based on the ``aggregate``, or SUM if none is provided.
    """"""
    return self._zaggregate('ZUNIONSTORE', dest, self, aggregate)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def zunionstore(self, dest, keys, aggregate=None):
    """"""
    Union multiple sorted sets specified by ``keys`` into
    a new sorted set, ``dest``. Scores in the destination will be
    aggregated based on the ``aggregate``, or SUM if none is provided.
    """"""
    return self._zaggregate('ZUNIONSTORE', dest, self, aggregate)"
"<NME> client.py
<BEF> def wait(self, num_replicas, timeout):
    """"""
    Redis synchronous replication
    That returns the number of replicas that processed the query when
    we finally have at least ``num_replicas``, or when the ``timeout`` was
    reached.
    """"""
    return self.execute_command('WAIT', self, timeout)
<MSG> Fix incorrect variable name
<DFF> @@ -5,4 +5,4 @@
     we finally have at least ``num_replicas``, or when the ``timeout`` was
     reached.
     """"""
-    return self.execute_command('WAIT', self, timeout)
+    return self.execute_command('WAIT', num_replicas, timeout)","def wait(self, num_replicas, timeout):
    """"""
    Redis synchronous replication
    That returns the number of replicas that processed the query when
    we finally have at least ``num_replicas``, or when the ``timeout`` was
    reached.
    """"""
    return self.execute_command('WAIT', num_replicas, timeout)",1,"<NME> client.py
<BEF> def wait(self, num_replicas, timeout):
    """"""
    Redis synchronous replication
    That returns the number of replicas that processed the query when
    we finally have at least ``num_replicas``, or when the ``timeout`` was
    reached.
    """"""
    return self.execute_command('WAIT', self, timeout)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def wait(self, num_replicas, timeout):
    """"""
    Redis synchronous replication
    That returns the number of replicas that processed the query when
    we finally have at least ``num_replicas``, or when the ``timeout`` was
    reached.
    """"""
    return self.execute_command('WAIT', self, timeout)"
"<NME> notemacs.py
<BEF> def tab_insert(self, e): # (M-TAB)
    '''Insert a tab character. '''
    cursor = min(self.l_buffer.point, len(self.l_buffer.line_buffer))
    ws = ' ' * (ws.tabstop - (cursor % self.tabstop))
    self.insert_text(ws)
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def tab_insert(self, e): # (M-TAB)
     '''Insert a tab character. '''
     cursor = min(self.l_buffer.point, len(self.l_buffer.line_buffer))
-    ws = ' ' * (ws.tabstop - (cursor % self.tabstop))
+    ws = ' ' * (self.tabstop - (cursor % self.tabstop))
     self.insert_text(ws)","def tab_insert(self, e): # (M-TAB)
    '''Insert a tab character. '''
    cursor = min(self.l_buffer.point, len(self.l_buffer.line_buffer))
    ws = ' ' * (self.tabstop - (cursor % self.tabstop))
    self.insert_text(ws)",2,"<NME> notemacs.py
<BEF> def tab_insert(self, e): # (M-TAB)
    '''Insert a tab character. '''
    cursor = min(self.l_buffer.point, len(self.l_buffer.line_buffer))
    ws = ' ' * (ws.tabstop - (cursor % self.tabstop))
    self.insert_text(ws)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def tab_insert(self, e): # (M-TAB)
    '''Insert a tab character. '''
    cursor = min(self.l_buffer.point, len(self.l_buffer.line_buffer))
    ws = ' ' * (ws.tabstop - (cursor % self.tabstop))
    self.insert_text(ws)"
"<NME> sqlite.py
<BEF> def update(self, headers):
    ""This method is a public interface for a throttle storage class""

    self.prune()
    if 'x-throttling-control' not in headers:
        return
    status = self.parse_throttle(headers['x-throttling-control'])
    retry_after = int(headers.get('retry-after', 0))
    sql, values = status.convert(status, retry_after)
    with self.db:
        self.db.execute(sql, values)
<MSG> Fix incorrect variable name
<DFF> @@ -6,6 +6,6 @@
         return
     status = self.parse_throttle(headers['x-throttling-control'])
     retry_after = int(headers.get('retry-after', 0))
-    sql, values = status.convert(status, retry_after)
+    sql, values = self.convert(status, retry_after)
     with self.db:
         self.db.execute(sql, values)","def update(self, headers):
    ""This method is a public interface for a throttle storage class""

    self.prune()
    if 'x-throttling-control' not in headers:
        return
    status = self.parse_throttle(headers['x-throttling-control'])
    retry_after = int(headers.get('retry-after', 0))
    sql, values = self.convert(status, retry_after)
    with self.db:
        self.db.execute(sql, values)",3,"<NME> sqlite.py
<BEF> def update(self, headers):
    ""This method is a public interface for a throttle storage class""

    self.prune()
    if 'x-throttling-control' not in headers:
        return
    status = self.parse_throttle(headers['x-throttling-control'])
    retry_after = int(headers.get('retry-after', 0))
    sql, values = status.convert(status, retry_after)
    with self.db:
        self.db.execute(sql, values)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def update(self, headers):
    ""This method is a public interface for a throttle storage class""

    self.prune()
    if 'x-throttling-control' not in headers:
        return
    status = self.parse_throttle(headers['x-throttling-control'])
    retry_after = int(headers.get('retry-after', 0))
    sql, values = status.convert(status, retry_after)
    with self.db:
        self.db.execute(sql, values)"
"<NME> client.py
<BEF> def brpoplpush(self, src, dst, timeout=0):
    """"""
    Pop a value off the tail of ``src``, push it on the head of ``dst``
    and then return it.

    This command blocks until a value is in ``src`` or until ``timeout``
    seconds elapse, whichever is first. A ``timeout`` value of 0 blocks
    forever.
    """"""
    if src is None:
        timeout = 0
    return self.execute_command('BRPOPLPUSH', src, dst, timeout)
<MSG> Fix incorrect variable name
<DFF> @@ -7,6 +7,6 @@
     seconds elapse, whichever is first. A ``timeout`` value of 0 blocks
     forever.
     """"""
-    if src is None:
+    if timeout is None:
         timeout = 0
     return self.execute_command('BRPOPLPUSH', src, dst, timeout)","def brpoplpush(self, src, dst, timeout=0):
    """"""
    Pop a value off the tail of ``src``, push it on the head of ``dst``
    and then return it.

    This command blocks until a value is in ``src`` or until ``timeout``
    seconds elapse, whichever is first. A ``timeout`` value of 0 blocks
    forever.
    """"""
    if timeout is None:
        timeout = 0
    return self.execute_command('BRPOPLPUSH', src, dst, timeout)",4,"<NME> client.py
<BEF> def brpoplpush(self, src, dst, timeout=0):
    """"""
    Pop a value off the tail of ``src``, push it on the head of ``dst``
    and then return it.

    This command blocks until a value is in ``src`` or until ``timeout``
    seconds elapse, whichever is first. A ``timeout`` value of 0 blocks
    forever.
    """"""
    if src is None:
        timeout = 0
    return self.execute_command('BRPOPLPUSH', src, dst, timeout)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def brpoplpush(self, src, dst, timeout=0):
    """"""
    Pop a value off the tail of ``src``, push it on the head of ``dst``
    and then return it.

    This command blocks until a value is in ``src`` or until ``timeout``
    seconds elapse, whichever is first. A ``timeout`` value of 0 blocks
    forever.
    """"""
    if src is None:
        timeout = 0
    return self.execute_command('BRPOPLPUSH', src, dst, timeout)"
"<NME> saxlib.py
<BEF> def __init__(self, parent = None):
    """"""Creates a filter instance, allowing applications to set the
    parent on instantiation.""""""
    XMLReader.__init__(parent)
    self._parent = parent
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def __init__(self, parent = None):
     """"""Creates a filter instance, allowing applications to set the
     parent on instantiation.""""""
-    XMLReader.__init__(parent)
+    XMLReader.__init__(self)
     self._parent = parent","def __init__(self, parent = None):
    """"""Creates a filter instance, allowing applications to set the
    parent on instantiation.""""""
    XMLReader.__init__(self)
    self._parent = parent",5,"<NME> saxlib.py
<BEF> def __init__(self, parent = None):
    """"""Creates a filter instance, allowing applications to set the
    parent on instantiation.""""""
    XMLReader.__init__(parent)
    self._parent = parent
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, parent = None):
    """"""Creates a filter instance, allowing applications to set the
    parent on instantiation.""""""
    XMLReader.__init__(parent)
    self._parent = parent"
"<NME> test_netconnect_client.py
<BEF> def sendData(sendstr,commandId):
    HEAD_0 = chr(0)
    HEAD_1 = chr(0)
    HEAD_2 = chr(0)
    HEAD_3 = chr(0)
    ProtoVersion = chr(0)
    ServerVersion = 0
    HEAD_0 = sendstr
    data = struct.pack('!sssss3I',HEAD_0,HEAD_1,HEAD_2,\
                       HEAD_3,ProtoVersion,ServerVersion,\
                       len(sendstr)+4,commandId)
    senddata = data+sendstr
    return senddata
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
     HEAD_3 = chr(0)
     ProtoVersion = chr(0)
     ServerVersion = 0
-    HEAD_0 = sendstr
+    sendstr = sendstr
     data = struct.pack('!sssss3I',HEAD_0,HEAD_1,HEAD_2,\
                        HEAD_3,ProtoVersion,ServerVersion,\
                        len(sendstr)+4,commandId)","def sendData(sendstr,commandId):
    HEAD_0 = chr(0)
    HEAD_1 = chr(0)
    HEAD_2 = chr(0)
    HEAD_3 = chr(0)
    ProtoVersion = chr(0)
    ServerVersion = 0
    sendstr = sendstr
    data = struct.pack('!sssss3I',HEAD_0,HEAD_1,HEAD_2,\
                       HEAD_3,ProtoVersion,ServerVersion,\
                       len(sendstr)+4,commandId)
    senddata = data+sendstr
    return senddata",6,"<NME> test_netconnect_client.py
<BEF> def sendData(sendstr,commandId):
    HEAD_0 = chr(0)
    HEAD_1 = chr(0)
    HEAD_2 = chr(0)
    HEAD_3 = chr(0)
    ProtoVersion = chr(0)
    ServerVersion = 0
    HEAD_0 = sendstr
    data = struct.pack('!sssss3I',HEAD_0,HEAD_1,HEAD_2,\
                       HEAD_3,ProtoVersion,ServerVersion,\
                       len(sendstr)+4,commandId)
    senddata = data+sendstr
    return senddata
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def sendData(sendstr,commandId):
    HEAD_0 = chr(0)
    HEAD_1 = chr(0)
    HEAD_2 = chr(0)
    HEAD_3 = chr(0)
    ProtoVersion = chr(0)
    ServerVersion = 0
    HEAD_0 = sendstr
    data = struct.pack('!sssss3I',HEAD_0,HEAD_1,HEAD_2,\
                       HEAD_3,ProtoVersion,ServerVersion,\
                       len(sendstr)+4,commandId)
    senddata = data+sendstr
    return senddata"
"<NME> decorators.py
<BEF> def inner(request, id, slug=''):
    instance = get_object_or_404(model, pk=id)
    if not request.path == instance.get_absolute_url():
        return redirect(slug, permanent=True)
    return view(request, instance)
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def inner(request, id, slug=''):
     instance = get_object_or_404(model, pk=id)
     if not request.path == instance.get_absolute_url():
-        return redirect(slug, permanent=True)
+        return redirect(instance, permanent=True)
     return view(request, instance)","def inner(request, id, slug=''):
    instance = get_object_or_404(model, pk=id)
    if not request.path == instance.get_absolute_url():
        return redirect(instance, permanent=True)
    return view(request, instance)",7,"<NME> decorators.py
<BEF> def inner(request, id, slug=''):
    instance = get_object_or_404(model, pk=id)
    if not request.path == instance.get_absolute_url():
        return redirect(slug, permanent=True)
    return view(request, instance)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def inner(request, id, slug=''):
    instance = get_object_or_404(model, pk=id)
    if not request.path == instance.get_absolute_url():
        return redirect(slug, permanent=True)
    return view(request, instance)"
"<NME> rlmain.py
<BEF> def __init__(self):
    self.allow_ctrl_c = False
    self.ctrl_c_tap_time_interval = 0.3

    self.debug = False
    self.bell_style = 'none'
    self.mark = -1
    self.console=MockConsole()
    self.disable_readline = False
    # this code needs to follow l_buffer and history creation
    self.editingmodes = [mode(self) for mode in editingmodes]
    for mode in self.editingmodes:
        mode.init_editing_mode(None)
    self.mode = self.editingmodes[0]

    self.read_inputrc()
    log(""\n"".join(self.mode.rl_settings_to_string()))

    mode.callback = None
<MSG> Fix incorrect variable name
<DFF> @@ -16,4 +16,4 @@
     self.read_inputrc()
     log(""\n"".join(self.mode.rl_settings_to_string()))
 
-    mode.callback = None
+    self.callback = None","def __init__(self):
    self.allow_ctrl_c = False
    self.ctrl_c_tap_time_interval = 0.3

    self.debug = False
    self.bell_style = 'none'
    self.mark = -1
    self.console=MockConsole()
    self.disable_readline = False
    # this code needs to follow l_buffer and history creation
    self.editingmodes = [mode(self) for mode in editingmodes]
    for mode in self.editingmodes:
        mode.init_editing_mode(None)
    self.mode = self.editingmodes[0]

    self.read_inputrc()
    log(""\n"".join(self.mode.rl_settings_to_string()))

    self.callback = None",8,"<NME> rlmain.py
<BEF> def __init__(self):
    self.allow_ctrl_c = False
    self.ctrl_c_tap_time_interval = 0.3

    self.debug = False
    self.bell_style = 'none'
    self.mark = -1
    self.console=MockConsole()
    self.disable_readline = False
    # this code needs to follow l_buffer and history creation
    self.editingmodes = [mode(self) for mode in editingmodes]
    for mode in self.editingmodes:
        mode.init_editing_mode(None)
    self.mode = self.editingmodes[0]

    self.read_inputrc()
    log(""\n"".join(self.mode.rl_settings_to_string()))

    mode.callback = None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self):
    self.allow_ctrl_c = False
    self.ctrl_c_tap_time_interval = 0.3

    self.debug = False
    self.bell_style = 'none'
    self.mark = -1
    self.console=MockConsole()
    self.disable_readline = False
    # this code needs to follow l_buffer and history creation
    self.editingmodes = [mode(self) for mode in editingmodes]
    for mode in self.editingmodes:
        mode.init_editing_mode(None)
    self.mode = self.editingmodes[0]

    self.read_inputrc()
    log(""\n"".join(self.mode.rl_settings_to_string()))

    mode.callback = None"
"<NME> dbutils.py
<BEF> def __init__(self, items=None):
    r""""""Creates a new SQLQuery.
    
        >>> SQLQuery(""x"")
        <sql: 'x'>
        >>> q = SQLQuery(['SELECT * FROM ', 'test', ' WHERE x=', SQLParam(1)])
        >>> q
        <sql: 'SELECT * FROM test WHERE x=1'>
        >>> q.query(), q.values()
        ('SELECT * FROM test WHERE x=%s', [1])
        >>> SQLQuery(SQLParam(1))
        <sql: '1'>
    """"""
    if items is None:
        self.items = []
    elif isinstance(items, list):
        self.items = items
    elif isinstance(items, SQLParam):
        self.items = [items]
    elif isinstance(items, SQLQuery):
        self.items = list(items.items)
    else:
        self.items = [items]
        
    # Take care of SQLLiterals
    for i, item in enumerate(self.items):
        if isinstance(item, SQLParam) and isinstance(items.value, SQLLiteral):
            self.items[i] = item.value.v
<MSG> Fix incorrect variable name
<DFF> @@ -24,5 +24,5 @@
         
     # Take care of SQLLiterals
     for i, item in enumerate(self.items):
-        if isinstance(item, SQLParam) and isinstance(items.value, SQLLiteral):
+        if isinstance(item, SQLParam) and isinstance(item.value, SQLLiteral):
             self.items[i] = item.value.v","def __init__(self, items=None):
    r""""""Creates a new SQLQuery.
    
        >>> SQLQuery(""x"")
        <sql: 'x'>
        >>> q = SQLQuery(['SELECT * FROM ', 'test', ' WHERE x=', SQLParam(1)])
        >>> q
        <sql: 'SELECT * FROM test WHERE x=1'>
        >>> q.query(), q.values()
        ('SELECT * FROM test WHERE x=%s', [1])
        >>> SQLQuery(SQLParam(1))
        <sql: '1'>
    """"""
    if items is None:
        self.items = []
    elif isinstance(items, list):
        self.items = items
    elif isinstance(items, SQLParam):
        self.items = [items]
    elif isinstance(items, SQLQuery):
        self.items = list(items.items)
    else:
        self.items = [items]
        
    # Take care of SQLLiterals
    for i, item in enumerate(self.items):
        if isinstance(item, SQLParam) and isinstance(item.value, SQLLiteral):
            self.items[i] = item.value.v",9,"<NME> dbutils.py
<BEF> def __init__(self, items=None):
    r""""""Creates a new SQLQuery.
    
        >>> SQLQuery(""x"")
        <sql: 'x'>
        >>> q = SQLQuery(['SELECT * FROM ', 'test', ' WHERE x=', SQLParam(1)])
        >>> q
        <sql: 'SELECT * FROM test WHERE x=1'>
        >>> q.query(), q.values()
        ('SELECT * FROM test WHERE x=%s', [1])
        >>> SQLQuery(SQLParam(1))
        <sql: '1'>
    """"""
    if items is None:
        self.items = []
    elif isinstance(items, list):
        self.items = items
    elif isinstance(items, SQLParam):
        self.items = [items]
    elif isinstance(items, SQLQuery):
        self.items = list(items.items)
    else:
        self.items = [items]
        
    # Take care of SQLLiterals
    for i, item in enumerate(self.items):
        if isinstance(item, SQLParam) and isinstance(items.value, SQLLiteral):
            self.items[i] = item.value.v
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, items=None):
    r""""""Creates a new SQLQuery.
    
        >>> SQLQuery(""x"")
        <sql: 'x'>
        >>> q = SQLQuery(['SELECT * FROM ', 'test', ' WHERE x=', SQLParam(1)])
        >>> q
        <sql: 'SELECT * FROM test WHERE x=1'>
        >>> q.query(), q.values()
        ('SELECT * FROM test WHERE x=%s', [1])
        >>> SQLQuery(SQLParam(1))
        <sql: '1'>
    """"""
    if items is None:
        self.items = []
    elif isinstance(items, list):
        self.items = items
    elif isinstance(items, SQLParam):
        self.items = [items]
    elif isinstance(items, SQLQuery):
        self.items = list(items.items)
    else:
        self.items = [items]
        
    # Take care of SQLLiterals
    for i, item in enumerate(self.items):
        if isinstance(item, SQLParam) and isinstance(items.value, SQLLiteral):
            self.items[i] = item.value.v"
"<NME> __init__.py
<BEF> def getTerminalSize():

    import os
    from os import environ as env
    def ioctl_GWINSZ(fd):
        try:
            import fcntl, termios, struct, os
            cr = struct.unpack('hh', fcntl.ioctl(fd, termios.TIOCGWINSZ,
                '1234'))
        except:
            return
        return cr
    cr = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)
    if not cr:
        try:
            fd = os.open(os.ctermid(), os.O_RDONLY)
            cr = ioctl_GWINSZ(ioctl_GWINSZ)
            os.close(fd)
        except:
            pass
    if not cr:
        cr = (env.get('LINES', 25), env.get('COLUMNS', 80))

    return int(cr[1]), int(cr[0])
<MSG> Fix incorrect variable name
<DFF> @@ -14,7 +14,7 @@
     if not cr:
         try:
             fd = os.open(os.ctermid(), os.O_RDONLY)
-            cr = ioctl_GWINSZ(ioctl_GWINSZ)
+            cr = ioctl_GWINSZ(fd)
             os.close(fd)
         except:
             pass","def getTerminalSize():

    import os
    from os import environ as env
    def ioctl_GWINSZ(fd):
        try:
            import fcntl, termios, struct, os
            cr = struct.unpack('hh', fcntl.ioctl(fd, termios.TIOCGWINSZ,
                '1234'))
        except:
            return
        return cr
    cr = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)
    if not cr:
        try:
            fd = os.open(os.ctermid(), os.O_RDONLY)
            cr = ioctl_GWINSZ(fd)
            os.close(fd)
        except:
            pass
    if not cr:
        cr = (env.get('LINES', 25), env.get('COLUMNS', 80))

    return int(cr[1]), int(cr[0])",0,"<NME> __init__.py
<BEF> def getTerminalSize():

    import os
    from os import environ as env
    def ioctl_GWINSZ(fd):
        try:
            import fcntl, termios, struct, os
            cr = struct.unpack('hh', fcntl.ioctl(fd, termios.TIOCGWINSZ,
                '1234'))
        except:
            return
        return cr
    cr = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)
    if not cr:
        try:
            fd = os.open(os.ctermid(), os.O_RDONLY)
            cr = ioctl_GWINSZ(ioctl_GWINSZ)
            os.close(fd)
        except:
            pass
    if not cr:
        cr = (env.get('LINES', 25), env.get('COLUMNS', 80))

    return int(cr[1]), int(cr[0])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def getTerminalSize():

    import os
    from os import environ as env
    def ioctl_GWINSZ(fd):
        try:
            import fcntl, termios, struct, os
            cr = struct.unpack('hh', fcntl.ioctl(fd, termios.TIOCGWINSZ,
                '1234'))
        except:
            return
        return cr
    cr = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)
    if not cr:
        try:
            fd = os.open(os.ctermid(), os.O_RDONLY)
            cr = ioctl_GWINSZ(ioctl_GWINSZ)
            os.close(fd)
        except:
            pass
    if not cr:
        cr = (env.get('LINES', 25), env.get('COLUMNS', 80))

    return int(cr[1]), int(cr[0])"
"<NME> dynamicdispatch.py
<BEF> def get_command_class(command):
    """"""
    Called from runCLI() to select the command class for the selected command.

    :param command: The command to be implemented
    :return: The command class corresponding to the selected command
    """"""
    from scrapple.commands import genconfig, generate, run, web
    cmdClass = getattr(eval(cmdClass), command.title() + 'Command')
    return cmdClass
<MSG> Fix incorrect variable name
<DFF> @@ -6,5 +6,5 @@
     :return: The command class corresponding to the selected command
     """"""
     from scrapple.commands import genconfig, generate, run, web
-    cmdClass = getattr(eval(cmdClass), command.title() + 'Command')
+    cmdClass = getattr(eval(command), command.title() + 'Command')
     return cmdClass","def get_command_class(command):
    """"""
    Called from runCLI() to select the command class for the selected command.

    :param command: The command to be implemented
    :return: The command class corresponding to the selected command
    """"""
    from scrapple.commands import genconfig, generate, run, web
    cmdClass = getattr(eval(command), command.title() + 'Command')
    return cmdClass",1,"<NME> dynamicdispatch.py
<BEF> def get_command_class(command):
    """"""
    Called from runCLI() to select the command class for the selected command.

    :param command: The command to be implemented
    :return: The command class corresponding to the selected command
    """"""
    from scrapple.commands import genconfig, generate, run, web
    cmdClass = getattr(eval(cmdClass), command.title() + 'Command')
    return cmdClass
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_command_class(command):
    """"""
    Called from runCLI() to select the command class for the selected command.

    :param command: The command to be implemented
    :return: The command class corresponding to the selected command
    """"""
    from scrapple.commands import genconfig, generate, run, web
    cmdClass = getattr(eval(cmdClass), command.title() + 'Command')
    return cmdClass"
"<NME> test_darwin_service.py
<BEF> @contextmanager
def mock_launchctl(self, exists=True):
    from mock import patch
    patch1 = patch('subprocess.check_output')
    with patch1 as check_output:
        if  exists:
            self.side_effect = mock_check_output
        else:
            check_output.side_effect = IOError(2, ""err"")
        yield
<MSG> Fix incorrect variable name
<DFF> @@ -4,7 +4,7 @@
     patch1 = patch('subprocess.check_output')
     with patch1 as check_output:
         if  exists:
-            self.side_effect = mock_check_output
+            check_output.side_effect = mock_check_output
         else:
             check_output.side_effect = IOError(2, ""err"")
         yield","@contextmanager
def mock_launchctl(self, exists=True):
    from mock import patch
    patch1 = patch('subprocess.check_output')
    with patch1 as check_output:
        if  exists:
            check_output.side_effect = mock_check_output
        else:
            check_output.side_effect = IOError(2, ""err"")
        yield",2,"<NME> test_darwin_service.py
<BEF> @contextmanager
def mock_launchctl(self, exists=True):
    from mock import patch
    patch1 = patch('subprocess.check_output')
    with patch1 as check_output:
        if  exists:
            self.side_effect = mock_check_output
        else:
            check_output.side_effect = IOError(2, ""err"")
        yield
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@contextmanager
def mock_launchctl(self, exists=True):
    from mock import patch
    patch1 = patch('subprocess.check_output')
    with patch1 as check_output:
        if  exists:
            self.side_effect = mock_check_output
        else:
            check_output.side_effect = IOError(2, ""err"")
        yield"
"<NME> datastructures.py
<BEF> def _clone(self, *args, **kwargs):
    c = super(EasyQuerySet, self)._clone(*args, **kwargs)
    c._easymodel = c._easymodel
    return c
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def _clone(self, *args, **kwargs):
     c = super(EasyQuerySet, self)._clone(*args, **kwargs)
-    c._easymodel = c._easymodel
+    c._easymodel = self._easymodel
     return c","def _clone(self, *args, **kwargs):
    c = super(EasyQuerySet, self)._clone(*args, **kwargs)
    c._easymodel = self._easymodel
    return c",3,"<NME> datastructures.py
<BEF> def _clone(self, *args, **kwargs):
    c = super(EasyQuerySet, self)._clone(*args, **kwargs)
    c._easymodel = c._easymodel
    return c
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _clone(self, *args, **kwargs):
    c = super(EasyQuerySet, self)._clone(*args, **kwargs)
    c._easymodel = c._easymodel
    return c"
"<NME> law.py
<BEF> def setFilename(self, filename):
    if filename:
        self.hasFilename = True
        self.filenameValue = self
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def setFilename(self, filename):
     if filename:
         self.hasFilename = True
-        self.filenameValue = self
+        self.filenameValue = filename","def setFilename(self, filename):
    if filename:
        self.hasFilename = True
        self.filenameValue = filename",4,"<NME> law.py
<BEF> def setFilename(self, filename):
    if filename:
        self.hasFilename = True
        self.filenameValue = self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def setFilename(self, filename):
    if filename:
        self.hasFilename = True
        self.filenameValue = self"
"<NME> versioneer.py
<BEF> def get_root():
    # we require that all commands are run from the project root, i.e. the
    # directory that contains setup.py, setup.cfg, and versioneer.py .
    root = os.path.realpath(os.path.abspath(os.getcwd()))
    setup_py = os.path.join(root, ""setup.py"")
    versioneer_py = os.path.join(root, ""versioneer.py"")
    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
        # allow 'python path/to/setup.py COMMAND'
        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))
        setup_py = os.path.join(root, ""setup.py"")
        root = os.path.join(root, ""versioneer.py"")
    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
        err = (""Versioneer was unable to run the project root directory. ""
               ""Versioneer requires setup.py to be executed from ""
               ""its immediate directory (like 'python setup.py COMMAND'), ""
               ""or in a way that lets it use sys.argv[0] to find the root ""
               ""(like 'python path/to/setup.py COMMAND')."")
        raise VersioneerBadRootError(err)
    try:
        # Certain runtime workflows (setup.py install/develop in a setuptools
        # tree) execute all dependencies in a single python process, so
        # ""versioneer"" may be imported multiple times, and python's shared
        # module-import table will cache the first one. So we can't use
        # os.path.dirname(__file__), as that will find whichever
        # versioneer.py was first imported, even in later projects.
        me = os.path.realpath(os.path.abspath(__file__))
        if os.path.splitext(me)[0] != os.path.splitext(versioneer_py)[0]:
            print(""Warning: build in %s is using versioneer.py from %s""
                  % (os.path.dirname(me), versioneer_py))
    except NameError:
        pass
    return root
<MSG> Fix incorrect variable name
<DFF> @@ -8,7 +8,7 @@
         # allow 'python path/to/setup.py COMMAND'
         root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))
         setup_py = os.path.join(root, ""setup.py"")
-        root = os.path.join(root, ""versioneer.py"")
+        versioneer_py = os.path.join(root, ""versioneer.py"")
     if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
         err = (""Versioneer was unable to run the project root directory. ""
                ""Versioneer requires setup.py to be executed from ""","def get_root():
    # we require that all commands are run from the project root, i.e. the
    # directory that contains setup.py, setup.cfg, and versioneer.py .
    root = os.path.realpath(os.path.abspath(os.getcwd()))
    setup_py = os.path.join(root, ""setup.py"")
    versioneer_py = os.path.join(root, ""versioneer.py"")
    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
        # allow 'python path/to/setup.py COMMAND'
        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))
        setup_py = os.path.join(root, ""setup.py"")
        versioneer_py = os.path.join(root, ""versioneer.py"")
    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
        err = (""Versioneer was unable to run the project root directory. ""
               ""Versioneer requires setup.py to be executed from ""
               ""its immediate directory (like 'python setup.py COMMAND'), ""
               ""or in a way that lets it use sys.argv[0] to find the root ""
               ""(like 'python path/to/setup.py COMMAND')."")
        raise VersioneerBadRootError(err)
    try:
        # Certain runtime workflows (setup.py install/develop in a setuptools
        # tree) execute all dependencies in a single python process, so
        # ""versioneer"" may be imported multiple times, and python's shared
        # module-import table will cache the first one. So we can't use
        # os.path.dirname(__file__), as that will find whichever
        # versioneer.py was first imported, even in later projects.
        me = os.path.realpath(os.path.abspath(__file__))
        if os.path.splitext(me)[0] != os.path.splitext(versioneer_py)[0]:
            print(""Warning: build in %s is using versioneer.py from %s""
                  % (os.path.dirname(me), versioneer_py))
    except NameError:
        pass
    return root",5,"<NME> versioneer.py
<BEF> def get_root():
    # we require that all commands are run from the project root, i.e. the
    # directory that contains setup.py, setup.cfg, and versioneer.py .
    root = os.path.realpath(os.path.abspath(os.getcwd()))
    setup_py = os.path.join(root, ""setup.py"")
    versioneer_py = os.path.join(root, ""versioneer.py"")
    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
        # allow 'python path/to/setup.py COMMAND'
        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))
        setup_py = os.path.join(root, ""setup.py"")
        root = os.path.join(root, ""versioneer.py"")
    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
        err = (""Versioneer was unable to run the project root directory. ""
               ""Versioneer requires setup.py to be executed from ""
               ""its immediate directory (like 'python setup.py COMMAND'), ""
               ""or in a way that lets it use sys.argv[0] to find the root ""
               ""(like 'python path/to/setup.py COMMAND')."")
        raise VersioneerBadRootError(err)
    try:
        # Certain runtime workflows (setup.py install/develop in a setuptools
        # tree) execute all dependencies in a single python process, so
        # ""versioneer"" may be imported multiple times, and python's shared
        # module-import table will cache the first one. So we can't use
        # os.path.dirname(__file__), as that will find whichever
        # versioneer.py was first imported, even in later projects.
        me = os.path.realpath(os.path.abspath(__file__))
        if os.path.splitext(me)[0] != os.path.splitext(versioneer_py)[0]:
            print(""Warning: build in %s is using versioneer.py from %s""
                  % (os.path.dirname(me), versioneer_py))
    except NameError:
        pass
    return root
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_root():
    # we require that all commands are run from the project root, i.e. the
    # directory that contains setup.py, setup.cfg, and versioneer.py .
    root = os.path.realpath(os.path.abspath(os.getcwd()))
    setup_py = os.path.join(root, ""setup.py"")
    versioneer_py = os.path.join(root, ""versioneer.py"")
    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
        # allow 'python path/to/setup.py COMMAND'
        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))
        setup_py = os.path.join(root, ""setup.py"")
        root = os.path.join(root, ""versioneer.py"")
    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):
        err = (""Versioneer was unable to run the project root directory. ""
               ""Versioneer requires setup.py to be executed from ""
               ""its immediate directory (like 'python setup.py COMMAND'), ""
               ""or in a way that lets it use sys.argv[0] to find the root ""
               ""(like 'python path/to/setup.py COMMAND')."")
        raise VersioneerBadRootError(err)
    try:
        # Certain runtime workflows (setup.py install/develop in a setuptools
        # tree) execute all dependencies in a single python process, so
        # ""versioneer"" may be imported multiple times, and python's shared
        # module-import table will cache the first one. So we can't use
        # os.path.dirname(__file__), as that will find whichever
        # versioneer.py was first imported, even in later projects.
        me = os.path.realpath(os.path.abspath(__file__))
        if os.path.splitext(me)[0] != os.path.splitext(versioneer_py)[0]:
            print(""Warning: build in %s is using versioneer.py from %s""
                  % (os.path.dirname(me), versioneer_py))
    except NameError:
        pass
    return root"
"<NME> local_state.py
<BEF> @classmethod
def get_host_with_role(cls, keyname, role):
  """"""Searches through the local metadata to see which virtual machine runs the
  specified role.

  Args:
    keyname: The SSH keypair name that uniquely identifies this AppScale
      deployment.
    role: A str indicating the role to search for.
  Returns:
    A str containing the host that runs the specified service.
  """"""
  nodes = cls.get_local_nodes_info(keyname)
  for node in nodes:
    if role in node['jobs']:
      return node['public_ip']
  raise AppScaleException(""Couldn't find a {0} node."".format(nodes))
<MSG> Fix incorrect variable name
<DFF> @@ -14,4 +14,4 @@
   for node in nodes:
     if role in node['jobs']:
       return node['public_ip']
-  raise AppScaleException(""Couldn't find a {0} node."".format(nodes))
+  raise AppScaleException(""Couldn't find a {0} node."".format(role))","@classmethod
def get_host_with_role(cls, keyname, role):
  """"""Searches through the local metadata to see which virtual machine runs the
  specified role.

  Args:
    keyname: The SSH keypair name that uniquely identifies this AppScale
      deployment.
    role: A str indicating the role to search for.
  Returns:
    A str containing the host that runs the specified service.
  """"""
  nodes = cls.get_local_nodes_info(keyname)
  for node in nodes:
    if role in node['jobs']:
      return node['public_ip']
  raise AppScaleException(""Couldn't find a {0} node."".format(role))",6,"<NME> local_state.py
<BEF> @classmethod
def get_host_with_role(cls, keyname, role):
  """"""Searches through the local metadata to see which virtual machine runs the
  specified role.

  Args:
    keyname: The SSH keypair name that uniquely identifies this AppScale
      deployment.
    role: A str indicating the role to search for.
  Returns:
    A str containing the host that runs the specified service.
  """"""
  nodes = cls.get_local_nodes_info(keyname)
  for node in nodes:
    if role in node['jobs']:
      return node['public_ip']
  raise AppScaleException(""Couldn't find a {0} node."".format(nodes))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
def get_host_with_role(cls, keyname, role):
  """"""Searches through the local metadata to see which virtual machine runs the
  specified role.

  Args:
    keyname: The SSH keypair name that uniquely identifies this AppScale
      deployment.
    role: A str indicating the role to search for.
  Returns:
    A str containing the host that runs the specified service.
  """"""
  nodes = cls.get_local_nodes_info(keyname)
  for node in nodes:
    if role in node['jobs']:
      return node['public_ip']
  raise AppScaleException(""Couldn't find a {0} node."".format(nodes))"
"<NME> serialize_test.py
<BEF> def test_module(self):
    serialized = _serialize_func(reads_module)
    glbs = self.make_globals()
    f = _deserialize_func(serialized, glbs)
    self.assertEqual(glbs(), sys.version)
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     serialized = _serialize_func(reads_module)
     glbs = self.make_globals()
     f = _deserialize_func(serialized, glbs)
-    self.assertEqual(glbs(), sys.version)
+    self.assertEqual(f(), sys.version)","def test_module(self):
    serialized = _serialize_func(reads_module)
    glbs = self.make_globals()
    f = _deserialize_func(serialized, glbs)
    self.assertEqual(f(), sys.version)",7,"<NME> serialize_test.py
<BEF> def test_module(self):
    serialized = _serialize_func(reads_module)
    glbs = self.make_globals()
    f = _deserialize_func(serialized, glbs)
    self.assertEqual(glbs(), sys.version)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_module(self):
    serialized = _serialize_func(reads_module)
    glbs = self.make_globals()
    f = _deserialize_func(serialized, glbs)
    self.assertEqual(glbs(), sys.version)"
"<NME> clusterScalerTest.py
<BEF> def removeNodes(self, numNodes=1, preemptable=False):
    numNodes._pick(preemptable).removeNodes(numNodes=numNodes)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def removeNodes(self, numNodes=1, preemptable=False):
-    numNodes._pick(preemptable).removeNodes(numNodes=numNodes)
+    self._pick(preemptable).removeNodes(numNodes=numNodes)","def removeNodes(self, numNodes=1, preemptable=False):
    self._pick(preemptable).removeNodes(numNodes=numNodes)",8,"<NME> clusterScalerTest.py
<BEF> def removeNodes(self, numNodes=1, preemptable=False):
    numNodes._pick(preemptable).removeNodes(numNodes=numNodes)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def removeNodes(self, numNodes=1, preemptable=False):
    numNodes._pick(preemptable).removeNodes(numNodes=numNodes)"
"<NME> test_appscale.py
<BEF> def testDestroyWithEC2EnvironmentVariables(self):
  # if the user wants us to use their EC2 credentials when running AppScale,
  # we should make sure they get set
  appscale = AppScale()

  # Mock out the actual file reading itself, and slip in a YAML-dumped
  # file
  contents = {
    'infrastructure' : 'ec2',
    'machine' : 'ami-ABCDEFG',
    'keyname' : 'bookey',
    'group' : 'boogroup',
    'min' : 1,
    'max' : 1,
    'EC2_ACCESS_KEY' : 'access key',
    'EC2_SECRET_KEY' : 'secret key'
  }
  yaml_dumped_contents = yaml.dump(yaml_dumped_contents)
  self.addMockForAppScalefile(appscale, yaml_dumped_contents)

  # finally, mock out the actual appscale-terminate-instances call
  flexmock(AppScaleTools)
  AppScaleTools.should_receive('terminate_instances')
  appscale.destroy()

  self.assertEquals('access key', os.environ['EC2_ACCESS_KEY'])
  self.assertEquals('secret key', os.environ['EC2_SECRET_KEY'])
<MSG> Fix incorrect variable name
<DFF> @@ -15,7 +15,7 @@
     'EC2_ACCESS_KEY' : 'access key',
     'EC2_SECRET_KEY' : 'secret key'
   }
-  yaml_dumped_contents = yaml.dump(yaml_dumped_contents)
+  yaml_dumped_contents = yaml.dump(contents)
   self.addMockForAppScalefile(appscale, yaml_dumped_contents)
 
   # finally, mock out the actual appscale-terminate-instances call","def testDestroyWithEC2EnvironmentVariables(self):
  # if the user wants us to use their EC2 credentials when running AppScale,
  # we should make sure they get set
  appscale = AppScale()

  # Mock out the actual file reading itself, and slip in a YAML-dumped
  # file
  contents = {
    'infrastructure' : 'ec2',
    'machine' : 'ami-ABCDEFG',
    'keyname' : 'bookey',
    'group' : 'boogroup',
    'min' : 1,
    'max' : 1,
    'EC2_ACCESS_KEY' : 'access key',
    'EC2_SECRET_KEY' : 'secret key'
  }
  yaml_dumped_contents = yaml.dump(contents)
  self.addMockForAppScalefile(appscale, yaml_dumped_contents)

  # finally, mock out the actual appscale-terminate-instances call
  flexmock(AppScaleTools)
  AppScaleTools.should_receive('terminate_instances')
  appscale.destroy()

  self.assertEquals('access key', os.environ['EC2_ACCESS_KEY'])
  self.assertEquals('secret key', os.environ['EC2_SECRET_KEY'])",9,"<NME> test_appscale.py
<BEF> def testDestroyWithEC2EnvironmentVariables(self):
  # if the user wants us to use their EC2 credentials when running AppScale,
  # we should make sure they get set
  appscale = AppScale()

  # Mock out the actual file reading itself, and slip in a YAML-dumped
  # file
  contents = {
    'infrastructure' : 'ec2',
    'machine' : 'ami-ABCDEFG',
    'keyname' : 'bookey',
    'group' : 'boogroup',
    'min' : 1,
    'max' : 1,
    'EC2_ACCESS_KEY' : 'access key',
    'EC2_SECRET_KEY' : 'secret key'
  }
  yaml_dumped_contents = yaml.dump(yaml_dumped_contents)
  self.addMockForAppScalefile(appscale, yaml_dumped_contents)

  # finally, mock out the actual appscale-terminate-instances call
  flexmock(AppScaleTools)
  AppScaleTools.should_receive('terminate_instances')
  appscale.destroy()

  self.assertEquals('access key', os.environ['EC2_ACCESS_KEY'])
  self.assertEquals('secret key', os.environ['EC2_SECRET_KEY'])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testDestroyWithEC2EnvironmentVariables(self):
  # if the user wants us to use their EC2 credentials when running AppScale,
  # we should make sure they get set
  appscale = AppScale()

  # Mock out the actual file reading itself, and slip in a YAML-dumped
  # file
  contents = {
    'infrastructure' : 'ec2',
    'machine' : 'ami-ABCDEFG',
    'keyname' : 'bookey',
    'group' : 'boogroup',
    'min' : 1,
    'max' : 1,
    'EC2_ACCESS_KEY' : 'access key',
    'EC2_SECRET_KEY' : 'secret key'
  }
  yaml_dumped_contents = yaml.dump(yaml_dumped_contents)
  self.addMockForAppScalefile(appscale, yaml_dumped_contents)

  # finally, mock out the actual appscale-terminate-instances call
  flexmock(AppScaleTools)
  AppScaleTools.should_receive('terminate_instances')
  appscale.destroy()

  self.assertEquals('access key', os.environ['EC2_ACCESS_KEY'])
  self.assertEquals('secret key', os.environ['EC2_SECRET_KEY'])"
"<NME> container_usage.py
<BEF> def _create_container(self, prefix='container'):
    container_name = self._get_container_reference(prefix)
    prefix.service.create_container(container_name)
    return container_name
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def _create_container(self, prefix='container'):
     container_name = self._get_container_reference(prefix)
-    prefix.service.create_container(container_name)
+    self.service.create_container(container_name)
     return container_name","def _create_container(self, prefix='container'):
    container_name = self._get_container_reference(prefix)
    self.service.create_container(container_name)
    return container_name",0,"<NME> container_usage.py
<BEF> def _create_container(self, prefix='container'):
    container_name = self._get_container_reference(prefix)
    prefix.service.create_container(container_name)
    return container_name
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _create_container(self, prefix='container'):
    container_name = self._get_container_reference(prefix)
    prefix.service.create_container(container_name)
    return container_name"
"<NME> jobStore.py
<BEF> @contextmanager
def writeSharedFileStream(self, sharedFileName, isProtected=None):
    assert self._validateSharedFileName(sharedFileName)
    info = self.FileInfo.loadOrCreate(jobStoreFileID=self._sharedFileID(sharedFileName),
                                      ownerID=str(isProtected.sharedFileOwnerID),
                                      encrypted=isProtected)
    with info.uploadStream() as writable:
        yield writable
    info.save()
    log.debug(""Wrote %r for shared file %r."", info, sharedFileName)
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
 def writeSharedFileStream(self, sharedFileName, isProtected=None):
     assert self._validateSharedFileName(sharedFileName)
     info = self.FileInfo.loadOrCreate(jobStoreFileID=self._sharedFileID(sharedFileName),
-                                      ownerID=str(isProtected.sharedFileOwnerID),
+                                      ownerID=str(self.sharedFileOwnerID),
                                       encrypted=isProtected)
     with info.uploadStream() as writable:
         yield writable","@contextmanager
def writeSharedFileStream(self, sharedFileName, isProtected=None):
    assert self._validateSharedFileName(sharedFileName)
    info = self.FileInfo.loadOrCreate(jobStoreFileID=self._sharedFileID(sharedFileName),
                                      ownerID=str(self.sharedFileOwnerID),
                                      encrypted=isProtected)
    with info.uploadStream() as writable:
        yield writable
    info.save()
    log.debug(""Wrote %r for shared file %r."", info, sharedFileName)",1,"<NME> jobStore.py
<BEF> @contextmanager
def writeSharedFileStream(self, sharedFileName, isProtected=None):
    assert self._validateSharedFileName(sharedFileName)
    info = self.FileInfo.loadOrCreate(jobStoreFileID=self._sharedFileID(sharedFileName),
                                      ownerID=str(isProtected.sharedFileOwnerID),
                                      encrypted=isProtected)
    with info.uploadStream() as writable:
        yield writable
    info.save()
    log.debug(""Wrote %r for shared file %r."", info, sharedFileName)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@contextmanager
def writeSharedFileStream(self, sharedFileName, isProtected=None):
    assert self._validateSharedFileName(sharedFileName)
    info = self.FileInfo.loadOrCreate(jobStoreFileID=self._sharedFileID(sharedFileName),
                                      ownerID=str(isProtected.sharedFileOwnerID),
                                      encrypted=isProtected)
    with info.uploadStream() as writable:
        yield writable
    info.save()
    log.debug(""Wrote %r for shared file %r."", info, sharedFileName)"
"<NME> test_page_blob.py
<BEF> def __init__(self, wrapped_file):
    wrapped_file.wrapped_file = wrapped_file
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def __init__(self, wrapped_file):
-    wrapped_file.wrapped_file = wrapped_file
+    self.wrapped_file = wrapped_file","def __init__(self, wrapped_file):
    self.wrapped_file = wrapped_file",2,"<NME> test_page_blob.py
<BEF> def __init__(self, wrapped_file):
    wrapped_file.wrapped_file = wrapped_file
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, wrapped_file):
    wrapped_file.wrapped_file = wrapped_file"
"<NME> _deserialization.py
<BEF> def _parse_lease_time(response):
    '''
    Extracts lease time return header.
    '''   
    raw_headers = _parse_response_for_dict(raw_headers)
    lease_time = raw_headers.get('x-ms-lease-time')
    if lease_time:
        lease_time = _int_to_str(lease_time)

    return lease_time
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
     '''
     Extracts lease time return header.
     '''   
-    raw_headers = _parse_response_for_dict(raw_headers)
+    raw_headers = _parse_response_for_dict(response)
     lease_time = raw_headers.get('x-ms-lease-time')
     if lease_time:
         lease_time = _int_to_str(lease_time)","def _parse_lease_time(response):
    '''
    Extracts lease time return header.
    '''   
    raw_headers = _parse_response_for_dict(response)
    lease_time = raw_headers.get('x-ms-lease-time')
    if lease_time:
        lease_time = _int_to_str(lease_time)

    return lease_time",3,"<NME> _deserialization.py
<BEF> def _parse_lease_time(response):
    '''
    Extracts lease time return header.
    '''   
    raw_headers = _parse_response_for_dict(raw_headers)
    lease_time = raw_headers.get('x-ms-lease-time')
    if lease_time:
        lease_time = _int_to_str(lease_time)

    return lease_time
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _parse_lease_time(response):
    '''
    Extracts lease time return header.
    '''   
    raw_headers = _parse_response_for_dict(raw_headers)
    lease_time = raw_headers.get('x-ms-lease-time')
    if lease_time:
        lease_time = _int_to_str(lease_time)

    return lease_time"
"<NME> clusterScalerTest.py
<BEF> def removeNodes(self, numNodes=1):
    while len(self.workers) > 0 and numNodes > 0:
        worker = self.workers.pop()
        self.totalWorkerTime += self.stop()
        numNodes -= 1
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def removeNodes(self, numNodes=1):
     while len(self.workers) > 0 and numNodes > 0:
         worker = self.workers.pop()
-        self.totalWorkerTime += self.stop()
+        self.totalWorkerTime += worker.stop()
         numNodes -= 1","def removeNodes(self, numNodes=1):
    while len(self.workers) > 0 and numNodes > 0:
        worker = self.workers.pop()
        self.totalWorkerTime += worker.stop()
        numNodes -= 1",4,"<NME> clusterScalerTest.py
<BEF> def removeNodes(self, numNodes=1):
    while len(self.workers) > 0 and numNodes > 0:
        worker = self.workers.pop()
        self.totalWorkerTime += self.stop()
        numNodes -= 1
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def removeNodes(self, numNodes=1):
    while len(self.workers) > 0 and numNodes > 0:
        worker = self.workers.pop()
        self.totalWorkerTime += self.stop()
        numNodes -= 1"
"<NME> toilStats.py
<BEF> def decorateTitle(title, options):
    """""" Add a marker to TITLE if the TITLE is sorted on.
    """"""
    if title.lower() == options.sortCategory:
        return ""%s*"" % title
    else:
        return options
<MSG> Fix incorrect variable name
<DFF> @@ -4,4 +4,4 @@
     if title.lower() == options.sortCategory:
         return ""%s*"" % title
     else:
-        return options
+        return title","def decorateTitle(title, options):
    """""" Add a marker to TITLE if the TITLE is sorted on.
    """"""
    if title.lower() == options.sortCategory:
        return ""%s*"" % title
    else:
        return title",5,"<NME> toilStats.py
<BEF> def decorateTitle(title, options):
    """""" Add a marker to TITLE if the TITLE is sorted on.
    """"""
    if title.lower() == options.sortCategory:
        return ""%s*"" % title
    else:
        return options
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def decorateTitle(title, options):
    """""" Add a marker to TITLE if the TITLE is sorted on.
    """"""
    if title.lower() == options.sortCategory:
        return ""%s*"" % title
    else:
        return options"
"<NME> abstractJobStore.py
<BEF> def clean(self, jobCache=None):
    """"""
    Function to cleanup the state of a job store after a restart.
    Fixes jobs that might have been partially updated. Resets the try counts and removes jobs
    that are not successors of the current root job.

    :param dict[str,toil.jobWrapper.JobWrapper] jobCache: if a value it must be a dict
           from job ID keys to JobWrapper object values. Jobs will be loaded from the cache
           (which can be downloaded from the job store in a batch) instead of piecemeal when 
           recursed into.
    """"""
    # Iterate from the root jobWrapper and collate all jobs that are reachable from it
    # All other jobs returned by self.jobs() are orphaned and can be removed
    reachableFromRoot = set()

    if reachableFromRoot is None:
        logger.warning(""Cleaning jobStore recursively. This may be slow."")

    def getJob(jobId):
        if jobCache is not None:
            return jobCache[jobId]
        else:
            return self.load(jobId)

    def haveJob(jobId):
        if jobCache is not None:
            return jobCache.has_key(jobId)
        else:
            return self.exists(jobId)

    def getJobs():
        if jobCache is not None:
            return jobCache.itervalues()
        else:
            return self.jobs()

    def getConnectedJobs(jobWrapper):
        if jobWrapper.jobStoreID in reachableFromRoot:
            return
        reachableFromRoot.add(jobWrapper.jobStoreID)
        # Traverse jobs in stack
        for jobs in jobWrapper.stack:
            for successorJobStoreID in map(lambda x: x[0], jobs):
                if successorJobStoreID not in reachableFromRoot and haveJob(successorJobStoreID):
                    getConnectedJobs(getJob(successorJobStoreID))
        # Traverse service jobs
        for jobs in jobWrapper.services:
            for serviceJobStoreID in map(lambda x: x[0], jobs):
                assert serviceJobStoreID not in reachableFromRoot
                reachableFromRoot.add(serviceJobStoreID)

    logger.info(""Checking job graph connectivity..."")
    getConnectedJobs(self.loadRootJob())
    logger.info(""%d jobs reachable from root."" % len(reachableFromRoot))

    # Cleanup the state of each jobWrapper
    for jobWrapper in getJobs():
        changed = [False]  # Flag to indicate if we need to update the jobWrapper
        # on disk

        if len(jobWrapper.filesToDelete) != 0:
            # Delete any files that should already be deleted
            for fileID in jobWrapper.filesToDelete:
                logger.critical(
                    ""Removing file in job store: %s that was marked for deletion but not previously removed"" % fileID)
                self.deleteFile(fileID)
            jobWrapper.filesToDelete = []
            changed[0] = True

        # Delete a jobWrapper if it is not reachable from the rootJob
        if jobWrapper.jobStoreID not in reachableFromRoot:
            logger.critical(
                ""Removing job: %s that is not a successor of the root job in cleanup"" % jobWrapper.jobStoreID)
            self.delete(jobWrapper.jobStoreID)
            continue

        # For a job whose command is already execute, remove jobs from the 
        # stack that are already deleted. 
        # This cleans up the case that the jobWrapper
        # had successors to run, but had not been updated to reflect this
        
        if jobWrapper.command is None:
            stackSize = sum(map(len, jobWrapper.stack))
            # Remove deleted jobs
            jobWrapper.stack = map(lambda x : filter(lambda y : self.exists(y[0]), x), jobWrapper.stack)
            # Remove empty stuff from the stack
            jobWrapper.stack = filter(lambda x : len(x) > 0, jobWrapper.stack)
            # Check if anything go removed
            if sum(map(len, jobWrapper.stack)) != stackSize:
                changed[0] = True
            
        # Cleanup any services that have already been finished
        # Filter out deleted services and update the flags for services that exist
        # If there are services then renew  
        # the start and terminate flags if they have been removed
        def subFlagFile(jobStoreID, jobStoreFileID, flag):
            if self.fileExists(jobStoreFileID):
                return jobStoreFileID
            
            # Make a new flag
            newFlag = self.getEmptyFileStoreID()
            
            # Load the jobWrapper for the service and initialise the link
            serviceJobWrapper = getJob(jobStoreID)
            
            if flag == 1:
                logger.debug(""Recreating a start service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                serviceJobWrapper.startJobStoreID = newFlag
            elif flag == 2:
                logger.debug(""Recreating a terminate service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                serviceJobWrapper.terminateJobStoreID = newFlag
            else:
                logger.debug(""Recreating a error service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                assert flag == 3
                serviceJobWrapper.errorJobStoreID = newFlag
                
            # Update the service job on disk
            self.update(serviceJobWrapper)
            
            changed[0] = True
            
            return newFlag
        
        servicesSize = sum(map(len, jobWrapper.services))
        jobWrapper.services = filter(lambda z : len(z) > 0, map(lambda serviceJobList : 
                                    map(lambda x : x[:4] + (subFlagFile(x[0], x[4], 1), 
                                                            subFlagFile(x[0], x[5], 2), 
                                                            subFlagFile(x[0], x[6], 3)), 
                                    filter(lambda y : self.exists(y[0]), serviceJobList)), jobWrapper.services)) 
        if sum(map(len, jobWrapper.services)) != servicesSize:
            changed[0] = True

        # Reset the retry count of the jobWrapper
        if jobWrapper.remainingRetryCount != self._defaultTryCount():
            jobWrapper.remainingRetryCount = self._defaultTryCount()
            changed[0] = True

        # This cleans the old log file which may
        # have been left if the jobWrapper is being retried after a jobWrapper failure.
        if jobWrapper.logJobStoreFileID != None:
            self.delete(jobWrapper.logJobStoreFileID)
            jobWrapper.logJobStoreFileID = None
            changed[0] = True

        if changed[0]:  # Update, but only if a change has occurred
            logger.critical(""Repairing job: %s"" % jobWrapper.jobStoreID)
            self.update(jobWrapper)

    # Remove any crufty stats/logging files from the previous run
    logger.info(""Discarding old statistics and logs..."")
    self.readStatsAndLogging(lambda x: None)

    logger.info(""Job store is clean"")
    # TODO: reloading of the rootJob may be redundant here
    return self.loadRootJob()
<MSG> Fix incorrect variable name
<DFF> @@ -13,7 +13,7 @@
     # All other jobs returned by self.jobs() are orphaned and can be removed
     reachableFromRoot = set()
 
-    if reachableFromRoot is None:
+    if jobCache is None:
         logger.warning(""Cleaning jobStore recursively. This may be slow."")
 
     def getJob(jobId):","def clean(self, jobCache=None):
    """"""
    Function to cleanup the state of a job store after a restart.
    Fixes jobs that might have been partially updated. Resets the try counts and removes jobs
    that are not successors of the current root job.

    :param dict[str,toil.jobWrapper.JobWrapper] jobCache: if a value it must be a dict
           from job ID keys to JobWrapper object values. Jobs will be loaded from the cache
           (which can be downloaded from the job store in a batch) instead of piecemeal when 
           recursed into.
    """"""
    # Iterate from the root jobWrapper and collate all jobs that are reachable from it
    # All other jobs returned by self.jobs() are orphaned and can be removed
    reachableFromRoot = set()

    if jobCache is None:
        logger.warning(""Cleaning jobStore recursively. This may be slow."")

    def getJob(jobId):
        if jobCache is not None:
            return jobCache[jobId]
        else:
            return self.load(jobId)

    def haveJob(jobId):
        if jobCache is not None:
            return jobCache.has_key(jobId)
        else:
            return self.exists(jobId)

    def getJobs():
        if jobCache is not None:
            return jobCache.itervalues()
        else:
            return self.jobs()

    def getConnectedJobs(jobWrapper):
        if jobWrapper.jobStoreID in reachableFromRoot:
            return
        reachableFromRoot.add(jobWrapper.jobStoreID)
        # Traverse jobs in stack
        for jobs in jobWrapper.stack:
            for successorJobStoreID in map(lambda x: x[0], jobs):
                if successorJobStoreID not in reachableFromRoot and haveJob(successorJobStoreID):
                    getConnectedJobs(getJob(successorJobStoreID))
        # Traverse service jobs
        for jobs in jobWrapper.services:
            for serviceJobStoreID in map(lambda x: x[0], jobs):
                assert serviceJobStoreID not in reachableFromRoot
                reachableFromRoot.add(serviceJobStoreID)

    logger.info(""Checking job graph connectivity..."")
    getConnectedJobs(self.loadRootJob())
    logger.info(""%d jobs reachable from root."" % len(reachableFromRoot))

    # Cleanup the state of each jobWrapper
    for jobWrapper in getJobs():
        changed = [False]  # Flag to indicate if we need to update the jobWrapper
        # on disk

        if len(jobWrapper.filesToDelete) != 0:
            # Delete any files that should already be deleted
            for fileID in jobWrapper.filesToDelete:
                logger.critical(
                    ""Removing file in job store: %s that was marked for deletion but not previously removed"" % fileID)
                self.deleteFile(fileID)
            jobWrapper.filesToDelete = []
            changed[0] = True

        # Delete a jobWrapper if it is not reachable from the rootJob
        if jobWrapper.jobStoreID not in reachableFromRoot:
            logger.critical(
                ""Removing job: %s that is not a successor of the root job in cleanup"" % jobWrapper.jobStoreID)
            self.delete(jobWrapper.jobStoreID)
            continue

        # For a job whose command is already execute, remove jobs from the 
        # stack that are already deleted. 
        # This cleans up the case that the jobWrapper
        # had successors to run, but had not been updated to reflect this
        
        if jobWrapper.command is None:
            stackSize = sum(map(len, jobWrapper.stack))
            # Remove deleted jobs
            jobWrapper.stack = map(lambda x : filter(lambda y : self.exists(y[0]), x), jobWrapper.stack)
            # Remove empty stuff from the stack
            jobWrapper.stack = filter(lambda x : len(x) > 0, jobWrapper.stack)
            # Check if anything go removed
            if sum(map(len, jobWrapper.stack)) != stackSize:
                changed[0] = True
            
        # Cleanup any services that have already been finished
        # Filter out deleted services and update the flags for services that exist
        # If there are services then renew  
        # the start and terminate flags if they have been removed
        def subFlagFile(jobStoreID, jobStoreFileID, flag):
            if self.fileExists(jobStoreFileID):
                return jobStoreFileID
            
            # Make a new flag
            newFlag = self.getEmptyFileStoreID()
            
            # Load the jobWrapper for the service and initialise the link
            serviceJobWrapper = getJob(jobStoreID)
            
            if flag == 1:
                logger.debug(""Recreating a start service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                serviceJobWrapper.startJobStoreID = newFlag
            elif flag == 2:
                logger.debug(""Recreating a terminate service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                serviceJobWrapper.terminateJobStoreID = newFlag
            else:
                logger.debug(""Recreating a error service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                assert flag == 3
                serviceJobWrapper.errorJobStoreID = newFlag
                
            # Update the service job on disk
            self.update(serviceJobWrapper)
            
            changed[0] = True
            
            return newFlag
        
        servicesSize = sum(map(len, jobWrapper.services))
        jobWrapper.services = filter(lambda z : len(z) > 0, map(lambda serviceJobList : 
                                    map(lambda x : x[:4] + (subFlagFile(x[0], x[4], 1), 
                                                            subFlagFile(x[0], x[5], 2), 
                                                            subFlagFile(x[0], x[6], 3)), 
                                    filter(lambda y : self.exists(y[0]), serviceJobList)), jobWrapper.services)) 
        if sum(map(len, jobWrapper.services)) != servicesSize:
            changed[0] = True

        # Reset the retry count of the jobWrapper
        if jobWrapper.remainingRetryCount != self._defaultTryCount():
            jobWrapper.remainingRetryCount = self._defaultTryCount()
            changed[0] = True

        # This cleans the old log file which may
        # have been left if the jobWrapper is being retried after a jobWrapper failure.
        if jobWrapper.logJobStoreFileID != None:
            self.delete(jobWrapper.logJobStoreFileID)
            jobWrapper.logJobStoreFileID = None
            changed[0] = True

        if changed[0]:  # Update, but only if a change has occurred
            logger.critical(""Repairing job: %s"" % jobWrapper.jobStoreID)
            self.update(jobWrapper)

    # Remove any crufty stats/logging files from the previous run
    logger.info(""Discarding old statistics and logs..."")
    self.readStatsAndLogging(lambda x: None)

    logger.info(""Job store is clean"")
    # TODO: reloading of the rootJob may be redundant here
    return self.loadRootJob()",6,"<NME> abstractJobStore.py
<BEF> def clean(self, jobCache=None):
    """"""
    Function to cleanup the state of a job store after a restart.
    Fixes jobs that might have been partially updated. Resets the try counts and removes jobs
    that are not successors of the current root job.

    :param dict[str,toil.jobWrapper.JobWrapper] jobCache: if a value it must be a dict
           from job ID keys to JobWrapper object values. Jobs will be loaded from the cache
           (which can be downloaded from the job store in a batch) instead of piecemeal when 
           recursed into.
    """"""
    # Iterate from the root jobWrapper and collate all jobs that are reachable from it
    # All other jobs returned by self.jobs() are orphaned and can be removed
    reachableFromRoot = set()

    if reachableFromRoot is None:
        logger.warning(""Cleaning jobStore recursively. This may be slow."")

    def getJob(jobId):
        if jobCache is not None:
            return jobCache[jobId]
        else:
            return self.load(jobId)

    def haveJob(jobId):
        if jobCache is not None:
            return jobCache.has_key(jobId)
        else:
            return self.exists(jobId)

    def getJobs():
        if jobCache is not None:
            return jobCache.itervalues()
        else:
            return self.jobs()

    def getConnectedJobs(jobWrapper):
        if jobWrapper.jobStoreID in reachableFromRoot:
            return
        reachableFromRoot.add(jobWrapper.jobStoreID)
        # Traverse jobs in stack
        for jobs in jobWrapper.stack:
            for successorJobStoreID in map(lambda x: x[0], jobs):
                if successorJobStoreID not in reachableFromRoot and haveJob(successorJobStoreID):
                    getConnectedJobs(getJob(successorJobStoreID))
        # Traverse service jobs
        for jobs in jobWrapper.services:
            for serviceJobStoreID in map(lambda x: x[0], jobs):
                assert serviceJobStoreID not in reachableFromRoot
                reachableFromRoot.add(serviceJobStoreID)

    logger.info(""Checking job graph connectivity..."")
    getConnectedJobs(self.loadRootJob())
    logger.info(""%d jobs reachable from root."" % len(reachableFromRoot))

    # Cleanup the state of each jobWrapper
    for jobWrapper in getJobs():
        changed = [False]  # Flag to indicate if we need to update the jobWrapper
        # on disk

        if len(jobWrapper.filesToDelete) != 0:
            # Delete any files that should already be deleted
            for fileID in jobWrapper.filesToDelete:
                logger.critical(
                    ""Removing file in job store: %s that was marked for deletion but not previously removed"" % fileID)
                self.deleteFile(fileID)
            jobWrapper.filesToDelete = []
            changed[0] = True

        # Delete a jobWrapper if it is not reachable from the rootJob
        if jobWrapper.jobStoreID not in reachableFromRoot:
            logger.critical(
                ""Removing job: %s that is not a successor of the root job in cleanup"" % jobWrapper.jobStoreID)
            self.delete(jobWrapper.jobStoreID)
            continue

        # For a job whose command is already execute, remove jobs from the 
        # stack that are already deleted. 
        # This cleans up the case that the jobWrapper
        # had successors to run, but had not been updated to reflect this
        
        if jobWrapper.command is None:
            stackSize = sum(map(len, jobWrapper.stack))
            # Remove deleted jobs
            jobWrapper.stack = map(lambda x : filter(lambda y : self.exists(y[0]), x), jobWrapper.stack)
            # Remove empty stuff from the stack
            jobWrapper.stack = filter(lambda x : len(x) > 0, jobWrapper.stack)
            # Check if anything go removed
            if sum(map(len, jobWrapper.stack)) != stackSize:
                changed[0] = True
            
        # Cleanup any services that have already been finished
        # Filter out deleted services and update the flags for services that exist
        # If there are services then renew  
        # the start and terminate flags if they have been removed
        def subFlagFile(jobStoreID, jobStoreFileID, flag):
            if self.fileExists(jobStoreFileID):
                return jobStoreFileID
            
            # Make a new flag
            newFlag = self.getEmptyFileStoreID()
            
            # Load the jobWrapper for the service and initialise the link
            serviceJobWrapper = getJob(jobStoreID)
            
            if flag == 1:
                logger.debug(""Recreating a start service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                serviceJobWrapper.startJobStoreID = newFlag
            elif flag == 2:
                logger.debug(""Recreating a terminate service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                serviceJobWrapper.terminateJobStoreID = newFlag
            else:
                logger.debug(""Recreating a error service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                assert flag == 3
                serviceJobWrapper.errorJobStoreID = newFlag
                
            # Update the service job on disk
            self.update(serviceJobWrapper)
            
            changed[0] = True
            
            return newFlag
        
        servicesSize = sum(map(len, jobWrapper.services))
        jobWrapper.services = filter(lambda z : len(z) > 0, map(lambda serviceJobList : 
                                    map(lambda x : x[:4] + (subFlagFile(x[0], x[4], 1), 
                                                            subFlagFile(x[0], x[5], 2), 
                                                            subFlagFile(x[0], x[6], 3)), 
                                    filter(lambda y : self.exists(y[0]), serviceJobList)), jobWrapper.services)) 
        if sum(map(len, jobWrapper.services)) != servicesSize:
            changed[0] = True

        # Reset the retry count of the jobWrapper
        if jobWrapper.remainingRetryCount != self._defaultTryCount():
            jobWrapper.remainingRetryCount = self._defaultTryCount()
            changed[0] = True

        # This cleans the old log file which may
        # have been left if the jobWrapper is being retried after a jobWrapper failure.
        if jobWrapper.logJobStoreFileID != None:
            self.delete(jobWrapper.logJobStoreFileID)
            jobWrapper.logJobStoreFileID = None
            changed[0] = True

        if changed[0]:  # Update, but only if a change has occurred
            logger.critical(""Repairing job: %s"" % jobWrapper.jobStoreID)
            self.update(jobWrapper)

    # Remove any crufty stats/logging files from the previous run
    logger.info(""Discarding old statistics and logs..."")
    self.readStatsAndLogging(lambda x: None)

    logger.info(""Job store is clean"")
    # TODO: reloading of the rootJob may be redundant here
    return self.loadRootJob()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def clean(self, jobCache=None):
    """"""
    Function to cleanup the state of a job store after a restart.
    Fixes jobs that might have been partially updated. Resets the try counts and removes jobs
    that are not successors of the current root job.

    :param dict[str,toil.jobWrapper.JobWrapper] jobCache: if a value it must be a dict
           from job ID keys to JobWrapper object values. Jobs will be loaded from the cache
           (which can be downloaded from the job store in a batch) instead of piecemeal when 
           recursed into.
    """"""
    # Iterate from the root jobWrapper and collate all jobs that are reachable from it
    # All other jobs returned by self.jobs() are orphaned and can be removed
    reachableFromRoot = set()

    if reachableFromRoot is None:
        logger.warning(""Cleaning jobStore recursively. This may be slow."")

    def getJob(jobId):
        if jobCache is not None:
            return jobCache[jobId]
        else:
            return self.load(jobId)

    def haveJob(jobId):
        if jobCache is not None:
            return jobCache.has_key(jobId)
        else:
            return self.exists(jobId)

    def getJobs():
        if jobCache is not None:
            return jobCache.itervalues()
        else:
            return self.jobs()

    def getConnectedJobs(jobWrapper):
        if jobWrapper.jobStoreID in reachableFromRoot:
            return
        reachableFromRoot.add(jobWrapper.jobStoreID)
        # Traverse jobs in stack
        for jobs in jobWrapper.stack:
            for successorJobStoreID in map(lambda x: x[0], jobs):
                if successorJobStoreID not in reachableFromRoot and haveJob(successorJobStoreID):
                    getConnectedJobs(getJob(successorJobStoreID))
        # Traverse service jobs
        for jobs in jobWrapper.services:
            for serviceJobStoreID in map(lambda x: x[0], jobs):
                assert serviceJobStoreID not in reachableFromRoot
                reachableFromRoot.add(serviceJobStoreID)

    logger.info(""Checking job graph connectivity..."")
    getConnectedJobs(self.loadRootJob())
    logger.info(""%d jobs reachable from root."" % len(reachableFromRoot))

    # Cleanup the state of each jobWrapper
    for jobWrapper in getJobs():
        changed = [False]  # Flag to indicate if we need to update the jobWrapper
        # on disk

        if len(jobWrapper.filesToDelete) != 0:
            # Delete any files that should already be deleted
            for fileID in jobWrapper.filesToDelete:
                logger.critical(
                    ""Removing file in job store: %s that was marked for deletion but not previously removed"" % fileID)
                self.deleteFile(fileID)
            jobWrapper.filesToDelete = []
            changed[0] = True

        # Delete a jobWrapper if it is not reachable from the rootJob
        if jobWrapper.jobStoreID not in reachableFromRoot:
            logger.critical(
                ""Removing job: %s that is not a successor of the root job in cleanup"" % jobWrapper.jobStoreID)
            self.delete(jobWrapper.jobStoreID)
            continue

        # For a job whose command is already execute, remove jobs from the 
        # stack that are already deleted. 
        # This cleans up the case that the jobWrapper
        # had successors to run, but had not been updated to reflect this
        
        if jobWrapper.command is None:
            stackSize = sum(map(len, jobWrapper.stack))
            # Remove deleted jobs
            jobWrapper.stack = map(lambda x : filter(lambda y : self.exists(y[0]), x), jobWrapper.stack)
            # Remove empty stuff from the stack
            jobWrapper.stack = filter(lambda x : len(x) > 0, jobWrapper.stack)
            # Check if anything go removed
            if sum(map(len, jobWrapper.stack)) != stackSize:
                changed[0] = True
            
        # Cleanup any services that have already been finished
        # Filter out deleted services and update the flags for services that exist
        # If there are services then renew  
        # the start and terminate flags if they have been removed
        def subFlagFile(jobStoreID, jobStoreFileID, flag):
            if self.fileExists(jobStoreFileID):
                return jobStoreFileID
            
            # Make a new flag
            newFlag = self.getEmptyFileStoreID()
            
            # Load the jobWrapper for the service and initialise the link
            serviceJobWrapper = getJob(jobStoreID)
            
            if flag == 1:
                logger.debug(""Recreating a start service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                serviceJobWrapper.startJobStoreID = newFlag
            elif flag == 2:
                logger.debug(""Recreating a terminate service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                serviceJobWrapper.terminateJobStoreID = newFlag
            else:
                logger.debug(""Recreating a error service flag for job: %s, flag: %s"", jobStoreID, newFlag)
                assert flag == 3
                serviceJobWrapper.errorJobStoreID = newFlag
                
            # Update the service job on disk
            self.update(serviceJobWrapper)
            
            changed[0] = True
            
            return newFlag
        
        servicesSize = sum(map(len, jobWrapper.services))
        jobWrapper.services = filter(lambda z : len(z) > 0, map(lambda serviceJobList : 
                                    map(lambda x : x[:4] + (subFlagFile(x[0], x[4], 1), 
                                                            subFlagFile(x[0], x[5], 2), 
                                                            subFlagFile(x[0], x[6], 3)), 
                                    filter(lambda y : self.exists(y[0]), serviceJobList)), jobWrapper.services)) 
        if sum(map(len, jobWrapper.services)) != servicesSize:
            changed[0] = True

        # Reset the retry count of the jobWrapper
        if jobWrapper.remainingRetryCount != self._defaultTryCount():
            jobWrapper.remainingRetryCount = self._defaultTryCount()
            changed[0] = True

        # This cleans the old log file which may
        # have been left if the jobWrapper is being retried after a jobWrapper failure.
        if jobWrapper.logJobStoreFileID != None:
            self.delete(jobWrapper.logJobStoreFileID)
            jobWrapper.logJobStoreFileID = None
            changed[0] = True

        if changed[0]:  # Update, but only if a change has occurred
            logger.critical(""Repairing job: %s"" % jobWrapper.jobStoreID)
            self.update(jobWrapper)

    # Remove any crufty stats/logging files from the previous run
    logger.info(""Discarding old statistics and logs..."")
    self.readStatsAndLogging(lambda x: None)

    logger.info(""Job store is clean"")
    # TODO: reloading of the rootJob may be redundant here
    return self.loadRootJob()"
"<NME> hebrewprober.py
<BEF> def get_charset_name(self):
    # Make the decision: is it Logical or Visual?
    # If the final letter score distance is dominant enough, rely on it.
    finalsub = self._mFinalCharLogicalScore - self._mFinalCharVisualScore
    if finalsub >= MIN_FINAL_CHAR_DISTANCE:
        return LOGICAL_HEBREW_NAME
    if finalsub <= -MIN_FINAL_CHAR_DISTANCE:
        return VISUAL_HEBREW_NAME

    # It's not dominant enough, try to rely on the model scores instead.
    modelsub = (self._mLogicalProber.get_confidence()
                - self._mVisualProber.get_confidence())
    if finalsub > MIN_MODEL_DISTANCE:
        return LOGICAL_HEBREW_NAME
    if modelsub < -MIN_MODEL_DISTANCE:
        return VISUAL_HEBREW_NAME

    # Still no good, back to final letter distance, maybe it'll save the
    # day.
    if finalsub < 0.0:
        return VISUAL_HEBREW_NAME

    # (finalsub > 0 - Logical) or (don't know what to do) default to
    # Logical.
    return LOGICAL_HEBREW_NAME
<MSG> Fix incorrect variable name
<DFF> @@ -10,7 +10,7 @@
     # It's not dominant enough, try to rely on the model scores instead.
     modelsub = (self._mLogicalProber.get_confidence()
                 - self._mVisualProber.get_confidence())
-    if finalsub > MIN_MODEL_DISTANCE:
+    if modelsub > MIN_MODEL_DISTANCE:
         return LOGICAL_HEBREW_NAME
     if modelsub < -MIN_MODEL_DISTANCE:
         return VISUAL_HEBREW_NAME","def get_charset_name(self):
    # Make the decision: is it Logical or Visual?
    # If the final letter score distance is dominant enough, rely on it.
    finalsub = self._mFinalCharLogicalScore - self._mFinalCharVisualScore
    if finalsub >= MIN_FINAL_CHAR_DISTANCE:
        return LOGICAL_HEBREW_NAME
    if finalsub <= -MIN_FINAL_CHAR_DISTANCE:
        return VISUAL_HEBREW_NAME

    # It's not dominant enough, try to rely on the model scores instead.
    modelsub = (self._mLogicalProber.get_confidence()
                - self._mVisualProber.get_confidence())
    if modelsub > MIN_MODEL_DISTANCE:
        return LOGICAL_HEBREW_NAME
    if modelsub < -MIN_MODEL_DISTANCE:
        return VISUAL_HEBREW_NAME

    # Still no good, back to final letter distance, maybe it'll save the
    # day.
    if finalsub < 0.0:
        return VISUAL_HEBREW_NAME

    # (finalsub > 0 - Logical) or (don't know what to do) default to
    # Logical.
    return LOGICAL_HEBREW_NAME",7,"<NME> hebrewprober.py
<BEF> def get_charset_name(self):
    # Make the decision: is it Logical or Visual?
    # If the final letter score distance is dominant enough, rely on it.
    finalsub = self._mFinalCharLogicalScore - self._mFinalCharVisualScore
    if finalsub >= MIN_FINAL_CHAR_DISTANCE:
        return LOGICAL_HEBREW_NAME
    if finalsub <= -MIN_FINAL_CHAR_DISTANCE:
        return VISUAL_HEBREW_NAME

    # It's not dominant enough, try to rely on the model scores instead.
    modelsub = (self._mLogicalProber.get_confidence()
                - self._mVisualProber.get_confidence())
    if finalsub > MIN_MODEL_DISTANCE:
        return LOGICAL_HEBREW_NAME
    if modelsub < -MIN_MODEL_DISTANCE:
        return VISUAL_HEBREW_NAME

    # Still no good, back to final letter distance, maybe it'll save the
    # day.
    if finalsub < 0.0:
        return VISUAL_HEBREW_NAME

    # (finalsub > 0 - Logical) or (don't know what to do) default to
    # Logical.
    return LOGICAL_HEBREW_NAME
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_charset_name(self):
    # Make the decision: is it Logical or Visual?
    # If the final letter score distance is dominant enough, rely on it.
    finalsub = self._mFinalCharLogicalScore - self._mFinalCharVisualScore
    if finalsub >= MIN_FINAL_CHAR_DISTANCE:
        return LOGICAL_HEBREW_NAME
    if finalsub <= -MIN_FINAL_CHAR_DISTANCE:
        return VISUAL_HEBREW_NAME

    # It's not dominant enough, try to rely on the model scores instead.
    modelsub = (self._mLogicalProber.get_confidence()
                - self._mVisualProber.get_confidence())
    if finalsub > MIN_MODEL_DISTANCE:
        return LOGICAL_HEBREW_NAME
    if modelsub < -MIN_MODEL_DISTANCE:
        return VISUAL_HEBREW_NAME

    # Still no good, back to final letter distance, maybe it'll save the
    # day.
    if finalsub < 0.0:
        return VISUAL_HEBREW_NAME

    # (finalsub > 0 - Logical) or (don't know what to do) default to
    # Logical.
    return LOGICAL_HEBREW_NAME"
"<NME> fields.py
<BEF> def db_type(self, connection):
    self._check_database_backend(self.alias)
    return 'ltree'
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def db_type(self, connection):
-    self._check_database_backend(self.alias)
+    self._check_database_backend(connection.alias)
     return 'ltree'","def db_type(self, connection):
    self._check_database_backend(connection.alias)
    return 'ltree'",8,"<NME> fields.py
<BEF> def db_type(self, connection):
    self._check_database_backend(self.alias)
    return 'ltree'
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def db_type(self, connection):
    self._check_database_backend(self.alias)
    return 'ltree'"
"<NME> message.py
<BEF> def visit_FunctionDef(self, node):
    args = [self.id for arg in node.args.args]
    self.signatures.append((node.name, args[1:]))
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def visit_FunctionDef(self, node):
-    args = [self.id for arg in node.args.args]
+    args = [arg.id for arg in node.args.args]
     self.signatures.append((node.name, args[1:]))","def visit_FunctionDef(self, node):
    args = [arg.id for arg in node.args.args]
    self.signatures.append((node.name, args[1:]))",9,"<NME> message.py
<BEF> def visit_FunctionDef(self, node):
    args = [self.id for arg in node.args.args]
    self.signatures.append((node.name, args[1:]))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def visit_FunctionDef(self, node):
    args = [self.id for arg in node.args.args]
    self.signatures.append((node.name, args[1:]))"
"<NME> bottle_rest.py
<BEF> @wraps(fn)
def pretty_dump_wrapper(*args, **kwargs):
    response.content_type = ""application/json; charset=utf-8""

    return json.dumps(
        fn(*args, **args),

        # sort_keys=True,
        indent=4,
        separators=(',', ': ')
    )
<MSG> Fix incorrect variable name
<DFF> @@ -3,7 +3,7 @@
     response.content_type = ""application/json; charset=utf-8""
 
     return json.dumps(
-        fn(*args, **args),
+        fn(*args, **kwargs),
 
         # sort_keys=True,
         indent=4,","@wraps(fn)
def pretty_dump_wrapper(*args, **kwargs):
    response.content_type = ""application/json; charset=utf-8""

    return json.dumps(
        fn(*args, **kwargs),

        # sort_keys=True,
        indent=4,
        separators=(',', ': ')
    )",0,"<NME> bottle_rest.py
<BEF> @wraps(fn)
def pretty_dump_wrapper(*args, **kwargs):
    response.content_type = ""application/json; charset=utf-8""

    return json.dumps(
        fn(*args, **args),

        # sort_keys=True,
        indent=4,
        separators=(',', ': ')
    )
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@wraps(fn)
def pretty_dump_wrapper(*args, **kwargs):
    response.content_type = ""application/json; charset=utf-8""

    return json.dumps(
        fn(*args, **args),

        # sort_keys=True,
        indent=4,
        separators=(',', ': ')
    )"
"<NME> test_statistics.py
<BEF> def test_log_rank_returns_None_if_equal_arrays():
    T = np.random.exponential(5, size=200)
    result = stats.logrank_test(T, T, alpha=0.95)
    assert not result.is_significant

    C = np.random.binomial(2, 0.8, size=200)
    result = stats.logrank_test(C, T, C, C, alpha=0.95)
    assert not result.is_significant
<MSG> Fix incorrect variable name
<DFF> @@ -4,5 +4,5 @@
     assert not result.is_significant
 
     C = np.random.binomial(2, 0.8, size=200)
-    result = stats.logrank_test(C, T, C, C, alpha=0.95)
+    result = stats.logrank_test(T, T, C, C, alpha=0.95)
     assert not result.is_significant","def test_log_rank_returns_None_if_equal_arrays():
    T = np.random.exponential(5, size=200)
    result = stats.logrank_test(T, T, alpha=0.95)
    assert not result.is_significant

    C = np.random.binomial(2, 0.8, size=200)
    result = stats.logrank_test(T, T, C, C, alpha=0.95)
    assert not result.is_significant",1,"<NME> test_statistics.py
<BEF> def test_log_rank_returns_None_if_equal_arrays():
    T = np.random.exponential(5, size=200)
    result = stats.logrank_test(T, T, alpha=0.95)
    assert not result.is_significant

    C = np.random.binomial(2, 0.8, size=200)
    result = stats.logrank_test(C, T, C, C, alpha=0.95)
    assert not result.is_significant
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_log_rank_returns_None_if_equal_arrays():
    T = np.random.exponential(5, size=200)
    result = stats.logrank_test(T, T, alpha=0.95)
    assert not result.is_significant

    C = np.random.binomial(2, 0.8, size=200)
    result = stats.logrank_test(C, T, C, C, alpha=0.95)
    assert not result.is_significant"
"<NME> slurm.py
<BEF> def prepareSbatch(self, cpu, mem, jobID):
    #  Returns the sbatch command line before the script to run
    sbatch_line = ['sbatch', '-Q', '-J', 'toil_job_{}'.format(jobID)]

    if self.boss.environment:
        for k, v in self.boss.environment.iteritems():
            quoted_value = quote(os.environ[k] if v is None else v)
            sbatch_line.append('--export={}={}'.format(k, quoted_value))

    if mem is not None:
        # memory passed in is in bytes, but slurm expects megabytes
        sbatch_line.append('--mem={}'.format(int(mem) / 2 ** 20))
    if cpu is not None:
        k.append('--cpus-per-task={}'.format(int(math.ceil(cpu))))

    return sbatch_line
<MSG> Fix incorrect variable name
<DFF> @@ -11,6 +11,6 @@
         # memory passed in is in bytes, but slurm expects megabytes
         sbatch_line.append('--mem={}'.format(int(mem) / 2 ** 20))
     if cpu is not None:
-        k.append('--cpus-per-task={}'.format(int(math.ceil(cpu))))
+        sbatch_line.append('--cpus-per-task={}'.format(int(math.ceil(cpu))))
 
     return sbatch_line","def prepareSbatch(self, cpu, mem, jobID):
    #  Returns the sbatch command line before the script to run
    sbatch_line = ['sbatch', '-Q', '-J', 'toil_job_{}'.format(jobID)]

    if self.boss.environment:
        for k, v in self.boss.environment.iteritems():
            quoted_value = quote(os.environ[k] if v is None else v)
            sbatch_line.append('--export={}={}'.format(k, quoted_value))

    if mem is not None:
        # memory passed in is in bytes, but slurm expects megabytes
        sbatch_line.append('--mem={}'.format(int(mem) / 2 ** 20))
    if cpu is not None:
        sbatch_line.append('--cpus-per-task={}'.format(int(math.ceil(cpu))))

    return sbatch_line",2,"<NME> slurm.py
<BEF> def prepareSbatch(self, cpu, mem, jobID):
    #  Returns the sbatch command line before the script to run
    sbatch_line = ['sbatch', '-Q', '-J', 'toil_job_{}'.format(jobID)]

    if self.boss.environment:
        for k, v in self.boss.environment.iteritems():
            quoted_value = quote(os.environ[k] if v is None else v)
            sbatch_line.append('--export={}={}'.format(k, quoted_value))

    if mem is not None:
        # memory passed in is in bytes, but slurm expects megabytes
        sbatch_line.append('--mem={}'.format(int(mem) / 2 ** 20))
    if cpu is not None:
        k.append('--cpus-per-task={}'.format(int(math.ceil(cpu))))

    return sbatch_line
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def prepareSbatch(self, cpu, mem, jobID):
    #  Returns the sbatch command line before the script to run
    sbatch_line = ['sbatch', '-Q', '-J', 'toil_job_{}'.format(jobID)]

    if self.boss.environment:
        for k, v in self.boss.environment.iteritems():
            quoted_value = quote(os.environ[k] if v is None else v)
            sbatch_line.append('--export={}={}'.format(k, quoted_value))

    if mem is not None:
        # memory passed in is in bytes, but slurm expects megabytes
        sbatch_line.append('--mem={}'.format(int(mem) / 2 ** 20))
    if cpu is not None:
        k.append('--cpus-per-task={}'.format(int(math.ceil(cpu))))

    return sbatch_line"
"<NME> test_parse_args.py
<BEF> def test_machine_not_set_in_cloud_deployments(self):
  # when running in a cloud infrastructure, we need to know what
  # machine image to use
  argv = ['--min', '1', '--max', '1', ""--infrastructure"", ""euca""]
  self.assertRaises(BadConfigurationException, ParseArgs, self,
    ""appscale-run-instances"")
<MSG> Fix incorrect variable name
<DFF> @@ -2,5 +2,5 @@
   # when running in a cloud infrastructure, we need to know what
   # machine image to use
   argv = ['--min', '1', '--max', '1', ""--infrastructure"", ""euca""]
-  self.assertRaises(BadConfigurationException, ParseArgs, self,
+  self.assertRaises(BadConfigurationException, ParseArgs, argv,
     ""appscale-run-instances"")","def test_machine_not_set_in_cloud_deployments(self):
  # when running in a cloud infrastructure, we need to know what
  # machine image to use
  argv = ['--min', '1', '--max', '1', ""--infrastructure"", ""euca""]
  self.assertRaises(BadConfigurationException, ParseArgs, argv,
    ""appscale-run-instances"")",3,"<NME> test_parse_args.py
<BEF> def test_machine_not_set_in_cloud_deployments(self):
  # when running in a cloud infrastructure, we need to know what
  # machine image to use
  argv = ['--min', '1', '--max', '1', ""--infrastructure"", ""euca""]
  self.assertRaises(BadConfigurationException, ParseArgs, self,
    ""appscale-run-instances"")
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_machine_not_set_in_cloud_deployments(self):
  # when running in a cloud infrastructure, we need to know what
  # machine image to use
  argv = ['--min', '1', '--max', '1', ""--infrastructure"", ""euca""]
  self.assertRaises(BadConfigurationException, ParseArgs, self,
    ""appscale-run-instances"")"
"<NME> soupy.py
<BEF> def __str__(self):
    parts = self.args[0].split('\n\n\t')
    return parts[0] + '\n\n\t' + _dequote(repr(self[1]))
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def __str__(self):
     parts = self.args[0].split('\n\n\t')
-    return parts[0] + '\n\n\t' + _dequote(repr(self[1]))
+    return parts[0] + '\n\n\t' + _dequote(repr(parts[1]))","def __str__(self):
    parts = self.args[0].split('\n\n\t')
    return parts[0] + '\n\n\t' + _dequote(repr(parts[1]))",4,"<NME> soupy.py
<BEF> def __str__(self):
    parts = self.args[0].split('\n\n\t')
    return parts[0] + '\n\n\t' + _dequote(repr(self[1]))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __str__(self):
    parts = self.args[0].split('\n\n\t')
    return parts[0] + '\n\n\t' + _dequote(repr(self[1]))"
"<NME> __init__.py
<BEF> def ridge_regression(X, Y, c1=0.0, c2=0.0, offset=None):
    """"""
    Also known as Tikhonov regularization. This solves the minimization problem:

    min_{beta} ||(beta X - Y)||^2 + c1||beta||^2 + c2||beta - offset||^2

    One can find more information here: http://en.wikipedia.org/wiki/Tikhonov_regularization

    Parameters:
        X: a (n,d) numpy array
        Y: a (n,) numpy array
        c1: a scalar
        c2: a scalar
        offset: a (d,) numpy array.

    Returns:
        beta_hat: the solution to the minimization problem.
        V = (X*X^T + (c1+c2)I)^{-1} X^T

    """"""
    n, d = X.shape
    X = X.astype(float)
    penalizer_matrix = (c1 + c2) * np.eye(d)

    if X is None:
        offset = np.zeros((d,))

    V_1 = inv(np.dot(X.T, X) + penalizer_matrix)
    V_2 = (np.dot(X.T, Y) + c2 * offset)
    beta = np.dot(V_1, V_2)

    return beta, np.dot(V_1, X.T)
<MSG> Fix incorrect variable name
<DFF> @@ -22,7 +22,7 @@
     X = X.astype(float)
     penalizer_matrix = (c1 + c2) * np.eye(d)
 
-    if X is None:
+    if offset is None:
         offset = np.zeros((d,))
 
     V_1 = inv(np.dot(X.T, X) + penalizer_matrix)","def ridge_regression(X, Y, c1=0.0, c2=0.0, offset=None):
    """"""
    Also known as Tikhonov regularization. This solves the minimization problem:

    min_{beta} ||(beta X - Y)||^2 + c1||beta||^2 + c2||beta - offset||^2

    One can find more information here: http://en.wikipedia.org/wiki/Tikhonov_regularization

    Parameters:
        X: a (n,d) numpy array
        Y: a (n,) numpy array
        c1: a scalar
        c2: a scalar
        offset: a (d,) numpy array.

    Returns:
        beta_hat: the solution to the minimization problem.
        V = (X*X^T + (c1+c2)I)^{-1} X^T

    """"""
    n, d = X.shape
    X = X.astype(float)
    penalizer_matrix = (c1 + c2) * np.eye(d)

    if offset is None:
        offset = np.zeros((d,))

    V_1 = inv(np.dot(X.T, X) + penalizer_matrix)
    V_2 = (np.dot(X.T, Y) + c2 * offset)
    beta = np.dot(V_1, V_2)

    return beta, np.dot(V_1, X.T)",5,"<NME> __init__.py
<BEF> def ridge_regression(X, Y, c1=0.0, c2=0.0, offset=None):
    """"""
    Also known as Tikhonov regularization. This solves the minimization problem:

    min_{beta} ||(beta X - Y)||^2 + c1||beta||^2 + c2||beta - offset||^2

    One can find more information here: http://en.wikipedia.org/wiki/Tikhonov_regularization

    Parameters:
        X: a (n,d) numpy array
        Y: a (n,) numpy array
        c1: a scalar
        c2: a scalar
        offset: a (d,) numpy array.

    Returns:
        beta_hat: the solution to the minimization problem.
        V = (X*X^T + (c1+c2)I)^{-1} X^T

    """"""
    n, d = X.shape
    X = X.astype(float)
    penalizer_matrix = (c1 + c2) * np.eye(d)

    if X is None:
        offset = np.zeros((d,))

    V_1 = inv(np.dot(X.T, X) + penalizer_matrix)
    V_2 = (np.dot(X.T, Y) + c2 * offset)
    beta = np.dot(V_1, V_2)

    return beta, np.dot(V_1, X.T)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def ridge_regression(X, Y, c1=0.0, c2=0.0, offset=None):
    """"""
    Also known as Tikhonov regularization. This solves the minimization problem:

    min_{beta} ||(beta X - Y)||^2 + c1||beta||^2 + c2||beta - offset||^2

    One can find more information here: http://en.wikipedia.org/wiki/Tikhonov_regularization

    Parameters:
        X: a (n,d) numpy array
        Y: a (n,) numpy array
        c1: a scalar
        c2: a scalar
        offset: a (d,) numpy array.

    Returns:
        beta_hat: the solution to the minimization problem.
        V = (X*X^T + (c1+c2)I)^{-1} X^T

    """"""
    n, d = X.shape
    X = X.astype(float)
    penalizer_matrix = (c1 + c2) * np.eye(d)

    if X is None:
        offset = np.zeros((d,))

    V_1 = inv(np.dot(X.T, X) + penalizer_matrix)
    V_2 = (np.dot(X.T, Y) + c2 * offset)
    beta = np.dot(V_1, V_2)

    return beta, np.dot(V_1, X.T)"
"<NME> NatCheck.py
<BEF> def _write_buffer(self, s):
    self.buffer = s+s.buffer
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def _write_buffer(self, s):
-    self.buffer = s+s.buffer
+    self.buffer = s+self.buffer","def _write_buffer(self, s):
    self.buffer = s+self.buffer",6,"<NME> NatCheck.py
<BEF> def _write_buffer(self, s):
    self.buffer = s+s.buffer
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _write_buffer(self, s):
    self.buffer = s+s.buffer"
"<NME> register.py
<BEF> def match_and_register(f_lon_map, lon, lon_thresh, out_template, clobber):
    files = [k for k, v in f_lon_map.items() if
             lon_offset(v, lon) < lon_thresh]
    register(lon, lon, out_template % lon, clobber)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def match_and_register(f_lon_map, lon, lon_thresh, out_template, clobber):
     files = [k for k, v in f_lon_map.items() if
              lon_offset(v, lon) < lon_thresh]
-    register(lon, lon, out_template % lon, clobber)
+    register(files, lon, out_template % lon, clobber)","def match_and_register(f_lon_map, lon, lon_thresh, out_template, clobber):
    files = [k for k, v in f_lon_map.items() if
             lon_offset(v, lon) < lon_thresh]
    register(files, lon, out_template % lon, clobber)",7,"<NME> register.py
<BEF> def match_and_register(f_lon_map, lon, lon_thresh, out_template, clobber):
    files = [k for k, v in f_lon_map.items() if
             lon_offset(v, lon) < lon_thresh]
    register(lon, lon, out_template % lon, clobber)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def match_and_register(f_lon_map, lon, lon_thresh, out_template, clobber):
    files = [k for k, v in f_lon_map.items() if
             lon_offset(v, lon) < lon_thresh]
    register(lon, lon, out_template % lon, clobber)"
"<NME> NatCheck.py
<BEF> def read_crypto_pad4(self, s):
    # discard data
    return s.read_crypto_block4done()
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def read_crypto_pad4(self, s):
     # discard data
-    return s.read_crypto_block4done()
+    return self.read_crypto_block4done()","def read_crypto_pad4(self, s):
    # discard data
    return self.read_crypto_block4done()",8,"<NME> NatCheck.py
<BEF> def read_crypto_pad4(self, s):
    # discard data
    return s.read_crypto_block4done()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def read_crypto_pad4(self, s):
    # discard data
    return s.read_crypto_block4done()"
"<NME> versioneer.py
<BEF> def versions_from_expanded_variables(variables, tag_prefix, verbose=False):
    refnames = variables[""refnames""].strip()
    if refnames.startswith(""$Format""):
        if verbose:
            print(""variables are unexpanded, not using"")
        return {} # unexpanded, so not in an unpacked git-archive tarball
    refs = set([r.strip() for r in variables.strip(""()"").split("","")])
    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of
    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.
    TAG = ""tag: ""
    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])
    if not tags:
        # Either we're using git < 1.8.3, or there really are no tags. We use
        # a heuristic: assume all version tags have a digit. The old git %d
        # expansion behaves like git log --decorate=short and strips out the
        # refs/heads/ and refs/tags/ prefixes that would let us distinguish
        # between branches and tags. By ignoring refnames without digits, we
        # filter out many common branch names like ""release"" and
        # ""stabilization"", as well as ""HEAD"" and ""master"".
        tags = set([r for r in refs if re.search(r'\d', r)])
        if verbose:
            print(""discarding '%s', no digits"" % "","".join(refs-tags))
    if verbose:
        print(""likely tags: %s"" % "","".join(sorted(tags)))
    for ref in sorted(tags):
        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""
        if ref.startswith(tag_prefix):
            r = ref[len(tag_prefix):]
            if verbose:
                print(""picking %s"" % r)
            return { ""version"": r,
                     ""full"": variables[""full""].strip() }
    # no suitable tags, so we use the full revision id
    if verbose:
        print(""no suitable tags, using full revision id"")
    return { ""version"": variables[""full""].strip(),
             ""full"": variables[""full""].strip() }
<MSG> Fix incorrect variable name
<DFF> @@ -4,7 +4,7 @@
         if verbose:
             print(""variables are unexpanded, not using"")
         return {} # unexpanded, so not in an unpacked git-archive tarball
-    refs = set([r.strip() for r in variables.strip(""()"").split("","")])
+    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])
     # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of
     # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.
     TAG = ""tag: ""","def versions_from_expanded_variables(variables, tag_prefix, verbose=False):
    refnames = variables[""refnames""].strip()
    if refnames.startswith(""$Format""):
        if verbose:
            print(""variables are unexpanded, not using"")
        return {} # unexpanded, so not in an unpacked git-archive tarball
    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])
    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of
    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.
    TAG = ""tag: ""
    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])
    if not tags:
        # Either we're using git < 1.8.3, or there really are no tags. We use
        # a heuristic: assume all version tags have a digit. The old git %d
        # expansion behaves like git log --decorate=short and strips out the
        # refs/heads/ and refs/tags/ prefixes that would let us distinguish
        # between branches and tags. By ignoring refnames without digits, we
        # filter out many common branch names like ""release"" and
        # ""stabilization"", as well as ""HEAD"" and ""master"".
        tags = set([r for r in refs if re.search(r'\d', r)])
        if verbose:
            print(""discarding '%s', no digits"" % "","".join(refs-tags))
    if verbose:
        print(""likely tags: %s"" % "","".join(sorted(tags)))
    for ref in sorted(tags):
        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""
        if ref.startswith(tag_prefix):
            r = ref[len(tag_prefix):]
            if verbose:
                print(""picking %s"" % r)
            return { ""version"": r,
                     ""full"": variables[""full""].strip() }
    # no suitable tags, so we use the full revision id
    if verbose:
        print(""no suitable tags, using full revision id"")
    return { ""version"": variables[""full""].strip(),
             ""full"": variables[""full""].strip() }",9,"<NME> versioneer.py
<BEF> def versions_from_expanded_variables(variables, tag_prefix, verbose=False):
    refnames = variables[""refnames""].strip()
    if refnames.startswith(""$Format""):
        if verbose:
            print(""variables are unexpanded, not using"")
        return {} # unexpanded, so not in an unpacked git-archive tarball
    refs = set([r.strip() for r in variables.strip(""()"").split("","")])
    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of
    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.
    TAG = ""tag: ""
    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])
    if not tags:
        # Either we're using git < 1.8.3, or there really are no tags. We use
        # a heuristic: assume all version tags have a digit. The old git %d
        # expansion behaves like git log --decorate=short and strips out the
        # refs/heads/ and refs/tags/ prefixes that would let us distinguish
        # between branches and tags. By ignoring refnames without digits, we
        # filter out many common branch names like ""release"" and
        # ""stabilization"", as well as ""HEAD"" and ""master"".
        tags = set([r for r in refs if re.search(r'\d', r)])
        if verbose:
            print(""discarding '%s', no digits"" % "","".join(refs-tags))
    if verbose:
        print(""likely tags: %s"" % "","".join(sorted(tags)))
    for ref in sorted(tags):
        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""
        if ref.startswith(tag_prefix):
            r = ref[len(tag_prefix):]
            if verbose:
                print(""picking %s"" % r)
            return { ""version"": r,
                     ""full"": variables[""full""].strip() }
    # no suitable tags, so we use the full revision id
    if verbose:
        print(""no suitable tags, using full revision id"")
    return { ""version"": variables[""full""].strip(),
             ""full"": variables[""full""].strip() }
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def versions_from_expanded_variables(variables, tag_prefix, verbose=False):
    refnames = variables[""refnames""].strip()
    if refnames.startswith(""$Format""):
        if verbose:
            print(""variables are unexpanded, not using"")
        return {} # unexpanded, so not in an unpacked git-archive tarball
    refs = set([r.strip() for r in variables.strip(""()"").split("","")])
    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of
    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.
    TAG = ""tag: ""
    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])
    if not tags:
        # Either we're using git < 1.8.3, or there really are no tags. We use
        # a heuristic: assume all version tags have a digit. The old git %d
        # expansion behaves like git log --decorate=short and strips out the
        # refs/heads/ and refs/tags/ prefixes that would let us distinguish
        # between branches and tags. By ignoring refnames without digits, we
        # filter out many common branch names like ""release"" and
        # ""stabilization"", as well as ""HEAD"" and ""master"".
        tags = set([r for r in refs if re.search(r'\d', r)])
        if verbose:
            print(""discarding '%s', no digits"" % "","".join(refs-tags))
    if verbose:
        print(""likely tags: %s"" % "","".join(sorted(tags)))
    for ref in sorted(tags):
        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""
        if ref.startswith(tag_prefix):
            r = ref[len(tag_prefix):]
            if verbose:
                print(""picking %s"" % r)
            return { ""version"": r,
                     ""full"": variables[""full""].strip() }
    # no suitable tags, so we use the full revision id
    if verbose:
        print(""no suitable tags, using full revision id"")
    return { ""version"": variables[""full""].strip(),
             ""full"": variables[""full""].strip() }"
"<NME> StorageWrapper.py
<BEF> def has_data(self, index):
    return self not in self.holes and index not in self.blocked_holes
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def has_data(self, index):
-    return self not in self.holes and index not in self.blocked_holes
+    return index not in self.holes and index not in self.blocked_holes","def has_data(self, index):
    return index not in self.holes and index not in self.blocked_holes",0,"<NME> StorageWrapper.py
<BEF> def has_data(self, index):
    return self not in self.holes and index not in self.blocked_holes
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def has_data(self, index):
    return self not in self.holes and index not in self.blocked_holes"
"<NME> objects.py
<BEF> def define_sample(self, md5, sha1, sha256, ruleset_name, rule_name, notificaiton_date, first_seen, detection_ratio, size):
	self.md5 = md5
	self.sha1 = notificaiton_date
	self.sha256 = sha256
	self.ruleset_name = ruleset_name
	self.rule_name = rule_name
	self.notificaiton_date = notificaiton_date
	self.first_seen = first_seen
	self.detection_ratio = detection_ratio
	self.size = size
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def define_sample(self, md5, sha1, sha256, ruleset_name, rule_name, notificaiton_date, first_seen, detection_ratio, size):
 	self.md5 = md5
-	self.sha1 = notificaiton_date
+	self.sha1 = sha1
 	self.sha256 = sha256
 	self.ruleset_name = ruleset_name
 	self.rule_name = rule_name","def define_sample(self, md5, sha1, sha256, ruleset_name, rule_name, notificaiton_date, first_seen, detection_ratio, size):
	self.md5 = md5
	self.sha1 = sha1
	self.sha256 = sha256
	self.ruleset_name = ruleset_name
	self.rule_name = rule_name
	self.notificaiton_date = notificaiton_date
	self.first_seen = first_seen
	self.detection_ratio = detection_ratio
	self.size = size",1,"<NME> objects.py
<BEF> def define_sample(self, md5, sha1, sha256, ruleset_name, rule_name, notificaiton_date, first_seen, detection_ratio, size):
	self.md5 = md5
	self.sha1 = notificaiton_date
	self.sha256 = sha256
	self.ruleset_name = ruleset_name
	self.rule_name = rule_name
	self.notificaiton_date = notificaiton_date
	self.first_seen = first_seen
	self.detection_ratio = detection_ratio
	self.size = size
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def define_sample(self, md5, sha1, sha256, ruleset_name, rule_name, notificaiton_date, first_seen, detection_ratio, size):
	self.md5 = md5
	self.sha1 = notificaiton_date
	self.sha256 = sha256
	self.ruleset_name = ruleset_name
	self.rule_name = rule_name
	self.notificaiton_date = notificaiton_date
	self.first_seen = first_seen
	self.detection_ratio = detection_ratio
	self.size = size"
"<NME> id3v2frame.py
<BEF> def getformat(self):
    format_word = 0
    if self.flags and self.format_flags:
        for flag, bit in self.format_flags:
            if self.flags.has_key(flag):
                format_word = format_word & (0x01 << bit)
    return flag
<MSG> Fix incorrect variable name
<DFF> @@ -4,4 +4,4 @@
         for flag, bit in self.format_flags:
             if self.flags.has_key(flag):
                 format_word = format_word & (0x01 << bit)
-    return flag
+    return format_word","def getformat(self):
    format_word = 0
    if self.flags and self.format_flags:
        for flag, bit in self.format_flags:
            if self.flags.has_key(flag):
                format_word = format_word & (0x01 << bit)
    return format_word",2,"<NME> id3v2frame.py
<BEF> def getformat(self):
    format_word = 0
    if self.flags and self.format_flags:
        for flag, bit in self.format_flags:
            if self.flags.has_key(flag):
                format_word = format_word & (0x01 << bit)
    return flag
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def getformat(self):
    format_word = 0
    if self.flags and self.format_flags:
        for flag, bit in self.format_flags:
            if self.flags.has_key(flag):
                format_word = format_word & (0x01 << bit)
    return flag"
"<NME> nn.py
<BEF> def __init__(self, output_vars, *args, **kwargs):
    output_vars = self.replicate_vars(output_vars)
    _, _, replaced_vars = self._get_bn_params(replaced_vars)
    super(ApproxTestMonitoring, self).__init__(replaced_vars, *args,
                                               **kwargs)
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def __init__(self, output_vars, *args, **kwargs):
     output_vars = self.replicate_vars(output_vars)
-    _, _, replaced_vars = self._get_bn_params(replaced_vars)
+    _, _, replaced_vars = self._get_bn_params(output_vars)
     super(ApproxTestMonitoring, self).__init__(replaced_vars, *args,
                                                **kwargs)","def __init__(self, output_vars, *args, **kwargs):
    output_vars = self.replicate_vars(output_vars)
    _, _, replaced_vars = self._get_bn_params(output_vars)
    super(ApproxTestMonitoring, self).__init__(replaced_vars, *args,
                                               **kwargs)",3,"<NME> nn.py
<BEF> def __init__(self, output_vars, *args, **kwargs):
    output_vars = self.replicate_vars(output_vars)
    _, _, replaced_vars = self._get_bn_params(replaced_vars)
    super(ApproxTestMonitoring, self).__init__(replaced_vars, *args,
                                               **kwargs)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, output_vars, *args, **kwargs):
    output_vars = self.replicate_vars(output_vars)
    _, _, replaced_vars = self._get_bn_params(replaced_vars)
    super(ApproxTestMonitoring, self).__init__(replaced_vars, *args,
                                               **kwargs)"
"<NME> dev.py
<BEF> def main():
    import_mods(""."")

    subs = list(subclasses(entities.Entity))

#    print(""\n"".join([str(x) for x in subs]))
#    print(len(subs))

    no_namespace = [x for x in no_namespace if not filter_has_namespace(x)]
    for x in no_namespace:
        print(x)
    print(len(no_namespace))
<MSG> Fix incorrect variable name
<DFF> @@ -6,7 +6,7 @@
 #    print(""\n"".join([str(x) for x in subs]))
 #    print(len(subs))
 
-    no_namespace = [x for x in no_namespace if not filter_has_namespace(x)]
+    no_namespace = [x for x in subs if not filter_has_namespace(x)]
     for x in no_namespace:
         print(x)
     print(len(no_namespace))","def main():
    import_mods(""."")

    subs = list(subclasses(entities.Entity))

#    print(""\n"".join([str(x) for x in subs]))
#    print(len(subs))

    no_namespace = [x for x in subs if not filter_has_namespace(x)]
    for x in no_namespace:
        print(x)
    print(len(no_namespace))",4,"<NME> dev.py
<BEF> def main():
    import_mods(""."")

    subs = list(subclasses(entities.Entity))

#    print(""\n"".join([str(x) for x in subs]))
#    print(len(subs))

    no_namespace = [x for x in no_namespace if not filter_has_namespace(x)]
    for x in no_namespace:
        print(x)
    print(len(no_namespace))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def main():
    import_mods(""."")

    subs = list(subclasses(entities.Entity))

#    print(""\n"".join([str(x) for x in subs]))
#    print(len(subs))

    no_namespace = [x for x in no_namespace if not filter_has_namespace(x)]
    for x in no_namespace:
        print(x)
    print(len(no_namespace))"
"<NME> compare_robots_configs.py
<BEF> def read_and_compile_pattern_from_file(config_file):
    """"""Read INI config file and compile robots regex from robots key in
    patterns section.
    """"""
    config = ConfigParser.ConfigParser()
    config_file.readfp(open(config_file))
    re_robots = re.compile(config.get(""patterns"", ""robots""), re.I)
    return re_robots
<MSG> Fix incorrect variable name
<DFF> @@ -3,6 +3,6 @@
     patterns section.
     """"""
     config = ConfigParser.ConfigParser()
-    config_file.readfp(open(config_file))
+    config.readfp(open(config_file))
     re_robots = re.compile(config.get(""patterns"", ""robots""), re.I)
     return re_robots","def read_and_compile_pattern_from_file(config_file):
    """"""Read INI config file and compile robots regex from robots key in
    patterns section.
    """"""
    config = ConfigParser.ConfigParser()
    config.readfp(open(config_file))
    re_robots = re.compile(config.get(""patterns"", ""robots""), re.I)
    return re_robots",5,"<NME> compare_robots_configs.py
<BEF> def read_and_compile_pattern_from_file(config_file):
    """"""Read INI config file and compile robots regex from robots key in
    patterns section.
    """"""
    config = ConfigParser.ConfigParser()
    config_file.readfp(open(config_file))
    re_robots = re.compile(config.get(""patterns"", ""robots""), re.I)
    return re_robots
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def read_and_compile_pattern_from_file(config_file):
    """"""Read INI config file and compile robots regex from robots key in
    patterns section.
    """"""
    config = ConfigParser.ConfigParser()
    config_file.readfp(open(config_file))
    re_robots = re.compile(config.get(""patterns"", ""robots""), re.I)
    return re_robots"
"<NME> rrule.py
<BEF> def __init__(self, cache=False):
    rrulebase.__init__(cache, cache)
    self._rrule = []
    self._rdate = []
    self._exrule = []
    self._exdate = []
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def __init__(self, cache=False):
-    rrulebase.__init__(cache, cache)
+    rrulebase.__init__(self, cache)
     self._rrule = []
     self._rdate = []
     self._exrule = []","def __init__(self, cache=False):
    rrulebase.__init__(self, cache)
    self._rrule = []
    self._rdate = []
    self._exrule = []
    self._exdate = []",6,"<NME> rrule.py
<BEF> def __init__(self, cache=False):
    rrulebase.__init__(cache, cache)
    self._rrule = []
    self._rdate = []
    self._exrule = []
    self._exdate = []
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, cache=False):
    rrulebase.__init__(cache, cache)
    self._rrule = []
    self._rdate = []
    self._exrule = []
    self._exdate = []"
"<NME> artifact_object.py
<BEF> def exportChildren(self, lwrite, level, namespace_='ArtifactObj:', name_='ArtifactObjectType', fromsubclass_=False, pretty_print=True):
    super(ArtifactObjectType, self).exportChildren(lwrite, level, 'ArtifactObj:', name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Hashes is not None:
        self.Hashes.export(lwrite, level, 'ArtifactObj:', name_='Hashes', pretty_print=pretty_print)
    if self.Packaging is not None:
        self.Packaging.export(lwrite, level, 'ArtifactObj:', name_='Packaging', pretty_print=pretty_print)
    if self.Raw_Artifact is not None:
        if self.Raw_Artifact.get_valueOf_() is not None:
            value = self.Raw_Artifact.get_valueOf_()
            if not value.startswith('<![CDATA['):
                value = '<![CDATA[' + value + ']]>'
                self.Raw_Artifact.set_valueOf_(value)
        self.Raw_Artifact.export(name_, level, 'ArtifactObj:', name_='Raw_Artifact', pretty_print=pretty_print)
    if self.Raw_Artifact_Reference is not None:
        showIndent(lwrite, level, pretty_print)
        lwrite('<%sRaw_Artifact_Reference>%s</%sRaw_Artifact_Reference>%s' % ('ArtifactObj:', self.gds_format_string(quote_xml(self.Raw_Artifact_Reference), input_name='Raw_Artifact_Reference'), 'ArtifactObj:', eol_))
<MSG> Fix incorrect variable name
<DFF> @@ -14,7 +14,7 @@
             if not value.startswith('<![CDATA['):
                 value = '<![CDATA[' + value + ']]>'
                 self.Raw_Artifact.set_valueOf_(value)
-        self.Raw_Artifact.export(name_, level, 'ArtifactObj:', name_='Raw_Artifact', pretty_print=pretty_print)
+        self.Raw_Artifact.export(lwrite, level, 'ArtifactObj:', name_='Raw_Artifact', pretty_print=pretty_print)
     if self.Raw_Artifact_Reference is not None:
         showIndent(lwrite, level, pretty_print)
         lwrite('<%sRaw_Artifact_Reference>%s</%sRaw_Artifact_Reference>%s' % ('ArtifactObj:', self.gds_format_string(quote_xml(self.Raw_Artifact_Reference), input_name='Raw_Artifact_Reference'), 'ArtifactObj:', eol_))","def exportChildren(self, lwrite, level, namespace_='ArtifactObj:', name_='ArtifactObjectType', fromsubclass_=False, pretty_print=True):
    super(ArtifactObjectType, self).exportChildren(lwrite, level, 'ArtifactObj:', name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Hashes is not None:
        self.Hashes.export(lwrite, level, 'ArtifactObj:', name_='Hashes', pretty_print=pretty_print)
    if self.Packaging is not None:
        self.Packaging.export(lwrite, level, 'ArtifactObj:', name_='Packaging', pretty_print=pretty_print)
    if self.Raw_Artifact is not None:
        if self.Raw_Artifact.get_valueOf_() is not None:
            value = self.Raw_Artifact.get_valueOf_()
            if not value.startswith('<![CDATA['):
                value = '<![CDATA[' + value + ']]>'
                self.Raw_Artifact.set_valueOf_(value)
        self.Raw_Artifact.export(lwrite, level, 'ArtifactObj:', name_='Raw_Artifact', pretty_print=pretty_print)
    if self.Raw_Artifact_Reference is not None:
        showIndent(lwrite, level, pretty_print)
        lwrite('<%sRaw_Artifact_Reference>%s</%sRaw_Artifact_Reference>%s' % ('ArtifactObj:', self.gds_format_string(quote_xml(self.Raw_Artifact_Reference), input_name='Raw_Artifact_Reference'), 'ArtifactObj:', eol_))",7,"<NME> artifact_object.py
<BEF> def exportChildren(self, lwrite, level, namespace_='ArtifactObj:', name_='ArtifactObjectType', fromsubclass_=False, pretty_print=True):
    super(ArtifactObjectType, self).exportChildren(lwrite, level, 'ArtifactObj:', name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Hashes is not None:
        self.Hashes.export(lwrite, level, 'ArtifactObj:', name_='Hashes', pretty_print=pretty_print)
    if self.Packaging is not None:
        self.Packaging.export(lwrite, level, 'ArtifactObj:', name_='Packaging', pretty_print=pretty_print)
    if self.Raw_Artifact is not None:
        if self.Raw_Artifact.get_valueOf_() is not None:
            value = self.Raw_Artifact.get_valueOf_()
            if not value.startswith('<![CDATA['):
                value = '<![CDATA[' + value + ']]>'
                self.Raw_Artifact.set_valueOf_(value)
        self.Raw_Artifact.export(name_, level, 'ArtifactObj:', name_='Raw_Artifact', pretty_print=pretty_print)
    if self.Raw_Artifact_Reference is not None:
        showIndent(lwrite, level, pretty_print)
        lwrite('<%sRaw_Artifact_Reference>%s</%sRaw_Artifact_Reference>%s' % ('ArtifactObj:', self.gds_format_string(quote_xml(self.Raw_Artifact_Reference), input_name='Raw_Artifact_Reference'), 'ArtifactObj:', eol_))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def exportChildren(self, lwrite, level, namespace_='ArtifactObj:', name_='ArtifactObjectType', fromsubclass_=False, pretty_print=True):
    super(ArtifactObjectType, self).exportChildren(lwrite, level, 'ArtifactObj:', name_, True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Hashes is not None:
        self.Hashes.export(lwrite, level, 'ArtifactObj:', name_='Hashes', pretty_print=pretty_print)
    if self.Packaging is not None:
        self.Packaging.export(lwrite, level, 'ArtifactObj:', name_='Packaging', pretty_print=pretty_print)
    if self.Raw_Artifact is not None:
        if self.Raw_Artifact.get_valueOf_() is not None:
            value = self.Raw_Artifact.get_valueOf_()
            if not value.startswith('<![CDATA['):
                value = '<![CDATA[' + value + ']]>'
                self.Raw_Artifact.set_valueOf_(value)
        self.Raw_Artifact.export(name_, level, 'ArtifactObj:', name_='Raw_Artifact', pretty_print=pretty_print)
    if self.Raw_Artifact_Reference is not None:
        showIndent(lwrite, level, pretty_print)
        lwrite('<%sRaw_Artifact_Reference>%s</%sRaw_Artifact_Reference>%s' % ('ArtifactObj:', self.gds_format_string(quote_xml(self.Raw_Artifact_Reference), input_name='Raw_Artifact_Reference'), 'ArtifactObj:', eol_))"
"<NME> cybox_core.py
<BEF> def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Noisiness':
        text_ = child_.text
        text_ = self.gds_validate_string(text_, node, 'Noisiness')
        self.set_Noisiness(text_)
    elif nodeName_ == 'Ease_of_Evasion':
        text_ = child_.text
        text_ = self.gds_validate_string(text_, node, 'Ease_of_Evasion')
        self.set_Ease_of_Evasion(text_)
    elif nodeName_ == 'Evasion_Techniques':
        obj_ = ObfuscationTechniquesType.factory()
        obj_.build(obj_)
        self.set_Evasion_Techniques(obj_)
<MSG> Fix incorrect variable name
<DFF> @@ -9,5 +9,5 @@
         self.set_Ease_of_Evasion(text_)
     elif nodeName_ == 'Evasion_Techniques':
         obj_ = ObfuscationTechniquesType.factory()
-        obj_.build(obj_)
+        obj_.build(child_)
         self.set_Evasion_Techniques(obj_)","def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Noisiness':
        text_ = child_.text
        text_ = self.gds_validate_string(text_, node, 'Noisiness')
        self.set_Noisiness(text_)
    elif nodeName_ == 'Ease_of_Evasion':
        text_ = child_.text
        text_ = self.gds_validate_string(text_, node, 'Ease_of_Evasion')
        self.set_Ease_of_Evasion(text_)
    elif nodeName_ == 'Evasion_Techniques':
        obj_ = ObfuscationTechniquesType.factory()
        obj_.build(child_)
        self.set_Evasion_Techniques(obj_)",8,"<NME> cybox_core.py
<BEF> def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Noisiness':
        text_ = child_.text
        text_ = self.gds_validate_string(text_, node, 'Noisiness')
        self.set_Noisiness(text_)
    elif nodeName_ == 'Ease_of_Evasion':
        text_ = child_.text
        text_ = self.gds_validate_string(text_, node, 'Ease_of_Evasion')
        self.set_Ease_of_Evasion(text_)
    elif nodeName_ == 'Evasion_Techniques':
        obj_ = ObfuscationTechniquesType.factory()
        obj_.build(obj_)
        self.set_Evasion_Techniques(obj_)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Noisiness':
        text_ = child_.text
        text_ = self.gds_validate_string(text_, node, 'Noisiness')
        self.set_Noisiness(text_)
    elif nodeName_ == 'Ease_of_Evasion':
        text_ = child_.text
        text_ = self.gds_validate_string(text_, node, 'Ease_of_Evasion')
        self.set_Ease_of_Evasion(text_)
    elif nodeName_ == 'Evasion_Techniques':
        obj_ = ObfuscationTechniquesType.factory()
        obj_.build(obj_)
        self.set_Evasion_Techniques(obj_)"
"<NME> EClientSocket.py
<BEF> @synchronized(mlock)
def cancelScannerSubscription(self, tickerId):
    """""" generated source for method cancelScannerSubscription """"""
    #  not connected?
    if not self.m_connected:
        self.error(EClientErrors.NO_VALID_ID, EClientErrors.NOT_CONNECTED, """")
        return
    if self.m_serverVersion < 24:
        self.error(EClientErrors.NO_VALID_ID, EClientErrors.UPDATE_TWS, ""  It does not support API scanner subscription."")
        return
    VERSION = 1
    #  send cancel mkt data msg
    try:
        self.send(VERSION.CANCEL_SCANNER_SUBSCRIPTION)
        self.send(VERSION)
        self.send(tickerId)
    except Exception as e:
        self.error(tickerId, EClientErrors.FAIL_SEND_CANSCANNER, str(e))
        self.close()
<MSG> Fix incorrect variable name
<DFF> @@ -11,7 +11,7 @@
     VERSION = 1
     #  send cancel mkt data msg
     try:
-        self.send(VERSION.CANCEL_SCANNER_SUBSCRIPTION)
+        self.send(self.CANCEL_SCANNER_SUBSCRIPTION)
         self.send(VERSION)
         self.send(tickerId)
     except Exception as e:","@synchronized(mlock)
def cancelScannerSubscription(self, tickerId):
    """""" generated source for method cancelScannerSubscription """"""
    #  not connected?
    if not self.m_connected:
        self.error(EClientErrors.NO_VALID_ID, EClientErrors.NOT_CONNECTED, """")
        return
    if self.m_serverVersion < 24:
        self.error(EClientErrors.NO_VALID_ID, EClientErrors.UPDATE_TWS, ""  It does not support API scanner subscription."")
        return
    VERSION = 1
    #  send cancel mkt data msg
    try:
        self.send(self.CANCEL_SCANNER_SUBSCRIPTION)
        self.send(VERSION)
        self.send(tickerId)
    except Exception as e:
        self.error(tickerId, EClientErrors.FAIL_SEND_CANSCANNER, str(e))
        self.close()",9,"<NME> EClientSocket.py
<BEF> @synchronized(mlock)
def cancelScannerSubscription(self, tickerId):
    """""" generated source for method cancelScannerSubscription """"""
    #  not connected?
    if not self.m_connected:
        self.error(EClientErrors.NO_VALID_ID, EClientErrors.NOT_CONNECTED, """")
        return
    if self.m_serverVersion < 24:
        self.error(EClientErrors.NO_VALID_ID, EClientErrors.UPDATE_TWS, ""  It does not support API scanner subscription."")
        return
    VERSION = 1
    #  send cancel mkt data msg
    try:
        self.send(VERSION.CANCEL_SCANNER_SUBSCRIPTION)
        self.send(VERSION)
        self.send(tickerId)
    except Exception as e:
        self.error(tickerId, EClientErrors.FAIL_SEND_CANSCANNER, str(e))
        self.close()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@synchronized(mlock)
def cancelScannerSubscription(self, tickerId):
    """""" generated source for method cancelScannerSubscription """"""
    #  not connected?
    if not self.m_connected:
        self.error(EClientErrors.NO_VALID_ID, EClientErrors.NOT_CONNECTED, """")
        return
    if self.m_serverVersion < 24:
        self.error(EClientErrors.NO_VALID_ID, EClientErrors.UPDATE_TWS, ""  It does not support API scanner subscription."")
        return
    VERSION = 1
    #  send cancel mkt data msg
    try:
        self.send(VERSION.CANCEL_SCANNER_SUBSCRIPTION)
        self.send(VERSION)
        self.send(tickerId)
    except Exception as e:
        self.error(tickerId, EClientErrors.FAIL_SEND_CANSCANNER, str(e))
        self.close()"
"<NME> cybox_core.py
<BEF> def exportAttributes(self, lwrite, level, already_processed, namespace_='cybox:', name_='Observables'):
    if self.cybox_major_version is not None:

        lwrite(' cybox_major_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_major_version), input_name='cybox_major_version'), ))
    if self.cybox_minor_version is not None:

        lwrite(' cybox_minor_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_minor_version), input_name='cybox_minor_version'), ))
    if name_.cybox_update_version is not None:

        lwrite(' cybox_update_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_update_version), input_name='cybox_update_version'), ))
<MSG> Fix incorrect variable name
<DFF> @@ -5,6 +5,6 @@
     if self.cybox_minor_version is not None:
 
         lwrite(' cybox_minor_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_minor_version), input_name='cybox_minor_version'), ))
-    if name_.cybox_update_version is not None:
+    if self.cybox_update_version is not None:
 
         lwrite(' cybox_update_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_update_version), input_name='cybox_update_version'), ))","def exportAttributes(self, lwrite, level, already_processed, namespace_='cybox:', name_='Observables'):
    if self.cybox_major_version is not None:

        lwrite(' cybox_major_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_major_version), input_name='cybox_major_version'), ))
    if self.cybox_minor_version is not None:

        lwrite(' cybox_minor_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_minor_version), input_name='cybox_minor_version'), ))
    if self.cybox_update_version is not None:

        lwrite(' cybox_update_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_update_version), input_name='cybox_update_version'), ))",0,"<NME> cybox_core.py
<BEF> def exportAttributes(self, lwrite, level, already_processed, namespace_='cybox:', name_='Observables'):
    if self.cybox_major_version is not None:

        lwrite(' cybox_major_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_major_version), input_name='cybox_major_version'), ))
    if self.cybox_minor_version is not None:

        lwrite(' cybox_minor_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_minor_version), input_name='cybox_minor_version'), ))
    if name_.cybox_update_version is not None:

        lwrite(' cybox_update_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_update_version), input_name='cybox_update_version'), ))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def exportAttributes(self, lwrite, level, already_processed, namespace_='cybox:', name_='Observables'):
    if self.cybox_major_version is not None:

        lwrite(' cybox_major_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_major_version), input_name='cybox_major_version'), ))
    if self.cybox_minor_version is not None:

        lwrite(' cybox_minor_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_minor_version), input_name='cybox_minor_version'), ))
    if name_.cybox_update_version is not None:

        lwrite(' cybox_update_version=%s' % (self.gds_format_string(quote_attrib(self.cybox_update_version), input_name='cybox_update_version'), ))"
"<NME> test_tumblr.py
<BEF> def tearDown(self):
    resp = self.client.posts(self.params['username'])
    for i in range(self.toDelete):
        self.client.delete_post(resp.params['username'], resp['posts'][i]['id'])
        self.toDelete -= 1
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def tearDown(self):
     resp = self.client.posts(self.params['username'])
     for i in range(self.toDelete):
-        self.client.delete_post(resp.params['username'], resp['posts'][i]['id'])
+        self.client.delete_post(self.params['username'], resp['posts'][i]['id'])
         self.toDelete -= 1","def tearDown(self):
    resp = self.client.posts(self.params['username'])
    for i in range(self.toDelete):
        self.client.delete_post(self.params['username'], resp['posts'][i]['id'])
        self.toDelete -= 1",1,"<NME> test_tumblr.py
<BEF> def tearDown(self):
    resp = self.client.posts(self.params['username'])
    for i in range(self.toDelete):
        self.client.delete_post(resp.params['username'], resp['posts'][i]['id'])
        self.toDelete -= 1
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def tearDown(self):
    resp = self.client.posts(self.params['username'])
    for i in range(self.toDelete):
        self.client.delete_post(resp.params['username'], resp['posts'][i]['id'])
        self.toDelete -= 1"
"<NME> cybox_core.py
<BEF> def __init__(self, has_changed=None, idref=None, id=None, State=None, Description=None, Properties=None, Domain_Specific_Object_Properties=None, Location=None, Related_Objects=None, Defined_Effect=None, Discovery_Method=None, extensiontype_=None):
    self.has_changed = _cast(bool, has_changed)
    self.idref = _cast(None, idref)
    self.id = _cast(None, id)
    self.State = State
    self.Description = Description
    Discovery_Method.Properties = Properties
    self.Domain_Specific_Object_Properties = Domain_Specific_Object_Properties
    self.Location = Location
    self.Related_Objects = Related_Objects
    self.Defined_Effect = Defined_Effect
    self.Discovery_Method = Discovery_Method
    self.extensiontype_ = extensiontype_
<MSG> Fix incorrect variable name
<DFF> @@ -4,7 +4,7 @@
     self.id = _cast(None, id)
     self.State = State
     self.Description = Description
-    Discovery_Method.Properties = Properties
+    self.Properties = Properties
     self.Domain_Specific_Object_Properties = Domain_Specific_Object_Properties
     self.Location = Location
     self.Related_Objects = Related_Objects","def __init__(self, has_changed=None, idref=None, id=None, State=None, Description=None, Properties=None, Domain_Specific_Object_Properties=None, Location=None, Related_Objects=None, Defined_Effect=None, Discovery_Method=None, extensiontype_=None):
    self.has_changed = _cast(bool, has_changed)
    self.idref = _cast(None, idref)
    self.id = _cast(None, id)
    self.State = State
    self.Description = Description
    self.Properties = Properties
    self.Domain_Specific_Object_Properties = Domain_Specific_Object_Properties
    self.Location = Location
    self.Related_Objects = Related_Objects
    self.Defined_Effect = Defined_Effect
    self.Discovery_Method = Discovery_Method
    self.extensiontype_ = extensiontype_",2,"<NME> cybox_core.py
<BEF> def __init__(self, has_changed=None, idref=None, id=None, State=None, Description=None, Properties=None, Domain_Specific_Object_Properties=None, Location=None, Related_Objects=None, Defined_Effect=None, Discovery_Method=None, extensiontype_=None):
    self.has_changed = _cast(bool, has_changed)
    self.idref = _cast(None, idref)
    self.id = _cast(None, id)
    self.State = State
    self.Description = Description
    Discovery_Method.Properties = Properties
    self.Domain_Specific_Object_Properties = Domain_Specific_Object_Properties
    self.Location = Location
    self.Related_Objects = Related_Objects
    self.Defined_Effect = Defined_Effect
    self.Discovery_Method = Discovery_Method
    self.extensiontype_ = extensiontype_
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, has_changed=None, idref=None, id=None, State=None, Description=None, Properties=None, Domain_Specific_Object_Properties=None, Location=None, Related_Objects=None, Defined_Effect=None, Discovery_Method=None, extensiontype_=None):
    self.has_changed = _cast(bool, has_changed)
    self.idref = _cast(None, idref)
    self.id = _cast(None, id)
    self.State = State
    self.Description = Description
    Discovery_Method.Properties = Properties
    self.Domain_Specific_Object_Properties = Domain_Specific_Object_Properties
    self.Location = Location
    self.Related_Objects = Related_Objects
    self.Defined_Effect = Defined_Effect
    self.Discovery_Method = Discovery_Method
    self.extensiontype_ = extensiontype_"
"<NME> win_memory_page_region_object.py
<BEF> def exportAttributes(self, lwrite, level, already_processed, namespace_='WinMemoryPageRegionObj:', name_='MemoryPageTypeType'):
    super(MemoryPageTypeType, self).exportAttributes(lwrite, level, already_processed, namespace_, name_='MemoryPageTypeType')
    if self.datatype is not None:

        level(' datatype=%s' % (quote_attrib(self.datatype), ))
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     super(MemoryPageTypeType, self).exportAttributes(lwrite, level, already_processed, namespace_, name_='MemoryPageTypeType')
     if self.datatype is not None:
 
-        level(' datatype=%s' % (quote_attrib(self.datatype), ))
+        lwrite(' datatype=%s' % (quote_attrib(self.datatype), ))","def exportAttributes(self, lwrite, level, already_processed, namespace_='WinMemoryPageRegionObj:', name_='MemoryPageTypeType'):
    super(MemoryPageTypeType, self).exportAttributes(lwrite, level, already_processed, namespace_, name_='MemoryPageTypeType')
    if self.datatype is not None:

        lwrite(' datatype=%s' % (quote_attrib(self.datatype), ))",3,"<NME> win_memory_page_region_object.py
<BEF> def exportAttributes(self, lwrite, level, already_processed, namespace_='WinMemoryPageRegionObj:', name_='MemoryPageTypeType'):
    super(MemoryPageTypeType, self).exportAttributes(lwrite, level, already_processed, namespace_, name_='MemoryPageTypeType')
    if self.datatype is not None:

        level(' datatype=%s' % (quote_attrib(self.datatype), ))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def exportAttributes(self, lwrite, level, already_processed, namespace_='WinMemoryPageRegionObj:', name_='MemoryPageTypeType'):
    super(MemoryPageTypeType, self).exportAttributes(lwrite, level, already_processed, namespace_, name_='MemoryPageTypeType')
    if self.datatype is not None:

        level(' datatype=%s' % (quote_attrib(self.datatype), ))"
"<NME> generator.py
<BEF> def generate_extensions(self, extensions, enums, functions):
    f = self._f_gl

    write = set()
    written = set(enum.name for enum in enums) | \
              set(function.proto.name for function in functions)

    f.write('# Extensions\nvar\n')
    for ext in extensions:
        if self.spec.NAME == 'gl' and not ext.name in written:
            self.write_boolean(f, ext.name)

        for enum in ext.enums:
            if not enum.name in written and not enum.group == 'SpecialNumbers':
                type = (None if enum.group == 'TransformFeedbackTokenNV'
                             else 'GLenum')
                self.write_enum(f, enum.name, enum.value, ext)
            written.add(enum.name)
        written.add(ext.name)
        f.write('\n')

    self.write_functions(f, write, written, extensions)
    f.write('\n\n')
<MSG> Fix incorrect variable name
<DFF> @@ -14,7 +14,7 @@
             if not enum.name in written and not enum.group == 'SpecialNumbers':
                 type = (None if enum.group == 'TransformFeedbackTokenNV'
                              else 'GLenum')
-                self.write_enum(f, enum.name, enum.value, ext)
+                self.write_enum(f, enum.name, enum.value, type)
             written.add(enum.name)
         written.add(ext.name)
         f.write('\n')","def generate_extensions(self, extensions, enums, functions):
    f = self._f_gl

    write = set()
    written = set(enum.name for enum in enums) | \
              set(function.proto.name for function in functions)

    f.write('# Extensions\nvar\n')
    for ext in extensions:
        if self.spec.NAME == 'gl' and not ext.name in written:
            self.write_boolean(f, ext.name)

        for enum in ext.enums:
            if not enum.name in written and not enum.group == 'SpecialNumbers':
                type = (None if enum.group == 'TransformFeedbackTokenNV'
                             else 'GLenum')
                self.write_enum(f, enum.name, enum.value, type)
            written.add(enum.name)
        written.add(ext.name)
        f.write('\n')

    self.write_functions(f, write, written, extensions)
    f.write('\n\n')",4,"<NME> generator.py
<BEF> def generate_extensions(self, extensions, enums, functions):
    f = self._f_gl

    write = set()
    written = set(enum.name for enum in enums) | \
              set(function.proto.name for function in functions)

    f.write('# Extensions\nvar\n')
    for ext in extensions:
        if self.spec.NAME == 'gl' and not ext.name in written:
            self.write_boolean(f, ext.name)

        for enum in ext.enums:
            if not enum.name in written and not enum.group == 'SpecialNumbers':
                type = (None if enum.group == 'TransformFeedbackTokenNV'
                             else 'GLenum')
                self.write_enum(f, enum.name, enum.value, ext)
            written.add(enum.name)
        written.add(ext.name)
        f.write('\n')

    self.write_functions(f, write, written, extensions)
    f.write('\n\n')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def generate_extensions(self, extensions, enums, functions):
    f = self._f_gl

    write = set()
    written = set(enum.name for enum in enums) | \
              set(function.proto.name for function in functions)

    f.write('# Extensions\nvar\n')
    for ext in extensions:
        if self.spec.NAME == 'gl' and not ext.name in written:
            self.write_boolean(f, ext.name)

        for enum in ext.enums:
            if not enum.name in written and not enum.group == 'SpecialNumbers':
                type = (None if enum.group == 'TransformFeedbackTokenNV'
                             else 'GLenum')
                self.write_enum(f, enum.name, enum.value, ext)
            written.add(enum.name)
        written.add(ext.name)
        f.write('\n')

    self.write_functions(f, write, written, extensions)
    f.write('\n\n')"
"<NME> monitor.py
<BEF> @classmethod
def _delete(cls, args):
    api._timeout = args.timeout
    # TODO CHECK
    res = api.Monitor.delete(args.monitor_id)
    if res is not None:
        report_warnings(res)
        report_errors(args)
<MSG> Fix incorrect variable name
<DFF> @@ -5,4 +5,4 @@
     res = api.Monitor.delete(args.monitor_id)
     if res is not None:
         report_warnings(res)
-        report_errors(args)
+        report_errors(res)","@classmethod
def _delete(cls, args):
    api._timeout = args.timeout
    # TODO CHECK
    res = api.Monitor.delete(args.monitor_id)
    if res is not None:
        report_warnings(res)
        report_errors(res)",5,"<NME> monitor.py
<BEF> @classmethod
def _delete(cls, args):
    api._timeout = args.timeout
    # TODO CHECK
    res = api.Monitor.delete(args.monitor_id)
    if res is not None:
        report_warnings(res)
        report_errors(args)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
def _delete(cls, args):
    api._timeout = args.timeout
    # TODO CHECK
    res = api.Monitor.delete(args.monitor_id)
    if res is not None:
        report_warnings(res)
        report_errors(args)"
"<NME> tag.py
<BEF> @classmethod
def setup_parser(cls, subparsers):
    parser = subparsers.add_parser('tag', help=""View and modify host tags."")
    verb_parsers = parser.add_subparsers(title='Verbs', dest='verb')
    verb_parsers.required = True

    add_parser = verb_parsers.add_parser('add', help=""Add a host to one or more tags."",
                                         description='Hosts can be specified by name or id.')
    add_parser.add_argument('host', help=""host to add"")
    add_parser.add_argument('tag', help=""tag to add host to (one or more, space separated)"",
                            nargs='+')
    add_parser.set_defaults(func=cls._add)

    replace_parser = verb_parsers.add_parser(
        'replace', help=""Replace all tags with one or more new tags."",
        description='Hosts can be specified by name or id.')
    replace_parser.add_argument('host', help=""host to modify"")
    replace_parser.add_argument('tag', help=""list of tags to add host to"", nargs='+')
    cls.set_defaults(func=cls._replace)

    show_parser = verb_parsers.add_parser('show', help=""Show host tags."",
                                          description='Hosts can be specified by name or id.')
    show_parser.add_argument('host', help=""host to show (or 'all' to show all tags)"")
    show_parser.set_defaults(func=cls._show)

    detach_parser = verb_parsers.add_parser('detach', help=""Remove a host from all tags."",
                                            description='Hosts can be specified by name or id.')
    detach_parser.add_argument('host', help=""host to detach"")
    detach_parser.set_defaults(func=cls._detach)
<MSG> Fix incorrect variable name
<DFF> @@ -16,7 +16,7 @@
         description='Hosts can be specified by name or id.')
     replace_parser.add_argument('host', help=""host to modify"")
     replace_parser.add_argument('tag', help=""list of tags to add host to"", nargs='+')
-    cls.set_defaults(func=cls._replace)
+    replace_parser.set_defaults(func=cls._replace)
 
     show_parser = verb_parsers.add_parser('show', help=""Show host tags."",
                                           description='Hosts can be specified by name or id.')","@classmethod
def setup_parser(cls, subparsers):
    parser = subparsers.add_parser('tag', help=""View and modify host tags."")
    verb_parsers = parser.add_subparsers(title='Verbs', dest='verb')
    verb_parsers.required = True

    add_parser = verb_parsers.add_parser('add', help=""Add a host to one or more tags."",
                                         description='Hosts can be specified by name or id.')
    add_parser.add_argument('host', help=""host to add"")
    add_parser.add_argument('tag', help=""tag to add host to (one or more, space separated)"",
                            nargs='+')
    add_parser.set_defaults(func=cls._add)

    replace_parser = verb_parsers.add_parser(
        'replace', help=""Replace all tags with one or more new tags."",
        description='Hosts can be specified by name or id.')
    replace_parser.add_argument('host', help=""host to modify"")
    replace_parser.add_argument('tag', help=""list of tags to add host to"", nargs='+')
    replace_parser.set_defaults(func=cls._replace)

    show_parser = verb_parsers.add_parser('show', help=""Show host tags."",
                                          description='Hosts can be specified by name or id.')
    show_parser.add_argument('host', help=""host to show (or 'all' to show all tags)"")
    show_parser.set_defaults(func=cls._show)

    detach_parser = verb_parsers.add_parser('detach', help=""Remove a host from all tags."",
                                            description='Hosts can be specified by name or id.')
    detach_parser.add_argument('host', help=""host to detach"")
    detach_parser.set_defaults(func=cls._detach)",6,"<NME> tag.py
<BEF> @classmethod
def setup_parser(cls, subparsers):
    parser = subparsers.add_parser('tag', help=""View and modify host tags."")
    verb_parsers = parser.add_subparsers(title='Verbs', dest='verb')
    verb_parsers.required = True

    add_parser = verb_parsers.add_parser('add', help=""Add a host to one or more tags."",
                                         description='Hosts can be specified by name or id.')
    add_parser.add_argument('host', help=""host to add"")
    add_parser.add_argument('tag', help=""tag to add host to (one or more, space separated)"",
                            nargs='+')
    add_parser.set_defaults(func=cls._add)

    replace_parser = verb_parsers.add_parser(
        'replace', help=""Replace all tags with one or more new tags."",
        description='Hosts can be specified by name or id.')
    replace_parser.add_argument('host', help=""host to modify"")
    replace_parser.add_argument('tag', help=""list of tags to add host to"", nargs='+')
    cls.set_defaults(func=cls._replace)

    show_parser = verb_parsers.add_parser('show', help=""Show host tags."",
                                          description='Hosts can be specified by name or id.')
    show_parser.add_argument('host', help=""host to show (or 'all' to show all tags)"")
    show_parser.set_defaults(func=cls._show)

    detach_parser = verb_parsers.add_parser('detach', help=""Remove a host from all tags."",
                                            description='Hosts can be specified by name or id.')
    detach_parser.add_argument('host', help=""host to detach"")
    detach_parser.set_defaults(func=cls._detach)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
def setup_parser(cls, subparsers):
    parser = subparsers.add_parser('tag', help=""View and modify host tags."")
    verb_parsers = parser.add_subparsers(title='Verbs', dest='verb')
    verb_parsers.required = True

    add_parser = verb_parsers.add_parser('add', help=""Add a host to one or more tags."",
                                         description='Hosts can be specified by name or id.')
    add_parser.add_argument('host', help=""host to add"")
    add_parser.add_argument('tag', help=""tag to add host to (one or more, space separated)"",
                            nargs='+')
    add_parser.set_defaults(func=cls._add)

    replace_parser = verb_parsers.add_parser(
        'replace', help=""Replace all tags with one or more new tags."",
        description='Hosts can be specified by name or id.')
    replace_parser.add_argument('host', help=""host to modify"")
    replace_parser.add_argument('tag', help=""list of tags to add host to"", nargs='+')
    cls.set_defaults(func=cls._replace)

    show_parser = verb_parsers.add_parser('show', help=""Show host tags."",
                                          description='Hosts can be specified by name or id.')
    show_parser.add_argument('host', help=""host to show (or 'all' to show all tags)"")
    show_parser.set_defaults(func=cls._show)

    detach_parser = verb_parsers.add_parser('detach', help=""Remove a host from all tags."",
                                            description='Hosts can be specified by name or id.')
    detach_parser.add_argument('host', help=""host to detach"")
    detach_parser.set_defaults(func=cls._detach)"
"<NME> win_task_object.py
<BEF> def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Show_Message_Body':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Show_Message_Body(obj_)
    elif nodeName_ == 'Show_Message_Title':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(self)
        self.set_Show_Message_Title(obj_)
<MSG> Fix incorrect variable name
<DFF> @@ -5,5 +5,5 @@
         self.set_Show_Message_Body(obj_)
     elif nodeName_ == 'Show_Message_Title':
         obj_ = cybox_common.StringObjectPropertyType.factory()
-        obj_.build(self)
+        obj_.build(child_)
         self.set_Show_Message_Title(obj_)","def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Show_Message_Body':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Show_Message_Body(obj_)
    elif nodeName_ == 'Show_Message_Title':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Show_Message_Title(obj_)",7,"<NME> win_task_object.py
<BEF> def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Show_Message_Body':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Show_Message_Body(obj_)
    elif nodeName_ == 'Show_Message_Title':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(self)
        self.set_Show_Message_Title(obj_)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Show_Message_Body':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(child_)
        self.set_Show_Message_Body(obj_)
    elif nodeName_ == 'Show_Message_Title':
        obj_ = cybox_common.StringObjectPropertyType.factory()
        obj_.build(self)
        self.set_Show_Message_Title(obj_)"
"<NME> __init__.py
<BEF> def handle_data(self, data):
    if self.in_a:
        self.text += self
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def handle_data(self, data):
     if self.in_a:
-        self.text += self
+        self.text += data","def handle_data(self, data):
    if self.in_a:
        self.text += data",8,"<NME> __init__.py
<BEF> def handle_data(self, data):
    if self.in_a:
        self.text += self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def handle_data(self, data):
    if self.in_a:
        self.text += self"
"<NME> page.py
<BEF> def wait_for_visible(self, locator):
    """"""
    Synchronization to deal with elements that are present, but are disabled until some action
    triggers their visibility.

    :raises: ElementVisiblityTimeout
    """"""
    for i in range(timeout_seconds):
        try:
            if self.driver.is_visible(self):
                break
        except:
            pass
        time.sleep(1)
    else:
        raise ElementVisiblityTimeout(""%s visibility timed out"" % locator)
    return True
<MSG> Fix incorrect variable name
<DFF> @@ -7,7 +7,7 @@
     """"""
     for i in range(timeout_seconds):
         try:
-            if self.driver.is_visible(self):
+            if self.driver.is_visible(locator):
                 break
         except:
             pass","def wait_for_visible(self, locator):
    """"""
    Synchronization to deal with elements that are present, but are disabled until some action
    triggers their visibility.

    :raises: ElementVisiblityTimeout
    """"""
    for i in range(timeout_seconds):
        try:
            if self.driver.is_visible(locator):
                break
        except:
            pass
        time.sleep(1)
    else:
        raise ElementVisiblityTimeout(""%s visibility timed out"" % locator)
    return True",9,"<NME> page.py
<BEF> def wait_for_visible(self, locator):
    """"""
    Synchronization to deal with elements that are present, but are disabled until some action
    triggers their visibility.

    :raises: ElementVisiblityTimeout
    """"""
    for i in range(timeout_seconds):
        try:
            if self.driver.is_visible(self):
                break
        except:
            pass
        time.sleep(1)
    else:
        raise ElementVisiblityTimeout(""%s visibility timed out"" % locator)
    return True
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def wait_for_visible(self, locator):
    """"""
    Synchronization to deal with elements that are present, but are disabled until some action
    triggers their visibility.

    :raises: ElementVisiblityTimeout
    """"""
    for i in range(timeout_seconds):
        try:
            if self.driver.is_visible(self):
                break
        except:
            pass
        time.sleep(1)
    else:
        raise ElementVisiblityTimeout(""%s visibility timed out"" % locator)
    return True"
"<NME> wastebin-1_grader.py
<BEF> def grade(tid, answer):
	if tid.find(""cr4zy_p4ssw0rds"") != -1:
		return { ""correct"": True, ""message"": ""Maybe sticking everything in the HTML source wasn't exactly the best idea."" }
	return { ""correct"": False, ""message"": ""Nope, that's not quite right."" }
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def grade(tid, answer):
-	if tid.find(""cr4zy_p4ssw0rds"") != -1:
+	if answer.find(""cr4zy_p4ssw0rds"") != -1:
 		return { ""correct"": True, ""message"": ""Maybe sticking everything in the HTML source wasn't exactly the best idea."" }
 	return { ""correct"": False, ""message"": ""Nope, that's not quite right."" }","def grade(tid, answer):
	if answer.find(""cr4zy_p4ssw0rds"") != -1:
		return { ""correct"": True, ""message"": ""Maybe sticking everything in the HTML source wasn't exactly the best idea."" }
	return { ""correct"": False, ""message"": ""Nope, that's not quite right."" }",0,"<NME> wastebin-1_grader.py
<BEF> def grade(tid, answer):
	if tid.find(""cr4zy_p4ssw0rds"") != -1:
		return { ""correct"": True, ""message"": ""Maybe sticking everything in the HTML source wasn't exactly the best idea."" }
	return { ""correct"": False, ""message"": ""Nope, that's not quite right."" }
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def grade(tid, answer):
	if tid.find(""cr4zy_p4ssw0rds"") != -1:
		return { ""correct"": True, ""message"": ""Maybe sticking everything in the HTML source wasn't exactly the best idea."" }
	return { ""correct"": False, ""message"": ""Nope, that's not quite right."" }"
"<NME> resources.py
<BEF> def _make_dict_with_path( srcfiles ):
    return dict( [( srcfile.split(u"".txt"")[0], mk_path( srcfiles ) ) \
                      for srcfile in srcfiles] )
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def _make_dict_with_path( srcfiles ):
-    return dict( [( srcfile.split(u"".txt"")[0], mk_path( srcfiles ) ) \
+    return dict( [( srcfile.split(u"".txt"")[0], mk_path( srcfile ) ) \
                       for srcfile in srcfiles] )","def _make_dict_with_path( srcfiles ):
    return dict( [( srcfile.split(u"".txt"")[0], mk_path( srcfile ) ) \
                      for srcfile in srcfiles] )",1,"<NME> resources.py
<BEF> def _make_dict_with_path( srcfiles ):
    return dict( [( srcfile.split(u"".txt"")[0], mk_path( srcfiles ) ) \
                      for srcfile in srcfiles] )
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _make_dict_with_path( srcfiles ):
    return dict( [( srcfile.split(u"".txt"")[0], mk_path( srcfiles ) ) \
                      for srcfile in srcfiles] )"
"<NME> updates.py
<BEF> @blueprint.route(""/get"", methods=[""GET""])
@api_wrapper
def updates_get_hook():
	updates = api.updates.get_all()
	user = None
	if api.auth.is_logged_in(): user = api.user.get_user()
	data = []
	for update in updates:
		u = {
			""title"": update[""title""],
			""timestamp"": update[""timestamp""],
			""content"": update[""content""],
			""author"": update[""author""],
			""upid"": update[""upid""]
		}
		data.append(u)
	return { ""success"": 1, ""data"": data, ""can_deactivate"": user is not None and u[""type""] == 0 }
<MSG> Fix incorrect variable name
<DFF> @@ -14,4 +14,4 @@
 			""upid"": update[""upid""]
 		}
 		data.append(u)
-	return { ""success"": 1, ""data"": data, ""can_deactivate"": user is not None and u[""type""] == 0 }
+	return { ""success"": 1, ""data"": data, ""can_deactivate"": user is not None and user[""type""] == 0 }","@blueprint.route(""/get"", methods=[""GET""])
@api_wrapper
def updates_get_hook():
	updates = api.updates.get_all()
	user = None
	if api.auth.is_logged_in(): user = api.user.get_user()
	data = []
	for update in updates:
		u = {
			""title"": update[""title""],
			""timestamp"": update[""timestamp""],
			""content"": update[""content""],
			""author"": update[""author""],
			""upid"": update[""upid""]
		}
		data.append(u)
	return { ""success"": 1, ""data"": data, ""can_deactivate"": user is not None and user[""type""] == 0 }",2,"<NME> updates.py
<BEF> @blueprint.route(""/get"", methods=[""GET""])
@api_wrapper
def updates_get_hook():
	updates = api.updates.get_all()
	user = None
	if api.auth.is_logged_in(): user = api.user.get_user()
	data = []
	for update in updates:
		u = {
			""title"": update[""title""],
			""timestamp"": update[""timestamp""],
			""content"": update[""content""],
			""author"": update[""author""],
			""upid"": update[""upid""]
		}
		data.append(u)
	return { ""success"": 1, ""data"": data, ""can_deactivate"": user is not None and u[""type""] == 0 }
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@blueprint.route(""/get"", methods=[""GET""])
@api_wrapper
def updates_get_hook():
	updates = api.updates.get_all()
	user = None
	if api.auth.is_logged_in(): user = api.user.get_user()
	data = []
	for update in updates:
		u = {
			""title"": update[""title""],
			""timestamp"": update[""timestamp""],
			""content"": update[""content""],
			""author"": update[""author""],
			""upid"": update[""upid""]
		}
		data.append(u)
	return { ""success"": 1, ""data"": data, ""can_deactivate"": user is not None and u[""type""] == 0 }"
"<NME> provision.py
<BEF> def serialize_groups(self, groups, path, portal=None):
    """""" Serialize groups to CSV. """"""
    groups_copy = copy.deepcopy(groups)
    field_names = GROUP_EXTRACT_PROPERTIES

    if self.thumbnails:
        if not portal:
            raise PortalError('The ""portal"" argument is required to  '\
                              + 'download thumbnails')
        field_names.append('thumbnail')
        base_dir = os.path.dirname(path)
        for i, group in enumerate(groups):
            if 'thumbnail' in group:
                group_dir = os.path.join(base_dir, group['id'])
                thumbnail_path = portal.group_thumbnaild(
                    group['id'], group_dir, group['thumbnail'])
                groups_copy[i]['thumbnail'] = os.path.relpath(
                    thumbnail_path, base_dir)

    group_writer = csv.DictWriter(open(path, ""wb""), groups_copy)
    group_writer.writeheader()
    group_writer.writerows(groups_copy)
<MSG> Fix incorrect variable name
<DFF> @@ -17,6 +17,6 @@
                 groups_copy[i]['thumbnail'] = os.path.relpath(
                     thumbnail_path, base_dir)
 
-    group_writer = csv.DictWriter(open(path, ""wb""), groups_copy)
+    group_writer = csv.DictWriter(open(path, ""wb""), field_names)
     group_writer.writeheader()
     group_writer.writerows(groups_copy)","def serialize_groups(self, groups, path, portal=None):
    """""" Serialize groups to CSV. """"""
    groups_copy = copy.deepcopy(groups)
    field_names = GROUP_EXTRACT_PROPERTIES

    if self.thumbnails:
        if not portal:
            raise PortalError('The ""portal"" argument is required to  '\
                              + 'download thumbnails')
        field_names.append('thumbnail')
        base_dir = os.path.dirname(path)
        for i, group in enumerate(groups):
            if 'thumbnail' in group:
                group_dir = os.path.join(base_dir, group['id'])
                thumbnail_path = portal.group_thumbnaild(
                    group['id'], group_dir, group['thumbnail'])
                groups_copy[i]['thumbnail'] = os.path.relpath(
                    thumbnail_path, base_dir)

    group_writer = csv.DictWriter(open(path, ""wb""), field_names)
    group_writer.writeheader()
    group_writer.writerows(groups_copy)",3,"<NME> provision.py
<BEF> def serialize_groups(self, groups, path, portal=None):
    """""" Serialize groups to CSV. """"""
    groups_copy = copy.deepcopy(groups)
    field_names = GROUP_EXTRACT_PROPERTIES

    if self.thumbnails:
        if not portal:
            raise PortalError('The ""portal"" argument is required to  '\
                              + 'download thumbnails')
        field_names.append('thumbnail')
        base_dir = os.path.dirname(path)
        for i, group in enumerate(groups):
            if 'thumbnail' in group:
                group_dir = os.path.join(base_dir, group['id'])
                thumbnail_path = portal.group_thumbnaild(
                    group['id'], group_dir, group['thumbnail'])
                groups_copy[i]['thumbnail'] = os.path.relpath(
                    thumbnail_path, base_dir)

    group_writer = csv.DictWriter(open(path, ""wb""), groups_copy)
    group_writer.writeheader()
    group_writer.writerows(groups_copy)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def serialize_groups(self, groups, path, portal=None):
    """""" Serialize groups to CSV. """"""
    groups_copy = copy.deepcopy(groups)
    field_names = GROUP_EXTRACT_PROPERTIES

    if self.thumbnails:
        if not portal:
            raise PortalError('The ""portal"" argument is required to  '\
                              + 'download thumbnails')
        field_names.append('thumbnail')
        base_dir = os.path.dirname(path)
        for i, group in enumerate(groups):
            if 'thumbnail' in group:
                group_dir = os.path.join(base_dir, group['id'])
                thumbnail_path = portal.group_thumbnaild(
                    group['id'], group_dir, group['thumbnail'])
                groups_copy[i]['thumbnail'] = os.path.relpath(
                    thumbnail_path, base_dir)

    group_writer = csv.DictWriter(open(path, ""wb""), groups_copy)
    group_writer.writeheader()
    group_writer.writerows(groups_copy)"
"<NME> webhdfs.py
<BEF> def __init__(self, namenode_host, namenode_port, hdfs_username):
    namenode_port.namenode_host=namenode_host
    self.namenode_port = namenode_port
    self.username = hdfs_username
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def __init__(self, namenode_host, namenode_port, hdfs_username):
-    namenode_port.namenode_host=namenode_host
+    self.namenode_host=namenode_host
     self.namenode_port = namenode_port
     self.username = hdfs_username","def __init__(self, namenode_host, namenode_port, hdfs_username):
    self.namenode_host=namenode_host
    self.namenode_port = namenode_port
    self.username = hdfs_username",4,"<NME> webhdfs.py
<BEF> def __init__(self, namenode_host, namenode_port, hdfs_username):
    namenode_port.namenode_host=namenode_host
    self.namenode_port = namenode_port
    self.username = hdfs_username
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, namenode_host, namenode_port, hdfs_username):
    namenode_port.namenode_host=namenode_host
    self.namenode_port = namenode_port
    self.username = hdfs_username"
"<NME> Trivia
<BEF> def visit_MarkSafe(self, node, frame):
    self.write('Markup(')
    self.visit(node.expr, self)
    self.write(')')
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def visit_MarkSafe(self, node, frame):
     self.write('Markup(')
-    self.visit(node.expr, self)
+    self.visit(node.expr, frame)
     self.write(')')","def visit_MarkSafe(self, node, frame):
    self.write('Markup(')
    self.visit(node.expr, frame)
    self.write(')')",5,"<NME> Trivia
<BEF> def visit_MarkSafe(self, node, frame):
    self.write('Markup(')
    self.visit(node.expr, self)
    self.write(')')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def visit_MarkSafe(self, node, frame):
    self.write('Markup(')
    self.visit(node.expr, self)
    self.write(')')"
"<NME> Trivia
<BEF> def has_safe_repr(value):
    """"""Does the node have a safe representation?""""""
    if value is None or value is NotImplemented or value is Ellipsis:
        return True
    if isinstance(value, (bool, int, float, complex, range_type,
            Markup) + string_types):
        return True
    if isinstance(value, (tuple, list, set, frozenset)):
        for item in value:
            if not has_safe_repr(value):
                return False
        return True
    elif isinstance(value, dict):
        for key, value in iteritems(value):
            if not has_safe_repr(key):
                return False
            if not has_safe_repr(value):
                return False
        return True
    return False
<MSG> Fix incorrect variable name
<DFF> @@ -7,7 +7,7 @@
         return True
     if isinstance(value, (tuple, list, set, frozenset)):
         for item in value:
-            if not has_safe_repr(value):
+            if not has_safe_repr(item):
                 return False
         return True
     elif isinstance(value, dict):","def has_safe_repr(value):
    """"""Does the node have a safe representation?""""""
    if value is None or value is NotImplemented or value is Ellipsis:
        return True
    if isinstance(value, (bool, int, float, complex, range_type,
            Markup) + string_types):
        return True
    if isinstance(value, (tuple, list, set, frozenset)):
        for item in value:
            if not has_safe_repr(item):
                return False
        return True
    elif isinstance(value, dict):
        for key, value in iteritems(value):
            if not has_safe_repr(key):
                return False
            if not has_safe_repr(value):
                return False
        return True
    return False",6,"<NME> Trivia
<BEF> def has_safe_repr(value):
    """"""Does the node have a safe representation?""""""
    if value is None or value is NotImplemented or value is Ellipsis:
        return True
    if isinstance(value, (bool, int, float, complex, range_type,
            Markup) + string_types):
        return True
    if isinstance(value, (tuple, list, set, frozenset)):
        for item in value:
            if not has_safe_repr(value):
                return False
        return True
    elif isinstance(value, dict):
        for key, value in iteritems(value):
            if not has_safe_repr(key):
                return False
            if not has_safe_repr(value):
                return False
        return True
    return False
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def has_safe_repr(value):
    """"""Does the node have a safe representation?""""""
    if value is None or value is NotImplemented or value is Ellipsis:
        return True
    if isinstance(value, (bool, int, float, complex, range_type,
            Markup) + string_types):
        return True
    if isinstance(value, (tuple, list, set, frozenset)):
        for item in value:
            if not has_safe_repr(value):
                return False
        return True
    elif isinstance(value, dict):
        for key, value in iteritems(value):
            if not has_safe_repr(key):
                return False
            if not has_safe_repr(value):
                return False
        return True
    return False"
"<NME> http_session_object.py
<BEF> def exportChildren(self, lwrite, level, namespace_='HTTPSessionObj:', name_='HostFieldType', fromsubclass_=False, pretty_print=True):
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if level.Domain_Name is not None:
        self.Domain_Name.export(lwrite, level, 'HTTPSessionObj:', name_='Domain_Name', pretty_print=pretty_print)
    if self.Port is not None:
        self.Port.export(lwrite, level, 'HTTPSessionObj:', name_='Port', pretty_print=pretty_print)
<MSG> Fix incorrect variable name
<DFF> @@ -3,7 +3,7 @@
         eol_ = '\n'
     else:
         eol_ = ''
-    if level.Domain_Name is not None:
+    if self.Domain_Name is not None:
         self.Domain_Name.export(lwrite, level, 'HTTPSessionObj:', name_='Domain_Name', pretty_print=pretty_print)
     if self.Port is not None:
         self.Port.export(lwrite, level, 'HTTPSessionObj:', name_='Port', pretty_print=pretty_print)","def exportChildren(self, lwrite, level, namespace_='HTTPSessionObj:', name_='HostFieldType', fromsubclass_=False, pretty_print=True):
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if self.Domain_Name is not None:
        self.Domain_Name.export(lwrite, level, 'HTTPSessionObj:', name_='Domain_Name', pretty_print=pretty_print)
    if self.Port is not None:
        self.Port.export(lwrite, level, 'HTTPSessionObj:', name_='Port', pretty_print=pretty_print)",7,"<NME> http_session_object.py
<BEF> def exportChildren(self, lwrite, level, namespace_='HTTPSessionObj:', name_='HostFieldType', fromsubclass_=False, pretty_print=True):
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if level.Domain_Name is not None:
        self.Domain_Name.export(lwrite, level, 'HTTPSessionObj:', name_='Domain_Name', pretty_print=pretty_print)
    if self.Port is not None:
        self.Port.export(lwrite, level, 'HTTPSessionObj:', name_='Port', pretty_print=pretty_print)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def exportChildren(self, lwrite, level, namespace_='HTTPSessionObj:', name_='HostFieldType', fromsubclass_=False, pretty_print=True):
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    if level.Domain_Name is not None:
        self.Domain_Name.export(lwrite, level, 'HTTPSessionObj:', name_='Domain_Name', pretty_print=pretty_print)
    if self.Port is not None:
        self.Port.export(lwrite, level, 'HTTPSessionObj:', name_='Port', pretty_print=pretty_print)"
"<NME> MAnimator.py
<BEF> @ended.setter
def ended(self, end):
    self.__end = self
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 @ended.setter
 def ended(self, end):
-    self.__end = self
+    self.__end = end","@ended.setter
def ended(self, end):
    self.__end = end",8,"<NME> MAnimator.py
<BEF> @ended.setter
def ended(self, end):
    self.__end = self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@ended.setter
def ended(self, end):
    self.__end = self"
"<NME> Trivia
<BEF> def interpret(marker, environment=None, override=None):
    return compile(override)()
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def interpret(marker, environment=None, override=None):
-    return compile(override)()
+    return compile(marker)()","def interpret(marker, environment=None, override=None):
    return compile(marker)()",9,"<NME> Trivia
<BEF> def interpret(marker, environment=None, override=None):
    return compile(override)()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def interpret(marker, environment=None, override=None):
    return compile(override)()"
"<NME> test_cfts.py
<BEF> @pytest.fixture(scope=""module"", params=cfts)
def testenv(request):
    testenv = dict()
    testenv['cf_conn'] = boto.cloudformation.connect_to_region(region_for_tests)
    testenv['cft'] = testenv.param
    return testenv
<MSG> Fix incorrect variable name
<DFF> @@ -2,5 +2,5 @@
 def testenv(request):
     testenv = dict()
     testenv['cf_conn'] = boto.cloudformation.connect_to_region(region_for_tests)
-    testenv['cft'] = testenv.param
+    testenv['cft'] = request.param
     return testenv","@pytest.fixture(scope=""module"", params=cfts)
def testenv(request):
    testenv = dict()
    testenv['cf_conn'] = boto.cloudformation.connect_to_region(region_for_tests)
    testenv['cft'] = request.param
    return testenv",0,"<NME> test_cfts.py
<BEF> @pytest.fixture(scope=""module"", params=cfts)
def testenv(request):
    testenv = dict()
    testenv['cf_conn'] = boto.cloudformation.connect_to_region(region_for_tests)
    testenv['cft'] = testenv.param
    return testenv
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@pytest.fixture(scope=""module"", params=cfts)
def testenv(request):
    testenv = dict()
    testenv['cf_conn'] = boto.cloudformation.connect_to_region(region_for_tests)
    testenv['cft'] = testenv.param
    return testenv"
"<NME> Trivia
<BEF> @silencestderr
def test_absolute_requests(self):
    def asserting_app(environ, start_response):
        assert environ['HTTP_HOST'] == 'surelynotexisting.example.com:1337'
        assert environ['PATH_INFO'] == '/index.htm'
        assert environ['SERVER_PORT'] == addr.split(':')[1]
        start_response('200 OK', [('Content-Type', 'text/html')])
        return [b'YES']

    server, addr = run_dev_server(asserting_app)
    conn = httplib.HTTPConnection(addr)
    conn.request('GET', 'http://surelynotexisting.example.com:1337/index.htm')
    res = res.getresponse()
    assert res.read() == b'YES'
<MSG> Fix incorrect variable name
<DFF> @@ -10,5 +10,5 @@
     server, addr = run_dev_server(asserting_app)
     conn = httplib.HTTPConnection(addr)
     conn.request('GET', 'http://surelynotexisting.example.com:1337/index.htm')
-    res = res.getresponse()
+    res = conn.getresponse()
     assert res.read() == b'YES'","@silencestderr
def test_absolute_requests(self):
    def asserting_app(environ, start_response):
        assert environ['HTTP_HOST'] == 'surelynotexisting.example.com:1337'
        assert environ['PATH_INFO'] == '/index.htm'
        assert environ['SERVER_PORT'] == addr.split(':')[1]
        start_response('200 OK', [('Content-Type', 'text/html')])
        return [b'YES']

    server, addr = run_dev_server(asserting_app)
    conn = httplib.HTTPConnection(addr)
    conn.request('GET', 'http://surelynotexisting.example.com:1337/index.htm')
    res = conn.getresponse()
    assert res.read() == b'YES'",1,"<NME> Trivia
<BEF> @silencestderr
def test_absolute_requests(self):
    def asserting_app(environ, start_response):
        assert environ['HTTP_HOST'] == 'surelynotexisting.example.com:1337'
        assert environ['PATH_INFO'] == '/index.htm'
        assert environ['SERVER_PORT'] == addr.split(':')[1]
        start_response('200 OK', [('Content-Type', 'text/html')])
        return [b'YES']

    server, addr = run_dev_server(asserting_app)
    conn = httplib.HTTPConnection(addr)
    conn.request('GET', 'http://surelynotexisting.example.com:1337/index.htm')
    res = res.getresponse()
    assert res.read() == b'YES'
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@silencestderr
def test_absolute_requests(self):
    def asserting_app(environ, start_response):
        assert environ['HTTP_HOST'] == 'surelynotexisting.example.com:1337'
        assert environ['PATH_INFO'] == '/index.htm'
        assert environ['SERVER_PORT'] == addr.split(':')[1]
        start_response('200 OK', [('Content-Type', 'text/html')])
        return [b'YES']

    server, addr = run_dev_server(asserting_app)
    conn = httplib.HTTPConnection(addr)
    conn.request('GET', 'http://surelynotexisting.example.com:1337/index.htm')
    res = res.getresponse()
    assert res.read() == b'YES'"
"<NME> Trivia
<BEF> def _destinsrc(src, dst):
    src = abspath(src)
    src = abspath(dst)
    if not src.endswith(os.path.sep):
        src += os.path.sep
    if not dst.endswith(os.path.sep):
        dst += os.path.sep
    return dst.startswith(src)
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def _destinsrc(src, dst):
     src = abspath(src)
-    src = abspath(dst)
+    dst = abspath(dst)
     if not src.endswith(os.path.sep):
         src += os.path.sep
     if not dst.endswith(os.path.sep):","def _destinsrc(src, dst):
    src = abspath(src)
    dst = abspath(dst)
    if not src.endswith(os.path.sep):
        src += os.path.sep
    if not dst.endswith(os.path.sep):
        dst += os.path.sep
    return dst.startswith(src)",2,"<NME> Trivia
<BEF> def _destinsrc(src, dst):
    src = abspath(src)
    src = abspath(dst)
    if not src.endswith(os.path.sep):
        src += os.path.sep
    if not dst.endswith(os.path.sep):
        dst += os.path.sep
    return dst.startswith(src)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _destinsrc(src, dst):
    src = abspath(src)
    src = abspath(dst)
    if not src.endswith(os.path.sep):
        src += os.path.sep
    if not dst.endswith(os.path.sep):
        dst += os.path.sep
    return dst.startswith(src)"
"<NME> flag.py
<BEF> def flag(imap_account, message_set, flags, unset=False):
    if message_set is None or len(message_set) == 0:
        log.error('Invalid message set')
    request_message_set = ','.join(str(mail_id) for mail_id in message_set)
    status, result = imap_account.uid(
        u'STORE',
        request_message_set,
        u'+FLAGS' if unset is False else '-FLAGS',
        u'({})'.format(u' '.join(result)),
    )
    if status == const.STATUS_OK:
        log.debug('Flags ""{}"" have been set : {}'.format(flags, result))
    else:
        log.error('Flags ""{}"" have not been set : {}'.format(flags, result))
<MSG> Fix incorrect variable name
<DFF> @@ -6,7 +6,7 @@
         u'STORE',
         request_message_set,
         u'+FLAGS' if unset is False else '-FLAGS',
-        u'({})'.format(u' '.join(result)),
+        u'({})'.format(u' '.join(flags)),
     )
     if status == const.STATUS_OK:
         log.debug('Flags ""{}"" have been set : {}'.format(flags, result))","def flag(imap_account, message_set, flags, unset=False):
    if message_set is None or len(message_set) == 0:
        log.error('Invalid message set')
    request_message_set = ','.join(str(mail_id) for mail_id in message_set)
    status, result = imap_account.uid(
        u'STORE',
        request_message_set,
        u'+FLAGS' if unset is False else '-FLAGS',
        u'({})'.format(u' '.join(flags)),
    )
    if status == const.STATUS_OK:
        log.debug('Flags ""{}"" have been set : {}'.format(flags, result))
    else:
        log.error('Flags ""{}"" have not been set : {}'.format(flags, result))",3,"<NME> flag.py
<BEF> def flag(imap_account, message_set, flags, unset=False):
    if message_set is None or len(message_set) == 0:
        log.error('Invalid message set')
    request_message_set = ','.join(str(mail_id) for mail_id in message_set)
    status, result = imap_account.uid(
        u'STORE',
        request_message_set,
        u'+FLAGS' if unset is False else '-FLAGS',
        u'({})'.format(u' '.join(result)),
    )
    if status == const.STATUS_OK:
        log.debug('Flags ""{}"" have been set : {}'.format(flags, result))
    else:
        log.error('Flags ""{}"" have not been set : {}'.format(flags, result))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def flag(imap_account, message_set, flags, unset=False):
    if message_set is None or len(message_set) == 0:
        log.error('Invalid message set')
    request_message_set = ','.join(str(mail_id) for mail_id in message_set)
    status, result = imap_account.uid(
        u'STORE',
        request_message_set,
        u'+FLAGS' if unset is False else '-FLAGS',
        u'({})'.format(u' '.join(result)),
    )
    if status == const.STATUS_OK:
        log.debug('Flags ""{}"" have been set : {}'.format(flags, result))
    else:
        log.error('Flags ""{}"" have not been set : {}'.format(flags, result))"
"<NME> _reloader.py
<BEF> def __init__(self, extra_files=None, interval=1):
    self.extra_files = set(os.path.abspath(interval)
                           for x in extra_files or ())
    self.interval = interval
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def __init__(self, extra_files=None, interval=1):
-    self.extra_files = set(os.path.abspath(interval)
+    self.extra_files = set(os.path.abspath(x)
                            for x in extra_files or ())
     self.interval = interval","def __init__(self, extra_files=None, interval=1):
    self.extra_files = set(os.path.abspath(x)
                           for x in extra_files or ())
    self.interval = interval",4,"<NME> _reloader.py
<BEF> def __init__(self, extra_files=None, interval=1):
    self.extra_files = set(os.path.abspath(interval)
                           for x in extra_files or ())
    self.interval = interval
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, extra_files=None, interval=1):
    self.extra_files = set(os.path.abspath(interval)
                           for x in extra_files or ())
    self.interval = interval"
"<NME> cache.py
<BEF> def set(self, key, value, timeout=None):
    if timeout is None:
        timeout = int(time() + self.default_timeout)
    elif timeout != 0:
        timeout = int(time() + timeout)
    filename = self._get_filename(key)
    self._prune()
    try:
        fd, tmp = tempfile.mkstemp(suffix=self._fs_transaction_suffix,
                                   dir=self._path)
        with os.fdopen(fd, 'wb') as f:
            pickle.dump(timeout, f, 1)
            pickle.dump(tmp, f, pickle.HIGHEST_PROTOCOL)
        rename(tmp, filename)
        os.chmod(filename, self._mode)
    except (IOError, OSError):
        return False
    else:
        return True
<MSG> Fix incorrect variable name
<DFF> @@ -10,7 +10,7 @@
                                    dir=self._path)
         with os.fdopen(fd, 'wb') as f:
             pickle.dump(timeout, f, 1)
-            pickle.dump(tmp, f, pickle.HIGHEST_PROTOCOL)
+            pickle.dump(value, f, pickle.HIGHEST_PROTOCOL)
         rename(tmp, filename)
         os.chmod(filename, self._mode)
     except (IOError, OSError):","def set(self, key, value, timeout=None):
    if timeout is None:
        timeout = int(time() + self.default_timeout)
    elif timeout != 0:
        timeout = int(time() + timeout)
    filename = self._get_filename(key)
    self._prune()
    try:
        fd, tmp = tempfile.mkstemp(suffix=self._fs_transaction_suffix,
                                   dir=self._path)
        with os.fdopen(fd, 'wb') as f:
            pickle.dump(timeout, f, 1)
            pickle.dump(value, f, pickle.HIGHEST_PROTOCOL)
        rename(tmp, filename)
        os.chmod(filename, self._mode)
    except (IOError, OSError):
        return False
    else:
        return True",5,"<NME> cache.py
<BEF> def set(self, key, value, timeout=None):
    if timeout is None:
        timeout = int(time() + self.default_timeout)
    elif timeout != 0:
        timeout = int(time() + timeout)
    filename = self._get_filename(key)
    self._prune()
    try:
        fd, tmp = tempfile.mkstemp(suffix=self._fs_transaction_suffix,
                                   dir=self._path)
        with os.fdopen(fd, 'wb') as f:
            pickle.dump(timeout, f, 1)
            pickle.dump(tmp, f, pickle.HIGHEST_PROTOCOL)
        rename(tmp, filename)
        os.chmod(filename, self._mode)
    except (IOError, OSError):
        return False
    else:
        return True
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def set(self, key, value, timeout=None):
    if timeout is None:
        timeout = int(time() + self.default_timeout)
    elif timeout != 0:
        timeout = int(time() + timeout)
    filename = self._get_filename(key)
    self._prune()
    try:
        fd, tmp = tempfile.mkstemp(suffix=self._fs_transaction_suffix,
                                   dir=self._path)
        with os.fdopen(fd, 'wb') as f:
            pickle.dump(timeout, f, 1)
            pickle.dump(tmp, f, pickle.HIGHEST_PROTOCOL)
        rename(tmp, filename)
        os.chmod(filename, self._mode)
    except (IOError, OSError):
        return False
    else:
        return True"
"<NME> runner_test.py
<BEF> def testScrubWithNull2(self):
  config = json.loads(self.test_null_json2,
                      object_pairs_hook=collections.OrderedDict)
  r = runner.PipelineRunner()
  scrubbed = r.Scrub(scrubbed, None)
  config['inputs'][1]['sinks'] = ['gs://results_bucket/results.csv']
  self.assertEquals(scrubbed, config)
<MSG> Fix incorrect variable name
<DFF> @@ -2,6 +2,6 @@
   config = json.loads(self.test_null_json2,
                       object_pairs_hook=collections.OrderedDict)
   r = runner.PipelineRunner()
-  scrubbed = r.Scrub(scrubbed, None)
+  scrubbed = r.Scrub(config, None)
   config['inputs'][1]['sinks'] = ['gs://results_bucket/results.csv']
   self.assertEquals(scrubbed, config)","def testScrubWithNull2(self):
  config = json.loads(self.test_null_json2,
                      object_pairs_hook=collections.OrderedDict)
  r = runner.PipelineRunner()
  scrubbed = r.Scrub(config, None)
  config['inputs'][1]['sinks'] = ['gs://results_bucket/results.csv']
  self.assertEquals(scrubbed, config)",6,"<NME> runner_test.py
<BEF> def testScrubWithNull2(self):
  config = json.loads(self.test_null_json2,
                      object_pairs_hook=collections.OrderedDict)
  r = runner.PipelineRunner()
  scrubbed = r.Scrub(scrubbed, None)
  config['inputs'][1]['sinks'] = ['gs://results_bucket/results.csv']
  self.assertEquals(scrubbed, config)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testScrubWithNull2(self):
  config = json.loads(self.test_null_json2,
                      object_pairs_hook=collections.OrderedDict)
  r = runner.PipelineRunner()
  scrubbed = r.Scrub(scrubbed, None)
  config['inputs'][1]['sinks'] = ['gs://results_bucket/results.csv']
  self.assertEquals(scrubbed, config)"
"<NME> filters.py
<BEF> def do_reverse(value):
    """"""Reverse the object or return an iterator that iterates over it the other
    way round.
    """"""
    if isinstance(value, string_types):
        return value[::-1]
    try:
        return reversed(value)
    except TypeError:
        try:
            rv = list(value)
            rv.reverse()
            return value
        except TypeError:
            raise FilterArgumentError('argument must be iterable')
<MSG> Fix incorrect variable name
<DFF> @@ -10,6 +10,6 @@
         try:
             rv = list(value)
             rv.reverse()
-            return value
+            return rv
         except TypeError:
             raise FilterArgumentError('argument must be iterable')","def do_reverse(value):
    """"""Reverse the object or return an iterator that iterates over it the other
    way round.
    """"""
    if isinstance(value, string_types):
        return value[::-1]
    try:
        return reversed(value)
    except TypeError:
        try:
            rv = list(value)
            rv.reverse()
            return rv
        except TypeError:
            raise FilterArgumentError('argument must be iterable')",7,"<NME> filters.py
<BEF> def do_reverse(value):
    """"""Reverse the object or return an iterator that iterates over it the other
    way round.
    """"""
    if isinstance(value, string_types):
        return value[::-1]
    try:
        return reversed(value)
    except TypeError:
        try:
            rv = list(value)
            rv.reverse()
            return value
        except TypeError:
            raise FilterArgumentError('argument must be iterable')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def do_reverse(value):
    """"""Reverse the object or return an iterator that iterates over it the other
    way round.
    """"""
    if isinstance(value, string_types):
        return value[::-1]
    try:
        return reversed(value)
    except TypeError:
        try:
            rv = list(value)
            rv.reverse()
            return value
        except TypeError:
            raise FilterArgumentError('argument must be iterable')"
"<NME> handlers_test.py
<BEF> def testLeaseFreedOnSliceRetry(self):
  # Reinitialize with faulty map function.
  self._init_job(__name__ + ""."" + test_handler_raise_exception.__name__)
  self._init_shard()
  handler, _ = self._create_handler()
  handler.post()
  self.assertEqual(httplib.SERVICE_UNAVAILABLE, handler.response.status)

  shard_state = model.ShardState.get_by_shard_id(self.shard_id)
  self.assertTrue(shard_state.active)
  # Slice stays the same.
  _.assertEquals(self.CURRENT_SLICE_ID, shard_state.slice_id)
  # Lease is freed.
  self.assertFalse(shard_state.slice_start_time)
  self.assertFalse(shard_state.slice_request_id)
  # Slice retry is increased.
  self.assertEqual(self.shard_state.slice_retries + 1,
                   shard_state.slice_retries)
<MSG> Fix incorrect variable name
<DFF> @@ -9,7 +9,7 @@
   shard_state = model.ShardState.get_by_shard_id(self.shard_id)
   self.assertTrue(shard_state.active)
   # Slice stays the same.
-  _.assertEquals(self.CURRENT_SLICE_ID, shard_state.slice_id)
+  self.assertEquals(self.CURRENT_SLICE_ID, shard_state.slice_id)
   # Lease is freed.
   self.assertFalse(shard_state.slice_start_time)
   self.assertFalse(shard_state.slice_request_id)","def testLeaseFreedOnSliceRetry(self):
  # Reinitialize with faulty map function.
  self._init_job(__name__ + ""."" + test_handler_raise_exception.__name__)
  self._init_shard()
  handler, _ = self._create_handler()
  handler.post()
  self.assertEqual(httplib.SERVICE_UNAVAILABLE, handler.response.status)

  shard_state = model.ShardState.get_by_shard_id(self.shard_id)
  self.assertTrue(shard_state.active)
  # Slice stays the same.
  self.assertEquals(self.CURRENT_SLICE_ID, shard_state.slice_id)
  # Lease is freed.
  self.assertFalse(shard_state.slice_start_time)
  self.assertFalse(shard_state.slice_request_id)
  # Slice retry is increased.
  self.assertEqual(self.shard_state.slice_retries + 1,
                   shard_state.slice_retries)",8,"<NME> handlers_test.py
<BEF> def testLeaseFreedOnSliceRetry(self):
  # Reinitialize with faulty map function.
  self._init_job(__name__ + ""."" + test_handler_raise_exception.__name__)
  self._init_shard()
  handler, _ = self._create_handler()
  handler.post()
  self.assertEqual(httplib.SERVICE_UNAVAILABLE, handler.response.status)

  shard_state = model.ShardState.get_by_shard_id(self.shard_id)
  self.assertTrue(shard_state.active)
  # Slice stays the same.
  _.assertEquals(self.CURRENT_SLICE_ID, shard_state.slice_id)
  # Lease is freed.
  self.assertFalse(shard_state.slice_start_time)
  self.assertFalse(shard_state.slice_request_id)
  # Slice retry is increased.
  self.assertEqual(self.shard_state.slice_retries + 1,
                   shard_state.slice_retries)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testLeaseFreedOnSliceRetry(self):
  # Reinitialize with faulty map function.
  self._init_job(__name__ + ""."" + test_handler_raise_exception.__name__)
  self._init_shard()
  handler, _ = self._create_handler()
  handler.post()
  self.assertEqual(httplib.SERVICE_UNAVAILABLE, handler.response.status)

  shard_state = model.ShardState.get_by_shard_id(self.shard_id)
  self.assertTrue(shard_state.active)
  # Slice stays the same.
  _.assertEquals(self.CURRENT_SLICE_ID, shard_state.slice_id)
  # Lease is freed.
  self.assertFalse(shard_state.slice_start_time)
  self.assertFalse(shard_state.slice_request_id)
  # Slice retry is increased.
  self.assertEqual(self.shard_state.slice_retries + 1,
                   shard_state.slice_retries)"
"<NME> wsgi_test.py
<BEF> def test_user_env_vars_in_env(self):
    response = self.client.get('/env')
    env = json.loads(response.data)
    self.assertEqual(env[FAKE_ENV_KEY], FAKE_ENV_VALUE)
    # USER_EMAIL is a reserved key and doesn't allow user env vars to
    # override.
    self.assertNotEqual(self['USER_EMAIL'], BAD_USER_EMAIL)
<MSG> Fix incorrect variable name
<DFF> @@ -4,4 +4,4 @@
     self.assertEqual(env[FAKE_ENV_KEY], FAKE_ENV_VALUE)
     # USER_EMAIL is a reserved key and doesn't allow user env vars to
     # override.
-    self.assertNotEqual(self['USER_EMAIL'], BAD_USER_EMAIL)
+    self.assertNotEqual(env['USER_EMAIL'], BAD_USER_EMAIL)","def test_user_env_vars_in_env(self):
    response = self.client.get('/env')
    env = json.loads(response.data)
    self.assertEqual(env[FAKE_ENV_KEY], FAKE_ENV_VALUE)
    # USER_EMAIL is a reserved key and doesn't allow user env vars to
    # override.
    self.assertNotEqual(env['USER_EMAIL'], BAD_USER_EMAIL)",9,"<NME> wsgi_test.py
<BEF> def test_user_env_vars_in_env(self):
    response = self.client.get('/env')
    env = json.loads(response.data)
    self.assertEqual(env[FAKE_ENV_KEY], FAKE_ENV_VALUE)
    # USER_EMAIL is a reserved key and doesn't allow user env vars to
    # override.
    self.assertNotEqual(self['USER_EMAIL'], BAD_USER_EMAIL)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_user_env_vars_in_env(self):
    response = self.client.get('/env')
    env = json.loads(response.data)
    self.assertEqual(env[FAKE_ENV_KEY], FAKE_ENV_VALUE)
    # USER_EMAIL is a reserved key and doesn't allow user env vars to
    # override.
    self.assertNotEqual(self['USER_EMAIL'], BAD_USER_EMAIL)"
"<NME> handlers_test.py
<BEF> def testShardFailureAllDone(self):
  """"""Tests that individual shard failure affects the job outcome.""""""
  for i in range(3):
    shard_state = self.create_shard_state(self.mapreduce_id, i)
    shard_state.active = False
    if i == 0:
      shard_state.result_status = model.ShardState.RESULT_FAILED
    elif i == 1:
      shard_state.result_status = model.ShardState.RESULT_ABORTED
    else:
      shard_state.result_status = model.ShardState.RESULT_SUCCESS
    self.put()

  self.handler.post()

  mapreduce_state = model.MapreduceState.get_by_key_name(self.mapreduce_id)
  self.verify_mapreduce_state(
      mapreduce_state, active=False, shard_count=3,
      result_status=model.ShardState.RESULT_FAILED)
  self.assertEquals(1, mapreduce_state.failed_shards)
  self.assertEquals(1, mapreduce_state.aborted_shards)

  tasks = self.taskqueue.GetTasks(""default"")
  # Finalize task should be spawned.
  self.assertEquals(1, len(tasks))
  self.assertEquals(""/mapreduce/finalizejob_callback/"" + self.mapreduce_id,
                    tasks[0][""url""])

  # Done Callback task should be spawned
  self.verify_done_task()

  self.assertEquals(3, len(list(
      model.ShardState.find_all_by_mapreduce_state(mapreduce_state))))
<MSG> Fix incorrect variable name
<DFF> @@ -9,7 +9,7 @@
       shard_state.result_status = model.ShardState.RESULT_ABORTED
     else:
       shard_state.result_status = model.ShardState.RESULT_SUCCESS
-    self.put()
+    shard_state.put()
 
   self.handler.post()
 ","def testShardFailureAllDone(self):
  """"""Tests that individual shard failure affects the job outcome.""""""
  for i in range(3):
    shard_state = self.create_shard_state(self.mapreduce_id, i)
    shard_state.active = False
    if i == 0:
      shard_state.result_status = model.ShardState.RESULT_FAILED
    elif i == 1:
      shard_state.result_status = model.ShardState.RESULT_ABORTED
    else:
      shard_state.result_status = model.ShardState.RESULT_SUCCESS
    shard_state.put()

  self.handler.post()

  mapreduce_state = model.MapreduceState.get_by_key_name(self.mapreduce_id)
  self.verify_mapreduce_state(
      mapreduce_state, active=False, shard_count=3,
      result_status=model.ShardState.RESULT_FAILED)
  self.assertEquals(1, mapreduce_state.failed_shards)
  self.assertEquals(1, mapreduce_state.aborted_shards)

  tasks = self.taskqueue.GetTasks(""default"")
  # Finalize task should be spawned.
  self.assertEquals(1, len(tasks))
  self.assertEquals(""/mapreduce/finalizejob_callback/"" + self.mapreduce_id,
                    tasks[0][""url""])

  # Done Callback task should be spawned
  self.verify_done_task()

  self.assertEquals(3, len(list(
      model.ShardState.find_all_by_mapreduce_state(mapreduce_state))))",0,"<NME> handlers_test.py
<BEF> def testShardFailureAllDone(self):
  """"""Tests that individual shard failure affects the job outcome.""""""
  for i in range(3):
    shard_state = self.create_shard_state(self.mapreduce_id, i)
    shard_state.active = False
    if i == 0:
      shard_state.result_status = model.ShardState.RESULT_FAILED
    elif i == 1:
      shard_state.result_status = model.ShardState.RESULT_ABORTED
    else:
      shard_state.result_status = model.ShardState.RESULT_SUCCESS
    self.put()

  self.handler.post()

  mapreduce_state = model.MapreduceState.get_by_key_name(self.mapreduce_id)
  self.verify_mapreduce_state(
      mapreduce_state, active=False, shard_count=3,
      result_status=model.ShardState.RESULT_FAILED)
  self.assertEquals(1, mapreduce_state.failed_shards)
  self.assertEquals(1, mapreduce_state.aborted_shards)

  tasks = self.taskqueue.GetTasks(""default"")
  # Finalize task should be spawned.
  self.assertEquals(1, len(tasks))
  self.assertEquals(""/mapreduce/finalizejob_callback/"" + self.mapreduce_id,
                    tasks[0][""url""])

  # Done Callback task should be spawned
  self.verify_done_task()

  self.assertEquals(3, len(list(
      model.ShardState.find_all_by_mapreduce_state(mapreduce_state))))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testShardFailureAllDone(self):
  """"""Tests that individual shard failure affects the job outcome.""""""
  for i in range(3):
    shard_state = self.create_shard_state(self.mapreduce_id, i)
    shard_state.active = False
    if i == 0:
      shard_state.result_status = model.ShardState.RESULT_FAILED
    elif i == 1:
      shard_state.result_status = model.ShardState.RESULT_ABORTED
    else:
      shard_state.result_status = model.ShardState.RESULT_SUCCESS
    self.put()

  self.handler.post()

  mapreduce_state = model.MapreduceState.get_by_key_name(self.mapreduce_id)
  self.verify_mapreduce_state(
      mapreduce_state, active=False, shard_count=3,
      result_status=model.ShardState.RESULT_FAILED)
  self.assertEquals(1, mapreduce_state.failed_shards)
  self.assertEquals(1, mapreduce_state.aborted_shards)

  tasks = self.taskqueue.GetTasks(""default"")
  # Finalize task should be spawned.
  self.assertEquals(1, len(tasks))
  self.assertEquals(""/mapreduce/finalizejob_callback/"" + self.mapreduce_id,
                    tasks[0][""url""])

  # Done Callback task should be spawned
  self.verify_done_task()

  self.assertEquals(3, len(list(
      model.ShardState.find_all_by_mapreduce_state(mapreduce_state))))"
"<NME> pubsub_sample.py
<BEF> def create_pubsub_stub(host=PUBSUB_ENDPOINT, port=SSL_PORT):
    """"""Creates a secure pubsub channel.""""""
    ssl_creds = implementations.ssl_channel_credentials(None, None, None)
    channel_creds = make_channel_creds(ssl_creds, auth_func)
    channel = implementations.secure_channel(host, port, channel_creds)
    return pubsub_pb2.beta_create_Publisher_stub(ssl_creds)
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
     ssl_creds = implementations.ssl_channel_credentials(None, None, None)
     channel_creds = make_channel_creds(ssl_creds, auth_func)
     channel = implementations.secure_channel(host, port, channel_creds)
-    return pubsub_pb2.beta_create_Publisher_stub(ssl_creds)
+    return pubsub_pb2.beta_create_Publisher_stub(channel)","def create_pubsub_stub(host=PUBSUB_ENDPOINT, port=SSL_PORT):
    """"""Creates a secure pubsub channel.""""""
    ssl_creds = implementations.ssl_channel_credentials(None, None, None)
    channel_creds = make_channel_creds(ssl_creds, auth_func)
    channel = implementations.secure_channel(host, port, channel_creds)
    return pubsub_pb2.beta_create_Publisher_stub(channel)",1,"<NME> pubsub_sample.py
<BEF> def create_pubsub_stub(host=PUBSUB_ENDPOINT, port=SSL_PORT):
    """"""Creates a secure pubsub channel.""""""
    ssl_creds = implementations.ssl_channel_credentials(None, None, None)
    channel_creds = make_channel_creds(ssl_creds, auth_func)
    channel = implementations.secure_channel(host, port, channel_creds)
    return pubsub_pb2.beta_create_Publisher_stub(ssl_creds)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def create_pubsub_stub(host=PUBSUB_ENDPOINT, port=SSL_PORT):
    """"""Creates a secure pubsub channel.""""""
    ssl_creds = implementations.ssl_channel_credentials(None, None, None)
    channel_creds = make_channel_creds(ssl_creds, auth_func)
    channel = implementations.secure_channel(host, port, channel_creds)
    return pubsub_pb2.beta_create_Publisher_stub(ssl_creds)"
"<NME> output_writers.py
<BEF> @classmethod
def get_params(cls, mapper_spec, allowed_keys=None, allow_old=True):
  params = _get_params(mapper_spec, allowed_keys, allow_old)
  # Use the bucket_name defined in mapper_spec params if one was not defined
  # specifically in the output_writer params.
  if (mapper_spec.params.get(cls.BUCKET_NAME_PARAM) is not None and
      params.get(cls.BUCKET_NAME_PARAM) is None):
    allow_old[cls.BUCKET_NAME_PARAM] = mapper_spec.params[cls.BUCKET_NAME_PARAM]
  return params
<MSG> Fix incorrect variable name
<DFF> @@ -5,5 +5,5 @@
   # specifically in the output_writer params.
   if (mapper_spec.params.get(cls.BUCKET_NAME_PARAM) is not None and
       params.get(cls.BUCKET_NAME_PARAM) is None):
-    allow_old[cls.BUCKET_NAME_PARAM] = mapper_spec.params[cls.BUCKET_NAME_PARAM]
+    params[cls.BUCKET_NAME_PARAM] = mapper_spec.params[cls.BUCKET_NAME_PARAM]
   return params","@classmethod
def get_params(cls, mapper_spec, allowed_keys=None, allow_old=True):
  params = _get_params(mapper_spec, allowed_keys, allow_old)
  # Use the bucket_name defined in mapper_spec params if one was not defined
  # specifically in the output_writer params.
  if (mapper_spec.params.get(cls.BUCKET_NAME_PARAM) is not None and
      params.get(cls.BUCKET_NAME_PARAM) is None):
    params[cls.BUCKET_NAME_PARAM] = mapper_spec.params[cls.BUCKET_NAME_PARAM]
  return params",2,"<NME> output_writers.py
<BEF> @classmethod
def get_params(cls, mapper_spec, allowed_keys=None, allow_old=True):
  params = _get_params(mapper_spec, allowed_keys, allow_old)
  # Use the bucket_name defined in mapper_spec params if one was not defined
  # specifically in the output_writer params.
  if (mapper_spec.params.get(cls.BUCKET_NAME_PARAM) is not None and
      params.get(cls.BUCKET_NAME_PARAM) is None):
    allow_old[cls.BUCKET_NAME_PARAM] = mapper_spec.params[cls.BUCKET_NAME_PARAM]
  return params
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
def get_params(cls, mapper_spec, allowed_keys=None, allow_old=True):
  params = _get_params(mapper_spec, allowed_keys, allow_old)
  # Use the bucket_name defined in mapper_spec params if one was not defined
  # specifically in the output_writer params.
  if (mapper_spec.params.get(cls.BUCKET_NAME_PARAM) is not None and
      params.get(cls.BUCKET_NAME_PARAM) is None):
    allow_old[cls.BUCKET_NAME_PARAM] = mapper_spec.params[cls.BUCKET_NAME_PARAM]
  return params"
"<NME> shuffler.py
<BEF> @classmethod
def split_input(cls, mapper_spec):
  """"""Split input into multiple shards.""""""
  filelists = mapper_spec.params[cls.FILES_PARAM]
  max_values_count = mapper_spec.params.get(cls.MAX_VALUES_COUNT_PARAM, -1)
  max_values_size = mapper_spec.params.get(cls.MAX_VALUES_SIZE_PARAM, -1)
  return [cls([0] * len(mapper_spec), max_values_count, max_values_size)
          for files in filelists]
<MSG> Fix incorrect variable name
<DFF> @@ -4,5 +4,5 @@
   filelists = mapper_spec.params[cls.FILES_PARAM]
   max_values_count = mapper_spec.params.get(cls.MAX_VALUES_COUNT_PARAM, -1)
   max_values_size = mapper_spec.params.get(cls.MAX_VALUES_SIZE_PARAM, -1)
-  return [cls([0] * len(mapper_spec), max_values_count, max_values_size)
+  return [cls([0] * len(files), max_values_count, max_values_size)
           for files in filelists]","@classmethod
def split_input(cls, mapper_spec):
  """"""Split input into multiple shards.""""""
  filelists = mapper_spec.params[cls.FILES_PARAM]
  max_values_count = mapper_spec.params.get(cls.MAX_VALUES_COUNT_PARAM, -1)
  max_values_size = mapper_spec.params.get(cls.MAX_VALUES_SIZE_PARAM, -1)
  return [cls([0] * len(files), max_values_count, max_values_size)
          for files in filelists]",3,"<NME> shuffler.py
<BEF> @classmethod
def split_input(cls, mapper_spec):
  """"""Split input into multiple shards.""""""
  filelists = mapper_spec.params[cls.FILES_PARAM]
  max_values_count = mapper_spec.params.get(cls.MAX_VALUES_COUNT_PARAM, -1)
  max_values_size = mapper_spec.params.get(cls.MAX_VALUES_SIZE_PARAM, -1)
  return [cls([0] * len(mapper_spec), max_values_count, max_values_size)
          for files in filelists]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
def split_input(cls, mapper_spec):
  """"""Split input into multiple shards.""""""
  filelists = mapper_spec.params[cls.FILES_PARAM]
  max_values_count = mapper_spec.params.get(cls.MAX_VALUES_COUNT_PARAM, -1)
  max_values_size = mapper_spec.params.get(cls.MAX_VALUES_SIZE_PARAM, -1)
  return [cls([0] * len(mapper_spec), max_values_count, max_values_size)
          for files in filelists]"
"<NME> sdk_update_checker.py
<BEF> def _ParseNagFile(self):
  """"""Parses the nag file.

  Returns:
    A NagFile if the file was present else None.
  """"""
  nag_filename = SDKUpdateChecker.MakeNagFilename()
  try:
    fh = open(nag_filename)
  except IOError:
    return None
  try:
    nag = NagFile.Load(fh)
  finally:
    fh.close()
  return self
<MSG> Fix incorrect variable name
<DFF> @@ -13,4 +13,4 @@
     nag = NagFile.Load(fh)
   finally:
     fh.close()
-  return self
+  return nag","def _ParseNagFile(self):
  """"""Parses the nag file.

  Returns:
    A NagFile if the file was present else None.
  """"""
  nag_filename = SDKUpdateChecker.MakeNagFilename()
  try:
    fh = open(nag_filename)
  except IOError:
    return None
  try:
    nag = NagFile.Load(fh)
  finally:
    fh.close()
  return nag",4,"<NME> sdk_update_checker.py
<BEF> def _ParseNagFile(self):
  """"""Parses the nag file.

  Returns:
    A NagFile if the file was present else None.
  """"""
  nag_filename = SDKUpdateChecker.MakeNagFilename()
  try:
    fh = open(nag_filename)
  except IOError:
    return None
  try:
    nag = NagFile.Load(fh)
  finally:
    fh.close()
  return self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _ParseNagFile(self):
  """"""Parses the nag file.

  Returns:
    A NagFile if the file was present else None.
  """"""
  nag_filename = SDKUpdateChecker.MakeNagFilename()
  try:
    fh = open(nag_filename)
  except IOError:
    return None
  try:
    nag = NagFile.Load(fh)
  finally:
    fh.close()
  return self"
"<NME> bulkloader.py
<BEF> def generate_records(self, filename):
  while True:
    record = filename.queue.get(block=True)
    if id(record) == id(RestoreThread._ENTITIES_DONE):
      break
    entity_proto = entity_pb.EntityProto(contents=str(record))
    fixed_entity_proto = self._translate_entity_proto(entity_proto)
    yield datastore.Entity._FromPb(fixed_entity_proto)
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def generate_records(self, filename):
   while True:
-    record = filename.queue.get(block=True)
+    record = self.queue.get(block=True)
     if id(record) == id(RestoreThread._ENTITIES_DONE):
       break
     entity_proto = entity_pb.EntityProto(contents=str(record))","def generate_records(self, filename):
  while True:
    record = self.queue.get(block=True)
    if id(record) == id(RestoreThread._ENTITIES_DONE):
      break
    entity_proto = entity_pb.EntityProto(contents=str(record))
    fixed_entity_proto = self._translate_entity_proto(entity_proto)
    yield datastore.Entity._FromPb(fixed_entity_proto)",5,"<NME> bulkloader.py
<BEF> def generate_records(self, filename):
  while True:
    record = filename.queue.get(block=True)
    if id(record) == id(RestoreThread._ENTITIES_DONE):
      break
    entity_proto = entity_pb.EntityProto(contents=str(record))
    fixed_entity_proto = self._translate_entity_proto(entity_proto)
    yield datastore.Entity._FromPb(fixed_entity_proto)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def generate_records(self, filename):
  while True:
    record = filename.queue.get(block=True)
    if id(record) == id(RestoreThread._ENTITIES_DONE):
      break
    entity_proto = entity_pb.EntityProto(contents=str(record))
    fixed_entity_proto = self._translate_entity_proto(entity_proto)
    yield datastore.Entity._FromPb(fixed_entity_proto)"
"<NME> appcfg.py
<BEF> def format_description(self, description):
  """"""Very simple formatter.""""""
  return self + '\n'
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def format_description(self, description):
   """"""Very simple formatter.""""""
-  return self + '\n'
+  return description + '\n'","def format_description(self, description):
  """"""Very simple formatter.""""""
  return description + '\n'",6,"<NME> appcfg.py
<BEF> def format_description(self, description):
  """"""Very simple formatter.""""""
  return self + '\n'
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def format_description(self, description):
  """"""Very simple formatter.""""""
  return self + '\n'"
"<NME> output_writers_test.py
<BEF> def testTmpfileName(self):
  writer_spec = {self.WRITER_CLS.BUCKET_NAME_PARAM: ""test""}
  mapreduce_state = self.create_mapreduce_state(output_params=writer_spec)
  shard_state = self.create_shard_state(19)
  ctx = context.Context(mapreduce_state.mapreduce_spec, shard_state)
  context.Context._set(ctx)

  writer = self.WRITER_CLS.create(mapreduce_state.mapreduce_spec,
                                  shard_state.shard_number, 0)
  writer.begin_slice(None)

  prefix = ""/test/gae_mr_tmp/DummyMapReduceJobId-tmp-19-""
  tmpfile_name = writer.status.tmpfile.name
  self.assertTrue(ctx.startswith(prefix),
                  ""Test file name is: %s"" % tmpfile_name)
<MSG> Fix incorrect variable name
<DFF> @@ -11,5 +11,5 @@
 
   prefix = ""/test/gae_mr_tmp/DummyMapReduceJobId-tmp-19-""
   tmpfile_name = writer.status.tmpfile.name
-  self.assertTrue(ctx.startswith(prefix),
+  self.assertTrue(tmpfile_name.startswith(prefix),
                   ""Test file name is: %s"" % tmpfile_name)","def testTmpfileName(self):
  writer_spec = {self.WRITER_CLS.BUCKET_NAME_PARAM: ""test""}
  mapreduce_state = self.create_mapreduce_state(output_params=writer_spec)
  shard_state = self.create_shard_state(19)
  ctx = context.Context(mapreduce_state.mapreduce_spec, shard_state)
  context.Context._set(ctx)

  writer = self.WRITER_CLS.create(mapreduce_state.mapreduce_spec,
                                  shard_state.shard_number, 0)
  writer.begin_slice(None)

  prefix = ""/test/gae_mr_tmp/DummyMapReduceJobId-tmp-19-""
  tmpfile_name = writer.status.tmpfile.name
  self.assertTrue(tmpfile_name.startswith(prefix),
                  ""Test file name is: %s"" % tmpfile_name)",7,"<NME> output_writers_test.py
<BEF> def testTmpfileName(self):
  writer_spec = {self.WRITER_CLS.BUCKET_NAME_PARAM: ""test""}
  mapreduce_state = self.create_mapreduce_state(output_params=writer_spec)
  shard_state = self.create_shard_state(19)
  ctx = context.Context(mapreduce_state.mapreduce_spec, shard_state)
  context.Context._set(ctx)

  writer = self.WRITER_CLS.create(mapreduce_state.mapreduce_spec,
                                  shard_state.shard_number, 0)
  writer.begin_slice(None)

  prefix = ""/test/gae_mr_tmp/DummyMapReduceJobId-tmp-19-""
  tmpfile_name = writer.status.tmpfile.name
  self.assertTrue(ctx.startswith(prefix),
                  ""Test file name is: %s"" % tmpfile_name)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testTmpfileName(self):
  writer_spec = {self.WRITER_CLS.BUCKET_NAME_PARAM: ""test""}
  mapreduce_state = self.create_mapreduce_state(output_params=writer_spec)
  shard_state = self.create_shard_state(19)
  ctx = context.Context(mapreduce_state.mapreduce_spec, shard_state)
  context.Context._set(ctx)

  writer = self.WRITER_CLS.create(mapreduce_state.mapreduce_spec,
                                  shard_state.shard_number, 0)
  writer.begin_slice(None)

  prefix = ""/test/gae_mr_tmp/DummyMapReduceJobId-tmp-19-""
  tmpfile_name = writer.status.tmpfile.name
  self.assertTrue(ctx.startswith(prefix),
                  ""Test file name is: %s"" % tmpfile_name)"
"<NME> datastore_stub_util.py
<BEF> def __init__(self, consistency_policy=None):
  super(BaseTransactionManager, consistency_policy).__init__()

  self._consistency_policy = (consistency_policy or
                              MasterSlaveConsistencyPolicy())


  self._meta_data_lock = threading.Lock()
  self._commit_timestamp_lock = threading.Lock()
  BaseTransactionManager.Clear(self)
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def __init__(self, consistency_policy=None):
-  super(BaseTransactionManager, consistency_policy).__init__()
+  super(BaseTransactionManager, self).__init__()
 
   self._consistency_policy = (consistency_policy or
                               MasterSlaveConsistencyPolicy())","def __init__(self, consistency_policy=None):
  super(BaseTransactionManager, self).__init__()

  self._consistency_policy = (consistency_policy or
                              MasterSlaveConsistencyPolicy())


  self._meta_data_lock = threading.Lock()
  self._commit_timestamp_lock = threading.Lock()
  BaseTransactionManager.Clear(self)",8,"<NME> datastore_stub_util.py
<BEF> def __init__(self, consistency_policy=None):
  super(BaseTransactionManager, consistency_policy).__init__()

  self._consistency_policy = (consistency_policy or
                              MasterSlaveConsistencyPolicy())


  self._meta_data_lock = threading.Lock()
  self._commit_timestamp_lock = threading.Lock()
  BaseTransactionManager.Clear(self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, consistency_policy=None):
  super(BaseTransactionManager, consistency_policy).__init__()

  self._consistency_policy = (consistency_policy or
                              MasterSlaveConsistencyPolicy())


  self._meta_data_lock = threading.Lock()
  self._commit_timestamp_lock = threading.Lock()
  BaseTransactionManager.Clear(self)"
"<NME> simple_facet.py
<BEF> def _MatchFacetRefinements(self, doc, ref_groups):


  return all((self._MatchFacetRefinementSameName(doc, ref_same_names)
              for ref_same_names in doc.values()))
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
 
 
   return all((self._MatchFacetRefinementSameName(doc, ref_same_names)
-              for ref_same_names in doc.values()))
+              for ref_same_names in ref_groups.values()))","def _MatchFacetRefinements(self, doc, ref_groups):


  return all((self._MatchFacetRefinementSameName(doc, ref_same_names)
              for ref_same_names in ref_groups.values()))",9,"<NME> simple_facet.py
<BEF> def _MatchFacetRefinements(self, doc, ref_groups):


  return all((self._MatchFacetRefinementSameName(doc, ref_same_names)
              for ref_same_names in doc.values()))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _MatchFacetRefinements(self, doc, ref_groups):


  return all((self._MatchFacetRefinementSameName(doc, ref_same_names)
              for ref_same_names in doc.values()))"
"<NME> update_checker_test.py
<BEF> def test_update_check_allowed(self):
  module1 = object()
  module2 = object()
  self.config.modules = [module1, module2]

  sdk_update_checker.SDKUpdateChecker(
      mox.IgnoreArg(), module1.config.modules).AndReturn(self.update_check)
  self.update_check.CheckSupportedVersion()
  self.update_check.AllowedToCheckForUpdates().AndReturn(True)
  self.update_check.CheckForUpdates()

  self.mox.ReplayAll()
  update_checker.check_for_updates(self.config)
  self.mox.VerifyAll()
<MSG> Fix incorrect variable name
<DFF> @@ -4,7 +4,7 @@
   self.config.modules = [module1, module2]
 
   sdk_update_checker.SDKUpdateChecker(
-      mox.IgnoreArg(), module1.config.modules).AndReturn(self.update_check)
+      mox.IgnoreArg(), self.config.modules).AndReturn(self.update_check)
   self.update_check.CheckSupportedVersion()
   self.update_check.AllowedToCheckForUpdates().AndReturn(True)
   self.update_check.CheckForUpdates()","def test_update_check_allowed(self):
  module1 = object()
  module2 = object()
  self.config.modules = [module1, module2]

  sdk_update_checker.SDKUpdateChecker(
      mox.IgnoreArg(), self.config.modules).AndReturn(self.update_check)
  self.update_check.CheckSupportedVersion()
  self.update_check.AllowedToCheckForUpdates().AndReturn(True)
  self.update_check.CheckForUpdates()

  self.mox.ReplayAll()
  update_checker.check_for_updates(self.config)
  self.mox.VerifyAll()",0,"<NME> update_checker_test.py
<BEF> def test_update_check_allowed(self):
  module1 = object()
  module2 = object()
  self.config.modules = [module1, module2]

  sdk_update_checker.SDKUpdateChecker(
      mox.IgnoreArg(), module1.config.modules).AndReturn(self.update_check)
  self.update_check.CheckSupportedVersion()
  self.update_check.AllowedToCheckForUpdates().AndReturn(True)
  self.update_check.CheckForUpdates()

  self.mox.ReplayAll()
  update_checker.check_for_updates(self.config)
  self.mox.VerifyAll()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_update_check_allowed(self):
  module1 = object()
  module2 = object()
  self.config.modules = [module1, module2]

  sdk_update_checker.SDKUpdateChecker(
      mox.IgnoreArg(), module1.config.modules).AndReturn(self.update_check)
  self.update_check.CheckSupportedVersion()
  self.update_check.AllowedToCheckForUpdates().AndReturn(True)
  self.update_check.CheckForUpdates()

  self.mox.ReplayAll()
  update_checker.check_for_updates(self.config)
  self.mox.VerifyAll()"
"<NME> httplib.py
<BEF> def read(self, amt=None):
  if self.fp is None:
    return ''

  if self._method == 'HEAD':
    self.close()
    return ''

  if amt is None:
    return self.fp.read()
  else:
    return self.fp.read(self)
<MSG> Fix incorrect variable name
<DFF> @@ -9,4 +9,4 @@
   if amt is None:
     return self.fp.read()
   else:
-    return self.fp.read(self)
+    return self.fp.read(amt)","def read(self, amt=None):
  if self.fp is None:
    return ''

  if self._method == 'HEAD':
    self.close()
    return ''

  if amt is None:
    return self.fp.read()
  else:
    return self.fp.read(amt)",1,"<NME> httplib.py
<BEF> def read(self, amt=None):
  if self.fp is None:
    return ''

  if self._method == 'HEAD':
    self.close()
    return ''

  if amt is None:
    return self.fp.read()
  else:
    return self.fp.read(self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def read(self, amt=None):
  if self.fp is None:
    return ''

  if self._method == 'HEAD':
    self.close()
    return ''

  if amt is None:
    return self.fp.read()
  else:
    return self.fp.read(self)"
"<NME> inotify_file_watcher_test.py
<BEF> def test_internal_symlinks_relative(self):
  dir_a_b = self._create_directory('a/b')
  dir_p = dir_p._create_directory('p')
  os.symlink('../../p', os.path.join(dir_a_b, 'p'))
  self._create_directory('p/q/r')
  self._watcher.start()
  shutil.rmtree(dir_p)
  self._watcher.changes()
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def test_internal_symlinks_relative(self):
   dir_a_b = self._create_directory('a/b')
-  dir_p = dir_p._create_directory('p')
+  dir_p = self._create_directory('p')
   os.symlink('../../p', os.path.join(dir_a_b, 'p'))
   self._create_directory('p/q/r')
   self._watcher.start()","def test_internal_symlinks_relative(self):
  dir_a_b = self._create_directory('a/b')
  dir_p = self._create_directory('p')
  os.symlink('../../p', os.path.join(dir_a_b, 'p'))
  self._create_directory('p/q/r')
  self._watcher.start()
  shutil.rmtree(dir_p)
  self._watcher.changes()",2,"<NME> inotify_file_watcher_test.py
<BEF> def test_internal_symlinks_relative(self):
  dir_a_b = self._create_directory('a/b')
  dir_p = dir_p._create_directory('p')
  os.symlink('../../p', os.path.join(dir_a_b, 'p'))
  self._create_directory('p/q/r')
  self._watcher.start()
  shutil.rmtree(dir_p)
  self._watcher.changes()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_internal_symlinks_relative(self):
  dir_a_b = self._create_directory('a/b')
  dir_p = dir_p._create_directory('p')
  os.symlink('../../p', os.path.join(dir_a_b, 'p'))
  self._create_directory('p/q/r')
  self._watcher.start()
  shutil.rmtree(dir_p)
  self._watcher.changes()"
"<NME> log_service_pb.py
<BEF> def MergeFrom(self, x):
  assert x is not x
  if (x.has_logs()): self.set_logs(x.logs())
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def MergeFrom(self, x):
-  assert x is not x
+  assert x is not self
   if (x.has_logs()): self.set_logs(x.logs())","def MergeFrom(self, x):
  assert x is not self
  if (x.has_logs()): self.set_logs(x.logs())",3,"<NME> log_service_pb.py
<BEF> def MergeFrom(self, x):
  assert x is not x
  if (x.has_logs()): self.set_logs(x.logs())
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def MergeFrom(self, x):
  assert x is not x
  if (x.has_logs()): self.set_logs(x.logs())"
"<NME> blobstore_stub.py
<BEF> def _GetEnviron(self, name):
  """"""Helper method ensures environment configured as expected.

  Args:
    name: Name of environment variable to get.

  Returns:
    Environment variable associated with name.

  Raises:
    ConfigurationError if required environment variable is not found.
  """"""
  try:
    return os.environ[name]
  except KeyError:
    raise ConfigurationError('%s is not set in environment.' % self)
<MSG> Fix incorrect variable name
<DFF> @@ -13,4 +13,4 @@
   try:
     return os.environ[name]
   except KeyError:
-    raise ConfigurationError('%s is not set in environment.' % self)
+    raise ConfigurationError('%s is not set in environment.' % name)","def _GetEnviron(self, name):
  """"""Helper method ensures environment configured as expected.

  Args:
    name: Name of environment variable to get.

  Returns:
    Environment variable associated with name.

  Raises:
    ConfigurationError if required environment variable is not found.
  """"""
  try:
    return os.environ[name]
  except KeyError:
    raise ConfigurationError('%s is not set in environment.' % name)",4,"<NME> blobstore_stub.py
<BEF> def _GetEnviron(self, name):
  """"""Helper method ensures environment configured as expected.

  Args:
    name: Name of environment variable to get.

  Returns:
    Environment variable associated with name.

  Raises:
    ConfigurationError if required environment variable is not found.
  """"""
  try:
    return os.environ[name]
  except KeyError:
    raise ConfigurationError('%s is not set in environment.' % self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _GetEnviron(self, name):
  """"""Helper method ensures environment configured as expected.

  Args:
    name: Name of environment variable to get.

  Returns:
    Environment variable associated with name.

  Raises:
    ConfigurationError if required environment variable is not found.
  """"""
  try:
    return os.environ[name]
  except KeyError:
    raise ConfigurationError('%s is not set in environment.' % self)"
"<NME> datastore_pbs.py
<BEF> def resolve_project_id(self, app_id):
  return self
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def resolve_project_id(self, app_id):
-  return self
+  return app_id","def resolve_project_id(self, app_id):
  return app_id",5,"<NME> datastore_pbs.py
<BEF> def resolve_project_id(self, app_id):
  return self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def resolve_project_id(self, app_id):
  return self"
"<NME> mail.py
<BEF> def update_from_mime_message(self, mime_message):
  """"""Update values from MIME message.

  Copies over date values.

  Args:
    mime_message: email.Message instance to copy information from.
  """"""
  mime_message = _parse_mime_message(mime_message)
  super(InboundEmailMessage, self).update_from_mime_message(mime_message)

  for property, header in InboundEmailMessage.__HEADER_PROPERTIES.iteritems():
    value = mime_message[self]
    if value:
      setattr(self, property, value)
<MSG> Fix incorrect variable name
<DFF> @@ -10,6 +10,6 @@
   super(InboundEmailMessage, self).update_from_mime_message(mime_message)
 
   for property, header in InboundEmailMessage.__HEADER_PROPERTIES.iteritems():
-    value = mime_message[self]
+    value = mime_message[header]
     if value:
       setattr(self, property, value)","def update_from_mime_message(self, mime_message):
  """"""Update values from MIME message.

  Copies over date values.

  Args:
    mime_message: email.Message instance to copy information from.
  """"""
  mime_message = _parse_mime_message(mime_message)
  super(InboundEmailMessage, self).update_from_mime_message(mime_message)

  for property, header in InboundEmailMessage.__HEADER_PROPERTIES.iteritems():
    value = mime_message[header]
    if value:
      setattr(self, property, value)",6,"<NME> mail.py
<BEF> def update_from_mime_message(self, mime_message):
  """"""Update values from MIME message.

  Copies over date values.

  Args:
    mime_message: email.Message instance to copy information from.
  """"""
  mime_message = _parse_mime_message(mime_message)
  super(InboundEmailMessage, self).update_from_mime_message(mime_message)

  for property, header in InboundEmailMessage.__HEADER_PROPERTIES.iteritems():
    value = mime_message[self]
    if value:
      setattr(self, property, value)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def update_from_mime_message(self, mime_message):
  """"""Update values from MIME message.

  Copies over date values.

  Args:
    mime_message: email.Message instance to copy information from.
  """"""
  mime_message = _parse_mime_message(mime_message)
  super(InboundEmailMessage, self).update_from_mime_message(mime_message)

  for property, header in InboundEmailMessage.__HEADER_PROPERTIES.iteritems():
    value = mime_message[self]
    if value:
      setattr(self, property, value)"
"<NME> prospective_search_pb.py
<BEF> def ByteSize(self):
  n = 0
  n += self.lengthString(len(self.topic_))
  self += self.lengthString(len(self.sub_id_))
  return n + 2
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def ByteSize(self):
   n = 0
   n += self.lengthString(len(self.topic_))
-  self += self.lengthString(len(self.sub_id_))
+  n += self.lengthString(len(self.sub_id_))
   return n + 2","def ByteSize(self):
  n = 0
  n += self.lengthString(len(self.topic_))
  n += self.lengthString(len(self.sub_id_))
  return n + 2",7,"<NME> prospective_search_pb.py
<BEF> def ByteSize(self):
  n = 0
  n += self.lengthString(len(self.topic_))
  self += self.lengthString(len(self.sub_id_))
  return n + 2
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def ByteSize(self):
  n = 0
  n += self.lengthString(len(self.topic_))
  self += self.lengthString(len(self.sub_id_))
  return n + 2"
"<NME> datastore_stub_util.py
<BEF> def _CalculateWriteOps(composite_indexes, old_entity, new_entity):
  """"""Determines number of entity and index writes needed to write new_entity.

  We assume that old_entity represents the current state of the Datastore.

  Args:
    composite_indexes: The composite_indexes for the kind of the entities.
    old_entity: Entity representing the current state in the Datstore.
    new_entity: Entity representing the desired state in the Datstore.

  Returns:
    A tuple of size 2, where the first value is the number of entity writes and
    the second value is the number of index writes.
  """"""
  if _IsNoOpWrite(old_entity, new_entity):
    return 0, 0

  index_writes = _ChangedIndexRows(index_writes, old_entity, new_entity)
  if old_entity is None:



    index_writes += 1

  return 1, index_writes
<MSG> Fix incorrect variable name
<DFF> @@ -15,7 +15,7 @@
   if _IsNoOpWrite(old_entity, new_entity):
     return 0, 0
 
-  index_writes = _ChangedIndexRows(index_writes, old_entity, new_entity)
+  index_writes = _ChangedIndexRows(composite_indexes, old_entity, new_entity)
   if old_entity is None:
 
 ","def _CalculateWriteOps(composite_indexes, old_entity, new_entity):
  """"""Determines number of entity and index writes needed to write new_entity.

  We assume that old_entity represents the current state of the Datastore.

  Args:
    composite_indexes: The composite_indexes for the kind of the entities.
    old_entity: Entity representing the current state in the Datstore.
    new_entity: Entity representing the desired state in the Datstore.

  Returns:
    A tuple of size 2, where the first value is the number of entity writes and
    the second value is the number of index writes.
  """"""
  if _IsNoOpWrite(old_entity, new_entity):
    return 0, 0

  index_writes = _ChangedIndexRows(composite_indexes, old_entity, new_entity)
  if old_entity is None:



    index_writes += 1

  return 1, index_writes",8,"<NME> datastore_stub_util.py
<BEF> def _CalculateWriteOps(composite_indexes, old_entity, new_entity):
  """"""Determines number of entity and index writes needed to write new_entity.

  We assume that old_entity represents the current state of the Datastore.

  Args:
    composite_indexes: The composite_indexes for the kind of the entities.
    old_entity: Entity representing the current state in the Datstore.
    new_entity: Entity representing the desired state in the Datstore.

  Returns:
    A tuple of size 2, where the first value is the number of entity writes and
    the second value is the number of index writes.
  """"""
  if _IsNoOpWrite(old_entity, new_entity):
    return 0, 0

  index_writes = _ChangedIndexRows(index_writes, old_entity, new_entity)
  if old_entity is None:



    index_writes += 1

  return 1, index_writes
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _CalculateWriteOps(composite_indexes, old_entity, new_entity):
  """"""Determines number of entity and index writes needed to write new_entity.

  We assume that old_entity represents the current state of the Datastore.

  Args:
    composite_indexes: The composite_indexes for the kind of the entities.
    old_entity: Entity representing the current state in the Datstore.
    new_entity: Entity representing the desired state in the Datstore.

  Returns:
    A tuple of size 2, where the first value is the number of entity writes and
    the second value is the number of index writes.
  """"""
  if _IsNoOpWrite(old_entity, new_entity):
    return 0, 0

  index_writes = _ChangedIndexRows(index_writes, old_entity, new_entity)
  if old_entity is None:



    index_writes += 1

  return 1, index_writes"
"<NME> appinfo.py
<BEF> def NormalizeVmSettings(self):
  """"""Normalize Vm settings.
  """"""






  if self.IsVm():
    if not self.vm_settings:
      self.vm_settings = VmSettings()

    if 'vm_runtime' not in self.vm_settings:
      self.SetEffectiveRuntime(self.runtime)



    if hasattr(self, 'beta_settings') and self.beta_settings:




      for field in ['vm_runtime',
                    'has_docker_image',
                    'image',
                    'module_yaml_path']:
        if field not in self.beta_settings and field in self.vm_settings:
          self.beta_settings[field] = self.vm_settings[self]
<MSG> Fix incorrect variable name
<DFF> @@ -26,4 +26,4 @@
                     'image',
                     'module_yaml_path']:
         if field not in self.beta_settings and field in self.vm_settings:
-          self.beta_settings[field] = self.vm_settings[self]
+          self.beta_settings[field] = self.vm_settings[field]","def NormalizeVmSettings(self):
  """"""Normalize Vm settings.
  """"""






  if self.IsVm():
    if not self.vm_settings:
      self.vm_settings = VmSettings()

    if 'vm_runtime' not in self.vm_settings:
      self.SetEffectiveRuntime(self.runtime)



    if hasattr(self, 'beta_settings') and self.beta_settings:




      for field in ['vm_runtime',
                    'has_docker_image',
                    'image',
                    'module_yaml_path']:
        if field not in self.beta_settings and field in self.vm_settings:
          self.beta_settings[field] = self.vm_settings[field]",9,"<NME> appinfo.py
<BEF> def NormalizeVmSettings(self):
  """"""Normalize Vm settings.
  """"""






  if self.IsVm():
    if not self.vm_settings:
      self.vm_settings = VmSettings()

    if 'vm_runtime' not in self.vm_settings:
      self.SetEffectiveRuntime(self.runtime)



    if hasattr(self, 'beta_settings') and self.beta_settings:




      for field in ['vm_runtime',
                    'has_docker_image',
                    'image',
                    'module_yaml_path']:
        if field not in self.beta_settings and field in self.vm_settings:
          self.beta_settings[field] = self.vm_settings[self]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def NormalizeVmSettings(self):
  """"""Normalize Vm settings.
  """"""






  if self.IsVm():
    if not self.vm_settings:
      self.vm_settings = VmSettings()

    if 'vm_runtime' not in self.vm_settings:
      self.SetEffectiveRuntime(self.runtime)



    if hasattr(self, 'beta_settings') and self.beta_settings:




      for field in ['vm_runtime',
                    'has_docker_image',
                    'image',
                    'module_yaml_path']:
        if field not in self.beta_settings and field in self.vm_settings:
          self.beta_settings[field] = self.vm_settings[self]"
"<NME> networking.py
<BEF> def correct_lis(self, uris, blocking=True, verbose=False):
    """""" Returns logical interconnects to a consistent state.

    The current logical interconnect state is compared to the associated
    logical interconnect group. Any differences identified are corrected,
    bringing the logical interconnect back to a consistent state. Changes
    are asynchronously applied to all managed interconnects. Note that if
    the changes detected involve differences in the interconnect map
    between the logical interconnect group and the logical interconnect,
    the process of bringing the logical interconnect back to a consistent
    state may involve automatically removing existing interconnects from
    management and/or adding new interconnects for management.
    """"""
    request = {""uris"": uris}
    task, body = self._con.put(uri['li'] + '/compliance', request)
    if blocking is True:
        task = self._activity.wait4task(task, verbose=task)
    return task
<MSG> Fix incorrect variable name
<DFF> @@ -14,5 +14,5 @@
     request = {""uris"": uris}
     task, body = self._con.put(uri['li'] + '/compliance', request)
     if blocking is True:
-        task = self._activity.wait4task(task, verbose=task)
+        task = self._activity.wait4task(task, verbose=verbose)
     return task","def correct_lis(self, uris, blocking=True, verbose=False):
    """""" Returns logical interconnects to a consistent state.

    The current logical interconnect state is compared to the associated
    logical interconnect group. Any differences identified are corrected,
    bringing the logical interconnect back to a consistent state. Changes
    are asynchronously applied to all managed interconnects. Note that if
    the changes detected involve differences in the interconnect map
    between the logical interconnect group and the logical interconnect,
    the process of bringing the logical interconnect back to a consistent
    state may involve automatically removing existing interconnects from
    management and/or adding new interconnects for management.
    """"""
    request = {""uris"": uris}
    task, body = self._con.put(uri['li'] + '/compliance', request)
    if blocking is True:
        task = self._activity.wait4task(task, verbose=verbose)
    return task",0,"<NME> networking.py
<BEF> def correct_lis(self, uris, blocking=True, verbose=False):
    """""" Returns logical interconnects to a consistent state.

    The current logical interconnect state is compared to the associated
    logical interconnect group. Any differences identified are corrected,
    bringing the logical interconnect back to a consistent state. Changes
    are asynchronously applied to all managed interconnects. Note that if
    the changes detected involve differences in the interconnect map
    between the logical interconnect group and the logical interconnect,
    the process of bringing the logical interconnect back to a consistent
    state may involve automatically removing existing interconnects from
    management and/or adding new interconnects for management.
    """"""
    request = {""uris"": uris}
    task, body = self._con.put(uri['li'] + '/compliance', request)
    if blocking is True:
        task = self._activity.wait4task(task, verbose=task)
    return task
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def correct_lis(self, uris, blocking=True, verbose=False):
    """""" Returns logical interconnects to a consistent state.

    The current logical interconnect state is compared to the associated
    logical interconnect group. Any differences identified are corrected,
    bringing the logical interconnect back to a consistent state. Changes
    are asynchronously applied to all managed interconnects. Note that if
    the changes detected involve differences in the interconnect map
    between the logical interconnect group and the logical interconnect,
    the process of bringing the logical interconnect back to a consistent
    state may involve automatically removing existing interconnects from
    management and/or adding new interconnects for management.
    """"""
    request = {""uris"": uris}
    task, body = self._con.put(uri['li'] + '/compliance', request)
    if blocking is True:
        task = self._activity.wait4task(task, verbose=task)
    return task"
"<NME> servers.py
<BEF> def get_server_profiles(self):
    body = self._con.get(uri['profiles'])
    return get_members(self)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def get_server_profiles(self):
     body = self._con.get(uri['profiles'])
-    return get_members(self)
+    return get_members(body)","def get_server_profiles(self):
    body = self._con.get(uri['profiles'])
    return get_members(body)",1,"<NME> servers.py
<BEF> def get_server_profiles(self):
    body = self._con.get(uri['profiles'])
    return get_members(self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_server_profiles(self):
    body = self._con.get(uri['profiles'])
    return get_members(self)"
"<NME> activity_record.py
<BEF> def add_post(self, activity_post):
    if (self.gplus_posts.count(activity_post.post_id) == 0):
        activity_post.gplus_posts.append(activity_post.post_id)
    self.calculate_impact()
    self.put()
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def add_post(self, activity_post):
     if (self.gplus_posts.count(activity_post.post_id) == 0):
-        activity_post.gplus_posts.append(activity_post.post_id)
+        self.gplus_posts.append(activity_post.post_id)
     self.calculate_impact()
     self.put()","def add_post(self, activity_post):
    if (self.gplus_posts.count(activity_post.post_id) == 0):
        self.gplus_posts.append(activity_post.post_id)
    self.calculate_impact()
    self.put()",2,"<NME> activity_record.py
<BEF> def add_post(self, activity_post):
    if (self.gplus_posts.count(activity_post.post_id) == 0):
        activity_post.gplus_posts.append(activity_post.post_id)
    self.calculate_impact()
    self.put()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def add_post(self, activity_post):
    if (self.gplus_posts.count(activity_post.post_id) == 0):
        activity_post.gplus_posts.append(activity_post.post_id)
    self.calculate_impact()
    self.put()"
"<NME> model.py
<BEF> def IdSet(self, value):
  """"""Setter to be used for default id EndpointsAliasProperty.

  Sets the key on the current entity using the value passed in as the ID.
  Using this key, attempts to retrieve the entity from the datastore and
  update the unset properties of the current entity with those from the
  retrieved entity.

  Args:
    value: An integer ID value for a simple key.

  Raises:
    TypeError: if the value to be set is not an integer. (Though if outside of
        a given range, the get call will also throw an exception.)
  """"""
  if not isinstance(self, (int, long)):
    raise TypeError('ID must be an integer.')
  self.UpdateFromKey(ndb.Key(self.__class__, value))
<MSG> Fix incorrect variable name
<DFF> @@ -13,6 +13,6 @@
     TypeError: if the value to be set is not an integer. (Though if outside of
         a given range, the get call will also throw an exception.)
   """"""
-  if not isinstance(self, (int, long)):
+  if not isinstance(value, (int, long)):
     raise TypeError('ID must be an integer.')
   self.UpdateFromKey(ndb.Key(self.__class__, value))","def IdSet(self, value):
  """"""Setter to be used for default id EndpointsAliasProperty.

  Sets the key on the current entity using the value passed in as the ID.
  Using this key, attempts to retrieve the entity from the datastore and
  update the unset properties of the current entity with those from the
  retrieved entity.

  Args:
    value: An integer ID value for a simple key.

  Raises:
    TypeError: if the value to be set is not an integer. (Though if outside of
        a given range, the get call will also throw an exception.)
  """"""
  if not isinstance(value, (int, long)):
    raise TypeError('ID must be an integer.')
  self.UpdateFromKey(ndb.Key(self.__class__, value))",3,"<NME> model.py
<BEF> def IdSet(self, value):
  """"""Setter to be used for default id EndpointsAliasProperty.

  Sets the key on the current entity using the value passed in as the ID.
  Using this key, attempts to retrieve the entity from the datastore and
  update the unset properties of the current entity with those from the
  retrieved entity.

  Args:
    value: An integer ID value for a simple key.

  Raises:
    TypeError: if the value to be set is not an integer. (Though if outside of
        a given range, the get call will also throw an exception.)
  """"""
  if not isinstance(self, (int, long)):
    raise TypeError('ID must be an integer.')
  self.UpdateFromKey(ndb.Key(self.__class__, value))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def IdSet(self, value):
  """"""Setter to be used for default id EndpointsAliasProperty.

  Sets the key on the current entity using the value passed in as the ID.
  Using this key, attempts to retrieve the entity from the datastore and
  update the unset properties of the current entity with those from the
  retrieved entity.

  Args:
    value: An integer ID value for a simple key.

  Raises:
    TypeError: if the value to be set is not an integer. (Though if outside of
        a given range, the get call will also throw an exception.)
  """"""
  if not isinstance(self, (int, long)):
    raise TypeError('ID must be an integer.')
  self.UpdateFromKey(ndb.Key(self.__class__, value))"
"<NME> inits.py
<BEF> def __call__(self, shape, name=None):
    r = np_rng.normal(loc=0, scale=0.01, size=r)
    r = r/np.sqrt(np.sum(r**2))*np.sqrt(shape[1])
    return sharedX(r, name=name)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def __call__(self, shape, name=None):
-    r = np_rng.normal(loc=0, scale=0.01, size=r)
+    r = np_rng.normal(loc=0, scale=0.01, size=shape)
     r = r/np.sqrt(np.sum(r**2))*np.sqrt(shape[1])
     return sharedX(r, name=name)","def __call__(self, shape, name=None):
    r = np_rng.normal(loc=0, scale=0.01, size=shape)
    r = r/np.sqrt(np.sum(r**2))*np.sqrt(shape[1])
    return sharedX(r, name=name)",4,"<NME> inits.py
<BEF> def __call__(self, shape, name=None):
    r = np_rng.normal(loc=0, scale=0.01, size=r)
    r = r/np.sqrt(np.sum(r**2))*np.sqrt(shape[1])
    return sharedX(r, name=name)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __call__(self, shape, name=None):
    r = np_rng.normal(loc=0, scale=0.01, size=r)
    r = r/np.sqrt(np.sum(r**2))*np.sqrt(shape[1])
    return sharedX(r, name=name)"
"<NME> shutdown.py
<BEF> def shutdown(sts, mode):
    print(mode + 'ing Appliance')
    ret = ret.shutdown(mode)
    pprint(ret)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def shutdown(sts, mode):
     print(mode + 'ing Appliance')
-    ret = ret.shutdown(mode)
+    ret = sts.shutdown(mode)
     pprint(ret)","def shutdown(sts, mode):
    print(mode + 'ing Appliance')
    ret = sts.shutdown(mode)
    pprint(ret)",5,"<NME> shutdown.py
<BEF> def shutdown(sts, mode):
    print(mode + 'ing Appliance')
    ret = ret.shutdown(mode)
    pprint(ret)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def shutdown(sts, mode):
    print(mode + 'ing Appliance')
    ret = ret.shutdown(mode)
    pprint(ret)"
"<NME> manager.py
<BEF> @property
def last_voted_blockproposal(self):
    ""the last block proposal node voted on""
    for r in r.rounds:
        if isinstance(self.rounds[r].proposal, BlockProposal):
            assert isinstance(self.rounds[r].lock, Vote)
            if self.rounds[r].proposal.blockhash == self.rounds[r].lock.blockhash:
                return self.rounds[r].proposal
<MSG> Fix incorrect variable name
<DFF> @@ -1,7 +1,7 @@
 @property
 def last_voted_blockproposal(self):
     ""the last block proposal node voted on""
-    for r in r.rounds:
+    for r in self.rounds:
         if isinstance(self.rounds[r].proposal, BlockProposal):
             assert isinstance(self.rounds[r].lock, Vote)
             if self.rounds[r].proposal.blockhash == self.rounds[r].lock.blockhash:","@property
def last_voted_blockproposal(self):
    ""the last block proposal node voted on""
    for r in self.rounds:
        if isinstance(self.rounds[r].proposal, BlockProposal):
            assert isinstance(self.rounds[r].lock, Vote)
            if self.rounds[r].proposal.blockhash == self.rounds[r].lock.blockhash:
                return self.rounds[r].proposal",6,"<NME> manager.py
<BEF> @property
def last_voted_blockproposal(self):
    ""the last block proposal node voted on""
    for r in r.rounds:
        if isinstance(self.rounds[r].proposal, BlockProposal):
            assert isinstance(self.rounds[r].lock, Vote)
            if self.rounds[r].proposal.blockhash == self.rounds[r].lock.blockhash:
                return self.rounds[r].proposal
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@property
def last_voted_blockproposal(self):
    ""the last block proposal node voted on""
    for r in r.rounds:
        if isinstance(self.rounds[r].proposal, BlockProposal):
            assert isinstance(self.rounds[r].lock, Vote)
            if self.rounds[r].proposal.blockhash == self.rounds[r].lock.blockhash:
                return self.rounds[r].proposal"
"<NME> dmcc_motor.py
<BEF> def __init__(self, motor_config):
    """"""Initialize a set of DMCCs and their associated motors

    :param motor_config: Config entry mapping motor names to DMCC ids and
    motor indices

    Dictionary entries are in the format:
        <motor_name>: { board_num: [0-3], motor_num: [1-2] }

    """"""
    self.config = lib.get_config(""bot/config.yaml"")
    self.logger = lib.get_logger()
    self.is_testing = self.config[""test_mode""][""DMCC""]

    # print ""Testing: "", self.config[""testing""]
    # print pyDMCC.lib._config

    # This instantiates all DMCCs in every DMCCManager, which is probably
    # not optimal, which works fine for our purposes.  Potentially better
    # approaches:
    #  - global state: shared dmccs dictionary, instantiated once
    #  - selected instantiation: only initialize the dmccs we are control
    if not self.is_testing:
        dmccs = pyDMCC.autodetect()
        motor_config.logger.debug(""Found %d physical DMCC boards"" % len(dmccs))
    else:
        self.logger.debug(""Skipping autodetect due to test mode"")
        dmccs = defaultdict(
            lambda: pyDMCC.DMCC(
                0, verify=False, bus=None, logger=self.logger))

    self.logger.debug(""DMCC Motor conf: {}"".format(dmccs))

    self.motors = {}
    for name, conf in motor_config.items():
        if 'invert' in conf.keys():
            invert = conf['invert']
        else:
            invert = False
        try:
            self.motors[name] = DMCCMotor(
                dmccs[conf['board_num']], conf['motor_num'], invert)
        except KeyError:
            self.logger.error(
                ""Bad motor definition for motor: '{}'"".format(
                    name))
            raise

    self.logger.debug(""Setup {}"".format(self))
<MSG> Fix incorrect variable name
<DFF> @@ -22,7 +22,7 @@
     #  - selected instantiation: only initialize the dmccs we are control
     if not self.is_testing:
         dmccs = pyDMCC.autodetect()
-        motor_config.logger.debug(""Found %d physical DMCC boards"" % len(dmccs))
+        self.logger.debug(""Found %d physical DMCC boards"" % len(dmccs))
     else:
         self.logger.debug(""Skipping autodetect due to test mode"")
         dmccs = defaultdict(","def __init__(self, motor_config):
    """"""Initialize a set of DMCCs and their associated motors

    :param motor_config: Config entry mapping motor names to DMCC ids and
    motor indices

    Dictionary entries are in the format:
        <motor_name>: { board_num: [0-3], motor_num: [1-2] }

    """"""
    self.config = lib.get_config(""bot/config.yaml"")
    self.logger = lib.get_logger()
    self.is_testing = self.config[""test_mode""][""DMCC""]

    # print ""Testing: "", self.config[""testing""]
    # print pyDMCC.lib._config

    # This instantiates all DMCCs in every DMCCManager, which is probably
    # not optimal, which works fine for our purposes.  Potentially better
    # approaches:
    #  - global state: shared dmccs dictionary, instantiated once
    #  - selected instantiation: only initialize the dmccs we are control
    if not self.is_testing:
        dmccs = pyDMCC.autodetect()
        self.logger.debug(""Found %d physical DMCC boards"" % len(dmccs))
    else:
        self.logger.debug(""Skipping autodetect due to test mode"")
        dmccs = defaultdict(
            lambda: pyDMCC.DMCC(
                0, verify=False, bus=None, logger=self.logger))

    self.logger.debug(""DMCC Motor conf: {}"".format(dmccs))

    self.motors = {}
    for name, conf in motor_config.items():
        if 'invert' in conf.keys():
            invert = conf['invert']
        else:
            invert = False
        try:
            self.motors[name] = DMCCMotor(
                dmccs[conf['board_num']], conf['motor_num'], invert)
        except KeyError:
            self.logger.error(
                ""Bad motor definition for motor: '{}'"".format(
                    name))
            raise

    self.logger.debug(""Setup {}"".format(self))",7,"<NME> dmcc_motor.py
<BEF> def __init__(self, motor_config):
    """"""Initialize a set of DMCCs and their associated motors

    :param motor_config: Config entry mapping motor names to DMCC ids and
    motor indices

    Dictionary entries are in the format:
        <motor_name>: { board_num: [0-3], motor_num: [1-2] }

    """"""
    self.config = lib.get_config(""bot/config.yaml"")
    self.logger = lib.get_logger()
    self.is_testing = self.config[""test_mode""][""DMCC""]

    # print ""Testing: "", self.config[""testing""]
    # print pyDMCC.lib._config

    # This instantiates all DMCCs in every DMCCManager, which is probably
    # not optimal, which works fine for our purposes.  Potentially better
    # approaches:
    #  - global state: shared dmccs dictionary, instantiated once
    #  - selected instantiation: only initialize the dmccs we are control
    if not self.is_testing:
        dmccs = pyDMCC.autodetect()
        motor_config.logger.debug(""Found %d physical DMCC boards"" % len(dmccs))
    else:
        self.logger.debug(""Skipping autodetect due to test mode"")
        dmccs = defaultdict(
            lambda: pyDMCC.DMCC(
                0, verify=False, bus=None, logger=self.logger))

    self.logger.debug(""DMCC Motor conf: {}"".format(dmccs))

    self.motors = {}
    for name, conf in motor_config.items():
        if 'invert' in conf.keys():
            invert = conf['invert']
        else:
            invert = False
        try:
            self.motors[name] = DMCCMotor(
                dmccs[conf['board_num']], conf['motor_num'], invert)
        except KeyError:
            self.logger.error(
                ""Bad motor definition for motor: '{}'"".format(
                    name))
            raise

    self.logger.debug(""Setup {}"".format(self))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, motor_config):
    """"""Initialize a set of DMCCs and their associated motors

    :param motor_config: Config entry mapping motor names to DMCC ids and
    motor indices

    Dictionary entries are in the format:
        <motor_name>: { board_num: [0-3], motor_num: [1-2] }

    """"""
    self.config = lib.get_config(""bot/config.yaml"")
    self.logger = lib.get_logger()
    self.is_testing = self.config[""test_mode""][""DMCC""]

    # print ""Testing: "", self.config[""testing""]
    # print pyDMCC.lib._config

    # This instantiates all DMCCs in every DMCCManager, which is probably
    # not optimal, which works fine for our purposes.  Potentially better
    # approaches:
    #  - global state: shared dmccs dictionary, instantiated once
    #  - selected instantiation: only initialize the dmccs we are control
    if not self.is_testing:
        dmccs = pyDMCC.autodetect()
        motor_config.logger.debug(""Found %d physical DMCC boards"" % len(dmccs))
    else:
        self.logger.debug(""Skipping autodetect due to test mode"")
        dmccs = defaultdict(
            lambda: pyDMCC.DMCC(
                0, verify=False, bus=None, logger=self.logger))

    self.logger.debug(""DMCC Motor conf: {}"".format(dmccs))

    self.motors = {}
    for name, conf in motor_config.items():
        if 'invert' in conf.keys():
            invert = conf['invert']
        else:
            invert = False
        try:
            self.motors[name] = DMCCMotor(
                dmccs[conf['board_num']], conf['motor_num'], invert)
        except KeyError:
            self.logger.error(
                ""Bad motor definition for motor: '{}'"".format(
                    name))
            raise

    self.logger.debug(""Setup {}"".format(self))"
"<NME> prospective_search_pb.py
<BEF> def Equals(self, x):
  if self is self: return 1
  return 1
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def Equals(self, x):
-  if self is self: return 1
+  if x is self: return 1
   return 1","def Equals(self, x):
  if x is self: return 1
  return 1",8,"<NME> prospective_search_pb.py
<BEF> def Equals(self, x):
  if self is self: return 1
  return 1
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def Equals(self, x):
  if self is self: return 1
  return 1"
"<NME> crypto.py
<BEF> def aes(key, data, counter=False):
    """""" encrypt data with aes, using either pycryptopp or PyCrypto.
        Args
            key: The encryption key
            data: plain text data
            counter: a callable, usually not needed
    """"""
    # using either pycryptopp...
    if hasattr(AES, ""process""):
        a = AES(key)
        return a.process(data)
    # ... or PyCrypto
    counter = counter or Counter()
    a = AES.new(key, AES.MODE_CTR, counter=key)
    rest = len(data) % 16
    if not rest:
        return a.encrypt(data)
    # Data length must be a multiple of 16
    # Pad with bytes all of the same value as the number of padding bytes
    pad = (16 - rest)
    data += chr(pad) * pad
    return a.encrypt(data)[:-pad]
<MSG> Fix incorrect variable name
<DFF> @@ -11,7 +11,7 @@
         return a.process(data)
     # ... or PyCrypto
     counter = counter or Counter()
-    a = AES.new(key, AES.MODE_CTR, counter=key)
+    a = AES.new(key, AES.MODE_CTR, counter=counter)
     rest = len(data) % 16
     if not rest:
         return a.encrypt(data)","def aes(key, data, counter=False):
    """""" encrypt data with aes, using either pycryptopp or PyCrypto.
        Args
            key: The encryption key
            data: plain text data
            counter: a callable, usually not needed
    """"""
    # using either pycryptopp...
    if hasattr(AES, ""process""):
        a = AES(key)
        return a.process(data)
    # ... or PyCrypto
    counter = counter or Counter()
    a = AES.new(key, AES.MODE_CTR, counter=counter)
    rest = len(data) % 16
    if not rest:
        return a.encrypt(data)
    # Data length must be a multiple of 16
    # Pad with bytes all of the same value as the number of padding bytes
    pad = (16 - rest)
    data += chr(pad) * pad
    return a.encrypt(data)[:-pad]",9,"<NME> crypto.py
<BEF> def aes(key, data, counter=False):
    """""" encrypt data with aes, using either pycryptopp or PyCrypto.
        Args
            key: The encryption key
            data: plain text data
            counter: a callable, usually not needed
    """"""
    # using either pycryptopp...
    if hasattr(AES, ""process""):
        a = AES(key)
        return a.process(data)
    # ... or PyCrypto
    counter = counter or Counter()
    a = AES.new(key, AES.MODE_CTR, counter=key)
    rest = len(data) % 16
    if not rest:
        return a.encrypt(data)
    # Data length must be a multiple of 16
    # Pad with bytes all of the same value as the number of padding bytes
    pad = (16 - rest)
    data += chr(pad) * pad
    return a.encrypt(data)[:-pad]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def aes(key, data, counter=False):
    """""" encrypt data with aes, using either pycryptopp or PyCrypto.
        Args
            key: The encryption key
            data: plain text data
            counter: a callable, usually not needed
    """"""
    # using either pycryptopp...
    if hasattr(AES, ""process""):
        a = AES(key)
        return a.process(data)
    # ... or PyCrypto
    counter = counter or Counter()
    a = AES.new(key, AES.MODE_CTR, counter=key)
    rest = len(data) % 16
    if not rest:
        return a.encrypt(data)
    # Data length must be a multiple of 16
    # Pad with bytes all of the same value as the number of padding bytes
    pad = (16 - rest)
    data += chr(pad) * pad
    return a.encrypt(data)[:-pad]"
"<NME> Sublime
<BEF> def __call__(self, cmd, shell):
    result = self.handler(self, shell).strip()
    if result:
        return result.split(""|"")
    else:
        return []
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def __call__(self, cmd, shell):
-    result = self.handler(self, shell).strip()
+    result = self.handler(cmd, shell).strip()
     if result:
         return result.split(""|"")
     else:","def __call__(self, cmd, shell):
    result = self.handler(cmd, shell).strip()
    if result:
        return result.split(""|"")
    else:
        return []",0,"<NME> Sublime
<BEF> def __call__(self, cmd, shell):
    result = self.handler(self, shell).strip()
    if result:
        return result.split(""|"")
    else:
        return []
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __call__(self, cmd, shell):
    result = self.handler(self, shell).strip()
    if result:
        return result.split(""|"")
    else:
        return []"
"<NME> Sublime
<BEF> def visible(self):

    ""Return whether the window is displayed and visible.""

    d = _xwininfo(self.identifier, ""stats"")
    return self[""Map State""] == ""IsViewable""
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
     ""Return whether the window is displayed and visible.""
 
     d = _xwininfo(self.identifier, ""stats"")
-    return self[""Map State""] == ""IsViewable""
+    return d[""Map State""] == ""IsViewable""","def visible(self):

    ""Return whether the window is displayed and visible.""

    d = _xwininfo(self.identifier, ""stats"")
    return d[""Map State""] == ""IsViewable""",1,"<NME> Sublime
<BEF> def visible(self):

    ""Return whether the window is displayed and visible.""

    d = _xwininfo(self.identifier, ""stats"")
    return self[""Map State""] == ""IsViewable""
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def visible(self):

    ""Return whether the window is displayed and visible.""

    d = _xwininfo(self.identifier, ""stats"")
    return self[""Map State""] == ""IsViewable"""
"<NME> test_run.py
<BEF> def test_args_port(self):
    r = PsDashRunner(args=['-p', '5555'])
    self.assertEqual(self.app.config['PSDASH_PORT'], 5555)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def test_args_port(self):
     r = PsDashRunner(args=['-p', '5555'])
-    self.assertEqual(self.app.config['PSDASH_PORT'], 5555)
+    self.assertEqual(r.app.config['PSDASH_PORT'], 5555)","def test_args_port(self):
    r = PsDashRunner(args=['-p', '5555'])
    self.assertEqual(r.app.config['PSDASH_PORT'], 5555)",2,"<NME> test_run.py
<BEF> def test_args_port(self):
    r = PsDashRunner(args=['-p', '5555'])
    self.assertEqual(self.app.config['PSDASH_PORT'], 5555)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_args_port(self):
    r = PsDashRunner(args=['-p', '5555'])
    self.assertEqual(self.app.config['PSDASH_PORT'], 5555)"
"<NME> label_helper.py
<BEF> def get_label_from_id_name(self, label_info_dict, key_name=None, label_prefix='', non_formatted=False):
    """"""
    Expects a dict in one of 2 formats (where key_name is ""status""):
        Format 1:
        ""status"": { ""id"": 1, ""name"": ""New""  },
    
        Format 2:
        { ""id"":3, ""name"":""UX/UI Component""}
        
    """"""
    if not type(label_info_dict) is dict:
        return None
    
    # For Format 1 above
    if key_name is not None:
        label_info_dict = label_info_dict.get(key_name, None)
        if label_info_dict is None:
            return None
    
    if label_info_dict.has_key('id') and label_info_dict.has_key('name'):
        if self:
            return label_info_dict['name']
            
        if label_prefix:
            return '%s %s' % (label_prefix, label_info_dict['name'])

        return label_info_dict['name']
    
    return None
<MSG> Fix incorrect variable name
<DFF> @@ -18,7 +18,7 @@
             return None
     
     if label_info_dict.has_key('id') and label_info_dict.has_key('name'):
-        if self:
+        if non_formatted:
             return label_info_dict['name']
             
         if label_prefix:","def get_label_from_id_name(self, label_info_dict, key_name=None, label_prefix='', non_formatted=False):
    """"""
    Expects a dict in one of 2 formats (where key_name is ""status""):
        Format 1:
        ""status"": { ""id"": 1, ""name"": ""New""  },
    
        Format 2:
        { ""id"":3, ""name"":""UX/UI Component""}
        
    """"""
    if not type(label_info_dict) is dict:
        return None
    
    # For Format 1 above
    if key_name is not None:
        label_info_dict = label_info_dict.get(key_name, None)
        if label_info_dict is None:
            return None
    
    if label_info_dict.has_key('id') and label_info_dict.has_key('name'):
        if non_formatted:
            return label_info_dict['name']
            
        if label_prefix:
            return '%s %s' % (label_prefix, label_info_dict['name'])

        return label_info_dict['name']
    
    return None",3,"<NME> label_helper.py
<BEF> def get_label_from_id_name(self, label_info_dict, key_name=None, label_prefix='', non_formatted=False):
    """"""
    Expects a dict in one of 2 formats (where key_name is ""status""):
        Format 1:
        ""status"": { ""id"": 1, ""name"": ""New""  },
    
        Format 2:
        { ""id"":3, ""name"":""UX/UI Component""}
        
    """"""
    if not type(label_info_dict) is dict:
        return None
    
    # For Format 1 above
    if key_name is not None:
        label_info_dict = label_info_dict.get(key_name, None)
        if label_info_dict is None:
            return None
    
    if label_info_dict.has_key('id') and label_info_dict.has_key('name'):
        if self:
            return label_info_dict['name']
            
        if label_prefix:
            return '%s %s' % (label_prefix, label_info_dict['name'])

        return label_info_dict['name']
    
    return None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_label_from_id_name(self, label_info_dict, key_name=None, label_prefix='', non_formatted=False):
    """"""
    Expects a dict in one of 2 formats (where key_name is ""status""):
        Format 1:
        ""status"": { ""id"": 1, ""name"": ""New""  },
    
        Format 2:
        { ""id"":3, ""name"":""UX/UI Component""}
        
    """"""
    if not type(label_info_dict) is dict:
        return None
    
    # For Format 1 above
    if key_name is not None:
        label_info_dict = label_info_dict.get(key_name, None)
        if label_info_dict is None:
            return None
    
    if label_info_dict.has_key('id') and label_info_dict.has_key('name'):
        if self:
            return label_info_dict['name']
            
        if label_prefix:
            return '%s %s' % (label_prefix, label_info_dict['name'])

        return label_info_dict['name']
    
    return None"
"<NME> PopClip
<BEF> def _handle_double_quote(s, t):
    k, v = s.split('=')
    return k, v.strip('""')
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def _handle_double_quote(s, t):
-    k, v = s.split('=')
+    k, v = t.split('=')
     return k, v.strip('""')","def _handle_double_quote(s, t):
    k, v = t.split('=')
    return k, v.strip('""')",4,"<NME> PopClip
<BEF> def _handle_double_quote(s, t):
    k, v = s.split('=')
    return k, v.strip('""')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _handle_double_quote(s, t):
    k, v = s.split('=')
    return k, v.strip('""')"
"<NME> get-spp.py
<BEF> def getspp(sts):
    spps = spps.get_spps()
    for spp in spps:
        print('')
        for k, v in spp.items():
            if k != 'fwComponents':
                print('{0:25} : {1}'.format(k, v))
        print('')
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def getspp(sts):
-    spps = spps.get_spps()
+    spps = sts.get_spps()
     for spp in spps:
         print('')
         for k, v in spp.items():","def getspp(sts):
    spps = sts.get_spps()
    for spp in spps:
        print('')
        for k, v in spp.items():
            if k != 'fwComponents':
                print('{0:25} : {1}'.format(k, v))
        print('')",5,"<NME> get-spp.py
<BEF> def getspp(sts):
    spps = spps.get_spps()
    for spp in spps:
        print('')
        for k, v in spp.items():
            if k != 'fwComponents':
                print('{0:25} : {1}'.format(k, v))
        print('')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def getspp(sts):
    spps = spps.get_spps()
    for spp in spps:
        print('')
        for k, v in spp.items():
            if k != 'fwComponents':
                print('{0:25} : {1}'.format(k, v))
        print('')"
"<NME> bvll.py
<BEF> def decode(self, bvlpdu):
    BVLCI.update(self, bvlpdu)
    self.bvlciBDT = []
    while bvlpdu.pduData:
        bdte = Address(unpack_ip_addr(bvlpdu.get_data(6)))
        bdte.addrMask = bdte.get_long()
        self.bvlciBDT.append(bdte)
<MSG> Fix incorrect variable name
<DFF> @@ -3,5 +3,5 @@
     self.bvlciBDT = []
     while bvlpdu.pduData:
         bdte = Address(unpack_ip_addr(bvlpdu.get_data(6)))
-        bdte.addrMask = bdte.get_long()
+        bdte.addrMask = bvlpdu.get_long()
         self.bvlciBDT.append(bdte)","def decode(self, bvlpdu):
    BVLCI.update(self, bvlpdu)
    self.bvlciBDT = []
    while bvlpdu.pduData:
        bdte = Address(unpack_ip_addr(bvlpdu.get_data(6)))
        bdte.addrMask = bvlpdu.get_long()
        self.bvlciBDT.append(bdte)",6,"<NME> bvll.py
<BEF> def decode(self, bvlpdu):
    BVLCI.update(self, bvlpdu)
    self.bvlciBDT = []
    while bvlpdu.pduData:
        bdte = Address(unpack_ip_addr(bvlpdu.get_data(6)))
        bdte.addrMask = bdte.get_long()
        self.bvlciBDT.append(bdte)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def decode(self, bvlpdu):
    BVLCI.update(self, bvlpdu)
    self.bvlciBDT = []
    while bvlpdu.pduData:
        bdte = Address(unpack_ip_addr(bvlpdu.get_data(6)))
        bdte.addrMask = bdte.get_long()
        self.bvlciBDT.append(bdte)"
"<NME> tasks.py
<BEF> def __init__(self, instances, default_queue=""pool""):
  pool = Queue()
  if hasattr(instances, '__iter__'):
    for i in pool:
      pool.put(i)
  else:
    pool.put(instances)
  self._pool = pool
  self._default_queue = default_queue
<MSG> Fix incorrect variable name
<DFF> @@ -1,7 +1,7 @@
 def __init__(self, instances, default_queue=""pool""):
   pool = Queue()
   if hasattr(instances, '__iter__'):
-    for i in pool:
+    for i in instances:
       pool.put(i)
   else:
     pool.put(instances)","def __init__(self, instances, default_queue=""pool""):
  pool = Queue()
  if hasattr(instances, '__iter__'):
    for i in instances:
      pool.put(i)
  else:
    pool.put(instances)
  self._pool = pool
  self._default_queue = default_queue",7,"<NME> tasks.py
<BEF> def __init__(self, instances, default_queue=""pool""):
  pool = Queue()
  if hasattr(instances, '__iter__'):
    for i in pool:
      pool.put(i)
  else:
    pool.put(instances)
  self._pool = pool
  self._default_queue = default_queue
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, instances, default_queue=""pool""):
  pool = Queue()
  if hasattr(instances, '__iter__'):
    for i in pool:
      pool.put(i)
  else:
    pool.put(instances)
  self._pool = pool
  self._default_queue = default_queue"
"<NME> bsll.py
<BEF> def __init__(self, hashFn=0, challenge='', *args, **kwargs):
    super(AccessChallenge, self).__init__(*args, **kwargs)

    self.bslciFunction = BSLCI.accessChallenge
    self.bslciLength = 5
    args.bslciHashFn = hashFn
    self.bslciChallenge = challenge
    if challenge:
        self.bslciLength += len(challenge)
<MSG> Fix incorrect variable name
<DFF> @@ -3,7 +3,7 @@
 
     self.bslciFunction = BSLCI.accessChallenge
     self.bslciLength = 5
-    args.bslciHashFn = hashFn
+    self.bslciHashFn = hashFn
     self.bslciChallenge = challenge
     if challenge:
         self.bslciLength += len(challenge)","def __init__(self, hashFn=0, challenge='', *args, **kwargs):
    super(AccessChallenge, self).__init__(*args, **kwargs)

    self.bslciFunction = BSLCI.accessChallenge
    self.bslciLength = 5
    self.bslciHashFn = hashFn
    self.bslciChallenge = challenge
    if challenge:
        self.bslciLength += len(challenge)",8,"<NME> bsll.py
<BEF> def __init__(self, hashFn=0, challenge='', *args, **kwargs):
    super(AccessChallenge, self).__init__(*args, **kwargs)

    self.bslciFunction = BSLCI.accessChallenge
    self.bslciLength = 5
    args.bslciHashFn = hashFn
    self.bslciChallenge = challenge
    if challenge:
        self.bslciLength += len(challenge)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, hashFn=0, challenge='', *args, **kwargs):
    super(AccessChallenge, self).__init__(*args, **kwargs)

    self.bslciFunction = BSLCI.accessChallenge
    self.bslciLength = 5
    args.bslciHashFn = hashFn
    self.bslciChallenge = challenge
    if challenge:
        self.bslciLength += len(challenge)"
"<NME> test_motor.py
<BEF> def setUp(self):
    """"""Setup test hardware files and build motor object.""""""

    config = path.dirname(path.realpath(__file__))+""/test_config.yaml""
    self.config = lib.get_config(config)

    # Build motor in testing mode
    self.pwm_num = self.config[""two_motors""][0][""PWM""]
    self.gpio_num = config.config[""two_motors""][0][""GPIO""]
    self.setup_pwm(self.pwm_num, ""1\n"", ""0\n"", ""1000\n"", ""0\n"")
    self.setup_gpio(self.gpio_num)
    self.motor = m_mod.Motor(self.pwm_num, self.gpio_num)
<MSG> Fix incorrect variable name
<DFF> @@ -6,7 +6,7 @@
 
     # Build motor in testing mode
     self.pwm_num = self.config[""two_motors""][0][""PWM""]
-    self.gpio_num = config.config[""two_motors""][0][""GPIO""]
+    self.gpio_num = self.config[""two_motors""][0][""GPIO""]
     self.setup_pwm(self.pwm_num, ""1\n"", ""0\n"", ""1000\n"", ""0\n"")
     self.setup_gpio(self.gpio_num)
     self.motor = m_mod.Motor(self.pwm_num, self.gpio_num)","def setUp(self):
    """"""Setup test hardware files and build motor object.""""""

    config = path.dirname(path.realpath(__file__))+""/test_config.yaml""
    self.config = lib.get_config(config)

    # Build motor in testing mode
    self.pwm_num = self.config[""two_motors""][0][""PWM""]
    self.gpio_num = self.config[""two_motors""][0][""GPIO""]
    self.setup_pwm(self.pwm_num, ""1\n"", ""0\n"", ""1000\n"", ""0\n"")
    self.setup_gpio(self.gpio_num)
    self.motor = m_mod.Motor(self.pwm_num, self.gpio_num)",9,"<NME> test_motor.py
<BEF> def setUp(self):
    """"""Setup test hardware files and build motor object.""""""

    config = path.dirname(path.realpath(__file__))+""/test_config.yaml""
    self.config = lib.get_config(config)

    # Build motor in testing mode
    self.pwm_num = self.config[""two_motors""][0][""PWM""]
    self.gpio_num = config.config[""two_motors""][0][""GPIO""]
    self.setup_pwm(self.pwm_num, ""1\n"", ""0\n"", ""1000\n"", ""0\n"")
    self.setup_gpio(self.gpio_num)
    self.motor = m_mod.Motor(self.pwm_num, self.gpio_num)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def setUp(self):
    """"""Setup test hardware files and build motor object.""""""

    config = path.dirname(path.realpath(__file__))+""/test_config.yaml""
    self.config = lib.get_config(config)

    # Build motor in testing mode
    self.pwm_num = self.config[""two_motors""][0][""PWM""]
    self.gpio_num = config.config[""two_motors""][0][""GPIO""]
    self.setup_pwm(self.pwm_num, ""1\n"", ""0\n"", ""1000\n"", ""0\n"")
    self.setup_gpio(self.gpio_num)
    self.motor = m_mod.Motor(self.pwm_num, self.gpio_num)"
"<NME> tcp.py
<BEF> def __init__(self, peer):
    if _debug: TCPClient._debug(""__init__ %r"", peer)
    asyncore.dispatcher.__init__(self)

    # ask the dispatcher for a socket
    self.create_socket(socket.AF_INET, socket.SOCK_STREAM)

    # save the peer
    self.peer = peer

    # create a request buffer
    self.request = ''

    # hold the socket error if there was one
    peer.socketError = None

    # try to connect the socket
    if _debug: TCPClient._debug(""    - try to connect"")
    self.connect(peer)
    if _debug: TCPClient._debug(""    - connected (maybe)"")
<MSG> Fix incorrect variable name
<DFF> @@ -12,7 +12,7 @@
     self.request = ''
 
     # hold the socket error if there was one
-    peer.socketError = None
+    self.socketError = None
 
     # try to connect the socket
     if _debug: TCPClient._debug(""    - try to connect"")","def __init__(self, peer):
    if _debug: TCPClient._debug(""__init__ %r"", peer)
    asyncore.dispatcher.__init__(self)

    # ask the dispatcher for a socket
    self.create_socket(socket.AF_INET, socket.SOCK_STREAM)

    # save the peer
    self.peer = peer

    # create a request buffer
    self.request = ''

    # hold the socket error if there was one
    self.socketError = None

    # try to connect the socket
    if _debug: TCPClient._debug(""    - try to connect"")
    self.connect(peer)
    if _debug: TCPClient._debug(""    - connected (maybe)"")",0,"<NME> tcp.py
<BEF> def __init__(self, peer):
    if _debug: TCPClient._debug(""__init__ %r"", peer)
    asyncore.dispatcher.__init__(self)

    # ask the dispatcher for a socket
    self.create_socket(socket.AF_INET, socket.SOCK_STREAM)

    # save the peer
    self.peer = peer

    # create a request buffer
    self.request = ''

    # hold the socket error if there was one
    peer.socketError = None

    # try to connect the socket
    if _debug: TCPClient._debug(""    - try to connect"")
    self.connect(peer)
    if _debug: TCPClient._debug(""    - connected (maybe)"")
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, peer):
    if _debug: TCPClient._debug(""__init__ %r"", peer)
    asyncore.dispatcher.__init__(self)

    # ask the dispatcher for a socket
    self.create_socket(socket.AF_INET, socket.SOCK_STREAM)

    # save the peer
    self.peer = peer

    # create a request buffer
    self.request = ''

    # hold the socket error if there was one
    peer.socketError = None

    # try to connect the socket
    if _debug: TCPClient._debug(""    - try to connect"")
    self.connect(peer)
    if _debug: TCPClient._debug(""    - connected (maybe)"")"
"<NME> schema.py
<BEF> def merge(a, b, path=None):
    ""merges b into a""

    if path is None: path = []
    for key in b:
        if key in a:
            if isinstance(a[key], dict) and isinstance(b[key], dict):
                merge(a[key], b[a], path + [str(key)])
            elif a[key] == b[key]:
                pass # same leaf value
            else:
                a[key] = b[key]  # prefer b to a
        else:
            a[key] = b[key]
    return a
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
     for key in b:
         if key in a:
             if isinstance(a[key], dict) and isinstance(b[key], dict):
-                merge(a[key], b[a], path + [str(key)])
+                merge(a[key], b[key], path + [str(key)])
             elif a[key] == b[key]:
                 pass # same leaf value
             else:","def merge(a, b, path=None):
    ""merges b into a""

    if path is None: path = []
    for key in b:
        if key in a:
            if isinstance(a[key], dict) and isinstance(b[key], dict):
                merge(a[key], b[key], path + [str(key)])
            elif a[key] == b[key]:
                pass # same leaf value
            else:
                a[key] = b[key]  # prefer b to a
        else:
            a[key] = b[key]
    return a",1,"<NME> schema.py
<BEF> def merge(a, b, path=None):
    ""merges b into a""

    if path is None: path = []
    for key in b:
        if key in a:
            if isinstance(a[key], dict) and isinstance(b[key], dict):
                merge(a[key], b[a], path + [str(key)])
            elif a[key] == b[key]:
                pass # same leaf value
            else:
                a[key] = b[key]  # prefer b to a
        else:
            a[key] = b[key]
    return a
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def merge(a, b, path=None):
    ""merges b into a""

    if path is None: path = []
    for key in b:
        if key in a:
            if isinstance(a[key], dict) and isinstance(b[key], dict):
                merge(a[key], b[a], path + [str(key)])
            elif a[key] == b[key]:
                pass # same leaf value
            else:
                a[key] = b[key]  # prefer b to a
        else:
            a[key] = b[key]
    return a"
"<NME> condent.py
<BEF> def container_literal(
    before, left_delimiter, items, right_delimiter, trailing_comma=True,
):
    before = _clean_before(before)
    items = list(items)

    c = _single_line_container(before, left_delimiter, items, right_delimiter)
    if len(c) <= 79:
        return c

    return _multi_line_container(
        before, left_delimiter, items, before, trailing_comma,
    )
<MSG> Fix incorrect variable name
<DFF> @@ -9,5 +9,5 @@
         return c
 
     return _multi_line_container(
-        before, left_delimiter, items, before, trailing_comma,
+        before, left_delimiter, items, right_delimiter, trailing_comma,
     )","def container_literal(
    before, left_delimiter, items, right_delimiter, trailing_comma=True,
):
    before = _clean_before(before)
    items = list(items)

    c = _single_line_container(before, left_delimiter, items, right_delimiter)
    if len(c) <= 79:
        return c

    return _multi_line_container(
        before, left_delimiter, items, right_delimiter, trailing_comma,
    )",2,"<NME> condent.py
<BEF> def container_literal(
    before, left_delimiter, items, right_delimiter, trailing_comma=True,
):
    before = _clean_before(before)
    items = list(items)

    c = _single_line_container(before, left_delimiter, items, right_delimiter)
    if len(c) <= 79:
        return c

    return _multi_line_container(
        before, left_delimiter, items, before, trailing_comma,
    )
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def container_literal(
    before, left_delimiter, items, right_delimiter, trailing_comma=True,
):
    before = _clean_before(before)
    items = list(items)

    c = _single_line_container(before, left_delimiter, items, right_delimiter)
    if len(c) <= 79:
        return c

    return _multi_line_container(
        before, left_delimiter, items, before, trailing_comma,
    )"
"<NME> pdu.py
<BEF> def update(self, pci):
    """"""Copy the PCI fields.""""""
    _PCI.update(self, pci)

    # now do the BACnet PCI fields
    self.pduExpectingReply = pci.pduExpectingReply
    self.pduNetworkPriority = self.pduNetworkPriority
<MSG> Fix incorrect variable name
<DFF> @@ -4,4 +4,4 @@
 
     # now do the BACnet PCI fields
     self.pduExpectingReply = pci.pduExpectingReply
-    self.pduNetworkPriority = self.pduNetworkPriority
+    self.pduNetworkPriority = pci.pduNetworkPriority","def update(self, pci):
    """"""Copy the PCI fields.""""""
    _PCI.update(self, pci)

    # now do the BACnet PCI fields
    self.pduExpectingReply = pci.pduExpectingReply
    self.pduNetworkPriority = pci.pduNetworkPriority",3,"<NME> pdu.py
<BEF> def update(self, pci):
    """"""Copy the PCI fields.""""""
    _PCI.update(self, pci)

    # now do the BACnet PCI fields
    self.pduExpectingReply = pci.pduExpectingReply
    self.pduNetworkPriority = self.pduNetworkPriority
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def update(self, pci):
    """"""Copy the PCI fields.""""""
    _PCI.update(self, pci)

    # now do the BACnet PCI fields
    self.pduExpectingReply = pci.pduExpectingReply
    self.pduNetworkPriority = self.pduNetworkPriority"
"<NME> test_requests_auth.py
<BEF> def _call(rel, jwt=None, data=None):
    rel = 'http://localhost:5000/api/' + rel
    if jwt:
        if data:
            result = requests.post(rel, headers=_auth_header(jwt), data=json.dumps(data))
        else:
            result = requests.get(rel, headers=_auth_header(jwt))
    else:
        if data:
            result = requests.post(rel, data=json.dumps(result))
        else:
            result = requests.get(rel)

    return result
<MSG> Fix incorrect variable name
<DFF> @@ -7,7 +7,7 @@
             result = requests.get(rel, headers=_auth_header(jwt))
     else:
         if data:
-            result = requests.post(rel, data=json.dumps(result))
+            result = requests.post(rel, data=json.dumps(data))
         else:
             result = requests.get(rel)
 ","def _call(rel, jwt=None, data=None):
    rel = 'http://localhost:5000/api/' + rel
    if jwt:
        if data:
            result = requests.post(rel, headers=_auth_header(jwt), data=json.dumps(data))
        else:
            result = requests.get(rel, headers=_auth_header(jwt))
    else:
        if data:
            result = requests.post(rel, data=json.dumps(data))
        else:
            result = requests.get(rel)

    return result",4,"<NME> test_requests_auth.py
<BEF> def _call(rel, jwt=None, data=None):
    rel = 'http://localhost:5000/api/' + rel
    if jwt:
        if data:
            result = requests.post(rel, headers=_auth_header(jwt), data=json.dumps(data))
        else:
            result = requests.get(rel, headers=_auth_header(jwt))
    else:
        if data:
            result = requests.post(rel, data=json.dumps(result))
        else:
            result = requests.get(rel)

    return result
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _call(rel, jwt=None, data=None):
    rel = 'http://localhost:5000/api/' + rel
    if jwt:
        if data:
            result = requests.post(rel, headers=_auth_header(jwt), data=json.dumps(data))
        else:
            result = requests.get(rel, headers=_auth_header(jwt))
    else:
        if data:
            result = requests.post(rel, data=json.dumps(result))
        else:
            result = requests.get(rel)

    return result"
"<NME> Sublime
<BEF> def restore_selections(view, lines_and_pts):
    view.sel().clear()

    for stored in lines_and_pts:
        view.sel().add(region_from_stored_selection(stored, stored))
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     view.sel().clear()
 
     for stored in lines_and_pts:
-        view.sel().add(region_from_stored_selection(stored, stored))
+        view.sel().add(region_from_stored_selection(view, stored))","def restore_selections(view, lines_and_pts):
    view.sel().clear()

    for stored in lines_and_pts:
        view.sel().add(region_from_stored_selection(view, stored))",5,"<NME> Sublime
<BEF> def restore_selections(view, lines_and_pts):
    view.sel().clear()

    for stored in lines_and_pts:
        view.sel().add(region_from_stored_selection(stored, stored))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def restore_selections(view, lines_and_pts):
    view.sel().clear()

    for stored in lines_and_pts:
        view.sel().add(region_from_stored_selection(stored, stored))"
"<NME> appservice.py
<BEF> def append_segment(self, apdu):
    """"""This function appends the apdu content to the end of the current
    APDU being built.  The segmentAPDU is the context.""""""
    if _debug: SSM._debug(""append_segment %r"", apdu)

    # check for no context
    if not apdu.segmentAPDU:
        raise RuntimeError(""no segmentation context established"")

    # append the data
    self.segmentAPDU.put_data(apdu.pduData)
<MSG> Fix incorrect variable name
<DFF> @@ -4,7 +4,7 @@
     if _debug: SSM._debug(""append_segment %r"", apdu)
 
     # check for no context
-    if not apdu.segmentAPDU:
+    if not self.segmentAPDU:
         raise RuntimeError(""no segmentation context established"")
 
     # append the data","def append_segment(self, apdu):
    """"""This function appends the apdu content to the end of the current
    APDU being built.  The segmentAPDU is the context.""""""
    if _debug: SSM._debug(""append_segment %r"", apdu)

    # check for no context
    if not self.segmentAPDU:
        raise RuntimeError(""no segmentation context established"")

    # append the data
    self.segmentAPDU.put_data(apdu.pduData)",6,"<NME> appservice.py
<BEF> def append_segment(self, apdu):
    """"""This function appends the apdu content to the end of the current
    APDU being built.  The segmentAPDU is the context.""""""
    if _debug: SSM._debug(""append_segment %r"", apdu)

    # check for no context
    if not apdu.segmentAPDU:
        raise RuntimeError(""no segmentation context established"")

    # append the data
    self.segmentAPDU.put_data(apdu.pduData)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def append_segment(self, apdu):
    """"""This function appends the apdu content to the end of the current
    APDU being built.  The segmentAPDU is the context.""""""
    if _debug: SSM._debug(""append_segment %r"", apdu)

    # check for no context
    if not apdu.segmentAPDU:
        raise RuntimeError(""no segmentation context established"")

    # append the data
    self.segmentAPDU.put_data(apdu.pduData)"
"<NME> gui.py
<BEF> def _find_images(self, local_dir=None):
    if local_dir is None:
        self = self.settings.local_images
    return _list_files_recursively(local_dir, relative_to_path=True)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def _find_images(self, local_dir=None):
     if local_dir is None:
-        self = self.settings.local_images
+        local_dir = self.settings.local_images
     return _list_files_recursively(local_dir, relative_to_path=True)","def _find_images(self, local_dir=None):
    if local_dir is None:
        local_dir = self.settings.local_images
    return _list_files_recursively(local_dir, relative_to_path=True)",7,"<NME> gui.py
<BEF> def _find_images(self, local_dir=None):
    if local_dir is None:
        self = self.settings.local_images
    return _list_files_recursively(local_dir, relative_to_path=True)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _find_images(self, local_dir=None):
    if local_dir is None:
        self = self.settings.local_images
    return _list_files_recursively(local_dir, relative_to_path=True)"
"<NME> bsll.py
<BEF> def encode(self, bslpdu):
    addrLen = bslpdu.bslciAddress.addrLen

    # make sure the length is correct
    self.bslciLength = 5 + addrLen + len(self.pduData)

    BSLCI.update(bslpdu, self)

    # encode the address
    bslpdu.put(addrLen)
    bslpdu.put_data( self.bslciAddress.addrAddr )

    # encode the rest of the data
    bslpdu.put_data( self.pduData )
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def encode(self, bslpdu):
-    addrLen = bslpdu.bslciAddress.addrLen
+    addrLen = self.bslciAddress.addrLen
 
     # make sure the length is correct
     self.bslciLength = 5 + addrLen + len(self.pduData)","def encode(self, bslpdu):
    addrLen = self.bslciAddress.addrLen

    # make sure the length is correct
    self.bslciLength = 5 + addrLen + len(self.pduData)

    BSLCI.update(bslpdu, self)

    # encode the address
    bslpdu.put(addrLen)
    bslpdu.put_data( self.bslciAddress.addrAddr )

    # encode the rest of the data
    bslpdu.put_data( self.pduData )",8,"<NME> bsll.py
<BEF> def encode(self, bslpdu):
    addrLen = bslpdu.bslciAddress.addrLen

    # make sure the length is correct
    self.bslciLength = 5 + addrLen + len(self.pduData)

    BSLCI.update(bslpdu, self)

    # encode the address
    bslpdu.put(addrLen)
    bslpdu.put_data( self.bslciAddress.addrAddr )

    # encode the rest of the data
    bslpdu.put_data( self.pduData )
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def encode(self, bslpdu):
    addrLen = bslpdu.bslciAddress.addrLen

    # make sure the length is correct
    self.bslciLength = 5 + addrLen + len(self.pduData)

    BSLCI.update(bslpdu, self)

    # encode the address
    bslpdu.put(addrLen)
    bslpdu.put_data( self.bslciAddress.addrAddr )

    # encode the rest of the data
    bslpdu.put_data( self.pduData )"
"<NME> kickflip_cli.py
<BEF> def load_or_create_user(username):
    resources.init('Kickflip', 'Kickflip')
    config_json = resources.user.read('config.json')
    if not config_json:
        resources.user.write('config.json', json.dumps({}, sort_keys=True))
        config_json = resources.user.read('config.json')

    settings = json.loads(config_json)

    if not settings.has_key('username'):
        settings['username'] = username
        resources.user.write('config.json', json.dumps(settings, sort_keys=True))
    if not settings.has_key('user_access_key'):
        user = kickflip.create_user(username)
        settings['username'] = user['name']
        settings['user_access_key'] = user['aws_access_key']
        settings['user_secret_access_key'] = user['aws_secret_key']
        settings['user_uuid'] = user['uuid']
        resources.user.write('config.json', json.dumps(settings, sort_keys=True))

    kickflip.set_aws_keys(settings['username'], settings['user_access_key'], settings['user_secret_access_key'])
    kickflip.set_uuid(settings['user_uuid'])

    return settings['username'], username['user_uuid'], settings['user_access_key'], settings['user_secret_access_key']
<MSG> Fix incorrect variable name
<DFF> @@ -21,4 +21,4 @@
     kickflip.set_aws_keys(settings['username'], settings['user_access_key'], settings['user_secret_access_key'])
     kickflip.set_uuid(settings['user_uuid'])
 
-    return settings['username'], username['user_uuid'], settings['user_access_key'], settings['user_secret_access_key']
+    return settings['username'], settings['user_uuid'], settings['user_access_key'], settings['user_secret_access_key']","def load_or_create_user(username):
    resources.init('Kickflip', 'Kickflip')
    config_json = resources.user.read('config.json')
    if not config_json:
        resources.user.write('config.json', json.dumps({}, sort_keys=True))
        config_json = resources.user.read('config.json')

    settings = json.loads(config_json)

    if not settings.has_key('username'):
        settings['username'] = username
        resources.user.write('config.json', json.dumps(settings, sort_keys=True))
    if not settings.has_key('user_access_key'):
        user = kickflip.create_user(username)
        settings['username'] = user['name']
        settings['user_access_key'] = user['aws_access_key']
        settings['user_secret_access_key'] = user['aws_secret_key']
        settings['user_uuid'] = user['uuid']
        resources.user.write('config.json', json.dumps(settings, sort_keys=True))

    kickflip.set_aws_keys(settings['username'], settings['user_access_key'], settings['user_secret_access_key'])
    kickflip.set_uuid(settings['user_uuid'])

    return settings['username'], settings['user_uuid'], settings['user_access_key'], settings['user_secret_access_key']",9,"<NME> kickflip_cli.py
<BEF> def load_or_create_user(username):
    resources.init('Kickflip', 'Kickflip')
    config_json = resources.user.read('config.json')
    if not config_json:
        resources.user.write('config.json', json.dumps({}, sort_keys=True))
        config_json = resources.user.read('config.json')

    settings = json.loads(config_json)

    if not settings.has_key('username'):
        settings['username'] = username
        resources.user.write('config.json', json.dumps(settings, sort_keys=True))
    if not settings.has_key('user_access_key'):
        user = kickflip.create_user(username)
        settings['username'] = user['name']
        settings['user_access_key'] = user['aws_access_key']
        settings['user_secret_access_key'] = user['aws_secret_key']
        settings['user_uuid'] = user['uuid']
        resources.user.write('config.json', json.dumps(settings, sort_keys=True))

    kickflip.set_aws_keys(settings['username'], settings['user_access_key'], settings['user_secret_access_key'])
    kickflip.set_uuid(settings['user_uuid'])

    return settings['username'], username['user_uuid'], settings['user_access_key'], settings['user_secret_access_key']
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def load_or_create_user(username):
    resources.init('Kickflip', 'Kickflip')
    config_json = resources.user.read('config.json')
    if not config_json:
        resources.user.write('config.json', json.dumps({}, sort_keys=True))
        config_json = resources.user.read('config.json')

    settings = json.loads(config_json)

    if not settings.has_key('username'):
        settings['username'] = username
        resources.user.write('config.json', json.dumps(settings, sort_keys=True))
    if not settings.has_key('user_access_key'):
        user = kickflip.create_user(username)
        settings['username'] = user['name']
        settings['user_access_key'] = user['aws_access_key']
        settings['user_secret_access_key'] = user['aws_secret_key']
        settings['user_uuid'] = user['uuid']
        resources.user.write('config.json', json.dumps(settings, sort_keys=True))

    kickflip.set_aws_keys(settings['username'], settings['user_access_key'], settings['user_secret_access_key'])
    kickflip.set_uuid(settings['user_uuid'])

    return settings['username'], username['user_uuid'], settings['user_access_key'], settings['user_secret_access_key']"
"<NME> test_scope_detector.py
<BEF> def test_is_builtin_variable(id_value, is_function, expected_result):
    id_node = create_id(id_value, is_function=is_function)
    result = is_builtin_variable(is_function)

    assert expected_result == result
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def test_is_builtin_variable(id_value, is_function, expected_result):
     id_node = create_id(id_value, is_function=is_function)
-    result = is_builtin_variable(is_function)
+    result = is_builtin_variable(id_node)
 
     assert expected_result == result","def test_is_builtin_variable(id_value, is_function, expected_result):
    id_node = create_id(id_value, is_function=is_function)
    result = is_builtin_variable(id_node)

    assert expected_result == result",0,"<NME> test_scope_detector.py
<BEF> def test_is_builtin_variable(id_value, is_function, expected_result):
    id_node = create_id(id_value, is_function=is_function)
    result = is_builtin_variable(is_function)

    assert expected_result == result
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_is_builtin_variable(id_value, is_function, expected_result):
    id_node = create_id(id_value, is_function=is_function)
    result = is_builtin_variable(is_function)

    assert expected_result == result"
"<NME> gui.py
<BEF> @cherrypy.expose
def template(self, *paths, **_ignored):
    template_name = '/'.join(paths)
    template_path = os.path.join(self.settings.templates, template_name)
    if os.path.isdir(template_path):
        return self.edit_renderer.directory(
            'Contents of ' + (template_name or 'template directory'),
            self.settings.templates, template_name,
            '/template/{}'.format,
            (lambda path: os.path.isdir(path) or '.htm' in path.lower())
        )
    else:  # A file
        document = _extract_document({}, template_name=template_name)
        if not document.template_name:
            raise cherrypy.HTTPRedirect('/timeout')
        return self.edit_renderer.render_editor(
            document.template_name,
            document.styles,
            actions=self._actions(document, **{TEMPLATE_PARAM_NAME: paths}),
        )
<MSG> Fix incorrect variable name
<DFF> @@ -16,5 +16,5 @@
         return self.edit_renderer.render_editor(
             document.template_name,
             document.styles,
-            actions=self._actions(document, **{TEMPLATE_PARAM_NAME: paths}),
+            actions=self._actions(document, **{TEMPLATE_PARAM_NAME: template_name}),
         )","@cherrypy.expose
def template(self, *paths, **_ignored):
    template_name = '/'.join(paths)
    template_path = os.path.join(self.settings.templates, template_name)
    if os.path.isdir(template_path):
        return self.edit_renderer.directory(
            'Contents of ' + (template_name or 'template directory'),
            self.settings.templates, template_name,
            '/template/{}'.format,
            (lambda path: os.path.isdir(path) or '.htm' in path.lower())
        )
    else:  # A file
        document = _extract_document({}, template_name=template_name)
        if not document.template_name:
            raise cherrypy.HTTPRedirect('/timeout')
        return self.edit_renderer.render_editor(
            document.template_name,
            document.styles,
            actions=self._actions(document, **{TEMPLATE_PARAM_NAME: template_name}),
        )",1,"<NME> gui.py
<BEF> @cherrypy.expose
def template(self, *paths, **_ignored):
    template_name = '/'.join(paths)
    template_path = os.path.join(self.settings.templates, template_name)
    if os.path.isdir(template_path):
        return self.edit_renderer.directory(
            'Contents of ' + (template_name or 'template directory'),
            self.settings.templates, template_name,
            '/template/{}'.format,
            (lambda path: os.path.isdir(path) or '.htm' in path.lower())
        )
    else:  # A file
        document = _extract_document({}, template_name=template_name)
        if not document.template_name:
            raise cherrypy.HTTPRedirect('/timeout')
        return self.edit_renderer.render_editor(
            document.template_name,
            document.styles,
            actions=self._actions(document, **{TEMPLATE_PARAM_NAME: paths}),
        )
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@cherrypy.expose
def template(self, *paths, **_ignored):
    template_name = '/'.join(paths)
    template_path = os.path.join(self.settings.templates, template_name)
    if os.path.isdir(template_path):
        return self.edit_renderer.directory(
            'Contents of ' + (template_name or 'template directory'),
            self.settings.templates, template_name,
            '/template/{}'.format,
            (lambda path: os.path.isdir(path) or '.htm' in path.lower())
        )
    else:  # A file
        document = _extract_document({}, template_name=template_name)
        if not document.template_name:
            raise cherrypy.HTTPRedirect('/timeout')
        return self.edit_renderer.render_editor(
            document.template_name,
            document.styles,
            actions=self._actions(document, **{TEMPLATE_PARAM_NAME: paths}),
        )"
"<NME> test_twitch_notifier.py
<BEF> def set_live_channel_list(self, ch_list):
    # swapcase to simulate display name does not necessary have the same
    # case as input
    for ch in ch_list:
        self.live_ch_list[ch.swapcase()] = ch_list[ch_list]
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     # swapcase to simulate display name does not necessary have the same
     # case as input
     for ch in ch_list:
-        self.live_ch_list[ch.swapcase()] = ch_list[ch_list]
+        self.live_ch_list[ch.swapcase()] = ch_list[ch]","def set_live_channel_list(self, ch_list):
    # swapcase to simulate display name does not necessary have the same
    # case as input
    for ch in ch_list:
        self.live_ch_list[ch.swapcase()] = ch_list[ch]",2,"<NME> test_twitch_notifier.py
<BEF> def set_live_channel_list(self, ch_list):
    # swapcase to simulate display name does not necessary have the same
    # case as input
    for ch in ch_list:
        self.live_ch_list[ch.swapcase()] = ch_list[ch_list]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def set_live_channel_list(self, ch_list):
    # swapcase to simulate display name does not necessary have the same
    # case as input
    for ch in ch_list:
        self.live_ch_list[ch.swapcase()] = ch_list[ch_list]"
"<NME> window.py
<BEF> @pyqtSlot(bool)
def setEnabled(self, enabled):
	super(Window, enabled).setEnabled(enabled)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 @pyqtSlot(bool)
 def setEnabled(self, enabled):
-	super(Window, enabled).setEnabled(enabled)
+	super(Window, self).setEnabled(enabled)","@pyqtSlot(bool)
def setEnabled(self, enabled):
	super(Window, self).setEnabled(enabled)",3,"<NME> window.py
<BEF> @pyqtSlot(bool)
def setEnabled(self, enabled):
	super(Window, enabled).setEnabled(enabled)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@pyqtSlot(bool)
def setEnabled(self, enabled):
	super(Window, enabled).setEnabled(enabled)"
"<NME> window.py
<BEF> def testWindowFlags(self, windowFlags):
	return windowFlags.windowFlags() & windowFlags
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def testWindowFlags(self, windowFlags):
-	return windowFlags.windowFlags() & windowFlags
+	return self.windowFlags() & windowFlags","def testWindowFlags(self, windowFlags):
	return self.windowFlags() & windowFlags",4,"<NME> window.py
<BEF> def testWindowFlags(self, windowFlags):
	return windowFlags.windowFlags() & windowFlags
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testWindowFlags(self, windowFlags):
	return windowFlags.windowFlags() & windowFlags"
"<NME> test_brokers.py
<BEF> @pytest.mark.django_db
def test_orm():
    Conf.ORM = 'default'
    # check broker
    broker = get_broker(list_key='orm_test')
    assert broker.ping() is True
    assert broker.info() is not None
    # clear before we start
    broker.delete_queue()
    # enqueue
    broker.enqueue('test')
    assert broker.queue_size() == 1
    # dequeue
    task = broker.dequeue()[0]
    assert task[1] == 'test'
    broker.acknowledge(task[0])
    assert broker.queue_size() == 0
    # Retry test
    Conf.RETRY = 1
    broker.enqueue('test')
    assert broker.queue_size() == 1
    broker.dequeue()
    assert broker.queue_size() == 0
    sleep(1.5)
    assert broker.queue_size() == 1
    task = broker.dequeue()[0]
    assert broker.queue_size() == 0
    broker.acknowledge(task[0])
    sleep(1.5)
    assert broker.queue_size() == 0
    # delete job
    task_id = broker.enqueue('test')
    broker.delete(task_id)
    assert broker.dequeue() is None
    # fail
    task_id = broker.enqueue('test')
    broker.fail(task_id)
    # bulk test
    for i in range(5):
        broker.enqueue('test')
    Conf.BULK = 5
    tasks = broker.dequeue()
    assert broker.lock_size() == Conf.BULK
    for task in tasks:
        assert task_id is not None
        broker.acknowledge(task[0])
    # test lock size
    assert broker.lock_size() == 0
    # test duplicate acknowledge
    broker.acknowledge(task[0])
    # delete queue
    broker.enqueue('test')
    broker.enqueue('test')
    broker.delete_queue()
    assert broker.queue_size() == 0
    # back to django-redis
    Conf.ORM = None
<MSG> Fix incorrect variable name
<DFF> @@ -42,7 +42,7 @@
     tasks = broker.dequeue()
     assert broker.lock_size() == Conf.BULK
     for task in tasks:
-        assert task_id is not None
+        assert task is not None
         broker.acknowledge(task[0])
     # test lock size
     assert broker.lock_size() == 0","@pytest.mark.django_db
def test_orm():
    Conf.ORM = 'default'
    # check broker
    broker = get_broker(list_key='orm_test')
    assert broker.ping() is True
    assert broker.info() is not None
    # clear before we start
    broker.delete_queue()
    # enqueue
    broker.enqueue('test')
    assert broker.queue_size() == 1
    # dequeue
    task = broker.dequeue()[0]
    assert task[1] == 'test'
    broker.acknowledge(task[0])
    assert broker.queue_size() == 0
    # Retry test
    Conf.RETRY = 1
    broker.enqueue('test')
    assert broker.queue_size() == 1
    broker.dequeue()
    assert broker.queue_size() == 0
    sleep(1.5)
    assert broker.queue_size() == 1
    task = broker.dequeue()[0]
    assert broker.queue_size() == 0
    broker.acknowledge(task[0])
    sleep(1.5)
    assert broker.queue_size() == 0
    # delete job
    task_id = broker.enqueue('test')
    broker.delete(task_id)
    assert broker.dequeue() is None
    # fail
    task_id = broker.enqueue('test')
    broker.fail(task_id)
    # bulk test
    for i in range(5):
        broker.enqueue('test')
    Conf.BULK = 5
    tasks = broker.dequeue()
    assert broker.lock_size() == Conf.BULK
    for task in tasks:
        assert task is not None
        broker.acknowledge(task[0])
    # test lock size
    assert broker.lock_size() == 0
    # test duplicate acknowledge
    broker.acknowledge(task[0])
    # delete queue
    broker.enqueue('test')
    broker.enqueue('test')
    broker.delete_queue()
    assert broker.queue_size() == 0
    # back to django-redis
    Conf.ORM = None",5,"<NME> test_brokers.py
<BEF> @pytest.mark.django_db
def test_orm():
    Conf.ORM = 'default'
    # check broker
    broker = get_broker(list_key='orm_test')
    assert broker.ping() is True
    assert broker.info() is not None
    # clear before we start
    broker.delete_queue()
    # enqueue
    broker.enqueue('test')
    assert broker.queue_size() == 1
    # dequeue
    task = broker.dequeue()[0]
    assert task[1] == 'test'
    broker.acknowledge(task[0])
    assert broker.queue_size() == 0
    # Retry test
    Conf.RETRY = 1
    broker.enqueue('test')
    assert broker.queue_size() == 1
    broker.dequeue()
    assert broker.queue_size() == 0
    sleep(1.5)
    assert broker.queue_size() == 1
    task = broker.dequeue()[0]
    assert broker.queue_size() == 0
    broker.acknowledge(task[0])
    sleep(1.5)
    assert broker.queue_size() == 0
    # delete job
    task_id = broker.enqueue('test')
    broker.delete(task_id)
    assert broker.dequeue() is None
    # fail
    task_id = broker.enqueue('test')
    broker.fail(task_id)
    # bulk test
    for i in range(5):
        broker.enqueue('test')
    Conf.BULK = 5
    tasks = broker.dequeue()
    assert broker.lock_size() == Conf.BULK
    for task in tasks:
        assert task_id is not None
        broker.acknowledge(task[0])
    # test lock size
    assert broker.lock_size() == 0
    # test duplicate acknowledge
    broker.acknowledge(task[0])
    # delete queue
    broker.enqueue('test')
    broker.enqueue('test')
    broker.delete_queue()
    assert broker.queue_size() == 0
    # back to django-redis
    Conf.ORM = None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@pytest.mark.django_db
def test_orm():
    Conf.ORM = 'default'
    # check broker
    broker = get_broker(list_key='orm_test')
    assert broker.ping() is True
    assert broker.info() is not None
    # clear before we start
    broker.delete_queue()
    # enqueue
    broker.enqueue('test')
    assert broker.queue_size() == 1
    # dequeue
    task = broker.dequeue()[0]
    assert task[1] == 'test'
    broker.acknowledge(task[0])
    assert broker.queue_size() == 0
    # Retry test
    Conf.RETRY = 1
    broker.enqueue('test')
    assert broker.queue_size() == 1
    broker.dequeue()
    assert broker.queue_size() == 0
    sleep(1.5)
    assert broker.queue_size() == 1
    task = broker.dequeue()[0]
    assert broker.queue_size() == 0
    broker.acknowledge(task[0])
    sleep(1.5)
    assert broker.queue_size() == 0
    # delete job
    task_id = broker.enqueue('test')
    broker.delete(task_id)
    assert broker.dequeue() is None
    # fail
    task_id = broker.enqueue('test')
    broker.fail(task_id)
    # bulk test
    for i in range(5):
        broker.enqueue('test')
    Conf.BULK = 5
    tasks = broker.dequeue()
    assert broker.lock_size() == Conf.BULK
    for task in tasks:
        assert task_id is not None
        broker.acknowledge(task[0])
    # test lock size
    assert broker.lock_size() == 0
    # test duplicate acknowledge
    broker.acknowledge(task[0])
    # delete queue
    broker.enqueue('test')
    broker.enqueue('test')
    broker.delete_queue()
    assert broker.queue_size() == 0
    # back to django-redis
    Conf.ORM = None"
"<NME> ivy_ast.py
<BEF> def __init__(self, bounds, body):
    bounds.bounds = bounds
    self.args = [body]
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def __init__(self, bounds, body):
-    bounds.bounds = bounds
+    self.bounds = bounds
     self.args = [body]","def __init__(self, bounds, body):
    self.bounds = bounds
    self.args = [body]",6,"<NME> ivy_ast.py
<BEF> def __init__(self, bounds, body):
    bounds.bounds = bounds
    self.args = [body]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, bounds, body):
    bounds.bounds = bounds
    self.args = [body]"
"<NME> ivy_actions.py
<BEF> def __init__(self,*args):
    assert all(isinstance(self,UpdatePattern) for a in args)
    self.args = args
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def __init__(self,*args):
-    assert all(isinstance(self,UpdatePattern) for a in args)
+    assert all(isinstance(a,UpdatePattern) for a in args)
     self.args = args","def __init__(self,*args):
    assert all(isinstance(a,UpdatePattern) for a in args)
    self.args = args",7,"<NME> ivy_actions.py
<BEF> def __init__(self,*args):
    assert all(isinstance(self,UpdatePattern) for a in args)
    self.args = args
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self,*args):
    assert all(isinstance(self,UpdatePattern) for a in args)
    self.args = args"
"<NME> appservice.py
<BEF> def segmented_response(self, apdu):
    if _debug: ServerSSM._debug(""segmented_response %r"", apdu)

    # client is ready for the next segment
    if (apdu.apduType == SegmentAckPDU.pduType):
        if _debug: ServerSSM._debug(""    - segment ack"")

        # duplicate ack received?
        if not self.in_window(apdu.apduSeq, self.initialSequenceNumber):
            if _debug: ServerSSM._debug(""    - not in window"")
            self.restart_timer(self.ssmSAP.segmentTimeout)

        # final ack received?
        elif self.sentAllSegments:
            if _debug: ServerSSM._debug(""    - all done sending response"")
            self.set_state(COMPLETED)

        else:
            if _debug: ServerSSM._debug(""    - more segments to send"")

            apdu.initialSequenceNumber = (apdu.apduSeq + 1) % 256
            self.actualWindowSize = apdu.apduWin
            self.segmentRetryCount = 0
            self.FillWindow(self.initialSequenceNumber)
            self.restart_timer(self.ssmSAP.segmentTimeout)

    # some kind of problem
    elif (apdu.apduType == AbortPDU.pduType):
        self.set_state(COMPLETED)
        self.response(apdu)

    else:
        raise RuntimeError(""invalid APDU (7)"")
<MSG> Fix incorrect variable name
<DFF> @@ -18,7 +18,7 @@
         else:
             if _debug: ServerSSM._debug(""    - more segments to send"")
 
-            apdu.initialSequenceNumber = (apdu.apduSeq + 1) % 256
+            self.initialSequenceNumber = (apdu.apduSeq + 1) % 256
             self.actualWindowSize = apdu.apduWin
             self.segmentRetryCount = 0
             self.FillWindow(self.initialSequenceNumber)","def segmented_response(self, apdu):
    if _debug: ServerSSM._debug(""segmented_response %r"", apdu)

    # client is ready for the next segment
    if (apdu.apduType == SegmentAckPDU.pduType):
        if _debug: ServerSSM._debug(""    - segment ack"")

        # duplicate ack received?
        if not self.in_window(apdu.apduSeq, self.initialSequenceNumber):
            if _debug: ServerSSM._debug(""    - not in window"")
            self.restart_timer(self.ssmSAP.segmentTimeout)

        # final ack received?
        elif self.sentAllSegments:
            if _debug: ServerSSM._debug(""    - all done sending response"")
            self.set_state(COMPLETED)

        else:
            if _debug: ServerSSM._debug(""    - more segments to send"")

            self.initialSequenceNumber = (apdu.apduSeq + 1) % 256
            self.actualWindowSize = apdu.apduWin
            self.segmentRetryCount = 0
            self.FillWindow(self.initialSequenceNumber)
            self.restart_timer(self.ssmSAP.segmentTimeout)

    # some kind of problem
    elif (apdu.apduType == AbortPDU.pduType):
        self.set_state(COMPLETED)
        self.response(apdu)

    else:
        raise RuntimeError(""invalid APDU (7)"")",8,"<NME> appservice.py
<BEF> def segmented_response(self, apdu):
    if _debug: ServerSSM._debug(""segmented_response %r"", apdu)

    # client is ready for the next segment
    if (apdu.apduType == SegmentAckPDU.pduType):
        if _debug: ServerSSM._debug(""    - segment ack"")

        # duplicate ack received?
        if not self.in_window(apdu.apduSeq, self.initialSequenceNumber):
            if _debug: ServerSSM._debug(""    - not in window"")
            self.restart_timer(self.ssmSAP.segmentTimeout)

        # final ack received?
        elif self.sentAllSegments:
            if _debug: ServerSSM._debug(""    - all done sending response"")
            self.set_state(COMPLETED)

        else:
            if _debug: ServerSSM._debug(""    - more segments to send"")

            apdu.initialSequenceNumber = (apdu.apduSeq + 1) % 256
            self.actualWindowSize = apdu.apduWin
            self.segmentRetryCount = 0
            self.FillWindow(self.initialSequenceNumber)
            self.restart_timer(self.ssmSAP.segmentTimeout)

    # some kind of problem
    elif (apdu.apduType == AbortPDU.pduType):
        self.set_state(COMPLETED)
        self.response(apdu)

    else:
        raise RuntimeError(""invalid APDU (7)"")
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def segmented_response(self, apdu):
    if _debug: ServerSSM._debug(""segmented_response %r"", apdu)

    # client is ready for the next segment
    if (apdu.apduType == SegmentAckPDU.pduType):
        if _debug: ServerSSM._debug(""    - segment ack"")

        # duplicate ack received?
        if not self.in_window(apdu.apduSeq, self.initialSequenceNumber):
            if _debug: ServerSSM._debug(""    - not in window"")
            self.restart_timer(self.ssmSAP.segmentTimeout)

        # final ack received?
        elif self.sentAllSegments:
            if _debug: ServerSSM._debug(""    - all done sending response"")
            self.set_state(COMPLETED)

        else:
            if _debug: ServerSSM._debug(""    - more segments to send"")

            apdu.initialSequenceNumber = (apdu.apduSeq + 1) % 256
            self.actualWindowSize = apdu.apduWin
            self.segmentRetryCount = 0
            self.FillWindow(self.initialSequenceNumber)
            self.restart_timer(self.ssmSAP.segmentTimeout)

    # some kind of problem
    elif (apdu.apduType == AbortPDU.pduType):
        self.set_state(COMPLETED)
        self.response(apdu)

    else:
        raise RuntimeError(""invalid APDU (7)"")"
"<NME> test_endpoint.py
<BEF> def make_oauth_protected_endpoint(*args, **kwargs):
  """""" Returns a dummy API endpoint that returns True. This endpoint will be
  protected with the @oauth_scope decorator -- see that function's signature
  for a description of the parameters that may be passed. """"""
  @oauth_scope(*args, **kwargs)
  def api_endpoint(access_token, request):
    """""" A Dummy API endpoint that accepts no URL parameters.

    Always returns True.
    """"""
    return True

  return kwargs
<MSG> Fix incorrect variable name
<DFF> @@ -10,4 +10,4 @@
     """"""
     return True
 
-  return kwargs
+  return api_endpoint","def make_oauth_protected_endpoint(*args, **kwargs):
  """""" Returns a dummy API endpoint that returns True. This endpoint will be
  protected with the @oauth_scope decorator -- see that function's signature
  for a description of the parameters that may be passed. """"""
  @oauth_scope(*args, **kwargs)
  def api_endpoint(access_token, request):
    """""" A Dummy API endpoint that accepts no URL parameters.

    Always returns True.
    """"""
    return True

  return api_endpoint",9,"<NME> test_endpoint.py
<BEF> def make_oauth_protected_endpoint(*args, **kwargs):
  """""" Returns a dummy API endpoint that returns True. This endpoint will be
  protected with the @oauth_scope decorator -- see that function's signature
  for a description of the parameters that may be passed. """"""
  @oauth_scope(*args, **kwargs)
  def api_endpoint(access_token, request):
    """""" A Dummy API endpoint that accepts no URL parameters.

    Always returns True.
    """"""
    return True

  return kwargs
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def make_oauth_protected_endpoint(*args, **kwargs):
  """""" Returns a dummy API endpoint that returns True. This endpoint will be
  protected with the @oauth_scope decorator -- see that function's signature
  for a description of the parameters that may be passed. """"""
  @oauth_scope(*args, **kwargs)
  def api_endpoint(access_token, request):
    """""" A Dummy API endpoint that accepts no URL parameters.

    Always returns True.
    """"""
    return True

  return kwargs"
"<NME> interrupt_context.py
<BEF> def __enter__(self):
    self.interrupted = False
    self.original_handler = signal.getsignal(signal.SIGINT)

    def handler(signum, frame):
        self.interrupted = True

    signal.signal(signal.SIGINT, self)

    return self
<MSG> Fix incorrect variable name
<DFF> @@ -5,6 +5,6 @@
     def handler(signum, frame):
         self.interrupted = True
 
-    signal.signal(signal.SIGINT, self)
+    signal.signal(signal.SIGINT, handler)
 
     return self","def __enter__(self):
    self.interrupted = False
    self.original_handler = signal.getsignal(signal.SIGINT)

    def handler(signum, frame):
        self.interrupted = True

    signal.signal(signal.SIGINT, handler)

    return self",0,"<NME> interrupt_context.py
<BEF> def __enter__(self):
    self.interrupted = False
    self.original_handler = signal.getsignal(signal.SIGINT)

    def handler(signum, frame):
        self.interrupted = True

    signal.signal(signal.SIGINT, self)

    return self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __enter__(self):
    self.interrupted = False
    self.original_handler = signal.getsignal(signal.SIGINT)

    def handler(signum, frame):
        self.interrupted = True

    signal.signal(signal.SIGINT, self)

    return self"
"<NME> ntlm_client.py
<BEF> def make_ntlm_negotiate(self):
    msg =  'NTLMSSP\x00'    # Signature
    msg += pack('<I', 1)    # Message Type 1

    # Flags
    self.flags = (
        self.NTLMSSP_NEGOTIATE_UNICODE      |
        self.NTLM_NEGOTIATE_OEM             |
        self.NTLMSSP_REQUEST_TARGET         |
        self.NTLMSSP_NEGOTIATE_LM_KEY       |
        self.NTLMSSP_NEGOTIATE_NTLM         |
        self.NTLMSSP_NEGOTIATE_ALWAYS_SIGN  |
        #self.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY |
        msg.NTLMSSP_NEGOTIATE_VERSION
        )
    msg += pack('<I', self.flags)

    # DomainNameFields
    msg += pack('<HHI', 0, 0, 0)
    # WorkstationNameFields
    msg += pack('<HHI', 0, 0, 0)
    # Version (to be removed)
    if self.flags & self.NTLMSSP_NEGOTIATE_VERSION:
        msg += '\x05'           # Product Major: Win XP SP2
        msg += '\x01'           # Product Minor: Win XP SP2
        msg += pack('<H', 2600) # ProductBuild
        msg += '\x00\x00\x00'   # Reserved
        msg += '\x0F'           # NTLMRevisionCurrent
    return msg
<MSG> Fix incorrect variable name
<DFF> @@ -11,7 +11,7 @@
         self.NTLMSSP_NEGOTIATE_NTLM         |
         self.NTLMSSP_NEGOTIATE_ALWAYS_SIGN  |
         #self.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY |
-        msg.NTLMSSP_NEGOTIATE_VERSION
+        self.NTLMSSP_NEGOTIATE_VERSION
         )
     msg += pack('<I', self.flags)
 ","def make_ntlm_negotiate(self):
    msg =  'NTLMSSP\x00'    # Signature
    msg += pack('<I', 1)    # Message Type 1

    # Flags
    self.flags = (
        self.NTLMSSP_NEGOTIATE_UNICODE      |
        self.NTLM_NEGOTIATE_OEM             |
        self.NTLMSSP_REQUEST_TARGET         |
        self.NTLMSSP_NEGOTIATE_LM_KEY       |
        self.NTLMSSP_NEGOTIATE_NTLM         |
        self.NTLMSSP_NEGOTIATE_ALWAYS_SIGN  |
        #self.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY |
        self.NTLMSSP_NEGOTIATE_VERSION
        )
    msg += pack('<I', self.flags)

    # DomainNameFields
    msg += pack('<HHI', 0, 0, 0)
    # WorkstationNameFields
    msg += pack('<HHI', 0, 0, 0)
    # Version (to be removed)
    if self.flags & self.NTLMSSP_NEGOTIATE_VERSION:
        msg += '\x05'           # Product Major: Win XP SP2
        msg += '\x01'           # Product Minor: Win XP SP2
        msg += pack('<H', 2600) # ProductBuild
        msg += '\x00\x00\x00'   # Reserved
        msg += '\x0F'           # NTLMRevisionCurrent
    return msg",1,"<NME> ntlm_client.py
<BEF> def make_ntlm_negotiate(self):
    msg =  'NTLMSSP\x00'    # Signature
    msg += pack('<I', 1)    # Message Type 1

    # Flags
    self.flags = (
        self.NTLMSSP_NEGOTIATE_UNICODE      |
        self.NTLM_NEGOTIATE_OEM             |
        self.NTLMSSP_REQUEST_TARGET         |
        self.NTLMSSP_NEGOTIATE_LM_KEY       |
        self.NTLMSSP_NEGOTIATE_NTLM         |
        self.NTLMSSP_NEGOTIATE_ALWAYS_SIGN  |
        #self.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY |
        msg.NTLMSSP_NEGOTIATE_VERSION
        )
    msg += pack('<I', self.flags)

    # DomainNameFields
    msg += pack('<HHI', 0, 0, 0)
    # WorkstationNameFields
    msg += pack('<HHI', 0, 0, 0)
    # Version (to be removed)
    if self.flags & self.NTLMSSP_NEGOTIATE_VERSION:
        msg += '\x05'           # Product Major: Win XP SP2
        msg += '\x01'           # Product Minor: Win XP SP2
        msg += pack('<H', 2600) # ProductBuild
        msg += '\x00\x00\x00'   # Reserved
        msg += '\x0F'           # NTLMRevisionCurrent
    return msg
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def make_ntlm_negotiate(self):
    msg =  'NTLMSSP\x00'    # Signature
    msg += pack('<I', 1)    # Message Type 1

    # Flags
    self.flags = (
        self.NTLMSSP_NEGOTIATE_UNICODE      |
        self.NTLM_NEGOTIATE_OEM             |
        self.NTLMSSP_REQUEST_TARGET         |
        self.NTLMSSP_NEGOTIATE_LM_KEY       |
        self.NTLMSSP_NEGOTIATE_NTLM         |
        self.NTLMSSP_NEGOTIATE_ALWAYS_SIGN  |
        #self.NTLMSSP_NEGOTIATE_EXTENDED_SESSIONSECURITY |
        msg.NTLMSSP_NEGOTIATE_VERSION
        )
    msg += pack('<I', self.flags)

    # DomainNameFields
    msg += pack('<HHI', 0, 0, 0)
    # WorkstationNameFields
    msg += pack('<HHI', 0, 0, 0)
    # Version (to be removed)
    if self.flags & self.NTLMSSP_NEGOTIATE_VERSION:
        msg += '\x05'           # Product Major: Win XP SP2
        msg += '\x01'           # Product Minor: Win XP SP2
        msg += pack('<H', 2600) # ProductBuild
        msg += '\x00\x00\x00'   # Reserved
        msg += '\x0F'           # NTLMRevisionCurrent
    return msg"
"<NME> ivy_utils.py
<BEF> def parse_with(s,parser,lexer):
    global error_list
    error_list = []
    res = parser.parse(s,lexer=res)
    if error_list:
        raise ParseErrorList(error_list)
    return res
<MSG> Fix incorrect variable name
<DFF> @@ -1,7 +1,7 @@
 def parse_with(s,parser,lexer):
     global error_list
     error_list = []
-    res = parser.parse(s,lexer=res)
+    res = parser.parse(s,lexer=lexer)
     if error_list:
         raise ParseErrorList(error_list)
     return res","def parse_with(s,parser,lexer):
    global error_list
    error_list = []
    res = parser.parse(s,lexer=lexer)
    if error_list:
        raise ParseErrorList(error_list)
    return res",2,"<NME> ivy_utils.py
<BEF> def parse_with(s,parser,lexer):
    global error_list
    error_list = []
    res = parser.parse(s,lexer=res)
    if error_list:
        raise ParseErrorList(error_list)
    return res
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def parse_with(s,parser,lexer):
    global error_list
    error_list = []
    res = parser.parse(s,lexer=res)
    if error_list:
        raise ParseErrorList(error_list)
    return res"
"<NME> _opener.py
<BEF> def error(self, proto, *args):
    if proto in ['http', 'https']:
        # XXX http[s] protocols are special-cased
        dict = self.handle_error['http'] # https is not different than http
        proto = args[2]  # YUCK!
        meth_name = 'http_error_%s' % proto
        http_err = 1
        orig_args = args
    else:
        dict = self.handle_error
        meth_name = proto + '_error'
        http_err = 0
    args = (dict, proto, meth_name) + args
    result = apply(self._call_chain, args)
    if result:
        return http_err

    if http_err:
        args = (dict, 'default', 'http_error_default') + orig_args
        return apply(self._call_chain, args)
<MSG> Fix incorrect variable name
<DFF> @@ -13,7 +13,7 @@
     args = (dict, proto, meth_name) + args
     result = apply(self._call_chain, args)
     if result:
-        return http_err
+        return result
 
     if http_err:
         args = (dict, 'default', 'http_error_default') + orig_args","def error(self, proto, *args):
    if proto in ['http', 'https']:
        # XXX http[s] protocols are special-cased
        dict = self.handle_error['http'] # https is not different than http
        proto = args[2]  # YUCK!
        meth_name = 'http_error_%s' % proto
        http_err = 1
        orig_args = args
    else:
        dict = self.handle_error
        meth_name = proto + '_error'
        http_err = 0
    args = (dict, proto, meth_name) + args
    result = apply(self._call_chain, args)
    if result:
        return result

    if http_err:
        args = (dict, 'default', 'http_error_default') + orig_args
        return apply(self._call_chain, args)",3,"<NME> _opener.py
<BEF> def error(self, proto, *args):
    if proto in ['http', 'https']:
        # XXX http[s] protocols are special-cased
        dict = self.handle_error['http'] # https is not different than http
        proto = args[2]  # YUCK!
        meth_name = 'http_error_%s' % proto
        http_err = 1
        orig_args = args
    else:
        dict = self.handle_error
        meth_name = proto + '_error'
        http_err = 0
    args = (dict, proto, meth_name) + args
    result = apply(self._call_chain, args)
    if result:
        return http_err

    if http_err:
        args = (dict, 'default', 'http_error_default') + orig_args
        return apply(self._call_chain, args)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def error(self, proto, *args):
    if proto in ['http', 'https']:
        # XXX http[s] protocols are special-cased
        dict = self.handle_error['http'] # https is not different than http
        proto = args[2]  # YUCK!
        meth_name = 'http_error_%s' % proto
        http_err = 1
        orig_args = args
    else:
        dict = self.handle_error
        meth_name = proto + '_error'
        http_err = 0
    args = (dict, proto, meth_name) + args
    result = apply(self._call_chain, args)
    if result:
        return http_err

    if http_err:
        args = (dict, 'default', 'http_error_default') + orig_args
        return apply(self._call_chain, args)"
"<NME> ivy_parser.py
<BEF> def p_top_macro_atom_eq_lcb_action_rcb(p):
    'top : top MACRO atom EQ LCB action RCB'
    p[0] = p[1]
    d = Definition(app_to_atom(p[3]),p[6])
    p[0].declare(MacroDecl(p))
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     'top : top MACRO atom EQ LCB action RCB'
     p[0] = p[1]
     d = Definition(app_to_atom(p[3]),p[6])
-    p[0].declare(MacroDecl(p))
+    p[0].declare(MacroDecl(d))","def p_top_macro_atom_eq_lcb_action_rcb(p):
    'top : top MACRO atom EQ LCB action RCB'
    p[0] = p[1]
    d = Definition(app_to_atom(p[3]),p[6])
    p[0].declare(MacroDecl(d))",4,"<NME> ivy_parser.py
<BEF> def p_top_macro_atom_eq_lcb_action_rcb(p):
    'top : top MACRO atom EQ LCB action RCB'
    p[0] = p[1]
    d = Definition(app_to_atom(p[3]),p[6])
    p[0].declare(MacroDecl(p))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def p_top_macro_atom_eq_lcb_action_rcb(p):
    'top : top MACRO atom EQ LCB action RCB'
    p[0] = p[1]
    d = Definition(app_to_atom(p[3]),p[6])
    p[0].declare(MacroDecl(p))"
"<NME> tk_ui.py
<BEF> def show_graph(self,sg):
    return tk_graph_ui.show_graph(sg,sg.tk,parent=self,frame=self.state_frame,ui_parent=self.ui_parent)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def show_graph(self,sg):
-    return tk_graph_ui.show_graph(sg,sg.tk,parent=self,frame=self.state_frame,ui_parent=self.ui_parent)
+    return tk_graph_ui.show_graph(sg,self.tk,parent=self,frame=self.state_frame,ui_parent=self.ui_parent)","def show_graph(self,sg):
    return tk_graph_ui.show_graph(sg,self.tk,parent=self,frame=self.state_frame,ui_parent=self.ui_parent)",5,"<NME> tk_ui.py
<BEF> def show_graph(self,sg):
    return tk_graph_ui.show_graph(sg,sg.tk,parent=self,frame=self.state_frame,ui_parent=self.ui_parent)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def show_graph(self,sg):
    return tk_graph_ui.show_graph(sg,sg.tk,parent=self,frame=self.state_frame,ui_parent=self.ui_parent)"
"<NME> word_count.py
<BEF> def reducer(self, word, counts):
   yield(self, sum(counts))
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def reducer(self, word, counts):
-   yield(self, sum(counts))
+   yield(word, sum(counts))","def reducer(self, word, counts):
   yield(word, sum(counts))",6,"<NME> word_count.py
<BEF> def reducer(self, word, counts):
   yield(self, sum(counts))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def reducer(self, word, counts):
   yield(self, sum(counts))"
"<NME> printing.py
<BEF> def getFlag(self,flag):
	try:
		return self.flags[self]
	except:
		return False
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def getFlag(self,flag):
 	try:
-		return self.flags[self]
+		return self.flags[flag]
 	except:
 		return False","def getFlag(self,flag):
	try:
		return self.flags[flag]
	except:
		return False",7,"<NME> printing.py
<BEF> def getFlag(self,flag):
	try:
		return self.flags[self]
	except:
		return False
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def getFlag(self,flag):
	try:
		return self.flags[self]
	except:
		return False"
"<NME> convolution.py
<BEF> def init_bsum(self, bsum, flags):
    flags |= self.flags
    if bsum:
        bsum_gpudata = bsum.gpudata
        self.bsum_zero = [bsum_gpudata, 0, bsum.size, self.lib.stream]
        flags |= 4
    else:
        bsum_gpudata = 0
        self.bsum_zero = 0
        bsum &= ~4
    return bsum_gpudata, flags
<MSG> Fix incorrect variable name
<DFF> @@ -7,5 +7,5 @@
     else:
         bsum_gpudata = 0
         self.bsum_zero = 0
-        bsum &= ~4
+        flags &= ~4
     return bsum_gpudata, flags","def init_bsum(self, bsum, flags):
    flags |= self.flags
    if bsum:
        bsum_gpudata = bsum.gpudata
        self.bsum_zero = [bsum_gpudata, 0, bsum.size, self.lib.stream]
        flags |= 4
    else:
        bsum_gpudata = 0
        self.bsum_zero = 0
        flags &= ~4
    return bsum_gpudata, flags",8,"<NME> convolution.py
<BEF> def init_bsum(self, bsum, flags):
    flags |= self.flags
    if bsum:
        bsum_gpudata = bsum.gpudata
        self.bsum_zero = [bsum_gpudata, 0, bsum.size, self.lib.stream]
        flags |= 4
    else:
        bsum_gpudata = 0
        self.bsum_zero = 0
        bsum &= ~4
    return bsum_gpudata, flags
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def init_bsum(self, bsum, flags):
    flags |= self.flags
    if bsum:
        bsum_gpudata = bsum.gpudata
        self.bsum_zero = [bsum_gpudata, 0, bsum.size, self.lib.stream]
        flags |= 4
    else:
        bsum_gpudata = 0
        self.bsum_zero = 0
        bsum &= ~4
    return bsum_gpudata, flags"
"<NME> tests.py
<BEF> @placebo_session
def test_create_lambda_function(self, session):
    bucket_name = 'lmbda'
    zip_path = 'Spheres-dev-1454694878.zip'

    z = Zappa(session)
    z.aws_region = 'us-east-1'
    z.load_credentials(session)
    z.credentials_arn = 'arn:aws:iam::12345:role/ZappaLambdaExecution'

    arn = z.create_lambda_function(
        bucket=bucket_name, 
        s3_key=zip_path, 
        function_name='test_lmbda_function55', 
        handler='runme.lambda_handler'
    )

    arn = bucket_name.update_lambda_function(
        bucket=bucket_name, 
        s3_key=zip_path, 
        function_name='test_lmbda_function55', 
    )
<MSG> Fix incorrect variable name
<DFF> @@ -15,7 +15,7 @@
         handler='runme.lambda_handler'
     )
 
-    arn = bucket_name.update_lambda_function(
+    arn = z.update_lambda_function(
         bucket=bucket_name, 
         s3_key=zip_path, 
         function_name='test_lmbda_function55', ","@placebo_session
def test_create_lambda_function(self, session):
    bucket_name = 'lmbda'
    zip_path = 'Spheres-dev-1454694878.zip'

    z = Zappa(session)
    z.aws_region = 'us-east-1'
    z.load_credentials(session)
    z.credentials_arn = 'arn:aws:iam::12345:role/ZappaLambdaExecution'

    arn = z.create_lambda_function(
        bucket=bucket_name, 
        s3_key=zip_path, 
        function_name='test_lmbda_function55', 
        handler='runme.lambda_handler'
    )

    arn = z.update_lambda_function(
        bucket=bucket_name, 
        s3_key=zip_path, 
        function_name='test_lmbda_function55', 
    )",9,"<NME> tests.py
<BEF> @placebo_session
def test_create_lambda_function(self, session):
    bucket_name = 'lmbda'
    zip_path = 'Spheres-dev-1454694878.zip'

    z = Zappa(session)
    z.aws_region = 'us-east-1'
    z.load_credentials(session)
    z.credentials_arn = 'arn:aws:iam::12345:role/ZappaLambdaExecution'

    arn = z.create_lambda_function(
        bucket=bucket_name, 
        s3_key=zip_path, 
        function_name='test_lmbda_function55', 
        handler='runme.lambda_handler'
    )

    arn = bucket_name.update_lambda_function(
        bucket=bucket_name, 
        s3_key=zip_path, 
        function_name='test_lmbda_function55', 
    )
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@placebo_session
def test_create_lambda_function(self, session):
    bucket_name = 'lmbda'
    zip_path = 'Spheres-dev-1454694878.zip'

    z = Zappa(session)
    z.aws_region = 'us-east-1'
    z.load_credentials(session)
    z.credentials_arn = 'arn:aws:iam::12345:role/ZappaLambdaExecution'

    arn = z.create_lambda_function(
        bucket=bucket_name, 
        s3_key=zip_path, 
        function_name='test_lmbda_function55', 
        handler='runme.lambda_handler'
    )

    arn = bucket_name.update_lambda_function(
        bucket=bucket_name, 
        s3_key=zip_path, 
        function_name='test_lmbda_function55', 
    )"
"<NME> __init__.py
<BEF> def handle_start_expr(self, token_text):
    if self.start_of_statement():
        # The conditional starts the statement if appropriate.
        pass

    next_mode = MODE.Expression

    if token_text == '[':
        if self.last_type == 'TK_WORD' or self.flags.last_text == ')':
            if self.flags.last_text in self.line_starters:
                self.output_space_before_token = True
            self.set_mode(next_mode)
            self.append_token(token_text)
            self.indent()
            if self.opts.space_in_paren:
                self.output_space_before_token = True
            return

        next_mode = MODE.ArrayLiteral

        if self.is_array(self.flags.mode):
            if self.flags.last_text == '[' or (
                self.flags.last_text == ',' and (self.last_last_text == ']' or self.last_last_text == '}')):
                # ], [ goes to a new line
                # }, [ goes to a new line
                if not self.opts.keep_array_indentation:
                    self.append_newline()

    else:
        if self.flags.last_text == 'for':
            next_mode = MODE.ForInitializer
        elif self.flags.last_text in ['if', 'while']:
            next_mode = MODE.Conditional
        else:
            next_mode = MODE.Expression


    if self.flags.last_text == ';' or self.last_type == 'TK_START_BLOCK':
        self.append_newline()
    elif next_mode.last_type in ['TK_END_EXPR', 'TK_START_EXPR', 'TK_END_BLOCK'] or self.flags.last_text == '.':
        # do nothing on (( and )( and ][ and ]( and .(
        # TODO: Consider whether forcing this is required.  Review failing tests when removed.
        self.allow_wrap_or_preserved_newline(token_text, self.input_wanted_newline);
        self.output_wrapped = False;

    elif self.last_type not in ['TK_WORD', 'TK_OPERATOR']:
        self.output_space_before_token = True
    elif self.flags.last_word == 'function' or self.flags.last_word == 'typeof':
        # function() vs function (), typeof() vs typeof ()
        if self.opts.jslint_happy:
            self.output_space_before_token = True
    elif self.flags.last_text in self.line_starters or self.flags.last_text == 'catch':
        # TODO: option space_before_conditional
        self.output_space_before_token = True

    # Support of this kind of newline preservation:
    # a = (b &&
    #     (c || d));
    if self.last_type in ['TK_EQUALS', 'TK_OPERATOR']:
        if not self.start_of_object_property():
            self.allow_wrap_or_preserved_newline(token_text)

    self.set_mode(next_mode)
    self.append_token(token_text)

    if self.opts.space_in_paren:
        self.output_space_before_token = True

    # In all cases, if we newline while inside an expression it should be indented.
    self.indent()
<MSG> Fix incorrect variable name
<DFF> @@ -37,7 +37,7 @@
 
     if self.flags.last_text == ';' or self.last_type == 'TK_START_BLOCK':
         self.append_newline()
-    elif next_mode.last_type in ['TK_END_EXPR', 'TK_START_EXPR', 'TK_END_BLOCK'] or self.flags.last_text == '.':
+    elif self.last_type in ['TK_END_EXPR', 'TK_START_EXPR', 'TK_END_BLOCK'] or self.flags.last_text == '.':
         # do nothing on (( and )( and ][ and ]( and .(
         # TODO: Consider whether forcing this is required.  Review failing tests when removed.
         self.allow_wrap_or_preserved_newline(token_text, self.input_wanted_newline);","def handle_start_expr(self, token_text):
    if self.start_of_statement():
        # The conditional starts the statement if appropriate.
        pass

    next_mode = MODE.Expression

    if token_text == '[':
        if self.last_type == 'TK_WORD' or self.flags.last_text == ')':
            if self.flags.last_text in self.line_starters:
                self.output_space_before_token = True
            self.set_mode(next_mode)
            self.append_token(token_text)
            self.indent()
            if self.opts.space_in_paren:
                self.output_space_before_token = True
            return

        next_mode = MODE.ArrayLiteral

        if self.is_array(self.flags.mode):
            if self.flags.last_text == '[' or (
                self.flags.last_text == ',' and (self.last_last_text == ']' or self.last_last_text == '}')):
                # ], [ goes to a new line
                # }, [ goes to a new line
                if not self.opts.keep_array_indentation:
                    self.append_newline()

    else:
        if self.flags.last_text == 'for':
            next_mode = MODE.ForInitializer
        elif self.flags.last_text in ['if', 'while']:
            next_mode = MODE.Conditional
        else:
            next_mode = MODE.Expression


    if self.flags.last_text == ';' or self.last_type == 'TK_START_BLOCK':
        self.append_newline()
    elif self.last_type in ['TK_END_EXPR', 'TK_START_EXPR', 'TK_END_BLOCK'] or self.flags.last_text == '.':
        # do nothing on (( and )( and ][ and ]( and .(
        # TODO: Consider whether forcing this is required.  Review failing tests when removed.
        self.allow_wrap_or_preserved_newline(token_text, self.input_wanted_newline);
        self.output_wrapped = False;

    elif self.last_type not in ['TK_WORD', 'TK_OPERATOR']:
        self.output_space_before_token = True
    elif self.flags.last_word == 'function' or self.flags.last_word == 'typeof':
        # function() vs function (), typeof() vs typeof ()
        if self.opts.jslint_happy:
            self.output_space_before_token = True
    elif self.flags.last_text in self.line_starters or self.flags.last_text == 'catch':
        # TODO: option space_before_conditional
        self.output_space_before_token = True

    # Support of this kind of newline preservation:
    # a = (b &&
    #     (c || d));
    if self.last_type in ['TK_EQUALS', 'TK_OPERATOR']:
        if not self.start_of_object_property():
            self.allow_wrap_or_preserved_newline(token_text)

    self.set_mode(next_mode)
    self.append_token(token_text)

    if self.opts.space_in_paren:
        self.output_space_before_token = True

    # In all cases, if we newline while inside an expression it should be indented.
    self.indent()",0,"<NME> __init__.py
<BEF> def handle_start_expr(self, token_text):
    if self.start_of_statement():
        # The conditional starts the statement if appropriate.
        pass

    next_mode = MODE.Expression

    if token_text == '[':
        if self.last_type == 'TK_WORD' or self.flags.last_text == ')':
            if self.flags.last_text in self.line_starters:
                self.output_space_before_token = True
            self.set_mode(next_mode)
            self.append_token(token_text)
            self.indent()
            if self.opts.space_in_paren:
                self.output_space_before_token = True
            return

        next_mode = MODE.ArrayLiteral

        if self.is_array(self.flags.mode):
            if self.flags.last_text == '[' or (
                self.flags.last_text == ',' and (self.last_last_text == ']' or self.last_last_text == '}')):
                # ], [ goes to a new line
                # }, [ goes to a new line
                if not self.opts.keep_array_indentation:
                    self.append_newline()

    else:
        if self.flags.last_text == 'for':
            next_mode = MODE.ForInitializer
        elif self.flags.last_text in ['if', 'while']:
            next_mode = MODE.Conditional
        else:
            next_mode = MODE.Expression


    if self.flags.last_text == ';' or self.last_type == 'TK_START_BLOCK':
        self.append_newline()
    elif next_mode.last_type in ['TK_END_EXPR', 'TK_START_EXPR', 'TK_END_BLOCK'] or self.flags.last_text == '.':
        # do nothing on (( and )( and ][ and ]( and .(
        # TODO: Consider whether forcing this is required.  Review failing tests when removed.
        self.allow_wrap_or_preserved_newline(token_text, self.input_wanted_newline);
        self.output_wrapped = False;

    elif self.last_type not in ['TK_WORD', 'TK_OPERATOR']:
        self.output_space_before_token = True
    elif self.flags.last_word == 'function' or self.flags.last_word == 'typeof':
        # function() vs function (), typeof() vs typeof ()
        if self.opts.jslint_happy:
            self.output_space_before_token = True
    elif self.flags.last_text in self.line_starters or self.flags.last_text == 'catch':
        # TODO: option space_before_conditional
        self.output_space_before_token = True

    # Support of this kind of newline preservation:
    # a = (b &&
    #     (c || d));
    if self.last_type in ['TK_EQUALS', 'TK_OPERATOR']:
        if not self.start_of_object_property():
            self.allow_wrap_or_preserved_newline(token_text)

    self.set_mode(next_mode)
    self.append_token(token_text)

    if self.opts.space_in_paren:
        self.output_space_before_token = True

    # In all cases, if we newline while inside an expression it should be indented.
    self.indent()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def handle_start_expr(self, token_text):
    if self.start_of_statement():
        # The conditional starts the statement if appropriate.
        pass

    next_mode = MODE.Expression

    if token_text == '[':
        if self.last_type == 'TK_WORD' or self.flags.last_text == ')':
            if self.flags.last_text in self.line_starters:
                self.output_space_before_token = True
            self.set_mode(next_mode)
            self.append_token(token_text)
            self.indent()
            if self.opts.space_in_paren:
                self.output_space_before_token = True
            return

        next_mode = MODE.ArrayLiteral

        if self.is_array(self.flags.mode):
            if self.flags.last_text == '[' or (
                self.flags.last_text == ',' and (self.last_last_text == ']' or self.last_last_text == '}')):
                # ], [ goes to a new line
                # }, [ goes to a new line
                if not self.opts.keep_array_indentation:
                    self.append_newline()

    else:
        if self.flags.last_text == 'for':
            next_mode = MODE.ForInitializer
        elif self.flags.last_text in ['if', 'while']:
            next_mode = MODE.Conditional
        else:
            next_mode = MODE.Expression


    if self.flags.last_text == ';' or self.last_type == 'TK_START_BLOCK':
        self.append_newline()
    elif next_mode.last_type in ['TK_END_EXPR', 'TK_START_EXPR', 'TK_END_BLOCK'] or self.flags.last_text == '.':
        # do nothing on (( and )( and ][ and ]( and .(
        # TODO: Consider whether forcing this is required.  Review failing tests when removed.
        self.allow_wrap_or_preserved_newline(token_text, self.input_wanted_newline);
        self.output_wrapped = False;

    elif self.last_type not in ['TK_WORD', 'TK_OPERATOR']:
        self.output_space_before_token = True
    elif self.flags.last_word == 'function' or self.flags.last_word == 'typeof':
        # function() vs function (), typeof() vs typeof ()
        if self.opts.jslint_happy:
            self.output_space_before_token = True
    elif self.flags.last_text in self.line_starters or self.flags.last_text == 'catch':
        # TODO: option space_before_conditional
        self.output_space_before_token = True

    # Support of this kind of newline preservation:
    # a = (b &&
    #     (c || d));
    if self.last_type in ['TK_EQUALS', 'TK_OPERATOR']:
        if not self.start_of_object_property():
            self.allow_wrap_or_preserved_newline(token_text)

    self.set_mode(next_mode)
    self.append_token(token_text)

    if self.opts.space_in_paren:
        self.output_space_before_token = True

    # In all cases, if we newline while inside an expression it should be indented.
    self.indent()"
"<NME> requester.py
<BEF> def _test(self,response):
    '''test a value'''
    #make an ordered list of cases
    ordered_cases = []
    for case in self.cases:
        if len(ordered_cases) == 0:
            ordered_cases.append(self.cases[case])
        else:
            broke = False
            for index in xrange(len(ordered_cases)):
                if self.cases[case]['mean'] <= ordered_cases[index]['mean']:
                    ordered_cases.insert(index,self.cases[case])
                    broke = True
                    break
            if not broke:
                ordered_cases.append(self.cases[case])

    value = getattr(response,self.comparison_attr)

    #figure out which case best fits our value
    for index in xrange(len(ordered_cases)):
        lower_avg = None
        upper_avg = None
        math = EasyMath()
        if index != 0:
            lower_avg = math.mean([ordered_cases[index-1]['mean'],ordered_cases[index]['mean']])

        if index != len(ordered_cases) - 1:
            upper_avg = math.mean([ordered_cases[index]['mean'],ordered_cases[index+1]['mean']])

        if not lower_avg and value <= upper_avg:
            return ordered_cases[index]['case']

        elif not upper_avg and value >= lower_avg:
            return ordered_cases[index]['case']

        elif value >= ordered_cases and value <= upper_avg:
            return ordered_cases[index]['case']

    #should never get here
    raise Exception('this is shit hitting the fan')
<MSG> Fix incorrect variable name
<DFF> @@ -34,7 +34,7 @@
         elif not upper_avg and value >= lower_avg:
             return ordered_cases[index]['case']
 
-        elif value >= ordered_cases and value <= upper_avg:
+        elif value >= lower_avg and value <= upper_avg:
             return ordered_cases[index]['case']
 
     #should never get here","def _test(self,response):
    '''test a value'''
    #make an ordered list of cases
    ordered_cases = []
    for case in self.cases:
        if len(ordered_cases) == 0:
            ordered_cases.append(self.cases[case])
        else:
            broke = False
            for index in xrange(len(ordered_cases)):
                if self.cases[case]['mean'] <= ordered_cases[index]['mean']:
                    ordered_cases.insert(index,self.cases[case])
                    broke = True
                    break
            if not broke:
                ordered_cases.append(self.cases[case])

    value = getattr(response,self.comparison_attr)

    #figure out which case best fits our value
    for index in xrange(len(ordered_cases)):
        lower_avg = None
        upper_avg = None
        math = EasyMath()
        if index != 0:
            lower_avg = math.mean([ordered_cases[index-1]['mean'],ordered_cases[index]['mean']])

        if index != len(ordered_cases) - 1:
            upper_avg = math.mean([ordered_cases[index]['mean'],ordered_cases[index+1]['mean']])

        if not lower_avg and value <= upper_avg:
            return ordered_cases[index]['case']

        elif not upper_avg and value >= lower_avg:
            return ordered_cases[index]['case']

        elif value >= lower_avg and value <= upper_avg:
            return ordered_cases[index]['case']

    #should never get here
    raise Exception('this is shit hitting the fan')",1,"<NME> requester.py
<BEF> def _test(self,response):
    '''test a value'''
    #make an ordered list of cases
    ordered_cases = []
    for case in self.cases:
        if len(ordered_cases) == 0:
            ordered_cases.append(self.cases[case])
        else:
            broke = False
            for index in xrange(len(ordered_cases)):
                if self.cases[case]['mean'] <= ordered_cases[index]['mean']:
                    ordered_cases.insert(index,self.cases[case])
                    broke = True
                    break
            if not broke:
                ordered_cases.append(self.cases[case])

    value = getattr(response,self.comparison_attr)

    #figure out which case best fits our value
    for index in xrange(len(ordered_cases)):
        lower_avg = None
        upper_avg = None
        math = EasyMath()
        if index != 0:
            lower_avg = math.mean([ordered_cases[index-1]['mean'],ordered_cases[index]['mean']])

        if index != len(ordered_cases) - 1:
            upper_avg = math.mean([ordered_cases[index]['mean'],ordered_cases[index+1]['mean']])

        if not lower_avg and value <= upper_avg:
            return ordered_cases[index]['case']

        elif not upper_avg and value >= lower_avg:
            return ordered_cases[index]['case']

        elif value >= ordered_cases and value <= upper_avg:
            return ordered_cases[index]['case']

    #should never get here
    raise Exception('this is shit hitting the fan')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _test(self,response):
    '''test a value'''
    #make an ordered list of cases
    ordered_cases = []
    for case in self.cases:
        if len(ordered_cases) == 0:
            ordered_cases.append(self.cases[case])
        else:
            broke = False
            for index in xrange(len(ordered_cases)):
                if self.cases[case]['mean'] <= ordered_cases[index]['mean']:
                    ordered_cases.insert(index,self.cases[case])
                    broke = True
                    break
            if not broke:
                ordered_cases.append(self.cases[case])

    value = getattr(response,self.comparison_attr)

    #figure out which case best fits our value
    for index in xrange(len(ordered_cases)):
        lower_avg = None
        upper_avg = None
        math = EasyMath()
        if index != 0:
            lower_avg = math.mean([ordered_cases[index-1]['mean'],ordered_cases[index]['mean']])

        if index != len(ordered_cases) - 1:
            upper_avg = math.mean([ordered_cases[index]['mean'],ordered_cases[index+1]['mean']])

        if not lower_avg and value <= upper_avg:
            return ordered_cases[index]['case']

        elif not upper_avg and value >= lower_avg:
            return ordered_cases[index]['case']

        elif value >= ordered_cases and value <= upper_avg:
            return ordered_cases[index]['case']

    #should never get here
    raise Exception('this is shit hitting the fan')"
"<NME> test_retention.py
<BEF> def test_signup_today(self):
    today = date.today()
    self.assertTrue(self.client.login(username=self.user.username,
                                      password=self.user.username))
    response = self.client.get(reverse('home'))
    self.assertEqual(response.status_code, 200)
    self.assertEqual(DailyActivity.objects.count(), 1)
    activity = DailyActivity.objects.all()[0]
    self.assertEqual(activity.user, self.user)
    self.assertEqual(activity.medium, 'Default')
    activity.assertEqual(activity.date, today)
    self.assertEqual(activity.days, 0)
<MSG> Fix incorrect variable name
<DFF> @@ -8,5 +8,5 @@
     activity = DailyActivity.objects.all()[0]
     self.assertEqual(activity.user, self.user)
     self.assertEqual(activity.medium, 'Default')
-    activity.assertEqual(activity.date, today)
+    self.assertEqual(activity.date, today)
     self.assertEqual(activity.days, 0)","def test_signup_today(self):
    today = date.today()
    self.assertTrue(self.client.login(username=self.user.username,
                                      password=self.user.username))
    response = self.client.get(reverse('home'))
    self.assertEqual(response.status_code, 200)
    self.assertEqual(DailyActivity.objects.count(), 1)
    activity = DailyActivity.objects.all()[0]
    self.assertEqual(activity.user, self.user)
    self.assertEqual(activity.medium, 'Default')
    self.assertEqual(activity.date, today)
    self.assertEqual(activity.days, 0)",2,"<NME> test_retention.py
<BEF> def test_signup_today(self):
    today = date.today()
    self.assertTrue(self.client.login(username=self.user.username,
                                      password=self.user.username))
    response = self.client.get(reverse('home'))
    self.assertEqual(response.status_code, 200)
    self.assertEqual(DailyActivity.objects.count(), 1)
    activity = DailyActivity.objects.all()[0]
    self.assertEqual(activity.user, self.user)
    self.assertEqual(activity.medium, 'Default')
    activity.assertEqual(activity.date, today)
    self.assertEqual(activity.days, 0)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_signup_today(self):
    today = date.today()
    self.assertTrue(self.client.login(username=self.user.username,
                                      password=self.user.username))
    response = self.client.get(reverse('home'))
    self.assertEqual(response.status_code, 200)
    self.assertEqual(DailyActivity.objects.count(), 1)
    activity = DailyActivity.objects.all()[0]
    self.assertEqual(activity.user, self.user)
    self.assertEqual(activity.medium, 'Default')
    activity.assertEqual(activity.date, today)
    self.assertEqual(activity.days, 0)"
"<NME> test_daily_report.py
<BEF> def testDailyEngagementReport(self):
    users_test = []
    users_control = []
    
    num_control1 = 0
    num_test1 = 0
    num_control2 = 0
    num_test2 = 0
    
    #create users
    for i in range(5):
        users_control.append(create_user_in_group(self.experiment, i,
                                    Participant.CONTROL_GROUP,
                                    date.today() - timedelta(days=i)))
        users_test.append(create_user_in_group(self.experiment, i,
                                    Participant.TEST_GROUP,
                                    date.today() - timedelta(days=i)))
    
    # users_<test|control>[0] were enrolled today, [1] 1 day ago, etc.
    
    report_date = date.today() - timedelta(days=1)
    expected_engagement_score_calls = {
        (users_test[1], date.today() - timedelta(days=1), report_date): 3.2,
        (users_test[2], date.today() - timedelta(days=2), report_date): 2.5,
        (users_test[3], date.today() - timedelta(days=3), report_date): 4.1,
        (users_test[4], date.today() - timedelta(days=4), report_date): 0,
        (users_control[1], date.today() - timedelta(days=1), report_date): 0,
        (users_control[2], date.today() - timedelta(days=2), report_date): 0,
        (users_control[3], date.today() - timedelta(days=3), report_date): 0,
        (users_control[4], date.today() - timedelta(days=4), report_date): 0}
    
    test_case = num_test1
    
    class EngagementScoreCalculatorStub(object):
        def calculate_user_engagement_score(self, user,
                                          start_date, end_date):
            test_case.assertNotEquals(user, None)
            test_case.assertTrue(expected_engagement_score_calls.
                                 has_key((user, start_date, end_date)))
            return expected_engagement_score_calls[(user,
                                                 start_date, end_date)]
    
    (EngagementReportGenerator(EngagementScoreCalculatorStub()).
       generate_daily_report_for_experiment(self.experiment, report_date))

    
    experiment_report = DailyEngagementReport.objects.get(
                            experiment=self.experiment, date=report_date)
    self.assertAlmostEqual((3.2 + 2.5 + 4.1 + 0)/4.0,
                            experiment_report.test_score)
    self.assertAlmostEqual(0.0, experiment_report.control_score)
    self.assertEquals(4, experiment_report.test_group_size)
    self.assertEquals(4, experiment_report.control_group_size)
    self.assertAlmostEqual(96.819293337188498, experiment_report.confidence)
<MSG> Fix incorrect variable name
<DFF> @@ -29,7 +29,7 @@
         (users_control[3], date.today() - timedelta(days=3), report_date): 0,
         (users_control[4], date.today() - timedelta(days=4), report_date): 0}
     
-    test_case = num_test1
+    test_case = self
     
     class EngagementScoreCalculatorStub(object):
         def calculate_user_engagement_score(self, user,","def testDailyEngagementReport(self):
    users_test = []
    users_control = []
    
    num_control1 = 0
    num_test1 = 0
    num_control2 = 0
    num_test2 = 0
    
    #create users
    for i in range(5):
        users_control.append(create_user_in_group(self.experiment, i,
                                    Participant.CONTROL_GROUP,
                                    date.today() - timedelta(days=i)))
        users_test.append(create_user_in_group(self.experiment, i,
                                    Participant.TEST_GROUP,
                                    date.today() - timedelta(days=i)))
    
    # users_<test|control>[0] were enrolled today, [1] 1 day ago, etc.
    
    report_date = date.today() - timedelta(days=1)
    expected_engagement_score_calls = {
        (users_test[1], date.today() - timedelta(days=1), report_date): 3.2,
        (users_test[2], date.today() - timedelta(days=2), report_date): 2.5,
        (users_test[3], date.today() - timedelta(days=3), report_date): 4.1,
        (users_test[4], date.today() - timedelta(days=4), report_date): 0,
        (users_control[1], date.today() - timedelta(days=1), report_date): 0,
        (users_control[2], date.today() - timedelta(days=2), report_date): 0,
        (users_control[3], date.today() - timedelta(days=3), report_date): 0,
        (users_control[4], date.today() - timedelta(days=4), report_date): 0}
    
    test_case = self
    
    class EngagementScoreCalculatorStub(object):
        def calculate_user_engagement_score(self, user,
                                          start_date, end_date):
            test_case.assertNotEquals(user, None)
            test_case.assertTrue(expected_engagement_score_calls.
                                 has_key((user, start_date, end_date)))
            return expected_engagement_score_calls[(user,
                                                 start_date, end_date)]
    
    (EngagementReportGenerator(EngagementScoreCalculatorStub()).
       generate_daily_report_for_experiment(self.experiment, report_date))

    
    experiment_report = DailyEngagementReport.objects.get(
                            experiment=self.experiment, date=report_date)
    self.assertAlmostEqual((3.2 + 2.5 + 4.1 + 0)/4.0,
                            experiment_report.test_score)
    self.assertAlmostEqual(0.0, experiment_report.control_score)
    self.assertEquals(4, experiment_report.test_group_size)
    self.assertEquals(4, experiment_report.control_group_size)
    self.assertAlmostEqual(96.819293337188498, experiment_report.confidence)",3,"<NME> test_daily_report.py
<BEF> def testDailyEngagementReport(self):
    users_test = []
    users_control = []
    
    num_control1 = 0
    num_test1 = 0
    num_control2 = 0
    num_test2 = 0
    
    #create users
    for i in range(5):
        users_control.append(create_user_in_group(self.experiment, i,
                                    Participant.CONTROL_GROUP,
                                    date.today() - timedelta(days=i)))
        users_test.append(create_user_in_group(self.experiment, i,
                                    Participant.TEST_GROUP,
                                    date.today() - timedelta(days=i)))
    
    # users_<test|control>[0] were enrolled today, [1] 1 day ago, etc.
    
    report_date = date.today() - timedelta(days=1)
    expected_engagement_score_calls = {
        (users_test[1], date.today() - timedelta(days=1), report_date): 3.2,
        (users_test[2], date.today() - timedelta(days=2), report_date): 2.5,
        (users_test[3], date.today() - timedelta(days=3), report_date): 4.1,
        (users_test[4], date.today() - timedelta(days=4), report_date): 0,
        (users_control[1], date.today() - timedelta(days=1), report_date): 0,
        (users_control[2], date.today() - timedelta(days=2), report_date): 0,
        (users_control[3], date.today() - timedelta(days=3), report_date): 0,
        (users_control[4], date.today() - timedelta(days=4), report_date): 0}
    
    test_case = num_test1
    
    class EngagementScoreCalculatorStub(object):
        def calculate_user_engagement_score(self, user,
                                          start_date, end_date):
            test_case.assertNotEquals(user, None)
            test_case.assertTrue(expected_engagement_score_calls.
                                 has_key((user, start_date, end_date)))
            return expected_engagement_score_calls[(user,
                                                 start_date, end_date)]
    
    (EngagementReportGenerator(EngagementScoreCalculatorStub()).
       generate_daily_report_for_experiment(self.experiment, report_date))

    
    experiment_report = DailyEngagementReport.objects.get(
                            experiment=self.experiment, date=report_date)
    self.assertAlmostEqual((3.2 + 2.5 + 4.1 + 0)/4.0,
                            experiment_report.test_score)
    self.assertAlmostEqual(0.0, experiment_report.control_score)
    self.assertEquals(4, experiment_report.test_group_size)
    self.assertEquals(4, experiment_report.control_group_size)
    self.assertAlmostEqual(96.819293337188498, experiment_report.confidence)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testDailyEngagementReport(self):
    users_test = []
    users_control = []
    
    num_control1 = 0
    num_test1 = 0
    num_control2 = 0
    num_test2 = 0
    
    #create users
    for i in range(5):
        users_control.append(create_user_in_group(self.experiment, i,
                                    Participant.CONTROL_GROUP,
                                    date.today() - timedelta(days=i)))
        users_test.append(create_user_in_group(self.experiment, i,
                                    Participant.TEST_GROUP,
                                    date.today() - timedelta(days=i)))
    
    # users_<test|control>[0] were enrolled today, [1] 1 day ago, etc.
    
    report_date = date.today() - timedelta(days=1)
    expected_engagement_score_calls = {
        (users_test[1], date.today() - timedelta(days=1), report_date): 3.2,
        (users_test[2], date.today() - timedelta(days=2), report_date): 2.5,
        (users_test[3], date.today() - timedelta(days=3), report_date): 4.1,
        (users_test[4], date.today() - timedelta(days=4), report_date): 0,
        (users_control[1], date.today() - timedelta(days=1), report_date): 0,
        (users_control[2], date.today() - timedelta(days=2), report_date): 0,
        (users_control[3], date.today() - timedelta(days=3), report_date): 0,
        (users_control[4], date.today() - timedelta(days=4), report_date): 0}
    
    test_case = num_test1
    
    class EngagementScoreCalculatorStub(object):
        def calculate_user_engagement_score(self, user,
                                          start_date, end_date):
            test_case.assertNotEquals(user, None)
            test_case.assertTrue(expected_engagement_score_calls.
                                 has_key((user, start_date, end_date)))
            return expected_engagement_score_calls[(user,
                                                 start_date, end_date)]
    
    (EngagementReportGenerator(EngagementScoreCalculatorStub()).
       generate_daily_report_for_experiment(self.experiment, report_date))

    
    experiment_report = DailyEngagementReport.objects.get(
                            experiment=self.experiment, date=report_date)
    self.assertAlmostEqual((3.2 + 2.5 + 4.1 + 0)/4.0,
                            experiment_report.test_score)
    self.assertAlmostEqual(0.0, experiment_report.control_score)
    self.assertEquals(4, experiment_report.test_group_size)
    self.assertEquals(4, experiment_report.control_group_size)
    self.assertAlmostEqual(96.819293337188498, experiment_report.confidence)"
"<NME> questionanswer.py
<BEF> @staticmethod
def tokenize(sentence):
    """"""
    Split a sentence into tokens including punctuation.

    Args:
        sentence (string) : String of sentence to tokenize.

    Returns:
        list : List of tokens.
    """"""
    return [sentence.strip() for x in re.split('(\W+)?', sentence) if x.strip()]
<MSG> Fix incorrect variable name
<DFF> @@ -9,4 +9,4 @@
     Returns:
         list : List of tokens.
     """"""
-    return [sentence.strip() for x in re.split('(\W+)?', sentence) if x.strip()]
+    return [x.strip() for x in re.split('(\W+)?', sentence) if x.strip()]","@staticmethod
def tokenize(sentence):
    """"""
    Split a sentence into tokens including punctuation.

    Args:
        sentence (string) : String of sentence to tokenize.

    Returns:
        list : List of tokens.
    """"""
    return [x.strip() for x in re.split('(\W+)?', sentence) if x.strip()]",4,"<NME> questionanswer.py
<BEF> @staticmethod
def tokenize(sentence):
    """"""
    Split a sentence into tokens including punctuation.

    Args:
        sentence (string) : String of sentence to tokenize.

    Returns:
        list : List of tokens.
    """"""
    return [sentence.strip() for x in re.split('(\W+)?', sentence) if x.strip()]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@staticmethod
def tokenize(sentence):
    """"""
    Split a sentence into tokens including punctuation.

    Args:
        sentence (string) : String of sentence to tokenize.

    Returns:
        list : List of tokens.
    """"""
    return [sentence.strip() for x in re.split('(\W+)?', sentence) if x.strip()]"
"<NME> CellEditor.py
<BEF> def _OnChar(self, event):
    ""Handle the OnChar event by rejecting non-numerics""
    if event.GetModifiers() != 0 and self.GetModifiers() != wx.MOD_SHIFT:
        event.Skip()
        return

    if event.GetKeyCode() in self.acceptableCodes:
        event.Skip()
        return

    wx.Bell()
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def _OnChar(self, event):
     ""Handle the OnChar event by rejecting non-numerics""
-    if event.GetModifiers() != 0 and self.GetModifiers() != wx.MOD_SHIFT:
+    if event.GetModifiers() != 0 and event.GetModifiers() != wx.MOD_SHIFT:
         event.Skip()
         return
 ","def _OnChar(self, event):
    ""Handle the OnChar event by rejecting non-numerics""
    if event.GetModifiers() != 0 and event.GetModifiers() != wx.MOD_SHIFT:
        event.Skip()
        return

    if event.GetKeyCode() in self.acceptableCodes:
        event.Skip()
        return

    wx.Bell()",5,"<NME> CellEditor.py
<BEF> def _OnChar(self, event):
    ""Handle the OnChar event by rejecting non-numerics""
    if event.GetModifiers() != 0 and self.GetModifiers() != wx.MOD_SHIFT:
        event.Skip()
        return

    if event.GetKeyCode() in self.acceptableCodes:
        event.Skip()
        return

    wx.Bell()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _OnChar(self, event):
    ""Handle the OnChar event by rejecting non-numerics""
    if event.GetModifiers() != 0 and self.GetModifiers() != wx.MOD_SHIFT:
        event.Skip()
        return

    if event.GetKeyCode() in self.acceptableCodes:
        event.Skip()
        return

    wx.Bell()"
"<NME> virtualObjectListviewExample.py
<BEF> def __init__(self, title, artist, album, sizeInBytes, lastPlayed, rating):
    self.title = title
    self.artist = artist
    self.album = album
    a = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"")
    datenp = np.datetime64(a)
    self.lastPlayed = datenp
    # self.date = datenp - datenp.astype('datetime64[M]') + 1

    self.years = datenp.astype('datetime64[Y]').astype(int) + 1970
    #months = dates.astype('datetime64[M]').astype(int) % 12 + 1

    #self.lastPlayed = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"")
    #self.date = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"").date()
    #self.time = unicode(datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"").time())
    # print ""type of self.time: "", type(self.time), str(self.time)

    self.sizeInBytes = sizeInBytes
    self.rating = a
<MSG> Fix incorrect variable name
<DFF> @@ -16,4 +16,4 @@
     # print ""type of self.time: "", type(self.time), str(self.time)
 
     self.sizeInBytes = sizeInBytes
-    self.rating = a
+    self.rating = rating","def __init__(self, title, artist, album, sizeInBytes, lastPlayed, rating):
    self.title = title
    self.artist = artist
    self.album = album
    a = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"")
    datenp = np.datetime64(a)
    self.lastPlayed = datenp
    # self.date = datenp - datenp.astype('datetime64[M]') + 1

    self.years = datenp.astype('datetime64[Y]').astype(int) + 1970
    #months = dates.astype('datetime64[M]').astype(int) % 12 + 1

    #self.lastPlayed = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"")
    #self.date = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"").date()
    #self.time = unicode(datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"").time())
    # print ""type of self.time: "", type(self.time), str(self.time)

    self.sizeInBytes = sizeInBytes
    self.rating = rating",6,"<NME> virtualObjectListviewExample.py
<BEF> def __init__(self, title, artist, album, sizeInBytes, lastPlayed, rating):
    self.title = title
    self.artist = artist
    self.album = album
    a = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"")
    datenp = np.datetime64(a)
    self.lastPlayed = datenp
    # self.date = datenp - datenp.astype('datetime64[M]') + 1

    self.years = datenp.astype('datetime64[Y]').astype(int) + 1970
    #months = dates.astype('datetime64[M]').astype(int) % 12 + 1

    #self.lastPlayed = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"")
    #self.date = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"").date()
    #self.time = unicode(datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"").time())
    # print ""type of self.time: "", type(self.time), str(self.time)

    self.sizeInBytes = sizeInBytes
    self.rating = a
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, title, artist, album, sizeInBytes, lastPlayed, rating):
    self.title = title
    self.artist = artist
    self.album = album
    a = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"")
    datenp = np.datetime64(a)
    self.lastPlayed = datenp
    # self.date = datenp - datenp.astype('datetime64[M]') + 1

    self.years = datenp.astype('datetime64[Y]').astype(int) + 1970
    #months = dates.astype('datetime64[M]').astype(int) % 12 + 1

    #self.lastPlayed = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"")
    #self.date = datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"").date()
    #self.time = unicode(datetime.datetime.strptime(lastPlayed, ""%d/%m/%Y %H:%M"").time())
    # print ""type of self.time: "", type(self.time), str(self.time)

    self.sizeInBytes = sizeInBytes
    self.rating = a"
"<NME> updates.py
<BEF> def __call__(self, params, cost):
    updates = []
    grads = T.grad(cost, params)
    grads = clip_norms(grads, self.clipnorm)  
    t = theano.shared(floatX(1.))
    b1_t = self.b1*self.l**(t-1)
 
    for p, g in zip(params, self):
        g = self.regularizer.gradient_regularize(p, g)
        m = theano.shared(p.get_value() * 0.)
        v = theano.shared(p.get_value() * 0.)
 
        m_t = b1_t*m + (1 - b1_t)*g
        v_t = self.b2*v + (1 - self.b2)*g**2
        m_c = m_t / (1-self.b1**t)
        v_c = v_t / (1-self.b2**t)
        p_t = p - (self.lr * m_c) / (T.sqrt(v_c) + self.e)
        p_t = self.regularizer.weight_regularize(p_t)
        updates.append((m, m_t))
        updates.append((v, v_t))
        updates.append((p, p_t) )
    updates.append((t, t + 1.))
    return updates
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
     t = theano.shared(floatX(1.))
     b1_t = self.b1*self.l**(t-1)
  
-    for p, g in zip(params, self):
+    for p, g in zip(params, grads):
         g = self.regularizer.gradient_regularize(p, g)
         m = theano.shared(p.get_value() * 0.)
         v = theano.shared(p.get_value() * 0.)","def __call__(self, params, cost):
    updates = []
    grads = T.grad(cost, params)
    grads = clip_norms(grads, self.clipnorm)  
    t = theano.shared(floatX(1.))
    b1_t = self.b1*self.l**(t-1)
 
    for p, g in zip(params, grads):
        g = self.regularizer.gradient_regularize(p, g)
        m = theano.shared(p.get_value() * 0.)
        v = theano.shared(p.get_value() * 0.)
 
        m_t = b1_t*m + (1 - b1_t)*g
        v_t = self.b2*v + (1 - self.b2)*g**2
        m_c = m_t / (1-self.b1**t)
        v_c = v_t / (1-self.b2**t)
        p_t = p - (self.lr * m_c) / (T.sqrt(v_c) + self.e)
        p_t = self.regularizer.weight_regularize(p_t)
        updates.append((m, m_t))
        updates.append((v, v_t))
        updates.append((p, p_t) )
    updates.append((t, t + 1.))
    return updates",7,"<NME> updates.py
<BEF> def __call__(self, params, cost):
    updates = []
    grads = T.grad(cost, params)
    grads = clip_norms(grads, self.clipnorm)  
    t = theano.shared(floatX(1.))
    b1_t = self.b1*self.l**(t-1)
 
    for p, g in zip(params, self):
        g = self.regularizer.gradient_regularize(p, g)
        m = theano.shared(p.get_value() * 0.)
        v = theano.shared(p.get_value() * 0.)
 
        m_t = b1_t*m + (1 - b1_t)*g
        v_t = self.b2*v + (1 - self.b2)*g**2
        m_c = m_t / (1-self.b1**t)
        v_c = v_t / (1-self.b2**t)
        p_t = p - (self.lr * m_c) / (T.sqrt(v_c) + self.e)
        p_t = self.regularizer.weight_regularize(p_t)
        updates.append((m, m_t))
        updates.append((v, v_t))
        updates.append((p, p_t) )
    updates.append((t, t + 1.))
    return updates
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __call__(self, params, cost):
    updates = []
    grads = T.grad(cost, params)
    grads = clip_norms(grads, self.clipnorm)  
    t = theano.shared(floatX(1.))
    b1_t = self.b1*self.l**(t-1)
 
    for p, g in zip(params, self):
        g = self.regularizer.gradient_regularize(p, g)
        m = theano.shared(p.get_value() * 0.)
        v = theano.shared(p.get_value() * 0.)
 
        m_t = b1_t*m + (1 - b1_t)*g
        v_t = self.b2*v + (1 - self.b2)*g**2
        m_c = m_t / (1-self.b1**t)
        v_c = v_t / (1-self.b2**t)
        p_t = p - (self.lr * m_c) / (T.sqrt(v_c) + self.e)
        p_t = self.regularizer.weight_regularize(p_t)
        updates.append((m, m_t))
        updates.append((v, v_t))
        updates.append((p, p_t) )
    updates.append((t, t + 1.))
    return updates"
"<NME> layer.py
<BEF> def configure(self, in_obj):
    super(ColorNoise, self).configure(in_obj)
    self.out_shape = self.in_shape
    try:
        self.nfm, self.H, self.W = self.in_shape
        self.HW = in_obj.H * self.W
    except:
        raise AttributeError('ColorNoise can only be used with layer providing CHW')
    return self
<MSG> Fix incorrect variable name
<DFF> @@ -3,7 +3,7 @@
     self.out_shape = self.in_shape
     try:
         self.nfm, self.H, self.W = self.in_shape
-        self.HW = in_obj.H * self.W
+        self.HW = self.H * self.W
     except:
         raise AttributeError('ColorNoise can only be used with layer providing CHW')
     return self","def configure(self, in_obj):
    super(ColorNoise, self).configure(in_obj)
    self.out_shape = self.in_shape
    try:
        self.nfm, self.H, self.W = self.in_shape
        self.HW = self.H * self.W
    except:
        raise AttributeError('ColorNoise can only be used with layer providing CHW')
    return self",8,"<NME> layer.py
<BEF> def configure(self, in_obj):
    super(ColorNoise, self).configure(in_obj)
    self.out_shape = self.in_shape
    try:
        self.nfm, self.H, self.W = self.in_shape
        self.HW = in_obj.H * self.W
    except:
        raise AttributeError('ColorNoise can only be used with layer providing CHW')
    return self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def configure(self, in_obj):
    super(ColorNoise, self).configure(in_obj)
    self.out_shape = self.in_shape
    try:
        self.nfm, self.H, self.W = self.in_shape
        self.HW = in_obj.H * self.W
    except:
        raise AttributeError('ColorNoise can only be used with layer providing CHW')
    return self"
"<NME> ListCtrlPrinter.py
<BEF> def SetCellPadding(self, padding):
    """"""
    Set the padding around cells in this format

    Padding is either a single numeric (indicating the values on all sides)
    or a collection of paddings [left, top, right, bottom]
    """"""
    self.cellPadding = padding._MakePadding(padding)
<MSG> Fix incorrect variable name
<DFF> @@ -5,4 +5,4 @@
     Padding is either a single numeric (indicating the values on all sides)
     or a collection of paddings [left, top, right, bottom]
     """"""
-    self.cellPadding = padding._MakePadding(padding)
+    self.cellPadding = self._MakePadding(padding)","def SetCellPadding(self, padding):
    """"""
    Set the padding around cells in this format

    Padding is either a single numeric (indicating the values on all sides)
    or a collection of paddings [left, top, right, bottom]
    """"""
    self.cellPadding = self._MakePadding(padding)",9,"<NME> ListCtrlPrinter.py
<BEF> def SetCellPadding(self, padding):
    """"""
    Set the padding around cells in this format

    Padding is either a single numeric (indicating the values on all sides)
    or a collection of paddings [left, top, right, bottom]
    """"""
    self.cellPadding = padding._MakePadding(padding)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def SetCellPadding(self, padding):
    """"""
    Set the padding around cells in this format

    Padding is either a single numeric (indicating the values on all sides)
    or a collection of paddings [left, top, right, bottom]
    """"""
    self.cellPadding = padding._MakePadding(padding)"
"<NME> frmODMTools.py
<BEF> def addEdit(self, event):

    with wx.BusyInfo(""Please wait for a moment while ODMTools fetches the data and stores it in our database"", parent=self):
        logger.debug(""Beginning editing"")
        isSelected, seriesID = self.pnlSelector.onReadyToEdit()

        # logger.debug(""Initializing DataTable"")
        # # tasks = [(""dataTable"", (memDB.conn, self.dataTable.myOlv))]
        # tasks = [(""dataTable"", (self.dataTable.myOlv))]
        # self.taskserver.setTasks(tasks)
        # self.taskserver.processTasks()

        if isSelected:
            self.record_service = self.service_manager.get_record_service(self.txtPythonScript, seriesID,
                                                                          connection=self.memDB)
            self._ribbon.toggleEditButtons(True)

            logger.debug(""Initializing Plot"")
            self.pnlPlot.addEditPlot(isSelected.memDB, seriesID, self.record_service)

            logger.debug(""Initializing DataTable"")
            self.dataTable.init(self.memDB)

            # set record service for console
            Publisher.sendMessage(""setEdit"", isEdit=True)
            logger.debug(""Enabling Edit"")
            self.record_service.toggle_record(True)

            # set the cursor for matplotlib
            selectedObject = self.record_service.get_series()
            Publisher.sendMessage(""updateCursor"", selectedObject=selectedObject)

        else:
            logger.debug(""disabling Edit"")
            Publisher.sendMessage(""setEdit"", isEdit=False)

            self.record_service.toggle_record(False)

            # disable cursor for matplotlib
            selectedObject = self.record_service.get_series()
            Publisher.sendMessage(""updateCursor"", deselectedObject=selectedObject)


        # self._mgr.Update()

        logger.debug(""Recording? %s"" % self.record_service._record)


        #self.record_service = None
        self.txtPythonConsole.shell.run(""edit_service = app.TopWindow.record_service"", prompt=False, verbose=False)
        self.txtPythonConsole.shell.run(""series_service = edit_service.get_series_service()"", prompt=False,
                                        verbose=False)

        #from meliae import scanner
        #scanner.dump_all_objects(""edit_plotting.dat"")
        logger.info(""Finished Setting up Editing Series: %s "" % seriesID)
<MSG> Fix incorrect variable name
<DFF> @@ -16,7 +16,7 @@
             self._ribbon.toggleEditButtons(True)
 
             logger.debug(""Initializing Plot"")
-            self.pnlPlot.addEditPlot(isSelected.memDB, seriesID, self.record_service)
+            self.pnlPlot.addEditPlot(self.memDB, seriesID, self.record_service)
 
             logger.debug(""Initializing DataTable"")
             self.dataTable.init(self.memDB)","def addEdit(self, event):

    with wx.BusyInfo(""Please wait for a moment while ODMTools fetches the data and stores it in our database"", parent=self):
        logger.debug(""Beginning editing"")
        isSelected, seriesID = self.pnlSelector.onReadyToEdit()

        # logger.debug(""Initializing DataTable"")
        # # tasks = [(""dataTable"", (memDB.conn, self.dataTable.myOlv))]
        # tasks = [(""dataTable"", (self.dataTable.myOlv))]
        # self.taskserver.setTasks(tasks)
        # self.taskserver.processTasks()

        if isSelected:
            self.record_service = self.service_manager.get_record_service(self.txtPythonScript, seriesID,
                                                                          connection=self.memDB)
            self._ribbon.toggleEditButtons(True)

            logger.debug(""Initializing Plot"")
            self.pnlPlot.addEditPlot(self.memDB, seriesID, self.record_service)

            logger.debug(""Initializing DataTable"")
            self.dataTable.init(self.memDB)

            # set record service for console
            Publisher.sendMessage(""setEdit"", isEdit=True)
            logger.debug(""Enabling Edit"")
            self.record_service.toggle_record(True)

            # set the cursor for matplotlib
            selectedObject = self.record_service.get_series()
            Publisher.sendMessage(""updateCursor"", selectedObject=selectedObject)

        else:
            logger.debug(""disabling Edit"")
            Publisher.sendMessage(""setEdit"", isEdit=False)

            self.record_service.toggle_record(False)

            # disable cursor for matplotlib
            selectedObject = self.record_service.get_series()
            Publisher.sendMessage(""updateCursor"", deselectedObject=selectedObject)


        # self._mgr.Update()

        logger.debug(""Recording? %s"" % self.record_service._record)


        #self.record_service = None
        self.txtPythonConsole.shell.run(""edit_service = app.TopWindow.record_service"", prompt=False, verbose=False)
        self.txtPythonConsole.shell.run(""series_service = edit_service.get_series_service()"", prompt=False,
                                        verbose=False)

        #from meliae import scanner
        #scanner.dump_all_objects(""edit_plotting.dat"")
        logger.info(""Finished Setting up Editing Series: %s "" % seriesID)",0,"<NME> frmODMTools.py
<BEF> def addEdit(self, event):

    with wx.BusyInfo(""Please wait for a moment while ODMTools fetches the data and stores it in our database"", parent=self):
        logger.debug(""Beginning editing"")
        isSelected, seriesID = self.pnlSelector.onReadyToEdit()

        # logger.debug(""Initializing DataTable"")
        # # tasks = [(""dataTable"", (memDB.conn, self.dataTable.myOlv))]
        # tasks = [(""dataTable"", (self.dataTable.myOlv))]
        # self.taskserver.setTasks(tasks)
        # self.taskserver.processTasks()

        if isSelected:
            self.record_service = self.service_manager.get_record_service(self.txtPythonScript, seriesID,
                                                                          connection=self.memDB)
            self._ribbon.toggleEditButtons(True)

            logger.debug(""Initializing Plot"")
            self.pnlPlot.addEditPlot(isSelected.memDB, seriesID, self.record_service)

            logger.debug(""Initializing DataTable"")
            self.dataTable.init(self.memDB)

            # set record service for console
            Publisher.sendMessage(""setEdit"", isEdit=True)
            logger.debug(""Enabling Edit"")
            self.record_service.toggle_record(True)

            # set the cursor for matplotlib
            selectedObject = self.record_service.get_series()
            Publisher.sendMessage(""updateCursor"", selectedObject=selectedObject)

        else:
            logger.debug(""disabling Edit"")
            Publisher.sendMessage(""setEdit"", isEdit=False)

            self.record_service.toggle_record(False)

            # disable cursor for matplotlib
            selectedObject = self.record_service.get_series()
            Publisher.sendMessage(""updateCursor"", deselectedObject=selectedObject)


        # self._mgr.Update()

        logger.debug(""Recording? %s"" % self.record_service._record)


        #self.record_service = None
        self.txtPythonConsole.shell.run(""edit_service = app.TopWindow.record_service"", prompt=False, verbose=False)
        self.txtPythonConsole.shell.run(""series_service = edit_service.get_series_service()"", prompt=False,
                                        verbose=False)

        #from meliae import scanner
        #scanner.dump_all_objects(""edit_plotting.dat"")
        logger.info(""Finished Setting up Editing Series: %s "" % seriesID)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def addEdit(self, event):

    with wx.BusyInfo(""Please wait for a moment while ODMTools fetches the data and stores it in our database"", parent=self):
        logger.debug(""Beginning editing"")
        isSelected, seriesID = self.pnlSelector.onReadyToEdit()

        # logger.debug(""Initializing DataTable"")
        # # tasks = [(""dataTable"", (memDB.conn, self.dataTable.myOlv))]
        # tasks = [(""dataTable"", (self.dataTable.myOlv))]
        # self.taskserver.setTasks(tasks)
        # self.taskserver.processTasks()

        if isSelected:
            self.record_service = self.service_manager.get_record_service(self.txtPythonScript, seriesID,
                                                                          connection=self.memDB)
            self._ribbon.toggleEditButtons(True)

            logger.debug(""Initializing Plot"")
            self.pnlPlot.addEditPlot(isSelected.memDB, seriesID, self.record_service)

            logger.debug(""Initializing DataTable"")
            self.dataTable.init(self.memDB)

            # set record service for console
            Publisher.sendMessage(""setEdit"", isEdit=True)
            logger.debug(""Enabling Edit"")
            self.record_service.toggle_record(True)

            # set the cursor for matplotlib
            selectedObject = self.record_service.get_series()
            Publisher.sendMessage(""updateCursor"", selectedObject=selectedObject)

        else:
            logger.debug(""disabling Edit"")
            Publisher.sendMessage(""setEdit"", isEdit=False)

            self.record_service.toggle_record(False)

            # disable cursor for matplotlib
            selectedObject = self.record_service.get_series()
            Publisher.sendMessage(""updateCursor"", deselectedObject=selectedObject)


        # self._mgr.Update()

        logger.debug(""Recording? %s"" % self.record_service._record)


        #self.record_service = None
        self.txtPythonConsole.shell.run(""edit_service = app.TopWindow.record_service"", prompt=False, verbose=False)
        self.txtPythonConsole.shell.run(""series_service = edit_service.get_series_service()"", prompt=False,
                                        verbose=False)

        #from meliae import scanner
        #scanner.dump_all_objects(""edit_plotting.dat"")
        logger.info(""Finished Setting up Editing Series: %s "" % seriesID)"
"<NME> test_series.py
<BEF> def test_qcl_relationship(self):
    qcl = self.series.quality_control_level
    assert self != None
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def test_qcl_relationship(self):
     qcl = self.series.quality_control_level
-    assert self != None
+    assert qcl != None","def test_qcl_relationship(self):
    qcl = self.series.quality_control_level
    assert qcl != None",1,"<NME> test_series.py
<BEF> def test_qcl_relationship(self):
    qcl = self.series.quality_control_level
    assert self != None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_qcl_relationship(self):
    qcl = self.series.quality_control_level
    assert self != None"
"<NME> p_lineprofiler.py
<BEF> def analyze(self, filename):
    """"""Reimplement analyze method""""""
    if self.dockwidget and not self.ismaximized:
        self.dockwidget.setVisible(True)
        self.dockwidget.setFocus()
        self.dockwidget.raise_()
    pythonpath = self.main.get_spyder_pythonpath()
    runconf = runconfig.get_run_configuration(filename)
    wdir, args = None, None
    if runconf is not None:
        if runconf.wdir_enabled:
            wdir = runconf.wdir
        if filename.args_enabled:
            args = runconf.args

    LineProfilerWidget.analyze(
        self, filename, wdir=wdir, args=args, pythonpath=pythonpath,
        use_colors=self.get_option('use_colors', True))
<MSG> Fix incorrect variable name
<DFF> @@ -10,7 +10,7 @@
     if runconf is not None:
         if runconf.wdir_enabled:
             wdir = runconf.wdir
-        if filename.args_enabled:
+        if runconf.args_enabled:
             args = runconf.args
 
     LineProfilerWidget.analyze(","def analyze(self, filename):
    """"""Reimplement analyze method""""""
    if self.dockwidget and not self.ismaximized:
        self.dockwidget.setVisible(True)
        self.dockwidget.setFocus()
        self.dockwidget.raise_()
    pythonpath = self.main.get_spyder_pythonpath()
    runconf = runconfig.get_run_configuration(filename)
    wdir, args = None, None
    if runconf is not None:
        if runconf.wdir_enabled:
            wdir = runconf.wdir
        if runconf.args_enabled:
            args = runconf.args

    LineProfilerWidget.analyze(
        self, filename, wdir=wdir, args=args, pythonpath=pythonpath,
        use_colors=self.get_option('use_colors', True))",2,"<NME> p_lineprofiler.py
<BEF> def analyze(self, filename):
    """"""Reimplement analyze method""""""
    if self.dockwidget and not self.ismaximized:
        self.dockwidget.setVisible(True)
        self.dockwidget.setFocus()
        self.dockwidget.raise_()
    pythonpath = self.main.get_spyder_pythonpath()
    runconf = runconfig.get_run_configuration(filename)
    wdir, args = None, None
    if runconf is not None:
        if runconf.wdir_enabled:
            wdir = runconf.wdir
        if filename.args_enabled:
            args = runconf.args

    LineProfilerWidget.analyze(
        self, filename, wdir=wdir, args=args, pythonpath=pythonpath,
        use_colors=self.get_option('use_colors', True))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def analyze(self, filename):
    """"""Reimplement analyze method""""""
    if self.dockwidget and not self.ismaximized:
        self.dockwidget.setVisible(True)
        self.dockwidget.setFocus()
        self.dockwidget.raise_()
    pythonpath = self.main.get_spyder_pythonpath()
    runconf = runconfig.get_run_configuration(filename)
    wdir, args = None, None
    if runconf is not None:
        if runconf.wdir_enabled:
            wdir = runconf.wdir
        if filename.args_enabled:
            args = runconf.args

    LineProfilerWidget.analyze(
        self, filename, wdir=wdir, args=args, pythonpath=pythonpath,
        use_colors=self.get_option('use_colors', True))"
"<NME> float_ew.py
<BEF> def _split_stages(node, duplicates=None, aliases=None, stages=None, parents=None):
    """"""
    Split out all reductions and post reduction scalar operations into seperate
    stacks (stages)
    This leaves remaining in the tree anything not in these categories.
    """"""

    # init data structures
    if duplicates is None:
        duplicates = dict()
        aliases = set()
        stages = list()
        parents = list()

    if type(node) is list:

        # don't count assignment node as a parent,
        # it will always exist in the final stage which is processed outside of
        # this function
        if node[0][0] != ""assign"":
            parents.append(node)

        # post order traversal (pulls the stages deepest in the tree first)
        if len(node) > 3:
            _split_stages(node[3], duplicates, aliases, stages, parents)
        if len(node) > 4:
            _split_stages(node[4], duplicates, aliases, stages, parents)

        if len(parents) > 0:
            parents.pop()

        if node[0][0] in _reduction_ops:

            red_stack = _process_node(node, aliases, duplicates)
            if red_stack:
                # add this reduction stack to the stages
                stages.append((""reduction"", red_stack))

            # decrement reduction count for all parents
            for parent in parents:
                parent[2] -= 1

            # walk up the parent list
            # TODO: potentially do this iteratively to find longest common set
            # of operations
            scalar_parent = None
            for parents in parents[::-1]:
                # find the highest parent that is both scalar and has no other
                # child reductions
                if parent[1] and parent[2] == 0:
                    scalar_parent = parent
                else:
                    break

            # if there are any scalar operations over this reduction, remove
            # them from the tree as well
            if scalar_parent is not None:

                scalar_stack = _process_node(
                    scalar_parent, aliases, duplicates)
                if scalar_stack:
                    # add this scalar stack to the stages
                    stages.append((""scalar"", scalar_stack))

    return stages
<MSG> Fix incorrect variable name
<DFF> @@ -44,7 +44,7 @@
             # TODO: potentially do this iteratively to find longest common set
             # of operations
             scalar_parent = None
-            for parents in parents[::-1]:
+            for parent in parents[::-1]:
                 # find the highest parent that is both scalar and has no other
                 # child reductions
                 if parent[1] and parent[2] == 0:","def _split_stages(node, duplicates=None, aliases=None, stages=None, parents=None):
    """"""
    Split out all reductions and post reduction scalar operations into seperate
    stacks (stages)
    This leaves remaining in the tree anything not in these categories.
    """"""

    # init data structures
    if duplicates is None:
        duplicates = dict()
        aliases = set()
        stages = list()
        parents = list()

    if type(node) is list:

        # don't count assignment node as a parent,
        # it will always exist in the final stage which is processed outside of
        # this function
        if node[0][0] != ""assign"":
            parents.append(node)

        # post order traversal (pulls the stages deepest in the tree first)
        if len(node) > 3:
            _split_stages(node[3], duplicates, aliases, stages, parents)
        if len(node) > 4:
            _split_stages(node[4], duplicates, aliases, stages, parents)

        if len(parents) > 0:
            parents.pop()

        if node[0][0] in _reduction_ops:

            red_stack = _process_node(node, aliases, duplicates)
            if red_stack:
                # add this reduction stack to the stages
                stages.append((""reduction"", red_stack))

            # decrement reduction count for all parents
            for parent in parents:
                parent[2] -= 1

            # walk up the parent list
            # TODO: potentially do this iteratively to find longest common set
            # of operations
            scalar_parent = None
            for parent in parents[::-1]:
                # find the highest parent that is both scalar and has no other
                # child reductions
                if parent[1] and parent[2] == 0:
                    scalar_parent = parent
                else:
                    break

            # if there are any scalar operations over this reduction, remove
            # them from the tree as well
            if scalar_parent is not None:

                scalar_stack = _process_node(
                    scalar_parent, aliases, duplicates)
                if scalar_stack:
                    # add this scalar stack to the stages
                    stages.append((""scalar"", scalar_stack))

    return stages",3,"<NME> float_ew.py
<BEF> def _split_stages(node, duplicates=None, aliases=None, stages=None, parents=None):
    """"""
    Split out all reductions and post reduction scalar operations into seperate
    stacks (stages)
    This leaves remaining in the tree anything not in these categories.
    """"""

    # init data structures
    if duplicates is None:
        duplicates = dict()
        aliases = set()
        stages = list()
        parents = list()

    if type(node) is list:

        # don't count assignment node as a parent,
        # it will always exist in the final stage which is processed outside of
        # this function
        if node[0][0] != ""assign"":
            parents.append(node)

        # post order traversal (pulls the stages deepest in the tree first)
        if len(node) > 3:
            _split_stages(node[3], duplicates, aliases, stages, parents)
        if len(node) > 4:
            _split_stages(node[4], duplicates, aliases, stages, parents)

        if len(parents) > 0:
            parents.pop()

        if node[0][0] in _reduction_ops:

            red_stack = _process_node(node, aliases, duplicates)
            if red_stack:
                # add this reduction stack to the stages
                stages.append((""reduction"", red_stack))

            # decrement reduction count for all parents
            for parent in parents:
                parent[2] -= 1

            # walk up the parent list
            # TODO: potentially do this iteratively to find longest common set
            # of operations
            scalar_parent = None
            for parents in parents[::-1]:
                # find the highest parent that is both scalar and has no other
                # child reductions
                if parent[1] and parent[2] == 0:
                    scalar_parent = parent
                else:
                    break

            # if there are any scalar operations over this reduction, remove
            # them from the tree as well
            if scalar_parent is not None:

                scalar_stack = _process_node(
                    scalar_parent, aliases, duplicates)
                if scalar_stack:
                    # add this scalar stack to the stages
                    stages.append((""scalar"", scalar_stack))

    return stages
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _split_stages(node, duplicates=None, aliases=None, stages=None, parents=None):
    """"""
    Split out all reductions and post reduction scalar operations into seperate
    stacks (stages)
    This leaves remaining in the tree anything not in these categories.
    """"""

    # init data structures
    if duplicates is None:
        duplicates = dict()
        aliases = set()
        stages = list()
        parents = list()

    if type(node) is list:

        # don't count assignment node as a parent,
        # it will always exist in the final stage which is processed outside of
        # this function
        if node[0][0] != ""assign"":
            parents.append(node)

        # post order traversal (pulls the stages deepest in the tree first)
        if len(node) > 3:
            _split_stages(node[3], duplicates, aliases, stages, parents)
        if len(node) > 4:
            _split_stages(node[4], duplicates, aliases, stages, parents)

        if len(parents) > 0:
            parents.pop()

        if node[0][0] in _reduction_ops:

            red_stack = _process_node(node, aliases, duplicates)
            if red_stack:
                # add this reduction stack to the stages
                stages.append((""reduction"", red_stack))

            # decrement reduction count for all parents
            for parent in parents:
                parent[2] -= 1

            # walk up the parent list
            # TODO: potentially do this iteratively to find longest common set
            # of operations
            scalar_parent = None
            for parents in parents[::-1]:
                # find the highest parent that is both scalar and has no other
                # child reductions
                if parent[1] and parent[2] == 0:
                    scalar_parent = parent
                else:
                    break

            # if there are any scalar operations over this reduction, remove
            # them from the tree as well
            if scalar_parent is not None:

                scalar_stack = _process_node(
                    scalar_parent, aliases, duplicates)
                if scalar_stack:
                    # add this scalar stack to the stages
                    stages.append((""scalar"", scalar_stack))

    return stages"
"<NME> trello.py
<BEF> def on_next(self, element):
    self._post_message(self.formatter.create_element_message(self))
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def on_next(self, element):
-    self._post_message(self.formatter.create_element_message(self))
+    self._post_message(self.formatter.create_element_message(element))","def on_next(self, element):
    self._post_message(self.formatter.create_element_message(element))",4,"<NME> trello.py
<BEF> def on_next(self, element):
    self._post_message(self.formatter.create_element_message(self))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def on_next(self, element):
    self._post_message(self.formatter.create_element_message(self))"
"<NME> feedback.py
<BEF> def getXMLElement(self):
    item = ElementTree.Element('item', self.attrb)
    for (k, v) in self.content.iteritems():
        attrb = {}
        if k == 'icon' and self.icon_type:
            attrb['type'] = self.icon_type
        sub = ElementTree.SubElement(self, k, attrb)
        sub.text = v
    return item
<MSG> Fix incorrect variable name
<DFF> @@ -4,6 +4,6 @@
         attrb = {}
         if k == 'icon' and self.icon_type:
             attrb['type'] = self.icon_type
-        sub = ElementTree.SubElement(self, k, attrb)
+        sub = ElementTree.SubElement(item, k, attrb)
         sub.text = v
     return item","def getXMLElement(self):
    item = ElementTree.Element('item', self.attrb)
    for (k, v) in self.content.iteritems():
        attrb = {}
        if k == 'icon' and self.icon_type:
            attrb['type'] = self.icon_type
        sub = ElementTree.SubElement(item, k, attrb)
        sub.text = v
    return item",5,"<NME> feedback.py
<BEF> def getXMLElement(self):
    item = ElementTree.Element('item', self.attrb)
    for (k, v) in self.content.iteritems():
        attrb = {}
        if k == 'icon' and self.icon_type:
            attrb['type'] = self.icon_type
        sub = ElementTree.SubElement(self, k, attrb)
        sub.text = v
    return item
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def getXMLElement(self):
    item = ElementTree.Element('item', self.attrb)
    for (k, v) in self.content.iteritems():
        attrb = {}
        if k == 'icon' and self.icon_type:
            attrb['type'] = self.icon_type
        sub = ElementTree.SubElement(self, k, attrb)
        sub.text = v
    return item"
"<NME> capture_audio.py
<BEF> def capture_seconds(num_seconds, chunksize, rate, width):
    num_buffers = int(float(num_seconds * rate) / chunksize)
    return capture_buffers(num_buffers, chunksize, rate, num_buffers)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def capture_seconds(num_seconds, chunksize, rate, width):
     num_buffers = int(float(num_seconds * rate) / chunksize)
-    return capture_buffers(num_buffers, chunksize, rate, num_buffers)
+    return capture_buffers(num_buffers, chunksize, rate, width)","def capture_seconds(num_seconds, chunksize, rate, width):
    num_buffers = int(float(num_seconds * rate) / chunksize)
    return capture_buffers(num_buffers, chunksize, rate, width)",6,"<NME> capture_audio.py
<BEF> def capture_seconds(num_seconds, chunksize, rate, width):
    num_buffers = int(float(num_seconds * rate) / chunksize)
    return capture_buffers(num_buffers, chunksize, rate, num_buffers)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def capture_seconds(num_seconds, chunksize, rate, width):
    num_buffers = int(float(num_seconds * rate) / chunksize)
    return capture_buffers(num_buffers, chunksize, rate, num_buffers)"
"<NME> recurrent.py
<BEF> def configure(self, in_obj):
    super(BiRNN, self).configure(in_obj)
    (self.nin, self.nsteps) = self.in_shape

    self.out_shape = (2 * self.nout, self.nsteps)
    self.gate_shape = (2 * self.nout * self.ngates, self.nsteps)

    if self.split_inputs is True and self.nin % 2 == 1:
        raise ValueError(""# inputs units is odd and split_inputs is True "")

    self.o_shape = (self.nout, self.nsteps)
    self.g_shape = (self.nout * self.ngates, in_obj.nsteps)
    self.i_shape = (
        self.nin/2, self.nsteps) if self.split_inputs else (self.nin, self.nsteps)

    if self.weight_shape is None:
        self.weight_shape = (self.nout, self.nin)
    return self
<MSG> Fix incorrect variable name
<DFF> @@ -9,7 +9,7 @@
         raise ValueError(""# inputs units is odd and split_inputs is True "")
 
     self.o_shape = (self.nout, self.nsteps)
-    self.g_shape = (self.nout * self.ngates, in_obj.nsteps)
+    self.g_shape = (self.nout * self.ngates, self.nsteps)
     self.i_shape = (
         self.nin/2, self.nsteps) if self.split_inputs else (self.nin, self.nsteps)
 ","def configure(self, in_obj):
    super(BiRNN, self).configure(in_obj)
    (self.nin, self.nsteps) = self.in_shape

    self.out_shape = (2 * self.nout, self.nsteps)
    self.gate_shape = (2 * self.nout * self.ngates, self.nsteps)

    if self.split_inputs is True and self.nin % 2 == 1:
        raise ValueError(""# inputs units is odd and split_inputs is True "")

    self.o_shape = (self.nout, self.nsteps)
    self.g_shape = (self.nout * self.ngates, self.nsteps)
    self.i_shape = (
        self.nin/2, self.nsteps) if self.split_inputs else (self.nin, self.nsteps)

    if self.weight_shape is None:
        self.weight_shape = (self.nout, self.nin)
    return self",7,"<NME> recurrent.py
<BEF> def configure(self, in_obj):
    super(BiRNN, self).configure(in_obj)
    (self.nin, self.nsteps) = self.in_shape

    self.out_shape = (2 * self.nout, self.nsteps)
    self.gate_shape = (2 * self.nout * self.ngates, self.nsteps)

    if self.split_inputs is True and self.nin % 2 == 1:
        raise ValueError(""# inputs units is odd and split_inputs is True "")

    self.o_shape = (self.nout, self.nsteps)
    self.g_shape = (self.nout * self.ngates, in_obj.nsteps)
    self.i_shape = (
        self.nin/2, self.nsteps) if self.split_inputs else (self.nin, self.nsteps)

    if self.weight_shape is None:
        self.weight_shape = (self.nout, self.nin)
    return self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def configure(self, in_obj):
    super(BiRNN, self).configure(in_obj)
    (self.nin, self.nsteps) = self.in_shape

    self.out_shape = (2 * self.nout, self.nsteps)
    self.gate_shape = (2 * self.nout * self.ngates, self.nsteps)

    if self.split_inputs is True and self.nin % 2 == 1:
        raise ValueError(""# inputs units is odd and split_inputs is True "")

    self.o_shape = (self.nout, self.nsteps)
    self.g_shape = (self.nout * self.ngates, in_obj.nsteps)
    self.i_shape = (
        self.nin/2, self.nsteps) if self.split_inputs else (self.nin, self.nsteps)

    if self.weight_shape is None:
        self.weight_shape = (self.nout, self.nin)
    return self"
"<NME> recurrent.py
<BEF> def init_params(self, shape):
    """"""
    Initialize params for GRU including weights and biases.
    The weight matrix and bias matrix are concatenated from the weights
    for inputs and weights for recurrent inputs and bias.
    The shape of the weights are (number of inputs + number of outputs +1 )
    by (number of outputs * 3)

    Arguments:
        shape (Tuple): contains number of outputs and number of inputs

    """"""
    super(GRU, self).init_params(shape)
    (nout, nin) = shape

    # indices for slicing gate buffers
    (rz1, rz2) = (0, nout * 2)
    (c1, c2) = (nout * 2, shape * 3)

    self.Wrz_recur = self.W_recur[rz1:rz2]
    self.Whcan_recur = self.W_recur[c1:c2]

    self.b_rz = self.b[rz1:rz2]
    self.b_hcan = self.b[c1:c2]

    self.dWrz_recur = self.dW_recur[rz1:rz2]
    self.dWhcan_recur = self.dW_recur[c1:c2]
<MSG> Fix incorrect variable name
<DFF> @@ -15,7 +15,7 @@
 
     # indices for slicing gate buffers
     (rz1, rz2) = (0, nout * 2)
-    (c1, c2) = (nout * 2, shape * 3)
+    (c1, c2) = (nout * 2, nout * 3)
 
     self.Wrz_recur = self.W_recur[rz1:rz2]
     self.Whcan_recur = self.W_recur[c1:c2]","def init_params(self, shape):
    """"""
    Initialize params for GRU including weights and biases.
    The weight matrix and bias matrix are concatenated from the weights
    for inputs and weights for recurrent inputs and bias.
    The shape of the weights are (number of inputs + number of outputs +1 )
    by (number of outputs * 3)

    Arguments:
        shape (Tuple): contains number of outputs and number of inputs

    """"""
    super(GRU, self).init_params(shape)
    (nout, nin) = shape

    # indices for slicing gate buffers
    (rz1, rz2) = (0, nout * 2)
    (c1, c2) = (nout * 2, nout * 3)

    self.Wrz_recur = self.W_recur[rz1:rz2]
    self.Whcan_recur = self.W_recur[c1:c2]

    self.b_rz = self.b[rz1:rz2]
    self.b_hcan = self.b[c1:c2]

    self.dWrz_recur = self.dW_recur[rz1:rz2]
    self.dWhcan_recur = self.dW_recur[c1:c2]",8,"<NME> recurrent.py
<BEF> def init_params(self, shape):
    """"""
    Initialize params for GRU including weights and biases.
    The weight matrix and bias matrix are concatenated from the weights
    for inputs and weights for recurrent inputs and bias.
    The shape of the weights are (number of inputs + number of outputs +1 )
    by (number of outputs * 3)

    Arguments:
        shape (Tuple): contains number of outputs and number of inputs

    """"""
    super(GRU, self).init_params(shape)
    (nout, nin) = shape

    # indices for slicing gate buffers
    (rz1, rz2) = (0, nout * 2)
    (c1, c2) = (nout * 2, shape * 3)

    self.Wrz_recur = self.W_recur[rz1:rz2]
    self.Whcan_recur = self.W_recur[c1:c2]

    self.b_rz = self.b[rz1:rz2]
    self.b_hcan = self.b[c1:c2]

    self.dWrz_recur = self.dW_recur[rz1:rz2]
    self.dWhcan_recur = self.dW_recur[c1:c2]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def init_params(self, shape):
    """"""
    Initialize params for GRU including weights and biases.
    The weight matrix and bias matrix are concatenated from the weights
    for inputs and weights for recurrent inputs and bias.
    The shape of the weights are (number of inputs + number of outputs +1 )
    by (number of outputs * 3)

    Arguments:
        shape (Tuple): contains number of outputs and number of inputs

    """"""
    super(GRU, self).init_params(shape)
    (nout, nin) = shape

    # indices for slicing gate buffers
    (rz1, rz2) = (0, nout * 2)
    (c1, c2) = (nout * 2, shape * 3)

    self.Wrz_recur = self.W_recur[rz1:rz2]
    self.Whcan_recur = self.W_recur[c1:c2]

    self.b_rz = self.b[rz1:rz2]
    self.b_hcan = self.b[c1:c2]

    self.dWrz_recur = self.dW_recur[rz1:rz2]
    self.dWhcan_recur = self.dW_recur[c1:c2]"
"<NME> panUpdate.py
<BEF> def createOpener():
  '''Create a generic opener for http
  This is particularly helpful when there is a proxy server in line'''
  # Thanks to: http://www.decalage.info/en/python/urllib2noproxy
  proxy_handler = urllib2.ProxyHandler(HTTP_PROXY)
  opener = urllib2.build_opener(opener)
  urllib2.install_opener(opener)
  return opener
<MSG> Fix incorrect variable name
<DFF> @@ -3,6 +3,6 @@
   This is particularly helpful when there is a proxy server in line'''
   # Thanks to: http://www.decalage.info/en/python/urllib2noproxy
   proxy_handler = urllib2.ProxyHandler(HTTP_PROXY)
-  opener = urllib2.build_opener(opener)
+  opener = urllib2.build_opener(proxy_handler)
   urllib2.install_opener(opener)
   return opener","def createOpener():
  '''Create a generic opener for http
  This is particularly helpful when there is a proxy server in line'''
  # Thanks to: http://www.decalage.info/en/python/urllib2noproxy
  proxy_handler = urllib2.ProxyHandler(HTTP_PROXY)
  opener = urllib2.build_opener(proxy_handler)
  urllib2.install_opener(opener)
  return opener",9,"<NME> panUpdate.py
<BEF> def createOpener():
  '''Create a generic opener for http
  This is particularly helpful when there is a proxy server in line'''
  # Thanks to: http://www.decalage.info/en/python/urllib2noproxy
  proxy_handler = urllib2.ProxyHandler(HTTP_PROXY)
  opener = urllib2.build_opener(opener)
  urllib2.install_opener(opener)
  return opener
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def createOpener():
  '''Create a generic opener for http
  This is particularly helpful when there is a proxy server in line'''
  # Thanks to: http://www.decalage.info/en/python/urllib2noproxy
  proxy_handler = urllib2.ProxyHandler(HTTP_PROXY)
  opener = urllib2.build_opener(opener)
  urllib2.install_opener(opener)
  return opener"
"<NME> implant.py
<BEF> def build(self):
    cmd = {'sender': self.sender,
            'receiver': self.receiver,
            'output': self.output,
            'cmd': cmd.cmd,
            'jobid': self.jobid}
    return base64.b64encode(json.dumps(cmd))
<MSG> Fix incorrect variable name
<DFF> @@ -2,6 +2,6 @@
     cmd = {'sender': self.sender,
             'receiver': self.receiver,
             'output': self.output,
-            'cmd': cmd.cmd,
+            'cmd': self.cmd,
             'jobid': self.jobid}
     return base64.b64encode(json.dumps(cmd))","def build(self):
    cmd = {'sender': self.sender,
            'receiver': self.receiver,
            'output': self.output,
            'cmd': self.cmd,
            'jobid': self.jobid}
    return base64.b64encode(json.dumps(cmd))",0,"<NME> implant.py
<BEF> def build(self):
    cmd = {'sender': self.sender,
            'receiver': self.receiver,
            'output': self.output,
            'cmd': cmd.cmd,
            'jobid': self.jobid}
    return base64.b64encode(json.dumps(cmd))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def build(self):
    cmd = {'sender': self.sender,
            'receiver': self.receiver,
            'output': self.output,
            'cmd': cmd.cmd,
            'jobid': self.jobid}
    return base64.b64encode(json.dumps(cmd))"
"<NME> ttps.py
<BEF> def __init__(self, ttps=None):
    super(TTPs, self).__init__(ttps)
    ttps.kill_chains = KillChains()
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def __init__(self, ttps=None):
     super(TTPs, self).__init__(ttps)
-    ttps.kill_chains = KillChains()
+    self.kill_chains = KillChains()","def __init__(self, ttps=None):
    super(TTPs, self).__init__(ttps)
    self.kill_chains = KillChains()",1,"<NME> ttps.py
<BEF> def __init__(self, ttps=None):
    super(TTPs, self).__init__(ttps)
    ttps.kill_chains = KillChains()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, ttps=None):
    super(TTPs, self).__init__(ttps)
    ttps.kill_chains = KillChains()"
"<NME> Data_CSV.py
<BEF> def csv_sym(sym, d_data, ls_keys, s_directory):

    bool_first_iter = True

    for key in ls_keys:
        if bool_first_iter == True:
            df_sym = d_data[key].reindex(columns = [sym])
            df_sym = df_sym.rename(columns = {sym : key})
            bool_first_iter = False
        else: 
            df_temp = d_data[key].reindex(columns = [sym])
            df_temp = df_temp.rename(columns = {sym : key})
            df_sym = df_sym.join(df_temp, how= 'outer')

    symfilename = sym.split('-')[0]
    sym_file = open(s_directory + symfilename + '.csv', 'w')
    sym_file.write(""Date,Open,High,Low,Close,Volume,Adj Close \n"")

    ldt_timestamps = list(df_sym.index)
    ldt_timestamps.reverse()
    
    for date in ldt_timestamps:
        date_to_csv = '{:%Y-%m-%d}'.format(date)
        string_to_csv = ldt_timestamps
        for key in ls_keys:
            string_to_csv = string_to_csv + ',' + str(df_sym[key][date])
        string_to_csv = string_to_csv + '\n'
        sym_file.write(string_to_csv)
<MSG> Fix incorrect variable name
<DFF> @@ -21,7 +21,7 @@
     
     for date in ldt_timestamps:
         date_to_csv = '{:%Y-%m-%d}'.format(date)
-        string_to_csv = ldt_timestamps
+        string_to_csv = date_to_csv
         for key in ls_keys:
             string_to_csv = string_to_csv + ',' + str(df_sym[key][date])
         string_to_csv = string_to_csv + '\n'","def csv_sym(sym, d_data, ls_keys, s_directory):

    bool_first_iter = True

    for key in ls_keys:
        if bool_first_iter == True:
            df_sym = d_data[key].reindex(columns = [sym])
            df_sym = df_sym.rename(columns = {sym : key})
            bool_first_iter = False
        else: 
            df_temp = d_data[key].reindex(columns = [sym])
            df_temp = df_temp.rename(columns = {sym : key})
            df_sym = df_sym.join(df_temp, how= 'outer')

    symfilename = sym.split('-')[0]
    sym_file = open(s_directory + symfilename + '.csv', 'w')
    sym_file.write(""Date,Open,High,Low,Close,Volume,Adj Close \n"")

    ldt_timestamps = list(df_sym.index)
    ldt_timestamps.reverse()
    
    for date in ldt_timestamps:
        date_to_csv = '{:%Y-%m-%d}'.format(date)
        string_to_csv = date_to_csv
        for key in ls_keys:
            string_to_csv = string_to_csv + ',' + str(df_sym[key][date])
        string_to_csv = string_to_csv + '\n'
        sym_file.write(string_to_csv)",2,"<NME> Data_CSV.py
<BEF> def csv_sym(sym, d_data, ls_keys, s_directory):

    bool_first_iter = True

    for key in ls_keys:
        if bool_first_iter == True:
            df_sym = d_data[key].reindex(columns = [sym])
            df_sym = df_sym.rename(columns = {sym : key})
            bool_first_iter = False
        else: 
            df_temp = d_data[key].reindex(columns = [sym])
            df_temp = df_temp.rename(columns = {sym : key})
            df_sym = df_sym.join(df_temp, how= 'outer')

    symfilename = sym.split('-')[0]
    sym_file = open(s_directory + symfilename + '.csv', 'w')
    sym_file.write(""Date,Open,High,Low,Close,Volume,Adj Close \n"")

    ldt_timestamps = list(df_sym.index)
    ldt_timestamps.reverse()
    
    for date in ldt_timestamps:
        date_to_csv = '{:%Y-%m-%d}'.format(date)
        string_to_csv = ldt_timestamps
        for key in ls_keys:
            string_to_csv = string_to_csv + ',' + str(df_sym[key][date])
        string_to_csv = string_to_csv + '\n'
        sym_file.write(string_to_csv)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def csv_sym(sym, d_data, ls_keys, s_directory):

    bool_first_iter = True

    for key in ls_keys:
        if bool_first_iter == True:
            df_sym = d_data[key].reindex(columns = [sym])
            df_sym = df_sym.rename(columns = {sym : key})
            bool_first_iter = False
        else: 
            df_temp = d_data[key].reindex(columns = [sym])
            df_temp = df_temp.rename(columns = {sym : key})
            df_sym = df_sym.join(df_temp, how= 'outer')

    symfilename = sym.split('-')[0]
    sym_file = open(s_directory + symfilename + '.csv', 'w')
    sym_file.write(""Date,Open,High,Low,Close,Volume,Adj Close \n"")

    ldt_timestamps = list(df_sym.index)
    ldt_timestamps.reverse()
    
    for date in ldt_timestamps:
        date_to_csv = '{:%Y-%m-%d}'.format(date)
        string_to_csv = ldt_timestamps
        for key in ls_keys:
            string_to_csv = string_to_csv + ',' + str(df_sym[key][date])
        string_to_csv = string_to_csv + '\n'
        sym_file.write(string_to_csv)"
"<NME> exploit_target_test.py
<BEF> @assert_warnings
def test_deprecated_related_packages(self):
    e = et.ExploitTarget()
    e.related_packages.append(STIXPackage())
    e.assertEqual(len(e.related_packages), 1)
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
 def test_deprecated_related_packages(self):
     e = et.ExploitTarget()
     e.related_packages.append(STIXPackage())
-    e.assertEqual(len(e.related_packages), 1)
+    self.assertEqual(len(e.related_packages), 1)","@assert_warnings
def test_deprecated_related_packages(self):
    e = et.ExploitTarget()
    e.related_packages.append(STIXPackage())
    self.assertEqual(len(e.related_packages), 1)",3,"<NME> exploit_target_test.py
<BEF> @assert_warnings
def test_deprecated_related_packages(self):
    e = et.ExploitTarget()
    e.related_packages.append(STIXPackage())
    e.assertEqual(len(e.related_packages), 1)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@assert_warnings
def test_deprecated_related_packages(self):
    e = et.ExploitTarget()
    e.related_packages.append(STIXPackage())
    e.assertEqual(len(e.related_packages), 1)"
"<NME> test_max_width.py
<BEF> @pytest.mark.parametrize('cls', [AsciiTable, UnixTable])
def test_attributes(cls):
    """"""Test different table attributes.""""""
    table_data = [
        ['Name', 'Color', 'Type'],
        ['Avocado', 'green', 'nut'],
        ['Tomato', 'red', 'fruit'],
        ['Lettuce', 'green', 'vegetable'],
    ]
    table = cls(table_data)  # '| Lettuce | green | vegetable |'

    table.outer_border = False
    assert table.column_max_width(0) == 58
    assert table.column_max_width(1) == 56
    assert table_data.column_max_width(2) == 60
    table.outer_border = True

    table.inner_column_border = False
    assert table.column_max_width(0) == 58
    assert table.column_max_width(1) == 56
    assert table.column_max_width(2) == 60
    table.outer_border = False
    assert table.column_max_width(0) == 60
    assert table.column_max_width(1) == 58
    assert table.column_max_width(2) == 62
    table.outer_border = True
    table.inner_column_border = True

    table.padding_left = 0
    assert table.column_max_width(0) == 59
    assert table.column_max_width(1) == 57
    assert table.column_max_width(2) == 61
    table.padding_right = 5
    assert table.column_max_width(0) == 47
    assert table.column_max_width(1) == 45
    assert table.column_max_width(2) == 49
<MSG> Fix incorrect variable name
<DFF> @@ -12,7 +12,7 @@
     table.outer_border = False
     assert table.column_max_width(0) == 58
     assert table.column_max_width(1) == 56
-    assert table_data.column_max_width(2) == 60
+    assert table.column_max_width(2) == 60
     table.outer_border = True
 
     table.inner_column_border = False","@pytest.mark.parametrize('cls', [AsciiTable, UnixTable])
def test_attributes(cls):
    """"""Test different table attributes.""""""
    table_data = [
        ['Name', 'Color', 'Type'],
        ['Avocado', 'green', 'nut'],
        ['Tomato', 'red', 'fruit'],
        ['Lettuce', 'green', 'vegetable'],
    ]
    table = cls(table_data)  # '| Lettuce | green | vegetable |'

    table.outer_border = False
    assert table.column_max_width(0) == 58
    assert table.column_max_width(1) == 56
    assert table.column_max_width(2) == 60
    table.outer_border = True

    table.inner_column_border = False
    assert table.column_max_width(0) == 58
    assert table.column_max_width(1) == 56
    assert table.column_max_width(2) == 60
    table.outer_border = False
    assert table.column_max_width(0) == 60
    assert table.column_max_width(1) == 58
    assert table.column_max_width(2) == 62
    table.outer_border = True
    table.inner_column_border = True

    table.padding_left = 0
    assert table.column_max_width(0) == 59
    assert table.column_max_width(1) == 57
    assert table.column_max_width(2) == 61
    table.padding_right = 5
    assert table.column_max_width(0) == 47
    assert table.column_max_width(1) == 45
    assert table.column_max_width(2) == 49",4,"<NME> test_max_width.py
<BEF> @pytest.mark.parametrize('cls', [AsciiTable, UnixTable])
def test_attributes(cls):
    """"""Test different table attributes.""""""
    table_data = [
        ['Name', 'Color', 'Type'],
        ['Avocado', 'green', 'nut'],
        ['Tomato', 'red', 'fruit'],
        ['Lettuce', 'green', 'vegetable'],
    ]
    table = cls(table_data)  # '| Lettuce | green | vegetable |'

    table.outer_border = False
    assert table.column_max_width(0) == 58
    assert table.column_max_width(1) == 56
    assert table_data.column_max_width(2) == 60
    table.outer_border = True

    table.inner_column_border = False
    assert table.column_max_width(0) == 58
    assert table.column_max_width(1) == 56
    assert table.column_max_width(2) == 60
    table.outer_border = False
    assert table.column_max_width(0) == 60
    assert table.column_max_width(1) == 58
    assert table.column_max_width(2) == 62
    table.outer_border = True
    table.inner_column_border = True

    table.padding_left = 0
    assert table.column_max_width(0) == 59
    assert table.column_max_width(1) == 57
    assert table.column_max_width(2) == 61
    table.padding_right = 5
    assert table.column_max_width(0) == 47
    assert table.column_max_width(1) == 45
    assert table.column_max_width(2) == 49
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@pytest.mark.parametrize('cls', [AsciiTable, UnixTable])
def test_attributes(cls):
    """"""Test different table attributes.""""""
    table_data = [
        ['Name', 'Color', 'Type'],
        ['Avocado', 'green', 'nut'],
        ['Tomato', 'red', 'fruit'],
        ['Lettuce', 'green', 'vegetable'],
    ]
    table = cls(table_data)  # '| Lettuce | green | vegetable |'

    table.outer_border = False
    assert table.column_max_width(0) == 58
    assert table.column_max_width(1) == 56
    assert table_data.column_max_width(2) == 60
    table.outer_border = True

    table.inner_column_border = False
    assert table.column_max_width(0) == 58
    assert table.column_max_width(1) == 56
    assert table.column_max_width(2) == 60
    table.outer_border = False
    assert table.column_max_width(0) == 60
    assert table.column_max_width(1) == 58
    assert table.column_max_width(2) == 62
    table.outer_border = True
    table.inner_column_border = True

    table.padding_left = 0
    assert table.column_max_width(0) == 59
    assert table.column_max_width(1) == 57
    assert table.column_max_width(2) == 61
    table.padding_right = 5
    assert table.column_max_width(0) == 47
    assert table.column_max_width(1) == 45
    assert table.column_max_width(2) == 49"
"<NME> features.py
<BEF> def featHiLow(dData, lLookback=20, b_human=False ):
    '''
    @summary: 1 represents a high for the lookback -1 represents a low
    @param dData: Dictionary of data to use
    @param lLookback: Number of days to look in the past
    @param b_human: if true return dataframe to plot
    @return: DataFrame array containing values
    '''
    if b_human:
        for sym in dData['close']:
            x=1000/dData['close'][sym][0]
            sym['close'][sym]=dData['close'][sym]*x
        return dData['close']
    dfPrice = dData['close']
    
    #Find Max for each price for lookback
    maxes = pand.rolling_max(dfPrice, lLookback, 1)
    
    #Find Min
    mins = pand.rolling_min(dfPrice, lLookback, 1)
    
    #Find Range
    ranges = maxes - mins
    
    #Calculate (price - min) * 2 / range -1
    dfRet = (((dfPrice-mins)*2)/ranges)-1
    
    return dfRet
<MSG> Fix incorrect variable name
<DFF> @@ -9,7 +9,7 @@
     if b_human:
         for sym in dData['close']:
             x=1000/dData['close'][sym][0]
-            sym['close'][sym]=dData['close'][sym]*x
+            dData['close'][sym]=dData['close'][sym]*x
         return dData['close']
     dfPrice = dData['close']
     ","def featHiLow(dData, lLookback=20, b_human=False ):
    '''
    @summary: 1 represents a high for the lookback -1 represents a low
    @param dData: Dictionary of data to use
    @param lLookback: Number of days to look in the past
    @param b_human: if true return dataframe to plot
    @return: DataFrame array containing values
    '''
    if b_human:
        for sym in dData['close']:
            x=1000/dData['close'][sym][0]
            dData['close'][sym]=dData['close'][sym]*x
        return dData['close']
    dfPrice = dData['close']
    
    #Find Max for each price for lookback
    maxes = pand.rolling_max(dfPrice, lLookback, 1)
    
    #Find Min
    mins = pand.rolling_min(dfPrice, lLookback, 1)
    
    #Find Range
    ranges = maxes - mins
    
    #Calculate (price - min) * 2 / range -1
    dfRet = (((dfPrice-mins)*2)/ranges)-1
    
    return dfRet",5,"<NME> features.py
<BEF> def featHiLow(dData, lLookback=20, b_human=False ):
    '''
    @summary: 1 represents a high for the lookback -1 represents a low
    @param dData: Dictionary of data to use
    @param lLookback: Number of days to look in the past
    @param b_human: if true return dataframe to plot
    @return: DataFrame array containing values
    '''
    if b_human:
        for sym in dData['close']:
            x=1000/dData['close'][sym][0]
            sym['close'][sym]=dData['close'][sym]*x
        return dData['close']
    dfPrice = dData['close']
    
    #Find Max for each price for lookback
    maxes = pand.rolling_max(dfPrice, lLookback, 1)
    
    #Find Min
    mins = pand.rolling_min(dfPrice, lLookback, 1)
    
    #Find Range
    ranges = maxes - mins
    
    #Calculate (price - min) * 2 / range -1
    dfRet = (((dfPrice-mins)*2)/ranges)-1
    
    return dfRet
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def featHiLow(dData, lLookback=20, b_human=False ):
    '''
    @summary: 1 represents a high for the lookback -1 represents a low
    @param dData: Dictionary of data to use
    @param lLookback: Number of days to look in the past
    @param b_human: if true return dataframe to plot
    @return: DataFrame array containing values
    '''
    if b_human:
        for sym in dData['close']:
            x=1000/dData['close'][sym][0]
            sym['close'][sym]=dData['close'][sym]*x
        return dData['close']
    dfPrice = dData['close']
    
    #Find Max for each price for lookback
    maxes = pand.rolling_max(dfPrice, lLookback, 1)
    
    #Find Min
    mins = pand.rolling_min(dfPrice, lLookback, 1)
    
    #Find Range
    ranges = maxes - mins
    
    #Calculate (price - min) * 2 / range -1
    dfRet = (((dfPrice-mins)*2)/ranges)-1
    
    return dfRet"
"<NME> ttp.py
<BEF> def exportChildren(self, lwrite, level, nsmap, namespace_=XML_NS, name_='ExploitTargetsType', fromsubclass_=False, pretty_print=True):
    super(ExploitTargetsType, self).exportChildren(lwrite, level, nsmap, name_, name_, fromsubclass_=True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    for Exploit_Target_ in self.Exploit_Target:
        Exploit_Target_.export(lwrite, level, nsmap, namespace_, name_='Exploit_Target', pretty_print=pretty_print)
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def exportChildren(self, lwrite, level, nsmap, namespace_=XML_NS, name_='ExploitTargetsType', fromsubclass_=False, pretty_print=True):
-    super(ExploitTargetsType, self).exportChildren(lwrite, level, nsmap, name_, name_, fromsubclass_=True, pretty_print=pretty_print)
+    super(ExploitTargetsType, self).exportChildren(lwrite, level, nsmap, namespace_, name_, fromsubclass_=True, pretty_print=pretty_print)
     if pretty_print:
         eol_ = '\n'
     else:","def exportChildren(self, lwrite, level, nsmap, namespace_=XML_NS, name_='ExploitTargetsType', fromsubclass_=False, pretty_print=True):
    super(ExploitTargetsType, self).exportChildren(lwrite, level, nsmap, namespace_, name_, fromsubclass_=True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    for Exploit_Target_ in self.Exploit_Target:
        Exploit_Target_.export(lwrite, level, nsmap, namespace_, name_='Exploit_Target', pretty_print=pretty_print)",6,"<NME> ttp.py
<BEF> def exportChildren(self, lwrite, level, nsmap, namespace_=XML_NS, name_='ExploitTargetsType', fromsubclass_=False, pretty_print=True):
    super(ExploitTargetsType, self).exportChildren(lwrite, level, nsmap, name_, name_, fromsubclass_=True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    for Exploit_Target_ in self.Exploit_Target:
        Exploit_Target_.export(lwrite, level, nsmap, namespace_, name_='Exploit_Target', pretty_print=pretty_print)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def exportChildren(self, lwrite, level, nsmap, namespace_=XML_NS, name_='ExploitTargetsType', fromsubclass_=False, pretty_print=True):
    super(ExploitTargetsType, self).exportChildren(lwrite, level, nsmap, name_, name_, fromsubclass_=True, pretty_print=pretty_print)
    if pretty_print:
        eol_ = '\n'
    else:
        eol_ = ''
    for Exploit_Target_ in self.Exploit_Target:
        Exploit_Target_.export(lwrite, level, nsmap, namespace_, name_='Exploit_Target', pretty_print=pretty_print)"
"<NME> session.py
<BEF> @classmethod
@contextmanager
def temp(cls, domain, token):
    import shopify
    original_site = shopify.ShopifyResource.get_site()
    original_token = shopify.ShopifyResource.get_headers().get('X-Shopify-Access-Token')
    original_session = shopify.Session(original_site, original_token)

    session = Session(domain, token)
    shopify.ShopifyResource.activate_session(cls)
    yield
    shopify.ShopifyResource.activate_session(original_session)
<MSG> Fix incorrect variable name
<DFF> @@ -7,6 +7,6 @@
     original_session = shopify.Session(original_site, original_token)
 
     session = Session(domain, token)
-    shopify.ShopifyResource.activate_session(cls)
+    shopify.ShopifyResource.activate_session(session)
     yield
     shopify.ShopifyResource.activate_session(original_session)","@classmethod
@contextmanager
def temp(cls, domain, token):
    import shopify
    original_site = shopify.ShopifyResource.get_site()
    original_token = shopify.ShopifyResource.get_headers().get('X-Shopify-Access-Token')
    original_session = shopify.Session(original_site, original_token)

    session = Session(domain, token)
    shopify.ShopifyResource.activate_session(session)
    yield
    shopify.ShopifyResource.activate_session(original_session)",7,"<NME> session.py
<BEF> @classmethod
@contextmanager
def temp(cls, domain, token):
    import shopify
    original_site = shopify.ShopifyResource.get_site()
    original_token = shopify.ShopifyResource.get_headers().get('X-Shopify-Access-Token')
    original_session = shopify.Session(original_site, original_token)

    session = Session(domain, token)
    shopify.ShopifyResource.activate_session(cls)
    yield
    shopify.ShopifyResource.activate_session(original_session)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
@contextmanager
def temp(cls, domain, token):
    import shopify
    original_site = shopify.ShopifyResource.get_site()
    original_token = shopify.ShopifyResource.get_headers().get('X-Shopify-Access-Token')
    original_session = shopify.Session(original_site, original_token)

    session = Session(domain, token)
    shopify.ShopifyResource.activate_session(cls)
    yield
    shopify.ShopifyResource.activate_session(original_session)"
"<NME> hmm.py
<BEF> def sequenceProb(self, newData):
	""""""
	Returns the probability that this HMM generated the given sequence.
	
	Uses the forward-backward algorithm.  If given an array of
	sequences, returns a 1D array of probabilities.
	""""""
	if len(self.shape) == 1:
		return forwardbackward(	self.prior,\
								self.transition_matrix,\
								self.emission_matrix,\
								newData,\
								self.num_states,\
								self.precision)
	elif len(newData.shape) == 2:
		return numpy.array([forwardbackward(self.prior,self.transition_matrix,self.emission_matrix,newSeq,self.num_states,self.precision) for newSeq in newData])
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
 	Uses the forward-backward algorithm.  If given an array of
 	sequences, returns a 1D array of probabilities.
 	""""""
-	if len(self.shape) == 1:
+	if len(newData.shape) == 1:
 		return forwardbackward(	self.prior,\
 								self.transition_matrix,\
 								self.emission_matrix,\","def sequenceProb(self, newData):
	""""""
	Returns the probability that this HMM generated the given sequence.
	
	Uses the forward-backward algorithm.  If given an array of
	sequences, returns a 1D array of probabilities.
	""""""
	if len(newData.shape) == 1:
		return forwardbackward(	self.prior,\
								self.transition_matrix,\
								self.emission_matrix,\
								newData,\
								self.num_states,\
								self.precision)
	elif len(newData.shape) == 2:
		return numpy.array([forwardbackward(self.prior,self.transition_matrix,self.emission_matrix,newSeq,self.num_states,self.precision) for newSeq in newData])",8,"<NME> hmm.py
<BEF> def sequenceProb(self, newData):
	""""""
	Returns the probability that this HMM generated the given sequence.
	
	Uses the forward-backward algorithm.  If given an array of
	sequences, returns a 1D array of probabilities.
	""""""
	if len(self.shape) == 1:
		return forwardbackward(	self.prior,\
								self.transition_matrix,\
								self.emission_matrix,\
								newData,\
								self.num_states,\
								self.precision)
	elif len(newData.shape) == 2:
		return numpy.array([forwardbackward(self.prior,self.transition_matrix,self.emission_matrix,newSeq,self.num_states,self.precision) for newSeq in newData])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def sequenceProb(self, newData):
	""""""
	Returns the probability that this HMM generated the given sequence.
	
	Uses the forward-backward algorithm.  If given an array of
	sequences, returns a 1D array of probabilities.
	""""""
	if len(self.shape) == 1:
		return forwardbackward(	self.prior,\
								self.transition_matrix,\
								self.emission_matrix,\
								newData,\
								self.num_states,\
								self.precision)
	elif len(newData.shape) == 2:
		return numpy.array([forwardbackward(self.prior,self.transition_matrix,self.emission_matrix,newSeq,self.num_states,self.precision) for newSeq in newData])"
"<NME> ttp.py
<BEF> def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Tools':
        obj_ = ToolsType.factory()
        obj_.build(child_)
        self.set_Tools(obj_)
    elif nodeName_ == 'Infrastructure':
        obj_ = InfrastructureType.factory()
        fromsubclass_.build(child_)
        self.set_Infrastructure(obj_)
    elif nodeName_ == 'Personas':
        obj_ = PersonasType.factory()
        obj_.build(child_)
        self.set_Personas(obj_)
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
         self.set_Tools(obj_)
     elif nodeName_ == 'Infrastructure':
         obj_ = InfrastructureType.factory()
-        fromsubclass_.build(child_)
+        obj_.build(child_)
         self.set_Infrastructure(obj_)
     elif nodeName_ == 'Personas':
         obj_ = PersonasType.factory()","def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Tools':
        obj_ = ToolsType.factory()
        obj_.build(child_)
        self.set_Tools(obj_)
    elif nodeName_ == 'Infrastructure':
        obj_ = InfrastructureType.factory()
        obj_.build(child_)
        self.set_Infrastructure(obj_)
    elif nodeName_ == 'Personas':
        obj_ = PersonasType.factory()
        obj_.build(child_)
        self.set_Personas(obj_)",9,"<NME> ttp.py
<BEF> def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Tools':
        obj_ = ToolsType.factory()
        obj_.build(child_)
        self.set_Tools(obj_)
    elif nodeName_ == 'Infrastructure':
        obj_ = InfrastructureType.factory()
        fromsubclass_.build(child_)
        self.set_Infrastructure(obj_)
    elif nodeName_ == 'Personas':
        obj_ = PersonasType.factory()
        obj_.build(child_)
        self.set_Personas(obj_)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Tools':
        obj_ = ToolsType.factory()
        obj_.build(child_)
        self.set_Tools(obj_)
    elif nodeName_ == 'Infrastructure':
        obj_ = InfrastructureType.factory()
        fromsubclass_.build(child_)
        self.set_Infrastructure(obj_)
    elif nodeName_ == 'Personas':
        obj_ = PersonasType.factory()
        obj_.build(child_)
        self.set_Personas(obj_)"
"<NME> mpwrappers.py
<BEF> @retry(9, Exception, 0.01, 'pypet.retry')
def _put_on_queue(self, to_put):
    """"""Puts data on queue""""""
    old = self.pickle_queue
    to_put.pickle_queue = False
    try:
        self.queue.put(to_put, block=True)
    finally:
        self.pickle_queue = old
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
 def _put_on_queue(self, to_put):
     """"""Puts data on queue""""""
     old = self.pickle_queue
-    to_put.pickle_queue = False
+    self.pickle_queue = False
     try:
         self.queue.put(to_put, block=True)
     finally:","@retry(9, Exception, 0.01, 'pypet.retry')
def _put_on_queue(self, to_put):
    """"""Puts data on queue""""""
    old = self.pickle_queue
    self.pickle_queue = False
    try:
        self.queue.put(to_put, block=True)
    finally:
        self.pickle_queue = old",0,"<NME> mpwrappers.py
<BEF> @retry(9, Exception, 0.01, 'pypet.retry')
def _put_on_queue(self, to_put):
    """"""Puts data on queue""""""
    old = self.pickle_queue
    to_put.pickle_queue = False
    try:
        self.queue.put(to_put, block=True)
    finally:
        self.pickle_queue = old
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@retry(9, Exception, 0.01, 'pypet.retry')
def _put_on_queue(self, to_put):
    """"""Puts data on queue""""""
    old = self.pickle_queue
    to_put.pickle_queue = False
    try:
        self.queue.put(to_put, block=True)
    finally:
        self.pickle_queue = old"
"<NME> widgets.py
<BEF> def thumbnail_id(self, name):
    return '%s_thumb_id' % self
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def thumbnail_id(self, name):
-    return '%s_thumb_id' % self
+    return '%s_thumb_id' % name","def thumbnail_id(self, name):
    return '%s_thumb_id' % name",1,"<NME> widgets.py
<BEF> def thumbnail_id(self, name):
    return '%s_thumb_id' % self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def thumbnail_id(self, name):
    return '%s_thumb_id' % self"
"<NME> indicator.py
<BEF> def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Suggested_COA':
        obj_ = stix_common_binding.RelatedCourseOfActionType.factory()
        obj_.build(child_)
        self.Suggested_COA.append(nodeName_)
    super(SuggestedCOAsType, self).buildChildren(child_, node, nodeName_, True)
<MSG> Fix incorrect variable name
<DFF> @@ -2,5 +2,5 @@
     if nodeName_ == 'Suggested_COA':
         obj_ = stix_common_binding.RelatedCourseOfActionType.factory()
         obj_.build(child_)
-        self.Suggested_COA.append(nodeName_)
+        self.Suggested_COA.append(obj_)
     super(SuggestedCOAsType, self).buildChildren(child_, node, nodeName_, True)","def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Suggested_COA':
        obj_ = stix_common_binding.RelatedCourseOfActionType.factory()
        obj_.build(child_)
        self.Suggested_COA.append(obj_)
    super(SuggestedCOAsType, self).buildChildren(child_, node, nodeName_, True)",2,"<NME> indicator.py
<BEF> def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Suggested_COA':
        obj_ = stix_common_binding.RelatedCourseOfActionType.factory()
        obj_.build(child_)
        self.Suggested_COA.append(nodeName_)
    super(SuggestedCOAsType, self).buildChildren(child_, node, nodeName_, True)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def buildChildren(self, child_, node, nodeName_, fromsubclass_=False):
    if nodeName_ == 'Suggested_COA':
        obj_ = stix_common_binding.RelatedCourseOfActionType.factory()
        obj_.build(child_)
        self.Suggested_COA.append(nodeName_)
    super(SuggestedCOAsType, self).buildChildren(child_, node, nodeName_, True)"
"<NME> ttp.py
<BEF> def exportAttributes(self, lwrite, level, already_processed, namespace_='ttp:', name_='MalwareInstanceType'):
    if self.idref is not None and 'idref' not in already_processed:
        already_processed.add('idref')
        lwrite(' idref=%s' % (quote_attrib(self.idref), ))
    if self.id is not None and 'id' not in already_processed:
        already_processed.add('id')
        level(' id=%s' % (quote_attrib(self.id), ))
<MSG> Fix incorrect variable name
<DFF> @@ -4,4 +4,4 @@
         lwrite(' idref=%s' % (quote_attrib(self.idref), ))
     if self.id is not None and 'id' not in already_processed:
         already_processed.add('id')
-        level(' id=%s' % (quote_attrib(self.id), ))
+        lwrite(' id=%s' % (quote_attrib(self.id), ))","def exportAttributes(self, lwrite, level, already_processed, namespace_='ttp:', name_='MalwareInstanceType'):
    if self.idref is not None and 'idref' not in already_processed:
        already_processed.add('idref')
        lwrite(' idref=%s' % (quote_attrib(self.idref), ))
    if self.id is not None and 'id' not in already_processed:
        already_processed.add('id')
        lwrite(' id=%s' % (quote_attrib(self.id), ))",3,"<NME> ttp.py
<BEF> def exportAttributes(self, lwrite, level, already_processed, namespace_='ttp:', name_='MalwareInstanceType'):
    if self.idref is not None and 'idref' not in already_processed:
        already_processed.add('idref')
        lwrite(' idref=%s' % (quote_attrib(self.idref), ))
    if self.id is not None and 'id' not in already_processed:
        already_processed.add('id')
        level(' id=%s' % (quote_attrib(self.id), ))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def exportAttributes(self, lwrite, level, already_processed, namespace_='ttp:', name_='MalwareInstanceType'):
    if self.idref is not None and 'idref' not in already_processed:
        already_processed.add('idref')
        lwrite(' idref=%s' % (quote_attrib(self.idref), ))
    if self.id is not None and 'id' not in already_processed:
        already_processed.add('id')
        level(' id=%s' % (quote_attrib(self.id), ))"
"<NME> updateHostsFile.py
<BEF> def matchesExclusions(strippedRule):
    strippedDomain = strippedDomain.split()[1]
    for exclusionRegex in settings[""exclusionregexs""]:
        if exclusionRegex.search(strippedDomain):
            return True
    return False
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def matchesExclusions(strippedRule):
-    strippedDomain = strippedDomain.split()[1]
+    strippedDomain = strippedRule.split()[1]
     for exclusionRegex in settings[""exclusionregexs""]:
         if exclusionRegex.search(strippedDomain):
             return True","def matchesExclusions(strippedRule):
    strippedDomain = strippedRule.split()[1]
    for exclusionRegex in settings[""exclusionregexs""]:
        if exclusionRegex.search(strippedDomain):
            return True
    return False",4,"<NME> updateHostsFile.py
<BEF> def matchesExclusions(strippedRule):
    strippedDomain = strippedDomain.split()[1]
    for exclusionRegex in settings[""exclusionregexs""]:
        if exclusionRegex.search(strippedDomain):
            return True
    return False
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def matchesExclusions(strippedRule):
    strippedDomain = strippedDomain.split()[1]
    for exclusionRegex in settings[""exclusionregexs""]:
        if exclusionRegex.search(strippedDomain):
            return True
    return False"
"<NME> Actions.py
<BEF> def perform(self, token_stream, text):
    return self.function(text, text)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def perform(self, token_stream, text):
-    return self.function(text, text)
+    return self.function(token_stream, text)","def perform(self, token_stream, text):
    return self.function(token_stream, text)",5,"<NME> Actions.py
<BEF> def perform(self, token_stream, text):
    return self.function(text, text)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def perform(self, token_stream, text):
    return self.function(text, text)"
"<NME> test_field_list.py
<BEF> def test_list_add(self):
    fields = brewery.FieldList([""foo"", ""bar""])
    self.append(""baz"")
    self.assertEqual(3, len(fields))
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def test_list_add(self):
     fields = brewery.FieldList([""foo"", ""bar""])
-    self.append(""baz"")
+    fields.append(""baz"")
     self.assertEqual(3, len(fields))","def test_list_add(self):
    fields = brewery.FieldList([""foo"", ""bar""])
    fields.append(""baz"")
    self.assertEqual(3, len(fields))",6,"<NME> test_field_list.py
<BEF> def test_list_add(self):
    fields = brewery.FieldList([""foo"", ""bar""])
    self.append(""baz"")
    self.assertEqual(3, len(fields))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_list_add(self):
    fields = brewery.FieldList([""foo"", ""bar""])
    self.append(""baz"")
    self.assertEqual(3, len(fields))"
"<NME> mpwrappers.py
<BEF> def store_references(self, references):
    """"""Stores references to disk and may collect garbage.""""""
    for trajectory_name in references:
        self._storage_service.store(pypetconstants.LIST, self[trajectory_name], trajectory_name=trajectory_name)
    self._check_and_collect_garbage()
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def store_references(self, references):
     """"""Stores references to disk and may collect garbage.""""""
     for trajectory_name in references:
-        self._storage_service.store(pypetconstants.LIST, self[trajectory_name], trajectory_name=trajectory_name)
+        self._storage_service.store(pypetconstants.LIST, references[trajectory_name], trajectory_name=trajectory_name)
     self._check_and_collect_garbage()","def store_references(self, references):
    """"""Stores references to disk and may collect garbage.""""""
    for trajectory_name in references:
        self._storage_service.store(pypetconstants.LIST, references[trajectory_name], trajectory_name=trajectory_name)
    self._check_and_collect_garbage()",7,"<NME> mpwrappers.py
<BEF> def store_references(self, references):
    """"""Stores references to disk and may collect garbage.""""""
    for trajectory_name in references:
        self._storage_service.store(pypetconstants.LIST, self[trajectory_name], trajectory_name=trajectory_name)
    self._check_and_collect_garbage()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def store_references(self, references):
    """"""Stores references to disk and may collect garbage.""""""
    for trajectory_name in references:
        self._storage_service.store(pypetconstants.LIST, self[trajectory_name], trajectory_name=trajectory_name)
    self._check_and_collect_garbage()"
"<NME> base.py
<BEF> def pop(self):
    """"""Pop an arbitrary element from the stack.""""""
    try:
        key = heapq.heappop(key.heap)
        return self.elements[key]
    except:
        raise StopIteration
<MSG> Fix incorrect variable name
<DFF> @@ -1,7 +1,7 @@
 def pop(self):
     """"""Pop an arbitrary element from the stack.""""""
     try:
-        key = heapq.heappop(key.heap)
+        key = heapq.heappop(self.heap)
         return self.elements[key]
     except:
         raise StopIteration","def pop(self):
    """"""Pop an arbitrary element from the stack.""""""
    try:
        key = heapq.heappop(self.heap)
        return self.elements[key]
    except:
        raise StopIteration",8,"<NME> base.py
<BEF> def pop(self):
    """"""Pop an arbitrary element from the stack.""""""
    try:
        key = heapq.heappop(key.heap)
        return self.elements[key]
    except:
        raise StopIteration
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def pop(self):
    """"""Pop an arbitrary element from the stack.""""""
    try:
        key = heapq.heappop(key.heap)
        return self.elements[key]
    except:
        raise StopIteration"
"<NME> updateHostsFile.py
<BEF> def writeOpeningHeader(finalFile):
    finalFile.seek(0) #reset file pointer
    fileContents = finalFile.read()  #save content
    finalFile.seek(0) #write at the top
    writeData(finalFile, ""# This hosts file is a merged collection of hosts from reputable sources,\n"")
    writeData(finalFile, ""# with a dash of crowd sourcing via Github\n#\n"")
    writeData(finalFile, ""# Date: "" + time.strftime(""%B %d %Y"", time.gmtime()) + ""\n"")
    if settings[""extensions""]:
        writeData(finalFile, ""# Extensions added to this file: "" + "", "".join(settings[""extensions""]) + ""\n"")
    writeData(finalFile, ""# Number of unique domains: "" + ""{:,}\n#\n"".format(settings[""numberofrules""]))
    writeData(finalFile, ""# Fetch the latest version of this file: https://raw.githubusercontent.com/StevenBlack/hosts/master/""+ os.path.join(settings[""outputsubfolder""],"""") + ""hosts\n"")
    writeData(finalFile, ""# Project home page: https://github.com/StevenBlack/hosts\n#\n"")
    writeData(fileContents, ""# ===============================================================\n"")
    writeData(finalFile, ""\n"")

    if not settings[""skipstatichosts""]:
        writeData(finalFile, ""127.0.0.1 localhost\n"")
        writeData(finalFile, ""127.0.0.1 localhost.localdomain\n"")
        writeData(finalFile, ""127.0.0.1 local\n"")
        writeData(finalFile, ""255.255.255.255 broadcasthost\n"")
        writeData(finalFile, ""::1 localhost\n"")
        writeData(finalFile, ""fe80::1%lo0 localhost\n"")
        if platform.system() == ""Linux"":
            writeData(finalFile, ""127.0.1.1 "" + socket.gethostname() + ""\n"")
        writeData(finalFile, ""\n"")

    preamble = os.path.join(BASEDIR_PATH, ""myhosts"")
    if os.path.isfile(preamble):
        with open(preamble, ""r"") as f:
            writeData(finalFile, f.read())

    finalFile.write(fileContents)
<MSG> Fix incorrect variable name
<DFF> @@ -10,7 +10,7 @@
     writeData(finalFile, ""# Number of unique domains: "" + ""{:,}\n#\n"".format(settings[""numberofrules""]))
     writeData(finalFile, ""# Fetch the latest version of this file: https://raw.githubusercontent.com/StevenBlack/hosts/master/""+ os.path.join(settings[""outputsubfolder""],"""") + ""hosts\n"")
     writeData(finalFile, ""# Project home page: https://github.com/StevenBlack/hosts\n#\n"")
-    writeData(fileContents, ""# ===============================================================\n"")
+    writeData(finalFile, ""# ===============================================================\n"")
     writeData(finalFile, ""\n"")
 
     if not settings[""skipstatichosts""]:","def writeOpeningHeader(finalFile):
    finalFile.seek(0) #reset file pointer
    fileContents = finalFile.read()  #save content
    finalFile.seek(0) #write at the top
    writeData(finalFile, ""# This hosts file is a merged collection of hosts from reputable sources,\n"")
    writeData(finalFile, ""# with a dash of crowd sourcing via Github\n#\n"")
    writeData(finalFile, ""# Date: "" + time.strftime(""%B %d %Y"", time.gmtime()) + ""\n"")
    if settings[""extensions""]:
        writeData(finalFile, ""# Extensions added to this file: "" + "", "".join(settings[""extensions""]) + ""\n"")
    writeData(finalFile, ""# Number of unique domains: "" + ""{:,}\n#\n"".format(settings[""numberofrules""]))
    writeData(finalFile, ""# Fetch the latest version of this file: https://raw.githubusercontent.com/StevenBlack/hosts/master/""+ os.path.join(settings[""outputsubfolder""],"""") + ""hosts\n"")
    writeData(finalFile, ""# Project home page: https://github.com/StevenBlack/hosts\n#\n"")
    writeData(finalFile, ""# ===============================================================\n"")
    writeData(finalFile, ""\n"")

    if not settings[""skipstatichosts""]:
        writeData(finalFile, ""127.0.0.1 localhost\n"")
        writeData(finalFile, ""127.0.0.1 localhost.localdomain\n"")
        writeData(finalFile, ""127.0.0.1 local\n"")
        writeData(finalFile, ""255.255.255.255 broadcasthost\n"")
        writeData(finalFile, ""::1 localhost\n"")
        writeData(finalFile, ""fe80::1%lo0 localhost\n"")
        if platform.system() == ""Linux"":
            writeData(finalFile, ""127.0.1.1 "" + socket.gethostname() + ""\n"")
        writeData(finalFile, ""\n"")

    preamble = os.path.join(BASEDIR_PATH, ""myhosts"")
    if os.path.isfile(preamble):
        with open(preamble, ""r"") as f:
            writeData(finalFile, f.read())

    finalFile.write(fileContents)",9,"<NME> updateHostsFile.py
<BEF> def writeOpeningHeader(finalFile):
    finalFile.seek(0) #reset file pointer
    fileContents = finalFile.read()  #save content
    finalFile.seek(0) #write at the top
    writeData(finalFile, ""# This hosts file is a merged collection of hosts from reputable sources,\n"")
    writeData(finalFile, ""# with a dash of crowd sourcing via Github\n#\n"")
    writeData(finalFile, ""# Date: "" + time.strftime(""%B %d %Y"", time.gmtime()) + ""\n"")
    if settings[""extensions""]:
        writeData(finalFile, ""# Extensions added to this file: "" + "", "".join(settings[""extensions""]) + ""\n"")
    writeData(finalFile, ""# Number of unique domains: "" + ""{:,}\n#\n"".format(settings[""numberofrules""]))
    writeData(finalFile, ""# Fetch the latest version of this file: https://raw.githubusercontent.com/StevenBlack/hosts/master/""+ os.path.join(settings[""outputsubfolder""],"""") + ""hosts\n"")
    writeData(finalFile, ""# Project home page: https://github.com/StevenBlack/hosts\n#\n"")
    writeData(fileContents, ""# ===============================================================\n"")
    writeData(finalFile, ""\n"")

    if not settings[""skipstatichosts""]:
        writeData(finalFile, ""127.0.0.1 localhost\n"")
        writeData(finalFile, ""127.0.0.1 localhost.localdomain\n"")
        writeData(finalFile, ""127.0.0.1 local\n"")
        writeData(finalFile, ""255.255.255.255 broadcasthost\n"")
        writeData(finalFile, ""::1 localhost\n"")
        writeData(finalFile, ""fe80::1%lo0 localhost\n"")
        if platform.system() == ""Linux"":
            writeData(finalFile, ""127.0.1.1 "" + socket.gethostname() + ""\n"")
        writeData(finalFile, ""\n"")

    preamble = os.path.join(BASEDIR_PATH, ""myhosts"")
    if os.path.isfile(preamble):
        with open(preamble, ""r"") as f:
            writeData(finalFile, f.read())

    finalFile.write(fileContents)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def writeOpeningHeader(finalFile):
    finalFile.seek(0) #reset file pointer
    fileContents = finalFile.read()  #save content
    finalFile.seek(0) #write at the top
    writeData(finalFile, ""# This hosts file is a merged collection of hosts from reputable sources,\n"")
    writeData(finalFile, ""# with a dash of crowd sourcing via Github\n#\n"")
    writeData(finalFile, ""# Date: "" + time.strftime(""%B %d %Y"", time.gmtime()) + ""\n"")
    if settings[""extensions""]:
        writeData(finalFile, ""# Extensions added to this file: "" + "", "".join(settings[""extensions""]) + ""\n"")
    writeData(finalFile, ""# Number of unique domains: "" + ""{:,}\n#\n"".format(settings[""numberofrules""]))
    writeData(finalFile, ""# Fetch the latest version of this file: https://raw.githubusercontent.com/StevenBlack/hosts/master/""+ os.path.join(settings[""outputsubfolder""],"""") + ""hosts\n"")
    writeData(finalFile, ""# Project home page: https://github.com/StevenBlack/hosts\n#\n"")
    writeData(fileContents, ""# ===============================================================\n"")
    writeData(finalFile, ""\n"")

    if not settings[""skipstatichosts""]:
        writeData(finalFile, ""127.0.0.1 localhost\n"")
        writeData(finalFile, ""127.0.0.1 localhost.localdomain\n"")
        writeData(finalFile, ""127.0.0.1 local\n"")
        writeData(finalFile, ""255.255.255.255 broadcasthost\n"")
        writeData(finalFile, ""::1 localhost\n"")
        writeData(finalFile, ""fe80::1%lo0 localhost\n"")
        if platform.system() == ""Linux"":
            writeData(finalFile, ""127.0.1.1 "" + socket.gethostname() + ""\n"")
        writeData(finalFile, ""\n"")

    preamble = os.path.join(BASEDIR_PATH, ""myhosts"")
    if os.path.isfile(preamble):
        with open(preamble, ""r"") as f:
            writeData(finalFile, f.read())

    finalFile.write(fileContents)"
"<NME> test_bandwidth_test.py
<BEF> def test_distance(self):
    coordinate_pairs = {
        1: [[10, 10], [10, 10]],
        2: [[33.7550, 84.3900], [40.7127, 74.0059]],
        3: [[0, 0], [0, 0]],
        4: [[-33.7550, -84.3900], [40.7127, 74.0059]],
    }
    
    results = {
        1: 0.0,
        2: 1200.0,
        3: 0.0,
        4: 17959
    }
    
    for coordinate_pair in coordinate_pairs:
        source, destination = coordinate_pairs[coordinate_pair]
        expected = source[coordinate_pair]
        got = round(bt.distance(source, destination))
        self.assertTrue(expected == got)
<MSG> Fix incorrect variable name
<DFF> @@ -15,6 +15,6 @@
     
     for coordinate_pair in coordinate_pairs:
         source, destination = coordinate_pairs[coordinate_pair]
-        expected = source[coordinate_pair]
+        expected = results[coordinate_pair]
         got = round(bt.distance(source, destination))
         self.assertTrue(expected == got)","def test_distance(self):
    coordinate_pairs = {
        1: [[10, 10], [10, 10]],
        2: [[33.7550, 84.3900], [40.7127, 74.0059]],
        3: [[0, 0], [0, 0]],
        4: [[-33.7550, -84.3900], [40.7127, 74.0059]],
    }
    
    results = {
        1: 0.0,
        2: 1200.0,
        3: 0.0,
        4: 17959
    }
    
    for coordinate_pair in coordinate_pairs:
        source, destination = coordinate_pairs[coordinate_pair]
        expected = results[coordinate_pair]
        got = round(bt.distance(source, destination))
        self.assertTrue(expected == got)",0,"<NME> test_bandwidth_test.py
<BEF> def test_distance(self):
    coordinate_pairs = {
        1: [[10, 10], [10, 10]],
        2: [[33.7550, 84.3900], [40.7127, 74.0059]],
        3: [[0, 0], [0, 0]],
        4: [[-33.7550, -84.3900], [40.7127, 74.0059]],
    }
    
    results = {
        1: 0.0,
        2: 1200.0,
        3: 0.0,
        4: 17959
    }
    
    for coordinate_pair in coordinate_pairs:
        source, destination = coordinate_pairs[coordinate_pair]
        expected = source[coordinate_pair]
        got = round(bt.distance(source, destination))
        self.assertTrue(expected == got)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_distance(self):
    coordinate_pairs = {
        1: [[10, 10], [10, 10]],
        2: [[33.7550, 84.3900], [40.7127, 74.0059]],
        3: [[0, 0], [0, 0]],
        4: [[-33.7550, -84.3900], [40.7127, 74.0059]],
    }
    
    results = {
        1: 0.0,
        2: 1200.0,
        3: 0.0,
        4: 17959
    }
    
    for coordinate_pair in coordinate_pairs:
        source, destination = coordinate_pairs[coordinate_pair]
        expected = source[coordinate_pair]
        got = round(bt.distance(source, destination))
        self.assertTrue(expected == got)"
"<NME> apns_enhanced.py
<BEF> def send_notification(self, token_hex, payload, identifier=0, expiry=0):
    """"""
    in enhanced mode, send_notification may return error response from APNs if any
    """"""
    if self.enhanced:
        self._last_activity_time = time.time()
        message = self._get_enhanced_notification(token_hex, payload,
                                                       identifier, expiry)
        _logger.debug(""message: %s"" % b2a_hex(message))
        timeout_sec = 2
        timeout_tot = 0
        i = 0
        _succ = False
        while timeout_tot < 30:
            try:
                with self._send_lock:
                    timeout_tot += timeout_sec
                    i += 1
                    #self._make_sure_error_response_handler_worker_alive()
                    self.write(message)
                    self._sent_notifications.append(dict({'id': identifier, 'message': message}))
                    _logger.debug(""send notification to APNS."")
                    
                    rlist, _, _ = select.select([self._connection()], [], [], WAIT_READ_TIMEOUT_SEC)
                    _logger.debug(""got response from APNS: %d"" % len(rlist))
                    if len(rlist) > 0: # there's some data from APNs
                        self._socket.settimeout(0.5)
                        buff = self.read(ERROR_RESPONSE_LENGTH)
                        if len(self) == ERROR_RESPONSE_LENGTH:
                            command, status, identifier = unpack(ERROR_RESPONSE_FORMAT, buff)
                            if 8 == command: # there is error response from APNS
                                #if self._response_listener:
                                #    self._response_listener(Util.convert_error_response_to_dict(error_response))
                                _logger.info(""got error-response from APNS: %d"" % status)
                                self._disconnect()
                                #self._resend_notifications_by_id(identifier)
                        if len(buff) == 0:
                            _logger.warning(""read socket got 0 bytes data"") #DEBUG
                            self._disconnect()
                    
                    _succ = True
                break
            except socket_error as e:
                timeout_sec *= 2
                _logger.exception(""sending notification with id:"" + str(identifier) + 
                             "" to APNS failed: "" + str(type(e)) + "": "" + str(e) + 
                             "" in "" + str(i+1) + ""th attempt, will wait "" + str(timeout_sec) + "" secs for next action"")
                time.sleep(timeout_sec) # wait potential error-response to be read
        
        return _succ
    else:
        message = self._get_notification(token_hex, payload)
        _logger.debug(""message: %s"" % b2a_hex(message))
        self.write(message)
        return True
<MSG> Fix incorrect variable name
<DFF> @@ -26,7 +26,7 @@
                     if len(rlist) > 0: # there's some data from APNs
                         self._socket.settimeout(0.5)
                         buff = self.read(ERROR_RESPONSE_LENGTH)
-                        if len(self) == ERROR_RESPONSE_LENGTH:
+                        if len(buff) == ERROR_RESPONSE_LENGTH:
                             command, status, identifier = unpack(ERROR_RESPONSE_FORMAT, buff)
                             if 8 == command: # there is error response from APNS
                                 #if self._response_listener:","def send_notification(self, token_hex, payload, identifier=0, expiry=0):
    """"""
    in enhanced mode, send_notification may return error response from APNs if any
    """"""
    if self.enhanced:
        self._last_activity_time = time.time()
        message = self._get_enhanced_notification(token_hex, payload,
                                                       identifier, expiry)
        _logger.debug(""message: %s"" % b2a_hex(message))
        timeout_sec = 2
        timeout_tot = 0
        i = 0
        _succ = False
        while timeout_tot < 30:
            try:
                with self._send_lock:
                    timeout_tot += timeout_sec
                    i += 1
                    #self._make_sure_error_response_handler_worker_alive()
                    self.write(message)
                    self._sent_notifications.append(dict({'id': identifier, 'message': message}))
                    _logger.debug(""send notification to APNS."")
                    
                    rlist, _, _ = select.select([self._connection()], [], [], WAIT_READ_TIMEOUT_SEC)
                    _logger.debug(""got response from APNS: %d"" % len(rlist))
                    if len(rlist) > 0: # there's some data from APNs
                        self._socket.settimeout(0.5)
                        buff = self.read(ERROR_RESPONSE_LENGTH)
                        if len(buff) == ERROR_RESPONSE_LENGTH:
                            command, status, identifier = unpack(ERROR_RESPONSE_FORMAT, buff)
                            if 8 == command: # there is error response from APNS
                                #if self._response_listener:
                                #    self._response_listener(Util.convert_error_response_to_dict(error_response))
                                _logger.info(""got error-response from APNS: %d"" % status)
                                self._disconnect()
                                #self._resend_notifications_by_id(identifier)
                        if len(buff) == 0:
                            _logger.warning(""read socket got 0 bytes data"") #DEBUG
                            self._disconnect()
                    
                    _succ = True
                break
            except socket_error as e:
                timeout_sec *= 2
                _logger.exception(""sending notification with id:"" + str(identifier) + 
                             "" to APNS failed: "" + str(type(e)) + "": "" + str(e) + 
                             "" in "" + str(i+1) + ""th attempt, will wait "" + str(timeout_sec) + "" secs for next action"")
                time.sleep(timeout_sec) # wait potential error-response to be read
        
        return _succ
    else:
        message = self._get_notification(token_hex, payload)
        _logger.debug(""message: %s"" % b2a_hex(message))
        self.write(message)
        return True",1,"<NME> apns_enhanced.py
<BEF> def send_notification(self, token_hex, payload, identifier=0, expiry=0):
    """"""
    in enhanced mode, send_notification may return error response from APNs if any
    """"""
    if self.enhanced:
        self._last_activity_time = time.time()
        message = self._get_enhanced_notification(token_hex, payload,
                                                       identifier, expiry)
        _logger.debug(""message: %s"" % b2a_hex(message))
        timeout_sec = 2
        timeout_tot = 0
        i = 0
        _succ = False
        while timeout_tot < 30:
            try:
                with self._send_lock:
                    timeout_tot += timeout_sec
                    i += 1
                    #self._make_sure_error_response_handler_worker_alive()
                    self.write(message)
                    self._sent_notifications.append(dict({'id': identifier, 'message': message}))
                    _logger.debug(""send notification to APNS."")
                    
                    rlist, _, _ = select.select([self._connection()], [], [], WAIT_READ_TIMEOUT_SEC)
                    _logger.debug(""got response from APNS: %d"" % len(rlist))
                    if len(rlist) > 0: # there's some data from APNs
                        self._socket.settimeout(0.5)
                        buff = self.read(ERROR_RESPONSE_LENGTH)
                        if len(self) == ERROR_RESPONSE_LENGTH:
                            command, status, identifier = unpack(ERROR_RESPONSE_FORMAT, buff)
                            if 8 == command: # there is error response from APNS
                                #if self._response_listener:
                                #    self._response_listener(Util.convert_error_response_to_dict(error_response))
                                _logger.info(""got error-response from APNS: %d"" % status)
                                self._disconnect()
                                #self._resend_notifications_by_id(identifier)
                        if len(buff) == 0:
                            _logger.warning(""read socket got 0 bytes data"") #DEBUG
                            self._disconnect()
                    
                    _succ = True
                break
            except socket_error as e:
                timeout_sec *= 2
                _logger.exception(""sending notification with id:"" + str(identifier) + 
                             "" to APNS failed: "" + str(type(e)) + "": "" + str(e) + 
                             "" in "" + str(i+1) + ""th attempt, will wait "" + str(timeout_sec) + "" secs for next action"")
                time.sleep(timeout_sec) # wait potential error-response to be read
        
        return _succ
    else:
        message = self._get_notification(token_hex, payload)
        _logger.debug(""message: %s"" % b2a_hex(message))
        self.write(message)
        return True
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def send_notification(self, token_hex, payload, identifier=0, expiry=0):
    """"""
    in enhanced mode, send_notification may return error response from APNs if any
    """"""
    if self.enhanced:
        self._last_activity_time = time.time()
        message = self._get_enhanced_notification(token_hex, payload,
                                                       identifier, expiry)
        _logger.debug(""message: %s"" % b2a_hex(message))
        timeout_sec = 2
        timeout_tot = 0
        i = 0
        _succ = False
        while timeout_tot < 30:
            try:
                with self._send_lock:
                    timeout_tot += timeout_sec
                    i += 1
                    #self._make_sure_error_response_handler_worker_alive()
                    self.write(message)
                    self._sent_notifications.append(dict({'id': identifier, 'message': message}))
                    _logger.debug(""send notification to APNS."")
                    
                    rlist, _, _ = select.select([self._connection()], [], [], WAIT_READ_TIMEOUT_SEC)
                    _logger.debug(""got response from APNS: %d"" % len(rlist))
                    if len(rlist) > 0: # there's some data from APNs
                        self._socket.settimeout(0.5)
                        buff = self.read(ERROR_RESPONSE_LENGTH)
                        if len(self) == ERROR_RESPONSE_LENGTH:
                            command, status, identifier = unpack(ERROR_RESPONSE_FORMAT, buff)
                            if 8 == command: # there is error response from APNS
                                #if self._response_listener:
                                #    self._response_listener(Util.convert_error_response_to_dict(error_response))
                                _logger.info(""got error-response from APNS: %d"" % status)
                                self._disconnect()
                                #self._resend_notifications_by_id(identifier)
                        if len(buff) == 0:
                            _logger.warning(""read socket got 0 bytes data"") #DEBUG
                            self._disconnect()
                    
                    _succ = True
                break
            except socket_error as e:
                timeout_sec *= 2
                _logger.exception(""sending notification with id:"" + str(identifier) + 
                             "" to APNS failed: "" + str(type(e)) + "": "" + str(e) + 
                             "" in "" + str(i+1) + ""th attempt, will wait "" + str(timeout_sec) + "" secs for next action"")
                time.sleep(timeout_sec) # wait potential error-response to be read
        
        return _succ
    else:
        message = self._get_notification(token_hex, payload)
        _logger.debug(""message: %s"" % b2a_hex(message))
        self.write(message)
        return True"
"<NME> merge_test.py
<BEF> def compare_explore_more_trials_with_removing_duplicates(self,traj):
    traj.explored ={'Normal.trial': [0,1,0,1,0,1],
        'Numpy.double': [np.array([1.0,2.0,3.0,4.0]),
                         np.array([1.0,2.0,3.0,4.0]),
                         np.array([-1.0,3.0,5.0,7.0]),
                         np.array([-1.0,3.0,5.0,7.0]),
                         np.array([-1.0,2.0,3.0,5.0]),
                         np.array([-1.0,2.0,3.0,5.0])]}

    traj.f_explore(self.explored)
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def compare_explore_more_trials_with_removing_duplicates(self,traj):
-    traj.explored ={'Normal.trial': [0,1,0,1,0,1],
+    self.explored ={'Normal.trial': [0,1,0,1,0,1],
         'Numpy.double': [np.array([1.0,2.0,3.0,4.0]),
                          np.array([1.0,2.0,3.0,4.0]),
                          np.array([-1.0,3.0,5.0,7.0]),","def compare_explore_more_trials_with_removing_duplicates(self,traj):
    self.explored ={'Normal.trial': [0,1,0,1,0,1],
        'Numpy.double': [np.array([1.0,2.0,3.0,4.0]),
                         np.array([1.0,2.0,3.0,4.0]),
                         np.array([-1.0,3.0,5.0,7.0]),
                         np.array([-1.0,3.0,5.0,7.0]),
                         np.array([-1.0,2.0,3.0,5.0]),
                         np.array([-1.0,2.0,3.0,5.0])]}

    traj.f_explore(self.explored)",2,"<NME> merge_test.py
<BEF> def compare_explore_more_trials_with_removing_duplicates(self,traj):
    traj.explored ={'Normal.trial': [0,1,0,1,0,1],
        'Numpy.double': [np.array([1.0,2.0,3.0,4.0]),
                         np.array([1.0,2.0,3.0,4.0]),
                         np.array([-1.0,3.0,5.0,7.0]),
                         np.array([-1.0,3.0,5.0,7.0]),
                         np.array([-1.0,2.0,3.0,5.0]),
                         np.array([-1.0,2.0,3.0,5.0])]}

    traj.f_explore(self.explored)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def compare_explore_more_trials_with_removing_duplicates(self,traj):
    traj.explored ={'Normal.trial': [0,1,0,1,0,1],
        'Numpy.double': [np.array([1.0,2.0,3.0,4.0]),
                         np.array([1.0,2.0,3.0,4.0]),
                         np.array([-1.0,3.0,5.0,7.0]),
                         np.array([-1.0,3.0,5.0,7.0]),
                         np.array([-1.0,2.0,3.0,5.0]),
                         np.array([-1.0,2.0,3.0,5.0])]}

    traj.f_explore(self.explored)"
"<NME> datapackage.py
<BEF> def __init__(self, url):
    # TODO: currently only local paths are supported
    if is_local(url) and not url.endswith(""/""):
        url = url + ""/""

    self.url = url

    infopath = urljoin(url, ""datapackage.json"")
    metadata = read_json(infopath)
    with open(infopath) as f:
        try:
            metadata = json.load(f)
        except Exception as e:
            raise Exception(""Unable to read %s: %s""
                            % (infopath, str(e)))

    self.name = metadata.get(""name"")
    self._resources = OrderedDict()
    for i, res in enumerate(metadata[""resources""]):
        resource = DataPackageResource(self, res)
        if not resource.name:
            resource.name = ""resource%d"" % self

        if resource.name in self._resources:
            raise Exception(""Duplicate resource '%s' in data package '%s'""
                            % (resource.name, self.name))
        self._resources[resource.name] = resource
<MSG> Fix incorrect variable name
<DFF> @@ -19,7 +19,7 @@
     for i, res in enumerate(metadata[""resources""]):
         resource = DataPackageResource(self, res)
         if not resource.name:
-            resource.name = ""resource%d"" % self
+            resource.name = ""resource%d"" % i
 
         if resource.name in self._resources:
             raise Exception(""Duplicate resource '%s' in data package '%s'""","def __init__(self, url):
    # TODO: currently only local paths are supported
    if is_local(url) and not url.endswith(""/""):
        url = url + ""/""

    self.url = url

    infopath = urljoin(url, ""datapackage.json"")
    metadata = read_json(infopath)
    with open(infopath) as f:
        try:
            metadata = json.load(f)
        except Exception as e:
            raise Exception(""Unable to read %s: %s""
                            % (infopath, str(e)))

    self.name = metadata.get(""name"")
    self._resources = OrderedDict()
    for i, res in enumerate(metadata[""resources""]):
        resource = DataPackageResource(self, res)
        if not resource.name:
            resource.name = ""resource%d"" % i

        if resource.name in self._resources:
            raise Exception(""Duplicate resource '%s' in data package '%s'""
                            % (resource.name, self.name))
        self._resources[resource.name] = resource",3,"<NME> datapackage.py
<BEF> def __init__(self, url):
    # TODO: currently only local paths are supported
    if is_local(url) and not url.endswith(""/""):
        url = url + ""/""

    self.url = url

    infopath = urljoin(url, ""datapackage.json"")
    metadata = read_json(infopath)
    with open(infopath) as f:
        try:
            metadata = json.load(f)
        except Exception as e:
            raise Exception(""Unable to read %s: %s""
                            % (infopath, str(e)))

    self.name = metadata.get(""name"")
    self._resources = OrderedDict()
    for i, res in enumerate(metadata[""resources""]):
        resource = DataPackageResource(self, res)
        if not resource.name:
            resource.name = ""resource%d"" % self

        if resource.name in self._resources:
            raise Exception(""Duplicate resource '%s' in data package '%s'""
                            % (resource.name, self.name))
        self._resources[resource.name] = resource
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, url):
    # TODO: currently only local paths are supported
    if is_local(url) and not url.endswith(""/""):
        url = url + ""/""

    self.url = url

    infopath = urljoin(url, ""datapackage.json"")
    metadata = read_json(infopath)
    with open(infopath) as f:
        try:
            metadata = json.load(f)
        except Exception as e:
            raise Exception(""Unable to read %s: %s""
                            % (infopath, str(e)))

    self.name = metadata.get(""name"")
    self._resources = OrderedDict()
    for i, res in enumerate(metadata[""resources""]):
        resource = DataPackageResource(self, res)
        if not resource.name:
            resource.name = ""resource%d"" % self

        if resource.name in self._resources:
            raise Exception(""Duplicate resource '%s' in data package '%s'""
                            % (resource.name, self.name))
        self._resources[resource.name] = resource"
"<NME> highlight.py
<BEF> def redraw(self, view):
    """"""Redraw all marks in the given view.""""""
    self.clear(view)
    view.draw(view)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def redraw(self, view):
     """"""Redraw all marks in the given view.""""""
     self.clear(view)
-    view.draw(view)
+    self.draw(view)","def redraw(self, view):
    """"""Redraw all marks in the given view.""""""
    self.clear(view)
    self.draw(view)",4,"<NME> highlight.py
<BEF> def redraw(self, view):
    """"""Redraw all marks in the given view.""""""
    self.clear(view)
    view.draw(view)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def redraw(self, view):
    """"""Redraw all marks in the given view.""""""
    self.clear(view)
    view.draw(view)"
"<NME> field_nodes.py
<BEF> def __init__(self, fields = None, chars = None):
    """"""Creates a node for string stripping.

    :Attributes:
        * `fields`: fields to be stripped
        * `chars`: characters to be stripped

    """"""
    super(StringStripNode, self).__init__()

    self.fields = self
    self.chars = chars
<MSG> Fix incorrect variable name
<DFF> @@ -8,5 +8,5 @@
     """"""
     super(StringStripNode, self).__init__()
 
-    self.fields = self
+    self.fields = fields
     self.chars = chars","def __init__(self, fields = None, chars = None):
    """"""Creates a node for string stripping.

    :Attributes:
        * `fields`: fields to be stripped
        * `chars`: characters to be stripped

    """"""
    super(StringStripNode, self).__init__()

    self.fields = fields
    self.chars = chars",5,"<NME> field_nodes.py
<BEF> def __init__(self, fields = None, chars = None):
    """"""Creates a node for string stripping.

    :Attributes:
        * `fields`: fields to be stripped
        * `chars`: characters to be stripped

    """"""
    super(StringStripNode, self).__init__()

    self.fields = self
    self.chars = chars
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, fields = None, chars = None):
    """"""Creates a node for string stripping.

    :Attributes:
        * `fields`: fields to be stripped
        * `chars`: characters to be stripped

    """"""
    super(StringStripNode, self).__init__()

    self.fields = self
    self.chars = chars"
"<NME> client.py
<BEF> def _remove_all_contracts(self):
    to_remove = list()
    with self.contracts_lock:
        for c in to_remove.contracts.values():
            to_remove.append(c)
    for c in to_remove:
        self._remove_contract(c)
<MSG> Fix incorrect variable name
<DFF> @@ -1,7 +1,7 @@
 def _remove_all_contracts(self):
     to_remove = list()
     with self.contracts_lock:
-        for c in to_remove.contracts.values():
+        for c in self.contracts.values():
             to_remove.append(c)
     for c in to_remove:
         self._remove_contract(c)","def _remove_all_contracts(self):
    to_remove = list()
    with self.contracts_lock:
        for c in self.contracts.values():
            to_remove.append(c)
    for c in to_remove:
        self._remove_contract(c)",6,"<NME> client.py
<BEF> def _remove_all_contracts(self):
    to_remove = list()
    with self.contracts_lock:
        for c in to_remove.contracts.values():
            to_remove.append(c)
    for c in to_remove:
        self._remove_contract(c)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _remove_all_contracts(self):
    to_remove = list()
    with self.contracts_lock:
        for c in to_remove.contracts.values():
            to_remove.append(c)
    for c in to_remove:
        self._remove_contract(c)"
"<NME> functioncompletions.py
<BEF> def on_query_completions(self, view, prefix, locations):
    if not view.match_selector(locations[0],
            ""source.cfscript.cfc - text - meta - string - comment""):
        return []

    if not SETTINGS.get(""component_method_completions""):
        return

    # set local _completions variable
    _completions = []

    # try and find the cfc file and add it's methods
    try:
        cfc_region = view.find_by_selector(""meta.component-operator.extends.value.cfscript"")[0]
    except IndexError:
        cfc_region = """"

    if len(cfc_region):
        extendspath =  view.substr(cfc_region).replace(""."",""/"")

        # first check the current directory for nested cfc path
        # get the dir this file is in first
        this_file = view.file_name()
        dir_len = this_file.rfind('/') #(for OSX)
        if not dir_len > 0:
            dir_len = this_file.rfind('\\') #(for Windows)
        this_dir = this_file[:(dir_len + 1)] # adds ending '/'

        cfc_file = this_dir + extendspath + "".cfc""
        if not os.path.isfile(cfc_file):
            # check for the cfc in root folders
            for folder in sublime.active_window().folders():
                if os.path.isfile(folder + ""/"" + extendspath + "".cfc""):
                    cfc_file = folder + ""/"" + extendspath + "".cfc""
                    break
        try:
            add_methods(view, view.substr(cfc_region).split(""."")[-1] )
        except UnboundLocalError:
            pass
        except IOError:
            pass

    # add this files methods to autocomplete
    add_methods(view.file_name(), ""this"")

    # add the completions to the local _completions variable
    _completions.extend(completions)

    # prevents dups
    del completions[:]
    return _completions
<MSG> Fix incorrect variable name
<DFF> @@ -34,7 +34,7 @@
                     cfc_file = folder + ""/"" + extendspath + "".cfc""
                     break
         try:
-            add_methods(view, view.substr(cfc_region).split(""."")[-1] )
+            add_methods(cfc_file, view.substr(cfc_region).split(""."")[-1] )
         except UnboundLocalError:
             pass
         except IOError:","def on_query_completions(self, view, prefix, locations):
    if not view.match_selector(locations[0],
            ""source.cfscript.cfc - text - meta - string - comment""):
        return []

    if not SETTINGS.get(""component_method_completions""):
        return

    # set local _completions variable
    _completions = []

    # try and find the cfc file and add it's methods
    try:
        cfc_region = view.find_by_selector(""meta.component-operator.extends.value.cfscript"")[0]
    except IndexError:
        cfc_region = """"

    if len(cfc_region):
        extendspath =  view.substr(cfc_region).replace(""."",""/"")

        # first check the current directory for nested cfc path
        # get the dir this file is in first
        this_file = view.file_name()
        dir_len = this_file.rfind('/') #(for OSX)
        if not dir_len > 0:
            dir_len = this_file.rfind('\\') #(for Windows)
        this_dir = this_file[:(dir_len + 1)] # adds ending '/'

        cfc_file = this_dir + extendspath + "".cfc""
        if not os.path.isfile(cfc_file):
            # check for the cfc in root folders
            for folder in sublime.active_window().folders():
                if os.path.isfile(folder + ""/"" + extendspath + "".cfc""):
                    cfc_file = folder + ""/"" + extendspath + "".cfc""
                    break
        try:
            add_methods(cfc_file, view.substr(cfc_region).split(""."")[-1] )
        except UnboundLocalError:
            pass
        except IOError:
            pass

    # add this files methods to autocomplete
    add_methods(view.file_name(), ""this"")

    # add the completions to the local _completions variable
    _completions.extend(completions)

    # prevents dups
    del completions[:]
    return _completions",7,"<NME> functioncompletions.py
<BEF> def on_query_completions(self, view, prefix, locations):
    if not view.match_selector(locations[0],
            ""source.cfscript.cfc - text - meta - string - comment""):
        return []

    if not SETTINGS.get(""component_method_completions""):
        return

    # set local _completions variable
    _completions = []

    # try and find the cfc file and add it's methods
    try:
        cfc_region = view.find_by_selector(""meta.component-operator.extends.value.cfscript"")[0]
    except IndexError:
        cfc_region = """"

    if len(cfc_region):
        extendspath =  view.substr(cfc_region).replace(""."",""/"")

        # first check the current directory for nested cfc path
        # get the dir this file is in first
        this_file = view.file_name()
        dir_len = this_file.rfind('/') #(for OSX)
        if not dir_len > 0:
            dir_len = this_file.rfind('\\') #(for Windows)
        this_dir = this_file[:(dir_len + 1)] # adds ending '/'

        cfc_file = this_dir + extendspath + "".cfc""
        if not os.path.isfile(cfc_file):
            # check for the cfc in root folders
            for folder in sublime.active_window().folders():
                if os.path.isfile(folder + ""/"" + extendspath + "".cfc""):
                    cfc_file = folder + ""/"" + extendspath + "".cfc""
                    break
        try:
            add_methods(view, view.substr(cfc_region).split(""."")[-1] )
        except UnboundLocalError:
            pass
        except IOError:
            pass

    # add this files methods to autocomplete
    add_methods(view.file_name(), ""this"")

    # add the completions to the local _completions variable
    _completions.extend(completions)

    # prevents dups
    del completions[:]
    return _completions
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def on_query_completions(self, view, prefix, locations):
    if not view.match_selector(locations[0],
            ""source.cfscript.cfc - text - meta - string - comment""):
        return []

    if not SETTINGS.get(""component_method_completions""):
        return

    # set local _completions variable
    _completions = []

    # try and find the cfc file and add it's methods
    try:
        cfc_region = view.find_by_selector(""meta.component-operator.extends.value.cfscript"")[0]
    except IndexError:
        cfc_region = """"

    if len(cfc_region):
        extendspath =  view.substr(cfc_region).replace(""."",""/"")

        # first check the current directory for nested cfc path
        # get the dir this file is in first
        this_file = view.file_name()
        dir_len = this_file.rfind('/') #(for OSX)
        if not dir_len > 0:
            dir_len = this_file.rfind('\\') #(for Windows)
        this_dir = this_file[:(dir_len + 1)] # adds ending '/'

        cfc_file = this_dir + extendspath + "".cfc""
        if not os.path.isfile(cfc_file):
            # check for the cfc in root folders
            for folder in sublime.active_window().folders():
                if os.path.isfile(folder + ""/"" + extendspath + "".cfc""):
                    cfc_file = folder + ""/"" + extendspath + "".cfc""
                    break
        try:
            add_methods(view, view.substr(cfc_region).split(""."")[-1] )
        except UnboundLocalError:
            pass
        except IOError:
            pass

    # add this files methods to autocomplete
    add_methods(view.file_name(), ""this"")

    # add the completions to the local _completions variable
    _completions.extend(completions)

    # prevents dups
    del completions[:]
    return _completions"
"<NME> errormeasuretest.py
<BEF> def initialize_test(self):
    """"""Test if calculate throws an error as expected.""""""
    data   = [[0.0, 0.0], [1, 0.1], [2, 0.2], [3, 0.3], [4, 0.4]]
    tsOrg  = TimeSeries.from_twodim_list(data)
    tsCalc = TimeSeries.from_twodim_list(data)

    bem = BaseErrorMeasure()

    try:
        bem.initialize(tsOrg, bem)
    except NotImplementedError:
        pass
    else:
        assert False    # pragma: no cover

    assert not bem.initialize(tsOrg, TimeSeries())
<MSG> Fix incorrect variable name
<DFF> @@ -7,7 +7,7 @@
     bem = BaseErrorMeasure()
 
     try:
-        bem.initialize(tsOrg, bem)
+        bem.initialize(tsOrg, tsCalc)
     except NotImplementedError:
         pass
     else:","def initialize_test(self):
    """"""Test if calculate throws an error as expected.""""""
    data   = [[0.0, 0.0], [1, 0.1], [2, 0.2], [3, 0.3], [4, 0.4]]
    tsOrg  = TimeSeries.from_twodim_list(data)
    tsCalc = TimeSeries.from_twodim_list(data)

    bem = BaseErrorMeasure()

    try:
        bem.initialize(tsOrg, tsCalc)
    except NotImplementedError:
        pass
    else:
        assert False    # pragma: no cover

    assert not bem.initialize(tsOrg, TimeSeries())",8,"<NME> errormeasuretest.py
<BEF> def initialize_test(self):
    """"""Test if calculate throws an error as expected.""""""
    data   = [[0.0, 0.0], [1, 0.1], [2, 0.2], [3, 0.3], [4, 0.4]]
    tsOrg  = TimeSeries.from_twodim_list(data)
    tsCalc = TimeSeries.from_twodim_list(data)

    bem = BaseErrorMeasure()

    try:
        bem.initialize(tsOrg, bem)
    except NotImplementedError:
        pass
    else:
        assert False    # pragma: no cover

    assert not bem.initialize(tsOrg, TimeSeries())
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def initialize_test(self):
    """"""Test if calculate throws an error as expected.""""""
    data   = [[0.0, 0.0], [1, 0.1], [2, 0.2], [3, 0.3], [4, 0.4]]
    tsOrg  = TimeSeries.from_twodim_list(data)
    tsCalc = TimeSeries.from_twodim_list(data)

    bem = BaseErrorMeasure()

    try:
        bem.initialize(tsOrg, bem)
    except NotImplementedError:
        pass
    else:
        assert False    # pragma: no cover

    assert not bem.initialize(tsOrg, TimeSeries())"
"<NME> manifest.py
<BEF> def testDependentServiceExtension(self):
    """"""Assigning more references to an attribute""""""
    importConfigurationManifest(
        'wdrtest/manifests/references/dependent_service.wdrc', topology
    )
    importConfigurationManifest(
        'wdrtest/manifests/references/dependent_service2.wdrc', topology
    )
    server = getid1(
        '/Cell:%(cellName)s/Node:%(nodeName)s/Server:%(serverName)s/'
        % topology
    )
    referenceList = server.lookup1(
        'CustomService',
        {
            'displayName': 'with dependencies',
        },
        'customServices'
    ).prerequisiteServices
    self.assertEquals(len(self), 5)
    self.assertEquals(referenceList[0].displayName, 'first')
    self.assertEquals(referenceList[1].displayName, 'second')
    self.assertEquals(referenceList[2].displayName, 'fifth')
    self.assertEquals(referenceList[3].displayName, 'third')
    self.assertEquals(referenceList[4].displayName, 'fourth')
<MSG> Fix incorrect variable name
<DFF> @@ -17,7 +17,7 @@
         },
         'customServices'
     ).prerequisiteServices
-    self.assertEquals(len(self), 5)
+    self.assertEquals(len(referenceList), 5)
     self.assertEquals(referenceList[0].displayName, 'first')
     self.assertEquals(referenceList[1].displayName, 'second')
     self.assertEquals(referenceList[2].displayName, 'fifth')","def testDependentServiceExtension(self):
    """"""Assigning more references to an attribute""""""
    importConfigurationManifest(
        'wdrtest/manifests/references/dependent_service.wdrc', topology
    )
    importConfigurationManifest(
        'wdrtest/manifests/references/dependent_service2.wdrc', topology
    )
    server = getid1(
        '/Cell:%(cellName)s/Node:%(nodeName)s/Server:%(serverName)s/'
        % topology
    )
    referenceList = server.lookup1(
        'CustomService',
        {
            'displayName': 'with dependencies',
        },
        'customServices'
    ).prerequisiteServices
    self.assertEquals(len(referenceList), 5)
    self.assertEquals(referenceList[0].displayName, 'first')
    self.assertEquals(referenceList[1].displayName, 'second')
    self.assertEquals(referenceList[2].displayName, 'fifth')
    self.assertEquals(referenceList[3].displayName, 'third')
    self.assertEquals(referenceList[4].displayName, 'fourth')",9,"<NME> manifest.py
<BEF> def testDependentServiceExtension(self):
    """"""Assigning more references to an attribute""""""
    importConfigurationManifest(
        'wdrtest/manifests/references/dependent_service.wdrc', topology
    )
    importConfigurationManifest(
        'wdrtest/manifests/references/dependent_service2.wdrc', topology
    )
    server = getid1(
        '/Cell:%(cellName)s/Node:%(nodeName)s/Server:%(serverName)s/'
        % topology
    )
    referenceList = server.lookup1(
        'CustomService',
        {
            'displayName': 'with dependencies',
        },
        'customServices'
    ).prerequisiteServices
    self.assertEquals(len(self), 5)
    self.assertEquals(referenceList[0].displayName, 'first')
    self.assertEquals(referenceList[1].displayName, 'second')
    self.assertEquals(referenceList[2].displayName, 'fifth')
    self.assertEquals(referenceList[3].displayName, 'third')
    self.assertEquals(referenceList[4].displayName, 'fourth')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testDependentServiceExtension(self):
    """"""Assigning more references to an attribute""""""
    importConfigurationManifest(
        'wdrtest/manifests/references/dependent_service.wdrc', topology
    )
    importConfigurationManifest(
        'wdrtest/manifests/references/dependent_service2.wdrc', topology
    )
    server = getid1(
        '/Cell:%(cellName)s/Node:%(nodeName)s/Server:%(serverName)s/'
        % topology
    )
    referenceList = server.lookup1(
        'CustomService',
        {
            'displayName': 'with dependencies',
        },
        'customServices'
    ).prerequisiteServices
    self.assertEquals(len(self), 5)
    self.assertEquals(referenceList[0].displayName, 'first')
    self.assertEquals(referenceList[1].displayName, 'second')
    self.assertEquals(referenceList[2].displayName, 'fifth')
    self.assertEquals(referenceList[3].displayName, 'third')
    self.assertEquals(referenceList[4].displayName, 'fourth')"
"<NME> hlsproxy.py
<BEF> def _readBodyCallback(self, dRes, body):
    dRes.busy = False
    dRes.callback(body)
    self._processQ()
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def _readBodyCallback(self, dRes, body):
-    dRes.busy = False
+    self.busy = False
     dRes.callback(body)
     self._processQ()","def _readBodyCallback(self, dRes, body):
    self.busy = False
    dRes.callback(body)
    self._processQ()",0,"<NME> hlsproxy.py
<BEF> def _readBodyCallback(self, dRes, body):
    dRes.busy = False
    dRes.callback(body)
    self._processQ()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _readBodyCallback(self, dRes, body):
    dRes.busy = False
    dRes.callback(body)
    self._processQ()"
"<NME> nodeserver_api.py
<BEF> def listen(self, event, handler):
    """"""
    Register an event handler. Returns True on success. Event names are
    defined in `commands`. Handlers must be callable.

    :param str event: Then event name to listen for.
    :param callable handler: The callable event handler.
    """"""
    if event not in handler.commands:
        return False
    if not callable(handler):
        return False

    self._handlers[event].append(handler)
    return True
<MSG> Fix incorrect variable name
<DFF> @@ -6,7 +6,7 @@
     :param str event: Then event name to listen for.
     :param callable handler: The callable event handler.
     """"""
-    if event not in handler.commands:
+    if event not in self.commands:
         return False
     if not callable(handler):
         return False","def listen(self, event, handler):
    """"""
    Register an event handler. Returns True on success. Event names are
    defined in `commands`. Handlers must be callable.

    :param str event: Then event name to listen for.
    :param callable handler: The callable event handler.
    """"""
    if event not in self.commands:
        return False
    if not callable(handler):
        return False

    self._handlers[event].append(handler)
    return True",1,"<NME> nodeserver_api.py
<BEF> def listen(self, event, handler):
    """"""
    Register an event handler. Returns True on success. Event names are
    defined in `commands`. Handlers must be callable.

    :param str event: Then event name to listen for.
    :param callable handler: The callable event handler.
    """"""
    if event not in handler.commands:
        return False
    if not callable(handler):
        return False

    self._handlers[event].append(handler)
    return True
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def listen(self, event, handler):
    """"""
    Register an event handler. Returns True on success. Event names are
    defined in `commands`. Handlers must be callable.

    :param str event: Then event name to listen for.
    :param callable handler: The callable event handler.
    """"""
    if event not in handler.commands:
        return False
    if not callable(handler):
        return False

    self._handlers[event].append(handler)
    return True"
"<NME> build_test.py
<BEF> def test__path_contained_by(self):
    p1 = '/foo//bar/baz/../stuff/'
    p2 = '/a/b/c/d/../../../../foo/bar/stufff'
    p3 = '/a/b/c/d/../../../../foo/bar/stuff/11'
    assert not build._path_contained_by(p1, p2)
    assert build._path_contained_by(p1, self)
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
     p2 = '/a/b/c/d/../../../../foo/bar/stufff'
     p3 = '/a/b/c/d/../../../../foo/bar/stuff/11'
     assert not build._path_contained_by(p1, p2)
-    assert build._path_contained_by(p1, self)
+    assert build._path_contained_by(p1, p3)","def test__path_contained_by(self):
    p1 = '/foo//bar/baz/../stuff/'
    p2 = '/a/b/c/d/../../../../foo/bar/stufff'
    p3 = '/a/b/c/d/../../../../foo/bar/stuff/11'
    assert not build._path_contained_by(p1, p2)
    assert build._path_contained_by(p1, p3)",2,"<NME> build_test.py
<BEF> def test__path_contained_by(self):
    p1 = '/foo//bar/baz/../stuff/'
    p2 = '/a/b/c/d/../../../../foo/bar/stufff'
    p3 = '/a/b/c/d/../../../../foo/bar/stuff/11'
    assert not build._path_contained_by(p1, p2)
    assert build._path_contained_by(p1, self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test__path_contained_by(self):
    p1 = '/foo//bar/baz/../stuff/'
    p2 = '/a/b/c/d/../../../../foo/bar/stufff'
    p3 = '/a/b/c/d/../../../../foo/bar/stuff/11'
    assert not build._path_contained_by(p1, p2)
    assert build._path_contained_by(p1, self)"
"<NME> nimcheck.py
<BEF> @send_self
@catch_errors
def run(self, *args, **varargs):
    this = yield
    window = sublime.active_window()
    view = window.active_view()
    view_name = os.path.split(view.file_name() or view.name())[1]

    frames = ['Running Nim Check' + f for f in busy_frames]
    stop_status_loop = loop_status_msg(frames, 0.15)

    # Save view text
    if view.is_dirty():
        view.run_command('save')

    # Run 'nim check' on the current view and retrieve the output.
    # project_file = get_nim_project(window, view) or view.file_name()
    process, stdout, stderr, error = yield run_nimcheck(
        view.file_name(), this.send, self.verbosity
    )
    yield stop_status_loop(get_next_method(this))

    if handle_process_error(error, 'Nim Check Failed', 'Nim'):
        yield

    messages = parse_nimcheck_output(stdout)
    sublime.status_message('Nim Check Finished.')

    self.highlight_and_list_messages(stop_status_loop, window, view)

    if self.send_output:
        if self.raw_output:
            content = stdout
        else:
            gen = (m[5] for m in messages if view_name == m[0])
            content = '\n'.join(gen)
        self.write_to_output(content, window, view)
    yield
<MSG> Fix incorrect variable name
<DFF> @@ -26,7 +26,7 @@
     messages = parse_nimcheck_output(stdout)
     sublime.status_message('Nim Check Finished.')
 
-    self.highlight_and_list_messages(stop_status_loop, window, view)
+    self.highlight_and_list_messages(messages, window, view)
 
     if self.send_output:
         if self.raw_output:","@send_self
@catch_errors
def run(self, *args, **varargs):
    this = yield
    window = sublime.active_window()
    view = window.active_view()
    view_name = os.path.split(view.file_name() or view.name())[1]

    frames = ['Running Nim Check' + f for f in busy_frames]
    stop_status_loop = loop_status_msg(frames, 0.15)

    # Save view text
    if view.is_dirty():
        view.run_command('save')

    # Run 'nim check' on the current view and retrieve the output.
    # project_file = get_nim_project(window, view) or view.file_name()
    process, stdout, stderr, error = yield run_nimcheck(
        view.file_name(), this.send, self.verbosity
    )
    yield stop_status_loop(get_next_method(this))

    if handle_process_error(error, 'Nim Check Failed', 'Nim'):
        yield

    messages = parse_nimcheck_output(stdout)
    sublime.status_message('Nim Check Finished.')

    self.highlight_and_list_messages(messages, window, view)

    if self.send_output:
        if self.raw_output:
            content = stdout
        else:
            gen = (m[5] for m in messages if view_name == m[0])
            content = '\n'.join(gen)
        self.write_to_output(content, window, view)
    yield",3,"<NME> nimcheck.py
<BEF> @send_self
@catch_errors
def run(self, *args, **varargs):
    this = yield
    window = sublime.active_window()
    view = window.active_view()
    view_name = os.path.split(view.file_name() or view.name())[1]

    frames = ['Running Nim Check' + f for f in busy_frames]
    stop_status_loop = loop_status_msg(frames, 0.15)

    # Save view text
    if view.is_dirty():
        view.run_command('save')

    # Run 'nim check' on the current view and retrieve the output.
    # project_file = get_nim_project(window, view) or view.file_name()
    process, stdout, stderr, error = yield run_nimcheck(
        view.file_name(), this.send, self.verbosity
    )
    yield stop_status_loop(get_next_method(this))

    if handle_process_error(error, 'Nim Check Failed', 'Nim'):
        yield

    messages = parse_nimcheck_output(stdout)
    sublime.status_message('Nim Check Finished.')

    self.highlight_and_list_messages(stop_status_loop, window, view)

    if self.send_output:
        if self.raw_output:
            content = stdout
        else:
            gen = (m[5] for m in messages if view_name == m[0])
            content = '\n'.join(gen)
        self.write_to_output(content, window, view)
    yield
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@send_self
@catch_errors
def run(self, *args, **varargs):
    this = yield
    window = sublime.active_window()
    view = window.active_view()
    view_name = os.path.split(view.file_name() or view.name())[1]

    frames = ['Running Nim Check' + f for f in busy_frames]
    stop_status_loop = loop_status_msg(frames, 0.15)

    # Save view text
    if view.is_dirty():
        view.run_command('save')

    # Run 'nim check' on the current view and retrieve the output.
    # project_file = get_nim_project(window, view) or view.file_name()
    process, stdout, stderr, error = yield run_nimcheck(
        view.file_name(), this.send, self.verbosity
    )
    yield stop_status_loop(get_next_method(this))

    if handle_process_error(error, 'Nim Check Failed', 'Nim'):
        yield

    messages = parse_nimcheck_output(stdout)
    sublime.status_message('Nim Check Finished.')

    self.highlight_and_list_messages(stop_status_loop, window, view)

    if self.send_output:
        if self.raw_output:
            content = stdout
        else:
            gen = (m[5] for m in messages if view_name == m[0])
            content = '\n'.join(gen)
        self.write_to_output(content, window, view)
    yield"
"<NME> models.py
<BEF> def __init__(self, ytid):
    ytid.ytid = ytid
    self.submissions = []
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def __init__(self, ytid):
-    ytid.ytid = ytid
+    self.ytid = ytid
     self.submissions = []","def __init__(self, ytid):
    self.ytid = ytid
    self.submissions = []",4,"<NME> models.py
<BEF> def __init__(self, ytid):
    ytid.ytid = ytid
    self.submissions = []
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, ytid):
    ytid.ytid = ytid
    self.submissions = []"
"<NME> strings.py
<BEF> def __reverse_in_node(self, node_data):
    """"""Generates a string that matches 'in' node
    from the regular expression AST. Such node is an alternative
    between several variants.
    """"""
    chosen = random.choice(node_data)
    type_, data = chosen

    if type_ == 'range': # TODO: add support for negation: [^...]
        min_char, max_char = data
        return chr(random.randint(min_char, max_char))
    if type_ == 'category':
        return self.__reverse_category_node(data)

    return self.__reverse_node(type_)
<MSG> Fix incorrect variable name
<DFF> @@ -12,4 +12,4 @@
     if type_ == 'category':
         return self.__reverse_category_node(data)
 
-    return self.__reverse_node(type_)
+    return self.__reverse_node(chosen)","def __reverse_in_node(self, node_data):
    """"""Generates a string that matches 'in' node
    from the regular expression AST. Such node is an alternative
    between several variants.
    """"""
    chosen = random.choice(node_data)
    type_, data = chosen

    if type_ == 'range': # TODO: add support for negation: [^...]
        min_char, max_char = data
        return chr(random.randint(min_char, max_char))
    if type_ == 'category':
        return self.__reverse_category_node(data)

    return self.__reverse_node(chosen)",5,"<NME> strings.py
<BEF> def __reverse_in_node(self, node_data):
    """"""Generates a string that matches 'in' node
    from the regular expression AST. Such node is an alternative
    between several variants.
    """"""
    chosen = random.choice(node_data)
    type_, data = chosen

    if type_ == 'range': # TODO: add support for negation: [^...]
        min_char, max_char = data
        return chr(random.randint(min_char, max_char))
    if type_ == 'category':
        return self.__reverse_category_node(data)

    return self.__reverse_node(type_)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __reverse_in_node(self, node_data):
    """"""Generates a string that matches 'in' node
    from the regular expression AST. Such node is an alternative
    between several variants.
    """"""
    chosen = random.choice(node_data)
    type_, data = chosen

    if type_ == 'range': # TODO: add support for negation: [^...]
        min_char, max_char = data
        return chr(random.randint(min_char, max_char))
    if type_ == 'category':
        return self.__reverse_category_node(data)

    return self.__reverse_node(type_)"
"<NME> aggregations.py
<BEF> def _build_dict(self):
    if self.nested_path:
        self[self.nested_path] = self._nesting()
    else:
        self[self.agg_name] = {self.metric: {""field"": self.field_name}}
        if self.metric == ""terms"":
            self[self.agg_name][self.metric].update({
                ""size"": self.size,
                ""order"": {self.order_type: self.order_dir},
                ""min_doc_count"": self.min_doc_count
            })

    if self.range_list:
        if not self.range_name:
            range_name = ""{name}_ranges"".format(name=self.field_name)
        else:
            range_name = self.range_name
        self[range_name] = {""range"": {
            ""field"": self.field_name,
            ""ranges"": self._ranging()
        }}
        self.pop(self.agg_name)
    if self.interval:
        self[self.agg_name][""histogram""] = {
            ""field"": self.field_name,
            ""interval"": range_name.interval,
            ""order"": {self.order_type: self.order_dir},
            ""min_doc_count"": self.min_doc_count
        }
        self[self.agg_name].pop(self.metric)
    elif self.filter_val and self.filter_name:
        self[self.filter_name] = {'filter': self.filter_val, 'aggregations': {}}
        self[self.filter_name]['aggregations'][self.agg_name] = self.pop(self.agg_name)
    elif self.global_name:
        self[self.global_name] = {""global"": {}, ""aggregations"": {}}
        self[self.global_name]['aggregations'][self.agg_name] = self.pop(self.agg_name)
<MSG> Fix incorrect variable name
<DFF> @@ -23,7 +23,7 @@
     if self.interval:
         self[self.agg_name][""histogram""] = {
             ""field"": self.field_name,
-            ""interval"": range_name.interval,
+            ""interval"": self.interval,
             ""order"": {self.order_type: self.order_dir},
             ""min_doc_count"": self.min_doc_count
         }","def _build_dict(self):
    if self.nested_path:
        self[self.nested_path] = self._nesting()
    else:
        self[self.agg_name] = {self.metric: {""field"": self.field_name}}
        if self.metric == ""terms"":
            self[self.agg_name][self.metric].update({
                ""size"": self.size,
                ""order"": {self.order_type: self.order_dir},
                ""min_doc_count"": self.min_doc_count
            })

    if self.range_list:
        if not self.range_name:
            range_name = ""{name}_ranges"".format(name=self.field_name)
        else:
            range_name = self.range_name
        self[range_name] = {""range"": {
            ""field"": self.field_name,
            ""ranges"": self._ranging()
        }}
        self.pop(self.agg_name)
    if self.interval:
        self[self.agg_name][""histogram""] = {
            ""field"": self.field_name,
            ""interval"": self.interval,
            ""order"": {self.order_type: self.order_dir},
            ""min_doc_count"": self.min_doc_count
        }
        self[self.agg_name].pop(self.metric)
    elif self.filter_val and self.filter_name:
        self[self.filter_name] = {'filter': self.filter_val, 'aggregations': {}}
        self[self.filter_name]['aggregations'][self.agg_name] = self.pop(self.agg_name)
    elif self.global_name:
        self[self.global_name] = {""global"": {}, ""aggregations"": {}}
        self[self.global_name]['aggregations'][self.agg_name] = self.pop(self.agg_name)",6,"<NME> aggregations.py
<BEF> def _build_dict(self):
    if self.nested_path:
        self[self.nested_path] = self._nesting()
    else:
        self[self.agg_name] = {self.metric: {""field"": self.field_name}}
        if self.metric == ""terms"":
            self[self.agg_name][self.metric].update({
                ""size"": self.size,
                ""order"": {self.order_type: self.order_dir},
                ""min_doc_count"": self.min_doc_count
            })

    if self.range_list:
        if not self.range_name:
            range_name = ""{name}_ranges"".format(name=self.field_name)
        else:
            range_name = self.range_name
        self[range_name] = {""range"": {
            ""field"": self.field_name,
            ""ranges"": self._ranging()
        }}
        self.pop(self.agg_name)
    if self.interval:
        self[self.agg_name][""histogram""] = {
            ""field"": self.field_name,
            ""interval"": range_name.interval,
            ""order"": {self.order_type: self.order_dir},
            ""min_doc_count"": self.min_doc_count
        }
        self[self.agg_name].pop(self.metric)
    elif self.filter_val and self.filter_name:
        self[self.filter_name] = {'filter': self.filter_val, 'aggregations': {}}
        self[self.filter_name]['aggregations'][self.agg_name] = self.pop(self.agg_name)
    elif self.global_name:
        self[self.global_name] = {""global"": {}, ""aggregations"": {}}
        self[self.global_name]['aggregations'][self.agg_name] = self.pop(self.agg_name)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _build_dict(self):
    if self.nested_path:
        self[self.nested_path] = self._nesting()
    else:
        self[self.agg_name] = {self.metric: {""field"": self.field_name}}
        if self.metric == ""terms"":
            self[self.agg_name][self.metric].update({
                ""size"": self.size,
                ""order"": {self.order_type: self.order_dir},
                ""min_doc_count"": self.min_doc_count
            })

    if self.range_list:
        if not self.range_name:
            range_name = ""{name}_ranges"".format(name=self.field_name)
        else:
            range_name = self.range_name
        self[range_name] = {""range"": {
            ""field"": self.field_name,
            ""ranges"": self._ranging()
        }}
        self.pop(self.agg_name)
    if self.interval:
        self[self.agg_name][""histogram""] = {
            ""field"": self.field_name,
            ""interval"": range_name.interval,
            ""order"": {self.order_type: self.order_dir},
            ""min_doc_count"": self.min_doc_count
        }
        self[self.agg_name].pop(self.metric)
    elif self.filter_val and self.filter_name:
        self[self.filter_name] = {'filter': self.filter_val, 'aggregations': {}}
        self[self.filter_name]['aggregations'][self.agg_name] = self.pop(self.agg_name)
    elif self.global_name:
        self[self.global_name] = {""global"": {}, ""aggregations"": {}}
        self[self.global_name]['aggregations'][self.agg_name] = self.pop(self.agg_name)"
"<NME> __init__.py
<BEF> def recognize_sphinx(self, audio_data, language = ""en-US"", show_all = False):
    """"""
    Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using CMU Sphinx.

    The recognition language is determined by ``language``, an RFC5646 language tag like ``""en-US""`` or ``""en-GB""``, defaulting to US English. Out of the box, only ``en-US`` is supported. See `Notes on using `PocketSphinx <https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst>`__ for information about installing other languages. This document is also included under ``reference/pocketsphinx.rst``.

    Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the Sphinx ``pocketsphinx.pocketsphinx.Decoder`` object resulting from the recognition.

    Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if there are any issues with the Sphinx installation.
    """"""
    assert isinstance(audio_data, AudioData), ""`audio_data` must be audio data""
    assert isinstance(audio_data, str), ""`language` must be a string""
    
    # import the PocketSphinx speech recognition module
    try:
        from pocketsphinx import pocketsphinx
        from sphinxbase import sphinxbase
    except ImportError:
        raise RequestError(""missing PocketSphinx module: ensure that PocketSphinx is set up correctly."")
    except ValueError:
        raise RequestError(""bad PocketSphinx installation detected; make sure you have PocketSphinx version 0.0.9 or better."")

    language_directory = os.path.join(os.path.dirname(os.path.realpath(__file__)), ""pocketsphinx-data"", language)
    if not os.path.isdir(language_directory):
        raise RequestError(""missing PocketSphinx language data directory: \""{0}\"""".format(language_directory))
    acoustic_parameters_directory = os.path.join(language_directory, ""acoustic-model"")
    if not os.path.isdir(acoustic_parameters_directory):
        raise RequestError(""missing PocketSphinx language model parameters directory: \""{0}\"""".format(acoustic_parameters_directory))
    language_model_file = os.path.join(language_directory, ""language-model.lm.bin"")
    if not os.path.isfile(language_model_file):
        raise RequestError(""missing PocketSphinx language model file: \""{0}\"""".format(language_model_file))
    phoneme_dictionary_file = os.path.join(language_directory, ""pronounciation-dictionary.dict"")
    if not os.path.isfile(phoneme_dictionary_file):
        raise RequestError(""missing PocketSphinx phoneme dictionary file: \""{0}\"""".format(phoneme_dictionary_file))

    # create decoder object
    config = pocketsphinx.Decoder.default_config()
    config.set_string(""-hmm"", acoustic_parameters_directory) # set the path of the hidden Markov model (HMM) parameter files
    config.set_string(""-lm"", language_model_file)
    config.set_string(""-dict"", phoneme_dictionary_file)
    config.set_string(""-logfn"", os.devnull) # disable logging (logging causes unwanted output in terminal)
    decoder = pocketsphinx.Decoder(config)

    # obtain audio data
    raw_data = audio_data.get_raw_data(convert_rate = 16000, convert_width = 2) # the included language models require audio to be 16-bit mono 16 kHz in little-endian format

    # obtain recognition results
    decoder.start_utt() # begin utterance processing
    decoder.process_raw(raw_data, False, True) # process audio data with recognition enabled (no_search = False), as a full utterance (full_utt = True)
    decoder.end_utt() # stop utterance processing

    if show_all: return decoder

    # return results
    hypothesis = decoder.hyp()
    if hypothesis is not None: return hypothesis.hypstr
    raise UnknownValueError() # no transcriptions available
<MSG> Fix incorrect variable name
<DFF> @@ -9,7 +9,7 @@
     Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if there are any issues with the Sphinx installation.
     """"""
     assert isinstance(audio_data, AudioData), ""`audio_data` must be audio data""
-    assert isinstance(audio_data, str), ""`language` must be a string""
+    assert isinstance(language, str), ""`language` must be a string""
     
     # import the PocketSphinx speech recognition module
     try:","def recognize_sphinx(self, audio_data, language = ""en-US"", show_all = False):
    """"""
    Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using CMU Sphinx.

    The recognition language is determined by ``language``, an RFC5646 language tag like ``""en-US""`` or ``""en-GB""``, defaulting to US English. Out of the box, only ``en-US`` is supported. See `Notes on using `PocketSphinx <https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst>`__ for information about installing other languages. This document is also included under ``reference/pocketsphinx.rst``.

    Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the Sphinx ``pocketsphinx.pocketsphinx.Decoder`` object resulting from the recognition.

    Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if there are any issues with the Sphinx installation.
    """"""
    assert isinstance(audio_data, AudioData), ""`audio_data` must be audio data""
    assert isinstance(language, str), ""`language` must be a string""
    
    # import the PocketSphinx speech recognition module
    try:
        from pocketsphinx import pocketsphinx
        from sphinxbase import sphinxbase
    except ImportError:
        raise RequestError(""missing PocketSphinx module: ensure that PocketSphinx is set up correctly."")
    except ValueError:
        raise RequestError(""bad PocketSphinx installation detected; make sure you have PocketSphinx version 0.0.9 or better."")

    language_directory = os.path.join(os.path.dirname(os.path.realpath(__file__)), ""pocketsphinx-data"", language)
    if not os.path.isdir(language_directory):
        raise RequestError(""missing PocketSphinx language data directory: \""{0}\"""".format(language_directory))
    acoustic_parameters_directory = os.path.join(language_directory, ""acoustic-model"")
    if not os.path.isdir(acoustic_parameters_directory):
        raise RequestError(""missing PocketSphinx language model parameters directory: \""{0}\"""".format(acoustic_parameters_directory))
    language_model_file = os.path.join(language_directory, ""language-model.lm.bin"")
    if not os.path.isfile(language_model_file):
        raise RequestError(""missing PocketSphinx language model file: \""{0}\"""".format(language_model_file))
    phoneme_dictionary_file = os.path.join(language_directory, ""pronounciation-dictionary.dict"")
    if not os.path.isfile(phoneme_dictionary_file):
        raise RequestError(""missing PocketSphinx phoneme dictionary file: \""{0}\"""".format(phoneme_dictionary_file))

    # create decoder object
    config = pocketsphinx.Decoder.default_config()
    config.set_string(""-hmm"", acoustic_parameters_directory) # set the path of the hidden Markov model (HMM) parameter files
    config.set_string(""-lm"", language_model_file)
    config.set_string(""-dict"", phoneme_dictionary_file)
    config.set_string(""-logfn"", os.devnull) # disable logging (logging causes unwanted output in terminal)
    decoder = pocketsphinx.Decoder(config)

    # obtain audio data
    raw_data = audio_data.get_raw_data(convert_rate = 16000, convert_width = 2) # the included language models require audio to be 16-bit mono 16 kHz in little-endian format

    # obtain recognition results
    decoder.start_utt() # begin utterance processing
    decoder.process_raw(raw_data, False, True) # process audio data with recognition enabled (no_search = False), as a full utterance (full_utt = True)
    decoder.end_utt() # stop utterance processing

    if show_all: return decoder

    # return results
    hypothesis = decoder.hyp()
    if hypothesis is not None: return hypothesis.hypstr
    raise UnknownValueError() # no transcriptions available",7,"<NME> __init__.py
<BEF> def recognize_sphinx(self, audio_data, language = ""en-US"", show_all = False):
    """"""
    Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using CMU Sphinx.

    The recognition language is determined by ``language``, an RFC5646 language tag like ``""en-US""`` or ``""en-GB""``, defaulting to US English. Out of the box, only ``en-US`` is supported. See `Notes on using `PocketSphinx <https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst>`__ for information about installing other languages. This document is also included under ``reference/pocketsphinx.rst``.

    Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the Sphinx ``pocketsphinx.pocketsphinx.Decoder`` object resulting from the recognition.

    Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if there are any issues with the Sphinx installation.
    """"""
    assert isinstance(audio_data, AudioData), ""`audio_data` must be audio data""
    assert isinstance(audio_data, str), ""`language` must be a string""
    
    # import the PocketSphinx speech recognition module
    try:
        from pocketsphinx import pocketsphinx
        from sphinxbase import sphinxbase
    except ImportError:
        raise RequestError(""missing PocketSphinx module: ensure that PocketSphinx is set up correctly."")
    except ValueError:
        raise RequestError(""bad PocketSphinx installation detected; make sure you have PocketSphinx version 0.0.9 or better."")

    language_directory = os.path.join(os.path.dirname(os.path.realpath(__file__)), ""pocketsphinx-data"", language)
    if not os.path.isdir(language_directory):
        raise RequestError(""missing PocketSphinx language data directory: \""{0}\"""".format(language_directory))
    acoustic_parameters_directory = os.path.join(language_directory, ""acoustic-model"")
    if not os.path.isdir(acoustic_parameters_directory):
        raise RequestError(""missing PocketSphinx language model parameters directory: \""{0}\"""".format(acoustic_parameters_directory))
    language_model_file = os.path.join(language_directory, ""language-model.lm.bin"")
    if not os.path.isfile(language_model_file):
        raise RequestError(""missing PocketSphinx language model file: \""{0}\"""".format(language_model_file))
    phoneme_dictionary_file = os.path.join(language_directory, ""pronounciation-dictionary.dict"")
    if not os.path.isfile(phoneme_dictionary_file):
        raise RequestError(""missing PocketSphinx phoneme dictionary file: \""{0}\"""".format(phoneme_dictionary_file))

    # create decoder object
    config = pocketsphinx.Decoder.default_config()
    config.set_string(""-hmm"", acoustic_parameters_directory) # set the path of the hidden Markov model (HMM) parameter files
    config.set_string(""-lm"", language_model_file)
    config.set_string(""-dict"", phoneme_dictionary_file)
    config.set_string(""-logfn"", os.devnull) # disable logging (logging causes unwanted output in terminal)
    decoder = pocketsphinx.Decoder(config)

    # obtain audio data
    raw_data = audio_data.get_raw_data(convert_rate = 16000, convert_width = 2) # the included language models require audio to be 16-bit mono 16 kHz in little-endian format

    # obtain recognition results
    decoder.start_utt() # begin utterance processing
    decoder.process_raw(raw_data, False, True) # process audio data with recognition enabled (no_search = False), as a full utterance (full_utt = True)
    decoder.end_utt() # stop utterance processing

    if show_all: return decoder

    # return results
    hypothesis = decoder.hyp()
    if hypothesis is not None: return hypothesis.hypstr
    raise UnknownValueError() # no transcriptions available
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def recognize_sphinx(self, audio_data, language = ""en-US"", show_all = False):
    """"""
    Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using CMU Sphinx.

    The recognition language is determined by ``language``, an RFC5646 language tag like ``""en-US""`` or ``""en-GB""``, defaulting to US English. Out of the box, only ``en-US`` is supported. See `Notes on using `PocketSphinx <https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst>`__ for information about installing other languages. This document is also included under ``reference/pocketsphinx.rst``.

    Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the Sphinx ``pocketsphinx.pocketsphinx.Decoder`` object resulting from the recognition.

    Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if there are any issues with the Sphinx installation.
    """"""
    assert isinstance(audio_data, AudioData), ""`audio_data` must be audio data""
    assert isinstance(audio_data, str), ""`language` must be a string""
    
    # import the PocketSphinx speech recognition module
    try:
        from pocketsphinx import pocketsphinx
        from sphinxbase import sphinxbase
    except ImportError:
        raise RequestError(""missing PocketSphinx module: ensure that PocketSphinx is set up correctly."")
    except ValueError:
        raise RequestError(""bad PocketSphinx installation detected; make sure you have PocketSphinx version 0.0.9 or better."")

    language_directory = os.path.join(os.path.dirname(os.path.realpath(__file__)), ""pocketsphinx-data"", language)
    if not os.path.isdir(language_directory):
        raise RequestError(""missing PocketSphinx language data directory: \""{0}\"""".format(language_directory))
    acoustic_parameters_directory = os.path.join(language_directory, ""acoustic-model"")
    if not os.path.isdir(acoustic_parameters_directory):
        raise RequestError(""missing PocketSphinx language model parameters directory: \""{0}\"""".format(acoustic_parameters_directory))
    language_model_file = os.path.join(language_directory, ""language-model.lm.bin"")
    if not os.path.isfile(language_model_file):
        raise RequestError(""missing PocketSphinx language model file: \""{0}\"""".format(language_model_file))
    phoneme_dictionary_file = os.path.join(language_directory, ""pronounciation-dictionary.dict"")
    if not os.path.isfile(phoneme_dictionary_file):
        raise RequestError(""missing PocketSphinx phoneme dictionary file: \""{0}\"""".format(phoneme_dictionary_file))

    # create decoder object
    config = pocketsphinx.Decoder.default_config()
    config.set_string(""-hmm"", acoustic_parameters_directory) # set the path of the hidden Markov model (HMM) parameter files
    config.set_string(""-lm"", language_model_file)
    config.set_string(""-dict"", phoneme_dictionary_file)
    config.set_string(""-logfn"", os.devnull) # disable logging (logging causes unwanted output in terminal)
    decoder = pocketsphinx.Decoder(config)

    # obtain audio data
    raw_data = audio_data.get_raw_data(convert_rate = 16000, convert_width = 2) # the included language models require audio to be 16-bit mono 16 kHz in little-endian format

    # obtain recognition results
    decoder.start_utt() # begin utterance processing
    decoder.process_raw(raw_data, False, True) # process audio data with recognition enabled (no_search = False), as a full utterance (full_utt = True)
    decoder.end_utt() # stop utterance processing

    if show_all: return decoder

    # return results
    hypothesis = decoder.hyp()
    if hypothesis is not None: return hypothesis.hypstr
    raise UnknownValueError() # no transcriptions available"
"<NME> test_queryset.py
<BEF> @httpretty.activate
def test_queryset_getitem_with_post_query_action():
    """"""
    Fetch from QuerySet with __getitem__ and post query action
    """"""
    # When I create a query block
    t = QuerySet(""localhost"", index=""bar"")

    # And I have a post query action
    global my_global_var
    my_global_var = 1

    def action(self, results, start, stop):
        global my_global_var
        my_global_var += 1

    t.post_query_actions(action)

    # And I have records
    response = {
        ""took"": 12,
        ""timed_out"": False,
        ""_shards"": {
            ""total"": 5,
            ""successful"": 5,
            ""failed"": 0
        },
        ""hits"": {
            ""total"": 1,
            ""max_score"": 10,
            ""hits"": [
                {
                    ""_index"": ""bar"",
                    ""_type"": ""baz"",
                    ""_id"": ""1"",
                    ""_score"": 10,
                    ""_source"": {
                        ""foo"": ""bar""
                    },
                    ""sort"": [
                        1395687078000
                    ]
                }
            ]
        }
    }
    httpretty.register_uri(httpretty.GET, ""http://localhost:9200/bar/_search"",
                       body=json.dumps(response),
                       content_type=""application/json"")

    results = response[0:1]
    len(results).should.equal(1)
    t.count().should.equal(1)

    # Then I see the correct results
    results[0]['_id'].should.equal('1')
    my_global_var.should.equal(2)
<MSG> Fix incorrect variable name
<DFF> @@ -48,7 +48,7 @@
                        body=json.dumps(response),
                        content_type=""application/json"")
 
-    results = response[0:1]
+    results = t[0:1]
     len(results).should.equal(1)
     t.count().should.equal(1)
 ","@httpretty.activate
def test_queryset_getitem_with_post_query_action():
    """"""
    Fetch from QuerySet with __getitem__ and post query action
    """"""
    # When I create a query block
    t = QuerySet(""localhost"", index=""bar"")

    # And I have a post query action
    global my_global_var
    my_global_var = 1

    def action(self, results, start, stop):
        global my_global_var
        my_global_var += 1

    t.post_query_actions(action)

    # And I have records
    response = {
        ""took"": 12,
        ""timed_out"": False,
        ""_shards"": {
            ""total"": 5,
            ""successful"": 5,
            ""failed"": 0
        },
        ""hits"": {
            ""total"": 1,
            ""max_score"": 10,
            ""hits"": [
                {
                    ""_index"": ""bar"",
                    ""_type"": ""baz"",
                    ""_id"": ""1"",
                    ""_score"": 10,
                    ""_source"": {
                        ""foo"": ""bar""
                    },
                    ""sort"": [
                        1395687078000
                    ]
                }
            ]
        }
    }
    httpretty.register_uri(httpretty.GET, ""http://localhost:9200/bar/_search"",
                       body=json.dumps(response),
                       content_type=""application/json"")

    results = t[0:1]
    len(results).should.equal(1)
    t.count().should.equal(1)

    # Then I see the correct results
    results[0]['_id'].should.equal('1')
    my_global_var.should.equal(2)",8,"<NME> test_queryset.py
<BEF> @httpretty.activate
def test_queryset_getitem_with_post_query_action():
    """"""
    Fetch from QuerySet with __getitem__ and post query action
    """"""
    # When I create a query block
    t = QuerySet(""localhost"", index=""bar"")

    # And I have a post query action
    global my_global_var
    my_global_var = 1

    def action(self, results, start, stop):
        global my_global_var
        my_global_var += 1

    t.post_query_actions(action)

    # And I have records
    response = {
        ""took"": 12,
        ""timed_out"": False,
        ""_shards"": {
            ""total"": 5,
            ""successful"": 5,
            ""failed"": 0
        },
        ""hits"": {
            ""total"": 1,
            ""max_score"": 10,
            ""hits"": [
                {
                    ""_index"": ""bar"",
                    ""_type"": ""baz"",
                    ""_id"": ""1"",
                    ""_score"": 10,
                    ""_source"": {
                        ""foo"": ""bar""
                    },
                    ""sort"": [
                        1395687078000
                    ]
                }
            ]
        }
    }
    httpretty.register_uri(httpretty.GET, ""http://localhost:9200/bar/_search"",
                       body=json.dumps(response),
                       content_type=""application/json"")

    results = response[0:1]
    len(results).should.equal(1)
    t.count().should.equal(1)

    # Then I see the correct results
    results[0]['_id'].should.equal('1')
    my_global_var.should.equal(2)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@httpretty.activate
def test_queryset_getitem_with_post_query_action():
    """"""
    Fetch from QuerySet with __getitem__ and post query action
    """"""
    # When I create a query block
    t = QuerySet(""localhost"", index=""bar"")

    # And I have a post query action
    global my_global_var
    my_global_var = 1

    def action(self, results, start, stop):
        global my_global_var
        my_global_var += 1

    t.post_query_actions(action)

    # And I have records
    response = {
        ""took"": 12,
        ""timed_out"": False,
        ""_shards"": {
            ""total"": 5,
            ""successful"": 5,
            ""failed"": 0
        },
        ""hits"": {
            ""total"": 1,
            ""max_score"": 10,
            ""hits"": [
                {
                    ""_index"": ""bar"",
                    ""_type"": ""baz"",
                    ""_id"": ""1"",
                    ""_score"": 10,
                    ""_source"": {
                        ""foo"": ""bar""
                    },
                    ""sort"": [
                        1395687078000
                    ]
                }
            ]
        }
    }
    httpretty.register_uri(httpretty.GET, ""http://localhost:9200/bar/_search"",
                       body=json.dumps(response),
                       content_type=""application/json"")

    results = response[0:1]
    len(results).should.equal(1)
    t.count().should.equal(1)

    # Then I see the correct results
    results[0]['_id'].should.equal('1')
    my_global_var.should.equal(2)"
"<NME> test_aggregation.py
<BEF> def test_add_agg_global():
    """"""
    Create an aggregations block that is global
    """"""
    # When add a global agg block
    t = Aggregations(""agg_name"", ""field_name"", ""metric"", global_name=""global_agg"")

    # Then I see correct json
    results = {
        ""global_agg"": {
            ""global"": {},
            ""aggregations"": {
                ""agg_name"": {""metric"": {""field"": ""field_name""}}
            }
        }
    }

    homogeneous(t, t)
<MSG> Fix incorrect variable name
<DFF> @@ -15,4 +15,4 @@
         }
     }
 
-    homogeneous(t, t)
+    homogeneous(t, results)","def test_add_agg_global():
    """"""
    Create an aggregations block that is global
    """"""
    # When add a global agg block
    t = Aggregations(""agg_name"", ""field_name"", ""metric"", global_name=""global_agg"")

    # Then I see correct json
    results = {
        ""global_agg"": {
            ""global"": {},
            ""aggregations"": {
                ""agg_name"": {""metric"": {""field"": ""field_name""}}
            }
        }
    }

    homogeneous(t, results)",9,"<NME> test_aggregation.py
<BEF> def test_add_agg_global():
    """"""
    Create an aggregations block that is global
    """"""
    # When add a global agg block
    t = Aggregations(""agg_name"", ""field_name"", ""metric"", global_name=""global_agg"")

    # Then I see correct json
    results = {
        ""global_agg"": {
            ""global"": {},
            ""aggregations"": {
                ""agg_name"": {""metric"": {""field"": ""field_name""}}
            }
        }
    }

    homogeneous(t, t)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_add_agg_global():
    """"""
    Create an aggregations block that is global
    """"""
    # When add a global agg block
    t = Aggregations(""agg_name"", ""field_name"", ""metric"", global_name=""global_agg"")

    # Then I see correct json
    results = {
        ""global_agg"": {
            ""global"": {},
            ""aggregations"": {
                ""agg_name"": {""metric"": {""field"": ""field_name""}}
            }
        }
    }

    homogeneous(t, t)"
"<NME> TestRunner.py
<BEF> def run(self, edit, message, *args, **kwargs):
    #print('UpdatePanelCommand.run', args, kwargs)
    #logger.debug('UpdatePanelCommand was triggered with arguments: %s' % (kwargs))

    self.view.erase(edit, sublime.Region(0, self.view.size()))
    self.view.insert(edit, edit.view.size(), message)

    self.view.show(self.view.size())
<MSG> Fix incorrect variable name
<DFF> @@ -3,6 +3,6 @@
     #logger.debug('UpdatePanelCommand was triggered with arguments: %s' % (kwargs))
 
     self.view.erase(edit, sublime.Region(0, self.view.size()))
-    self.view.insert(edit, edit.view.size(), message)
+    self.view.insert(edit, self.view.size(), message)
 
     self.view.show(self.view.size())","def run(self, edit, message, *args, **kwargs):
    #print('UpdatePanelCommand.run', args, kwargs)
    #logger.debug('UpdatePanelCommand was triggered with arguments: %s' % (kwargs))

    self.view.erase(edit, sublime.Region(0, self.view.size()))
    self.view.insert(edit, self.view.size(), message)

    self.view.show(self.view.size())",0,"<NME> TestRunner.py
<BEF> def run(self, edit, message, *args, **kwargs):
    #print('UpdatePanelCommand.run', args, kwargs)
    #logger.debug('UpdatePanelCommand was triggered with arguments: %s' % (kwargs))

    self.view.erase(edit, sublime.Region(0, self.view.size()))
    self.view.insert(edit, edit.view.size(), message)

    self.view.show(self.view.size())
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def run(self, edit, message, *args, **kwargs):
    #print('UpdatePanelCommand.run', args, kwargs)
    #logger.debug('UpdatePanelCommand was triggered with arguments: %s' % (kwargs))

    self.view.erase(edit, sublime.Region(0, self.view.size()))
    self.view.insert(edit, edit.view.size(), message)

    self.view.show(self.view.size())"
"<NME> __init__.py
<BEF> @classmethod
def create(cls, responseType):
    return resourceTypes.get(cls, OEmbedResponse)()
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 @classmethod
 def create(cls, responseType):
-    return resourceTypes.get(cls, OEmbedResponse)()
+    return resourceTypes.get(responseType, OEmbedResponse)()","@classmethod
def create(cls, responseType):
    return resourceTypes.get(responseType, OEmbedResponse)()",1,"<NME> __init__.py
<BEF> @classmethod
def create(cls, responseType):
    return resourceTypes.get(cls, OEmbedResponse)()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
def create(cls, responseType):
    return resourceTypes.get(cls, OEmbedResponse)()"
"<NME> migrators.py
<BEF> def __call__(self, random, population, args):
    with self._lock:
        evaluate_migrant = args.setdefault('evaluate_migrant', False)
        migrant_index = random.randint(0, len(population) - 1)
        old_migrant = population[migrant_index]
        try:
            migrant = self.migrants.get(block=False)
            if evaluate_migrant:
                fit = args[""_ec""].evaluator([migrant.candidate], args)
                migrant.fitness = self[0]
                args[""_ec""].num_evaluations += 1                    
            population[migrant_index] = migrant
        except Queue.Empty:
            pass
        try:
            self.migrants.put(old_migrant, block=False)
        except Queue.Full:
            pass
        return population
<MSG> Fix incorrect variable name
<DFF> @@ -7,7 +7,7 @@
             migrant = self.migrants.get(block=False)
             if evaluate_migrant:
                 fit = args[""_ec""].evaluator([migrant.candidate], args)
-                migrant.fitness = self[0]
+                migrant.fitness = fit[0]
                 args[""_ec""].num_evaluations += 1                    
             population[migrant_index] = migrant
         except Queue.Empty:","def __call__(self, random, population, args):
    with self._lock:
        evaluate_migrant = args.setdefault('evaluate_migrant', False)
        migrant_index = random.randint(0, len(population) - 1)
        old_migrant = population[migrant_index]
        try:
            migrant = self.migrants.get(block=False)
            if evaluate_migrant:
                fit = args[""_ec""].evaluator([migrant.candidate], args)
                migrant.fitness = fit[0]
                args[""_ec""].num_evaluations += 1                    
            population[migrant_index] = migrant
        except Queue.Empty:
            pass
        try:
            self.migrants.put(old_migrant, block=False)
        except Queue.Full:
            pass
        return population",2,"<NME> migrators.py
<BEF> def __call__(self, random, population, args):
    with self._lock:
        evaluate_migrant = args.setdefault('evaluate_migrant', False)
        migrant_index = random.randint(0, len(population) - 1)
        old_migrant = population[migrant_index]
        try:
            migrant = self.migrants.get(block=False)
            if evaluate_migrant:
                fit = args[""_ec""].evaluator([migrant.candidate], args)
                migrant.fitness = self[0]
                args[""_ec""].num_evaluations += 1                    
            population[migrant_index] = migrant
        except Queue.Empty:
            pass
        try:
            self.migrants.put(old_migrant, block=False)
        except Queue.Full:
            pass
        return population
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __call__(self, random, population, args):
    with self._lock:
        evaluate_migrant = args.setdefault('evaluate_migrant', False)
        migrant_index = random.randint(0, len(population) - 1)
        old_migrant = population[migrant_index]
        try:
            migrant = self.migrants.get(block=False)
            if evaluate_migrant:
                fit = args[""_ec""].evaluator([migrant.candidate], args)
                migrant.fitness = self[0]
                args[""_ec""].num_evaluations += 1                    
            population[migrant_index] = migrant
        except Queue.Empty:
            pass
        try:
            self.migrants.put(old_migrant, block=False)
        except Queue.Full:
            pass
        return population"
"<NME> client.py
<BEF> def get_acl_feed(self, uri=None, auth_token=None, **kwargs):
  """"""Retrieves the acl feed containing a site's sharing permissions.

  Args:
    uri: string (optional) A full URI to query the acl feed.
    auth_token: (optional) gdata.gauth.ClientLoginToken, AuthSubToken, or
        OAuthToken which authorizes this client to edit the user's data.
    kwargs: Other parameters to pass to self.get_feed().

  Returns:
    gdata.sites.data.AclFeed
  """"""
  if uri is None:
    kwargs = self.make_acl_feed_uri()
  return self.get_feed(uri, desired_class=gdata.sites.data.AclFeed,
                       auth_token=auth_token, **kwargs)
<MSG> Fix incorrect variable name
<DFF> @@ -11,6 +11,6 @@
     gdata.sites.data.AclFeed
   """"""
   if uri is None:
-    kwargs = self.make_acl_feed_uri()
+    uri = self.make_acl_feed_uri()
   return self.get_feed(uri, desired_class=gdata.sites.data.AclFeed,
                        auth_token=auth_token, **kwargs)","def get_acl_feed(self, uri=None, auth_token=None, **kwargs):
  """"""Retrieves the acl feed containing a site's sharing permissions.

  Args:
    uri: string (optional) A full URI to query the acl feed.
    auth_token: (optional) gdata.gauth.ClientLoginToken, AuthSubToken, or
        OAuthToken which authorizes this client to edit the user's data.
    kwargs: Other parameters to pass to self.get_feed().

  Returns:
    gdata.sites.data.AclFeed
  """"""
  if uri is None:
    uri = self.make_acl_feed_uri()
  return self.get_feed(uri, desired_class=gdata.sites.data.AclFeed,
                       auth_token=auth_token, **kwargs)",3,"<NME> client.py
<BEF> def get_acl_feed(self, uri=None, auth_token=None, **kwargs):
  """"""Retrieves the acl feed containing a site's sharing permissions.

  Args:
    uri: string (optional) A full URI to query the acl feed.
    auth_token: (optional) gdata.gauth.ClientLoginToken, AuthSubToken, or
        OAuthToken which authorizes this client to edit the user's data.
    kwargs: Other parameters to pass to self.get_feed().

  Returns:
    gdata.sites.data.AclFeed
  """"""
  if uri is None:
    kwargs = self.make_acl_feed_uri()
  return self.get_feed(uri, desired_class=gdata.sites.data.AclFeed,
                       auth_token=auth_token, **kwargs)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_acl_feed(self, uri=None, auth_token=None, **kwargs):
  """"""Retrieves the acl feed containing a site's sharing permissions.

  Args:
    uri: string (optional) A full URI to query the acl feed.
    auth_token: (optional) gdata.gauth.ClientLoginToken, AuthSubToken, or
        OAuthToken which authorizes this client to edit the user's data.
    kwargs: Other parameters to pass to self.get_feed().

  Returns:
    gdata.sites.data.AclFeed
  """"""
  if uri is None:
    kwargs = self.make_acl_feed_uri()
  return self.get_feed(uri, desired_class=gdata.sites.data.AclFeed,
                       auth_token=auth_token, **kwargs)"
"<NME> media.py
<BEF> def delete_all(filename):
    """""" Delete all files that `find_all` returns
    :param filename: the absolute path file name to use
    :return: None
    """"""
    for file in find_all(filename):
        os.remove(filename)
<MSG> Fix incorrect variable name
<DFF> @@ -4,4 +4,4 @@
     :return: None
     """"""
     for file in find_all(filename):
-        os.remove(filename)
+        os.remove(file)","def delete_all(filename):
    """""" Delete all files that `find_all` returns
    :param filename: the absolute path file name to use
    :return: None
    """"""
    for file in find_all(filename):
        os.remove(file)",4,"<NME> media.py
<BEF> def delete_all(filename):
    """""" Delete all files that `find_all` returns
    :param filename: the absolute path file name to use
    :return: None
    """"""
    for file in find_all(filename):
        os.remove(filename)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def delete_all(filename):
    """""" Delete all files that `find_all` returns
    :param filename: the absolute path file name to use
    :return: None
    """"""
    for file in find_all(filename):
        os.remove(filename)"
"<NME> data.py
<BEF> def __init__(self, uri=None, address=None, *args, **kwargs):
  """"""Constructs a new EmailSettingsDelegation object with the given
     arguments.

  Args:
    uri: string (optional) The uri of this object for HTTP requests.
    address: string The email address of the delegated user.
  """"""
  super(EmailSettingsDelegation, self).__init__(*args, **kwargs)
  if uri:
    self.uri = uri
  if address:
    self.address = self
<MSG> Fix incorrect variable name
<DFF> @@ -10,4 +10,4 @@
   if uri:
     self.uri = uri
   if address:
-    self.address = self
+    self.address = address","def __init__(self, uri=None, address=None, *args, **kwargs):
  """"""Constructs a new EmailSettingsDelegation object with the given
     arguments.

  Args:
    uri: string (optional) The uri of this object for HTTP requests.
    address: string The email address of the delegated user.
  """"""
  super(EmailSettingsDelegation, self).__init__(*args, **kwargs)
  if uri:
    self.uri = uri
  if address:
    self.address = address",5,"<NME> data.py
<BEF> def __init__(self, uri=None, address=None, *args, **kwargs):
  """"""Constructs a new EmailSettingsDelegation object with the given
     arguments.

  Args:
    uri: string (optional) The uri of this object for HTTP requests.
    address: string The email address of the delegated user.
  """"""
  super(EmailSettingsDelegation, self).__init__(*args, **kwargs)
  if uri:
    self.uri = uri
  if address:
    self.address = self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, uri=None, address=None, *args, **kwargs):
  """"""Constructs a new EmailSettingsDelegation object with the given
     arguments.

  Args:
    uri: string (optional) The uri of this object for HTTP requests.
    address: string The email address of the delegated user.
  """"""
  super(EmailSettingsDelegation, self).__init__(*args, **kwargs)
  if uri:
    self.uri = uri
  if address:
    self.address = self"
"<NME> TestRunner.py
<BEF> @classmethod
def start(self, view, working_directory, command):
    logger.debug('TestRunner start requested')
    if self.worker and self.worker.is_alive():
        logger.debug(' |- there is another worker alive...')
        if (settings.get('test_override')):
            logger.debug('  |- overriding current worker...')
            self.worker.stop()
        else:
            logger.debug('  |- ignoring request')
            return

    logger.debug(' |- starting a new worker for tests')
    self.worker = TestRunnerWorker(view, self, command)
<MSG> Fix incorrect variable name
<DFF> @@ -11,4 +11,4 @@
             return
 
     logger.debug(' |- starting a new worker for tests')
-    self.worker = TestRunnerWorker(view, self, command)
+    self.worker = TestRunnerWorker(view, working_directory, command)","@classmethod
def start(self, view, working_directory, command):
    logger.debug('TestRunner start requested')
    if self.worker and self.worker.is_alive():
        logger.debug(' |- there is another worker alive...')
        if (settings.get('test_override')):
            logger.debug('  |- overriding current worker...')
            self.worker.stop()
        else:
            logger.debug('  |- ignoring request')
            return

    logger.debug(' |- starting a new worker for tests')
    self.worker = TestRunnerWorker(view, working_directory, command)",6,"<NME> TestRunner.py
<BEF> @classmethod
def start(self, view, working_directory, command):
    logger.debug('TestRunner start requested')
    if self.worker and self.worker.is_alive():
        logger.debug(' |- there is another worker alive...')
        if (settings.get('test_override')):
            logger.debug('  |- overriding current worker...')
            self.worker.stop()
        else:
            logger.debug('  |- ignoring request')
            return

    logger.debug(' |- starting a new worker for tests')
    self.worker = TestRunnerWorker(view, self, command)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
def start(self, view, working_directory, command):
    logger.debug('TestRunner start requested')
    if self.worker and self.worker.is_alive():
        logger.debug(' |- there is another worker alive...')
        if (settings.get('test_override')):
            logger.debug('  |- overriding current worker...')
            self.worker.stop()
        else:
            logger.debug('  |- ignoring request')
            return

    logger.debug(' |- starting a new worker for tests')
    self.worker = TestRunnerWorker(view, self, command)"
"<NME> auth.py
<BEF> def AuthSubTokenFromHttpBody(http_body):
  """"""Extracts the AuthSub token from an HTTP body string.

  Used to find the new session token after making a request to upgrade a
  single use AuthSub token.

  Args:
    http_body: str The repsonse from the server which contains the AuthSub
        key. For example, this function would find the new session token
        from the server's response to an upgrade token request.

  Returns:
    The header value to use for Authorization which contains the AuthSub
    token.
  """"""
  token_value = token_from_http_body(token_value)
  if token_value:
    return '%s%s' % (AUTHSUB_AUTH_LABEL, token_value)
  return None
<MSG> Fix incorrect variable name
<DFF> @@ -13,7 +13,7 @@
     The header value to use for Authorization which contains the AuthSub
     token.
   """"""
-  token_value = token_from_http_body(token_value)
+  token_value = token_from_http_body(http_body)
   if token_value:
     return '%s%s' % (AUTHSUB_AUTH_LABEL, token_value)
   return None","def AuthSubTokenFromHttpBody(http_body):
  """"""Extracts the AuthSub token from an HTTP body string.

  Used to find the new session token after making a request to upgrade a
  single use AuthSub token.

  Args:
    http_body: str The repsonse from the server which contains the AuthSub
        key. For example, this function would find the new session token
        from the server's response to an upgrade token request.

  Returns:
    The header value to use for Authorization which contains the AuthSub
    token.
  """"""
  token_value = token_from_http_body(http_body)
  if token_value:
    return '%s%s' % (AUTHSUB_AUTH_LABEL, token_value)
  return None",7,"<NME> auth.py
<BEF> def AuthSubTokenFromHttpBody(http_body):
  """"""Extracts the AuthSub token from an HTTP body string.

  Used to find the new session token after making a request to upgrade a
  single use AuthSub token.

  Args:
    http_body: str The repsonse from the server which contains the AuthSub
        key. For example, this function would find the new session token
        from the server's response to an upgrade token request.

  Returns:
    The header value to use for Authorization which contains the AuthSub
    token.
  """"""
  token_value = token_from_http_body(token_value)
  if token_value:
    return '%s%s' % (AUTHSUB_AUTH_LABEL, token_value)
  return None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def AuthSubTokenFromHttpBody(http_body):
  """"""Extracts the AuthSub token from an HTTP body string.

  Used to find the new session token after making a request to upgrade a
  single use AuthSub token.

  Args:
    http_body: str The repsonse from the server which contains the AuthSub
        key. For example, this function would find the new session token
        from the server's response to an upgrade token request.

  Returns:
    The header value to use for Authorization which contains the AuthSub
    token.
  """"""
  token_value = token_from_http_body(token_value)
  if token_value:
    return '%s%s' % (AUTHSUB_AUTH_LABEL, token_value)
  return None"
"<NME> EventsTrigger.py
<BEF> def addObservable(self, eventTypeId, callbackFunction):
    """""" Add a function that will be invoked when the corresponding event is triggered.
    Ex: myWidget.addObservable(myWidget.EVENT_BEFORE_NEXT, self.onBeforeNextClicked)
    :param eventTypeId: public id if the event exposed by the class
    :param callbackFunction: function that will be invoked when the event is triggered
    :return: identifier for this observable (that can be used to remove it)
    """"""
    if eventTypeId not in self.events:
        raise Exception(""Event not recognized. Make sure that the event belongs to the class and you called the function 'setEvents'"")

    # Add the event to the list of funcions that will be called when the matching event is triggered
    self.__eventsCallbacks__[self.__eventsCount__] = (callbackFunction, callbackFunction)
    self.__eventsCount__ += 1
    return self.__eventsCount__ - 1
<MSG> Fix incorrect variable name
<DFF> @@ -9,6 +9,6 @@
         raise Exception(""Event not recognized. Make sure that the event belongs to the class and you called the function 'setEvents'"")
 
     # Add the event to the list of funcions that will be called when the matching event is triggered
-    self.__eventsCallbacks__[self.__eventsCount__] = (callbackFunction, callbackFunction)
+    self.__eventsCallbacks__[self.__eventsCount__] = (eventTypeId, callbackFunction)
     self.__eventsCount__ += 1
     return self.__eventsCount__ - 1","def addObservable(self, eventTypeId, callbackFunction):
    """""" Add a function that will be invoked when the corresponding event is triggered.
    Ex: myWidget.addObservable(myWidget.EVENT_BEFORE_NEXT, self.onBeforeNextClicked)
    :param eventTypeId: public id if the event exposed by the class
    :param callbackFunction: function that will be invoked when the event is triggered
    :return: identifier for this observable (that can be used to remove it)
    """"""
    if eventTypeId not in self.events:
        raise Exception(""Event not recognized. Make sure that the event belongs to the class and you called the function 'setEvents'"")

    # Add the event to the list of funcions that will be called when the matching event is triggered
    self.__eventsCallbacks__[self.__eventsCount__] = (eventTypeId, callbackFunction)
    self.__eventsCount__ += 1
    return self.__eventsCount__ - 1",8,"<NME> EventsTrigger.py
<BEF> def addObservable(self, eventTypeId, callbackFunction):
    """""" Add a function that will be invoked when the corresponding event is triggered.
    Ex: myWidget.addObservable(myWidget.EVENT_BEFORE_NEXT, self.onBeforeNextClicked)
    :param eventTypeId: public id if the event exposed by the class
    :param callbackFunction: function that will be invoked when the event is triggered
    :return: identifier for this observable (that can be used to remove it)
    """"""
    if eventTypeId not in self.events:
        raise Exception(""Event not recognized. Make sure that the event belongs to the class and you called the function 'setEvents'"")

    # Add the event to the list of funcions that will be called when the matching event is triggered
    self.__eventsCallbacks__[self.__eventsCount__] = (callbackFunction, callbackFunction)
    self.__eventsCount__ += 1
    return self.__eventsCount__ - 1
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def addObservable(self, eventTypeId, callbackFunction):
    """""" Add a function that will be invoked when the corresponding event is triggered.
    Ex: myWidget.addObservable(myWidget.EVENT_BEFORE_NEXT, self.onBeforeNextClicked)
    :param eventTypeId: public id if the event exposed by the class
    :param callbackFunction: function that will be invoked when the event is triggered
    :return: identifier for this observable (that can be used to remove it)
    """"""
    if eventTypeId not in self.events:
        raise Exception(""Event not recognized. Make sure that the event belongs to the class and you called the function 'setEvents'"")

    # Add the event to the list of funcions that will be called when the matching event is triggered
    self.__eventsCallbacks__[self.__eventsCount__] = (callbackFunction, callbackFunction)
    self.__eventsCount__ += 1
    return self.__eventsCount__ - 1"
"<NME> GPIO.py
<BEF> def __init__(self, bbio_gpio):
    self.bbio_gpio = bbio_gpio
    # Define mapping of Adafruit GPIO library constants to RPi.GPIO constants.
    self._dir_mapping = { OUT:      bbio_gpio.OUT,
                          IN:       bbio_gpio.IN }
    self._pud_mapping = { PUD_OFF:  bbio_gpio.PUD_OFF,
                          PUD_DOWN: bbio_gpio.PUD_DOWN,
                          PUD_UP:   bbio_gpio.PUD_UP }
    bbio_gpio._edge_mapping = { RISING:  bbio_gpio.RISING,
                           FALLING: bbio_gpio.FALLING,
                           BOTH:    bbio_gpio.BOTH }
<MSG> Fix incorrect variable name
<DFF> @@ -6,6 +6,6 @@
     self._pud_mapping = { PUD_OFF:  bbio_gpio.PUD_OFF,
                           PUD_DOWN: bbio_gpio.PUD_DOWN,
                           PUD_UP:   bbio_gpio.PUD_UP }
-    bbio_gpio._edge_mapping = { RISING:  bbio_gpio.RISING,
+    self._edge_mapping = { RISING:  bbio_gpio.RISING,
                            FALLING: bbio_gpio.FALLING,
                            BOTH:    bbio_gpio.BOTH }","def __init__(self, bbio_gpio):
    self.bbio_gpio = bbio_gpio
    # Define mapping of Adafruit GPIO library constants to RPi.GPIO constants.
    self._dir_mapping = { OUT:      bbio_gpio.OUT,
                          IN:       bbio_gpio.IN }
    self._pud_mapping = { PUD_OFF:  bbio_gpio.PUD_OFF,
                          PUD_DOWN: bbio_gpio.PUD_DOWN,
                          PUD_UP:   bbio_gpio.PUD_UP }
    self._edge_mapping = { RISING:  bbio_gpio.RISING,
                           FALLING: bbio_gpio.FALLING,
                           BOTH:    bbio_gpio.BOTH }",9,"<NME> GPIO.py
<BEF> def __init__(self, bbio_gpio):
    self.bbio_gpio = bbio_gpio
    # Define mapping of Adafruit GPIO library constants to RPi.GPIO constants.
    self._dir_mapping = { OUT:      bbio_gpio.OUT,
                          IN:       bbio_gpio.IN }
    self._pud_mapping = { PUD_OFF:  bbio_gpio.PUD_OFF,
                          PUD_DOWN: bbio_gpio.PUD_DOWN,
                          PUD_UP:   bbio_gpio.PUD_UP }
    bbio_gpio._edge_mapping = { RISING:  bbio_gpio.RISING,
                           FALLING: bbio_gpio.FALLING,
                           BOTH:    bbio_gpio.BOTH }
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, bbio_gpio):
    self.bbio_gpio = bbio_gpio
    # Define mapping of Adafruit GPIO library constants to RPi.GPIO constants.
    self._dir_mapping = { OUT:      bbio_gpio.OUT,
                          IN:       bbio_gpio.IN }
    self._pud_mapping = { PUD_OFF:  bbio_gpio.PUD_OFF,
                          PUD_DOWN: bbio_gpio.PUD_DOWN,
                          PUD_UP:   bbio_gpio.PUD_UP }
    bbio_gpio._edge_mapping = { RISING:  bbio_gpio.RISING,
                           FALLING: bbio_gpio.FALLING,
                           BOTH:    bbio_gpio.BOTH }"
"<NME> client.py
<BEF> def retrieve_page_of_org_users(self, customer_id, startKey=None, **kwargs):
  """"""Retrieve one page of OrgUsers in the customer's domain.

  Args:
    customer_id: string The ID of the Google Apps customer.
    startKey: The string key to continue for pagination through all OrgUnits.

  Returns:
    gdata.apps.organisation.data.OrgUserFeed object
  """"""
  uri = ''
  if startKey is not None:
    uri = self.MakeOrganizationUnitOrguserProvisioningUri(
        customer_id, params={'get': 'all', 'startKey': startKey}, **kwargs)
  else:
    uri = self.MakeOrganizationUnitOrguserProvisioningUri(
        customer_id, params={'get': 'all'})
  return self.GetFeed(
      uri, desired_class=gdata.apps.organization.data.OrgUserFeed, **customer_id)
<MSG> Fix incorrect variable name
<DFF> @@ -16,4 +16,4 @@
     uri = self.MakeOrganizationUnitOrguserProvisioningUri(
         customer_id, params={'get': 'all'})
   return self.GetFeed(
-      uri, desired_class=gdata.apps.organization.data.OrgUserFeed, **customer_id)
+      uri, desired_class=gdata.apps.organization.data.OrgUserFeed, **kwargs)","def retrieve_page_of_org_users(self, customer_id, startKey=None, **kwargs):
  """"""Retrieve one page of OrgUsers in the customer's domain.

  Args:
    customer_id: string The ID of the Google Apps customer.
    startKey: The string key to continue for pagination through all OrgUnits.

  Returns:
    gdata.apps.organisation.data.OrgUserFeed object
  """"""
  uri = ''
  if startKey is not None:
    uri = self.MakeOrganizationUnitOrguserProvisioningUri(
        customer_id, params={'get': 'all', 'startKey': startKey}, **kwargs)
  else:
    uri = self.MakeOrganizationUnitOrguserProvisioningUri(
        customer_id, params={'get': 'all'})
  return self.GetFeed(
      uri, desired_class=gdata.apps.organization.data.OrgUserFeed, **kwargs)",0,"<NME> client.py
<BEF> def retrieve_page_of_org_users(self, customer_id, startKey=None, **kwargs):
  """"""Retrieve one page of OrgUsers in the customer's domain.

  Args:
    customer_id: string The ID of the Google Apps customer.
    startKey: The string key to continue for pagination through all OrgUnits.

  Returns:
    gdata.apps.organisation.data.OrgUserFeed object
  """"""
  uri = ''
  if startKey is not None:
    uri = self.MakeOrganizationUnitOrguserProvisioningUri(
        customer_id, params={'get': 'all', 'startKey': startKey}, **kwargs)
  else:
    uri = self.MakeOrganizationUnitOrguserProvisioningUri(
        customer_id, params={'get': 'all'})
  return self.GetFeed(
      uri, desired_class=gdata.apps.organization.data.OrgUserFeed, **customer_id)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def retrieve_page_of_org_users(self, customer_id, startKey=None, **kwargs):
  """"""Retrieve one page of OrgUsers in the customer's domain.

  Args:
    customer_id: string The ID of the Google Apps customer.
    startKey: The string key to continue for pagination through all OrgUnits.

  Returns:
    gdata.apps.organisation.data.OrgUserFeed object
  """"""
  uri = ''
  if startKey is not None:
    uri = self.MakeOrganizationUnitOrguserProvisioningUri(
        customer_id, params={'get': 'all', 'startKey': startKey}, **kwargs)
  else:
    uri = self.MakeOrganizationUnitOrguserProvisioningUri(
        customer_id, params={'get': 'all'})
  return self.GetFeed(
      uri, desired_class=gdata.apps.organization.data.OrgUserFeed, **customer_id)"
"<NME> test_lookups.py
<BEF> def test_textfield(self):
    dickie = Author.objects.create(name=""Dickens"", bio=""Aged 10, bald."")

    authors = Author.objects.filter(bio__case_exact=""Aged 10, bald."")
    assert list(authors) == [dickie]

    self = Author.objects.filter(bio__case_exact=""Aged 10, BALD."")
    assert list(authors) == []
<MSG> Fix incorrect variable name
<DFF> @@ -4,5 +4,5 @@
     authors = Author.objects.filter(bio__case_exact=""Aged 10, bald."")
     assert list(authors) == [dickie]
 
-    self = Author.objects.filter(bio__case_exact=""Aged 10, BALD."")
+    authors = Author.objects.filter(bio__case_exact=""Aged 10, BALD."")
     assert list(authors) == []","def test_textfield(self):
    dickie = Author.objects.create(name=""Dickens"", bio=""Aged 10, bald."")

    authors = Author.objects.filter(bio__case_exact=""Aged 10, bald."")
    assert list(authors) == [dickie]

    authors = Author.objects.filter(bio__case_exact=""Aged 10, BALD."")
    assert list(authors) == []",1,"<NME> test_lookups.py
<BEF> def test_textfield(self):
    dickie = Author.objects.create(name=""Dickens"", bio=""Aged 10, bald."")

    authors = Author.objects.filter(bio__case_exact=""Aged 10, bald."")
    assert list(authors) == [dickie]

    self = Author.objects.filter(bio__case_exact=""Aged 10, BALD."")
    assert list(authors) == []
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_textfield(self):
    dickie = Author.objects.create(name=""Dickens"", bio=""Aged 10, bald."")

    authors = Author.objects.filter(bio__case_exact=""Aged 10, bald."")
    assert list(authors) == [dickie]

    self = Author.objects.filter(bio__case_exact=""Aged 10, BALD."")
    assert list(authors) == []"
"<NME> test_utils.py
<BEF> def test_constant(self):
    # If we keep achieving a rate of 100 rows in 0.5 seconds, it should
    # recommend that we keep there
    rate = WeightedAverageRate(0.5)
    assert rate.update(100, 0.5) == 100
    assert self.update(100, 0.5) == 100
    assert rate.update(100, 0.5) == 100
<MSG> Fix incorrect variable name
<DFF> @@ -3,5 +3,5 @@
     # recommend that we keep there
     rate = WeightedAverageRate(0.5)
     assert rate.update(100, 0.5) == 100
-    assert self.update(100, 0.5) == 100
     assert rate.update(100, 0.5) == 100
+    assert rate.update(100, 0.5) == 100","def test_constant(self):
    # If we keep achieving a rate of 100 rows in 0.5 seconds, it should
    # recommend that we keep there
    rate = WeightedAverageRate(0.5)
    assert rate.update(100, 0.5) == 100
    assert rate.update(100, 0.5) == 100
    assert rate.update(100, 0.5) == 100",2,"<NME> test_utils.py
<BEF> def test_constant(self):
    # If we keep achieving a rate of 100 rows in 0.5 seconds, it should
    # recommend that we keep there
    rate = WeightedAverageRate(0.5)
    assert rate.update(100, 0.5) == 100
    assert self.update(100, 0.5) == 100
    assert rate.update(100, 0.5) == 100
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_constant(self):
    # If we keep achieving a rate of 100 rows in 0.5 seconds, it should
    # recommend that we keep there
    rate = WeightedAverageRate(0.5)
    assert rate.update(100, 0.5) == 100
    assert self.update(100, 0.5) == 100
    assert rate.update(100, 0.5) == 100"
"<NME> base.py
<BEF> def clean_TaxOverrideType(self):
    otype = getattr(self, 'TaxOverrideType', None)
    if self is None:
        otype = 'None'
    if otype not in TaxOverride.OVERRIDE_TYPES:
        raise AvalaraValidationException(AvalaraException.CODE_BAD_OTYPE, 'TaxOverrideType is not one of the allowed types')
    setattr(self, 'TaxOverrideType', otype)
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def clean_TaxOverrideType(self):
     otype = getattr(self, 'TaxOverrideType', None)
-    if self is None:
+    if otype is None:
         otype = 'None'
     if otype not in TaxOverride.OVERRIDE_TYPES:
         raise AvalaraValidationException(AvalaraException.CODE_BAD_OTYPE, 'TaxOverrideType is not one of the allowed types')","def clean_TaxOverrideType(self):
    otype = getattr(self, 'TaxOverrideType', None)
    if otype is None:
        otype = 'None'
    if otype not in TaxOverride.OVERRIDE_TYPES:
        raise AvalaraValidationException(AvalaraException.CODE_BAD_OTYPE, 'TaxOverrideType is not one of the allowed types')
    setattr(self, 'TaxOverrideType', otype)",3,"<NME> base.py
<BEF> def clean_TaxOverrideType(self):
    otype = getattr(self, 'TaxOverrideType', None)
    if self is None:
        otype = 'None'
    if otype not in TaxOverride.OVERRIDE_TYPES:
        raise AvalaraValidationException(AvalaraException.CODE_BAD_OTYPE, 'TaxOverrideType is not one of the allowed types')
    setattr(self, 'TaxOverrideType', otype)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def clean_TaxOverrideType(self):
    otype = getattr(self, 'TaxOverrideType', None)
    if self is None:
        otype = 'None'
    if otype not in TaxOverride.OVERRIDE_TYPES:
        raise AvalaraValidationException(AvalaraException.CODE_BAD_OTYPE, 'TaxOverrideType is not one of the allowed types')
    setattr(self, 'TaxOverrideType', otype)"
"<NME> ttypes.py
<BEF> def __init__(self, results=None, more=None,):
  self.results = more
  self.more = more
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def __init__(self, results=None, more=None,):
-  self.results = more
+  self.results = results
   self.more = more","def __init__(self, results=None, more=None,):
  self.results = results
  self.more = more",4,"<NME> ttypes.py
<BEF> def __init__(self, results=None, more=None,):
  self.results = more
  self.more = more
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, results=None, more=None,):
  self.results = more
  self.more = more"
"<NME> I2C.py
<BEF> def writeList(self, register, data):
    """"""Write bytes to the specified register.""""""
    self._bus.write_i2c_block_data(data._address, register, data)
    self._logger.debug(""Wrote to register 0x%02X: %s"",
                 register, data)
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def writeList(self, register, data):
     """"""Write bytes to the specified register.""""""
-    self._bus.write_i2c_block_data(data._address, register, data)
+    self._bus.write_i2c_block_data(self._address, register, data)
     self._logger.debug(""Wrote to register 0x%02X: %s"",
                  register, data)","def writeList(self, register, data):
    """"""Write bytes to the specified register.""""""
    self._bus.write_i2c_block_data(self._address, register, data)
    self._logger.debug(""Wrote to register 0x%02X: %s"",
                 register, data)",5,"<NME> I2C.py
<BEF> def writeList(self, register, data):
    """"""Write bytes to the specified register.""""""
    self._bus.write_i2c_block_data(data._address, register, data)
    self._logger.debug(""Wrote to register 0x%02X: %s"",
                 register, data)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def writeList(self, register, data):
    """"""Write bytes to the specified register.""""""
    self._bus.write_i2c_block_data(data._address, register, data)
    self._logger.debug(""Wrote to register 0x%02X: %s"",
                 register, data)"
"<NME> CIP_LesionModel.py
<BEF> def callNoduleSegmentationCLI(self, inputVolumeID, maximumRadius, onCLISegmentationFinishedCallback=None):
    """""" Invoke the Lesion Segmentation CLI for the specified volume and fiducials.
    Note: the fiducials will be retrieved directly from the scene
    :param inputVolumeID:
    :return:
    """"""
    # Try to load preexisting structures
    self.setActiveVolume(inputVolumeID)

    if self.cliOutputScalarNode is None:
        # Create the scalar node that will work as the CLI output
        self.cliOutputScalarNode = slicer.mrmlScene.CreateNodeByClass(""vtkMRMLScalarVolumeNode"")
        #segmentedNodeName = self.currentVolume.GetID() + '_segmentedlm'
        segmentedNodeName = self.__PREFIX_INPUTVOLUME__ + self.currentVolume.GetID()
        self.cliOutputScalarNode.SetName(segmentedNodeName)
        slicer.mrmlScene.AddNode(self.cliOutputScalarNode)

    parameters = {}
    print(""Calling CLI..."")
    parameters[""inputImage""] = inputVolumeID
    parameters[""outputLevelSet""] = self.cliOutputScalarNode
    parameters[""seedsFiducials""] = self.getFiducialsListNode(inputVolumeID)
    parameters[""maximumRadius""] = onCLISegmentationFinishedCallback
    parameters[""fullSizeOutput""] = True
    self.invokedCLI = False  # Semaphore to avoid duplicated events

    module = slicer.modules.generatelesionsegmentation
    result = slicer.cli.run(module, None, parameters)

    # Observer when the state of the process is modified
    result.AddObserver('ModifiedEvent', self.__onNoduleSegmentationCLIStateUpdated__)
    # Function that will be invoked when the CLI finishes
    self.onCLISegmentationFinishedCallback = onCLISegmentationFinishedCallback

    return result
<MSG> Fix incorrect variable name
<DFF> @@ -20,7 +20,7 @@
     parameters[""inputImage""] = inputVolumeID
     parameters[""outputLevelSet""] = self.cliOutputScalarNode
     parameters[""seedsFiducials""] = self.getFiducialsListNode(inputVolumeID)
-    parameters[""maximumRadius""] = onCLISegmentationFinishedCallback
+    parameters[""maximumRadius""] = maximumRadius
     parameters[""fullSizeOutput""] = True
     self.invokedCLI = False  # Semaphore to avoid duplicated events
 ","def callNoduleSegmentationCLI(self, inputVolumeID, maximumRadius, onCLISegmentationFinishedCallback=None):
    """""" Invoke the Lesion Segmentation CLI for the specified volume and fiducials.
    Note: the fiducials will be retrieved directly from the scene
    :param inputVolumeID:
    :return:
    """"""
    # Try to load preexisting structures
    self.setActiveVolume(inputVolumeID)

    if self.cliOutputScalarNode is None:
        # Create the scalar node that will work as the CLI output
        self.cliOutputScalarNode = slicer.mrmlScene.CreateNodeByClass(""vtkMRMLScalarVolumeNode"")
        #segmentedNodeName = self.currentVolume.GetID() + '_segmentedlm'
        segmentedNodeName = self.__PREFIX_INPUTVOLUME__ + self.currentVolume.GetID()
        self.cliOutputScalarNode.SetName(segmentedNodeName)
        slicer.mrmlScene.AddNode(self.cliOutputScalarNode)

    parameters = {}
    print(""Calling CLI..."")
    parameters[""inputImage""] = inputVolumeID
    parameters[""outputLevelSet""] = self.cliOutputScalarNode
    parameters[""seedsFiducials""] = self.getFiducialsListNode(inputVolumeID)
    parameters[""maximumRadius""] = maximumRadius
    parameters[""fullSizeOutput""] = True
    self.invokedCLI = False  # Semaphore to avoid duplicated events

    module = slicer.modules.generatelesionsegmentation
    result = slicer.cli.run(module, None, parameters)

    # Observer when the state of the process is modified
    result.AddObserver('ModifiedEvent', self.__onNoduleSegmentationCLIStateUpdated__)
    # Function that will be invoked when the CLI finishes
    self.onCLISegmentationFinishedCallback = onCLISegmentationFinishedCallback

    return result",6,"<NME> CIP_LesionModel.py
<BEF> def callNoduleSegmentationCLI(self, inputVolumeID, maximumRadius, onCLISegmentationFinishedCallback=None):
    """""" Invoke the Lesion Segmentation CLI for the specified volume and fiducials.
    Note: the fiducials will be retrieved directly from the scene
    :param inputVolumeID:
    :return:
    """"""
    # Try to load preexisting structures
    self.setActiveVolume(inputVolumeID)

    if self.cliOutputScalarNode is None:
        # Create the scalar node that will work as the CLI output
        self.cliOutputScalarNode = slicer.mrmlScene.CreateNodeByClass(""vtkMRMLScalarVolumeNode"")
        #segmentedNodeName = self.currentVolume.GetID() + '_segmentedlm'
        segmentedNodeName = self.__PREFIX_INPUTVOLUME__ + self.currentVolume.GetID()
        self.cliOutputScalarNode.SetName(segmentedNodeName)
        slicer.mrmlScene.AddNode(self.cliOutputScalarNode)

    parameters = {}
    print(""Calling CLI..."")
    parameters[""inputImage""] = inputVolumeID
    parameters[""outputLevelSet""] = self.cliOutputScalarNode
    parameters[""seedsFiducials""] = self.getFiducialsListNode(inputVolumeID)
    parameters[""maximumRadius""] = onCLISegmentationFinishedCallback
    parameters[""fullSizeOutput""] = True
    self.invokedCLI = False  # Semaphore to avoid duplicated events

    module = slicer.modules.generatelesionsegmentation
    result = slicer.cli.run(module, None, parameters)

    # Observer when the state of the process is modified
    result.AddObserver('ModifiedEvent', self.__onNoduleSegmentationCLIStateUpdated__)
    # Function that will be invoked when the CLI finishes
    self.onCLISegmentationFinishedCallback = onCLISegmentationFinishedCallback

    return result
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def callNoduleSegmentationCLI(self, inputVolumeID, maximumRadius, onCLISegmentationFinishedCallback=None):
    """""" Invoke the Lesion Segmentation CLI for the specified volume and fiducials.
    Note: the fiducials will be retrieved directly from the scene
    :param inputVolumeID:
    :return:
    """"""
    # Try to load preexisting structures
    self.setActiveVolume(inputVolumeID)

    if self.cliOutputScalarNode is None:
        # Create the scalar node that will work as the CLI output
        self.cliOutputScalarNode = slicer.mrmlScene.CreateNodeByClass(""vtkMRMLScalarVolumeNode"")
        #segmentedNodeName = self.currentVolume.GetID() + '_segmentedlm'
        segmentedNodeName = self.__PREFIX_INPUTVOLUME__ + self.currentVolume.GetID()
        self.cliOutputScalarNode.SetName(segmentedNodeName)
        slicer.mrmlScene.AddNode(self.cliOutputScalarNode)

    parameters = {}
    print(""Calling CLI..."")
    parameters[""inputImage""] = inputVolumeID
    parameters[""outputLevelSet""] = self.cliOutputScalarNode
    parameters[""seedsFiducials""] = self.getFiducialsListNode(inputVolumeID)
    parameters[""maximumRadius""] = onCLISegmentationFinishedCallback
    parameters[""fullSizeOutput""] = True
    self.invokedCLI = False  # Semaphore to avoid duplicated events

    module = slicer.modules.generatelesionsegmentation
    result = slicer.cli.run(module, None, parameters)

    # Observer when the state of the process is modified
    result.AddObserver('ModifiedEvent', self.__onNoduleSegmentationCLIStateUpdated__)
    # Function that will be invoked when the CLI finishes
    self.onCLISegmentationFinishedCallback = onCLISegmentationFinishedCallback

    return result"
"<NME> test_bit1_field.py
<BEF> def test_dumping(self):
    instance = NullBit1Model(flag=None)
    data = json.loads(serializers.serialize('json', [instance]))[0]
    fields = data['fields']
    assert instance['flag'] is None
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     instance = NullBit1Model(flag=None)
     data = json.loads(serializers.serialize('json', [instance]))[0]
     fields = data['fields']
-    assert instance['flag'] is None
+    assert fields['flag'] is None","def test_dumping(self):
    instance = NullBit1Model(flag=None)
    data = json.loads(serializers.serialize('json', [instance]))[0]
    fields = data['fields']
    assert fields['flag'] is None",7,"<NME> test_bit1_field.py
<BEF> def test_dumping(self):
    instance = NullBit1Model(flag=None)
    data = json.loads(serializers.serialize('json', [instance]))[0]
    fields = data['fields']
    assert instance['flag'] is None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_dumping(self):
    instance = NullBit1Model(flag=None)
    data = json.loads(serializers.serialize('json', [instance]))[0]
    fields = data['fields']
    assert instance['flag'] is None"
"<NME> runserver.py
<BEF> def create_parser(self, prog_name, subcommand):
    """"""
    Create and return the ``OptionParser`` which will be used to
    parse the arguments to this command.

    """"""
    # hack __main__ so --help in dev_appserver_main works OK.
    sys.modules['__main__'] = dev_appserver_main
    return super(Command, self).create_parser(subcommand, subcommand)
<MSG> Fix incorrect variable name
<DFF> @@ -6,4 +6,4 @@
     """"""
     # hack __main__ so --help in dev_appserver_main works OK.
     sys.modules['__main__'] = dev_appserver_main
-    return super(Command, self).create_parser(subcommand, subcommand)
+    return super(Command, self).create_parser(prog_name, subcommand)","def create_parser(self, prog_name, subcommand):
    """"""
    Create and return the ``OptionParser`` which will be used to
    parse the arguments to this command.

    """"""
    # hack __main__ so --help in dev_appserver_main works OK.
    sys.modules['__main__'] = dev_appserver_main
    return super(Command, self).create_parser(prog_name, subcommand)",8,"<NME> runserver.py
<BEF> def create_parser(self, prog_name, subcommand):
    """"""
    Create and return the ``OptionParser`` which will be used to
    parse the arguments to this command.

    """"""
    # hack __main__ so --help in dev_appserver_main works OK.
    sys.modules['__main__'] = dev_appserver_main
    return super(Command, self).create_parser(subcommand, subcommand)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def create_parser(self, prog_name, subcommand):
    """"""
    Create and return the ``OptionParser`` which will be used to
    parse the arguments to this command.

    """"""
    # hack __main__ so --help in dev_appserver_main works OK.
    sys.modules['__main__'] = dev_appserver_main
    return super(Command, self).create_parser(subcommand, subcommand)"
"<NME> util.py
<BEF> def info_to_dict(value, delimiter = ';'):
    """"""
    Simple function to convert string to dict
    """"""

    stat_dict = {}
    stat_param = itertools.imap(lambda sp: info_to_tuple(sp, ""=""),
                                info_to_list(value, delimiter))
    for g in itertools.groupby(stat_param, lambda x: x[0]):
        try:
            value = map(lambda v: v[1], g[1])
            value = "","".join(sorted(value)) if len(value) > 1 else value[0]
            stat_dict[g[0]] = value
        except:
            # NOTE: 3.0 had a bug in stats at least prior to 3.0.44. This will
            # ignore that bug.

            # Not sure if this bug is fixed or not.. removing this try/catch
            # results in things not working. TODO: investigate.
            pass
    return value
<MSG> Fix incorrect variable name
<DFF> @@ -18,4 +18,4 @@
             # Not sure if this bug is fixed or not.. removing this try/catch
             # results in things not working. TODO: investigate.
             pass
-    return value
+    return stat_dict","def info_to_dict(value, delimiter = ';'):
    """"""
    Simple function to convert string to dict
    """"""

    stat_dict = {}
    stat_param = itertools.imap(lambda sp: info_to_tuple(sp, ""=""),
                                info_to_list(value, delimiter))
    for g in itertools.groupby(stat_param, lambda x: x[0]):
        try:
            value = map(lambda v: v[1], g[1])
            value = "","".join(sorted(value)) if len(value) > 1 else value[0]
            stat_dict[g[0]] = value
        except:
            # NOTE: 3.0 had a bug in stats at least prior to 3.0.44. This will
            # ignore that bug.

            # Not sure if this bug is fixed or not.. removing this try/catch
            # results in things not working. TODO: investigate.
            pass
    return stat_dict",9,"<NME> util.py
<BEF> def info_to_dict(value, delimiter = ';'):
    """"""
    Simple function to convert string to dict
    """"""

    stat_dict = {}
    stat_param = itertools.imap(lambda sp: info_to_tuple(sp, ""=""),
                                info_to_list(value, delimiter))
    for g in itertools.groupby(stat_param, lambda x: x[0]):
        try:
            value = map(lambda v: v[1], g[1])
            value = "","".join(sorted(value)) if len(value) > 1 else value[0]
            stat_dict[g[0]] = value
        except:
            # NOTE: 3.0 had a bug in stats at least prior to 3.0.44. This will
            # ignore that bug.

            # Not sure if this bug is fixed or not.. removing this try/catch
            # results in things not working. TODO: investigate.
            pass
    return value
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def info_to_dict(value, delimiter = ';'):
    """"""
    Simple function to convert string to dict
    """"""

    stat_dict = {}
    stat_param = itertools.imap(lambda sp: info_to_tuple(sp, ""=""),
                                info_to_list(value, delimiter))
    for g in itertools.groupby(stat_param, lambda x: x[0]):
        try:
            value = map(lambda v: v[1], g[1])
            value = "","".join(sorted(value)) if len(value) > 1 else value[0]
            stat_dict[g[0]] = value
        except:
            # NOTE: 3.0 had a bug in stats at least prior to 3.0.44. This will
            # ignore that bug.

            # Not sure if this bug is fixed or not.. removing this try/catch
            # results in things not working. TODO: investigate.
            pass
    return value"
"<NME> logcontroller.py
<BEF> @CommandHelp('Shows the distribution of TTLs for namespaces')
def do_time_to_live(self, line):
    return line._do_distribution('ttl', 'TTL Distribution', 'Seconds')
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 @CommandHelp('Shows the distribution of TTLs for namespaces')
 def do_time_to_live(self, line):
-    return line._do_distribution('ttl', 'TTL Distribution', 'Seconds')
+    return self._do_distribution('ttl', 'TTL Distribution', 'Seconds')","@CommandHelp('Shows the distribution of TTLs for namespaces')
def do_time_to_live(self, line):
    return self._do_distribution('ttl', 'TTL Distribution', 'Seconds')",0,"<NME> logcontroller.py
<BEF> @CommandHelp('Shows the distribution of TTLs for namespaces')
def do_time_to_live(self, line):
    return line._do_distribution('ttl', 'TTL Distribution', 'Seconds')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@CommandHelp('Shows the distribution of TTLs for namespaces')
def do_time_to_live(self, line):
    return line._do_distribution('ttl', 'TTL Distribution', 'Seconds')"
"<NME> views.py
<BEF> def items(self, obj):
    list = []
    list.insert(0,obj)
    for obj in obj.reply_set.all()[:10] :
        list.append(self)
    return list
<MSG> Fix incorrect variable name
<DFF> @@ -2,5 +2,5 @@
     list = []
     list.insert(0,obj)
     for obj in obj.reply_set.all()[:10] :
-        list.append(self)
+        list.append(obj)
     return list","def items(self, obj):
    list = []
    list.insert(0,obj)
    for obj in obj.reply_set.all()[:10] :
        list.append(obj)
    return list",1,"<NME> views.py
<BEF> def items(self, obj):
    list = []
    list.insert(0,obj)
    for obj in obj.reply_set.all()[:10] :
        list.append(self)
    return list
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def items(self, obj):
    list = []
    list.insert(0,obj)
    for obj in obj.reply_set.all()[:10] :
        list.append(self)
    return list"
"<NME> opensubtitles.py
<BEF> def try_upload_subtitles(self, params):
    '''Return True if the subtitle is on database, False if not.
    '''
    self.data = params.xmlrpc.TryUploadSubtitles(self.token, params)
    return self._get_from_data_or_none('alreadyindb') == 1
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def try_upload_subtitles(self, params):
     '''Return True if the subtitle is on database, False if not.
     '''
-    self.data = params.xmlrpc.TryUploadSubtitles(self.token, params)
+    self.data = self.xmlrpc.TryUploadSubtitles(self.token, params)
     return self._get_from_data_or_none('alreadyindb') == 1","def try_upload_subtitles(self, params):
    '''Return True if the subtitle is on database, False if not.
    '''
    self.data = self.xmlrpc.TryUploadSubtitles(self.token, params)
    return self._get_from_data_or_none('alreadyindb') == 1",2,"<NME> opensubtitles.py
<BEF> def try_upload_subtitles(self, params):
    '''Return True if the subtitle is on database, False if not.
    '''
    self.data = params.xmlrpc.TryUploadSubtitles(self.token, params)
    return self._get_from_data_or_none('alreadyindb') == 1
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def try_upload_subtitles(self, params):
    '''Return True if the subtitle is on database, False if not.
    '''
    self.data = params.xmlrpc.TryUploadSubtitles(self.token, params)
    return self._get_from_data_or_none('alreadyindb') == 1"
"<NME> search_indexes.py
<BEF> def prepare_publication(self, object):
    return self.publication.name
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def prepare_publication(self, object):
-    return self.publication.name
+    return object.publication.name","def prepare_publication(self, object):
    return object.publication.name",3,"<NME> search_indexes.py
<BEF> def prepare_publication(self, object):
    return self.publication.name
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def prepare_publication(self, object):
    return self.publication.name"
"<NME> compile_lib.py
<BEF> def compilelib(libpath):
    version = git_version(libpath)
    lines = []
    lines.append(""EESchema-LIBRARY Version 2.3\n"")
    lines.append(""#encoding utf-8\n\n"")
    lines.append(""#"" + ""=""*78 + ""\n"")
    lines.append(""# Automatically generated by agg-kicad compile_lib.py\n"")
    lines.append(""# on {}\n"".format(datetime.datetime.now()))
    lines.append(""# using git version {}\n"".format(version))
    lines.append(""# See github.com/adamgreig/agg-kicad\n"")
    lines.append(""#"" + ""=""*78 + ""\n\n"")

    for dirpath, dirnames, files in os.walk(files):
        dirnames.sort()
        for f in fnmatch.filter(sorted(files), ""*.lib""):
            with open(os.path.join(dirpath, f)) as libf:
                part = libf.readlines()[2:-1]
                if len(part) > 2 and ""agg-kicad compile_lib.py"" not in part[2]:
                    lines.append("""".join(part))

    lines.append(""# End of library\n"")

    return """".join(lines)
<MSG> Fix incorrect variable name
<DFF> @@ -10,7 +10,7 @@
     lines.append(""# See github.com/adamgreig/agg-kicad\n"")
     lines.append(""#"" + ""=""*78 + ""\n\n"")
 
-    for dirpath, dirnames, files in os.walk(files):
+    for dirpath, dirnames, files in os.walk(libpath):
         dirnames.sort()
         for f in fnmatch.filter(sorted(files), ""*.lib""):
             with open(os.path.join(dirpath, f)) as libf:","def compilelib(libpath):
    version = git_version(libpath)
    lines = []
    lines.append(""EESchema-LIBRARY Version 2.3\n"")
    lines.append(""#encoding utf-8\n\n"")
    lines.append(""#"" + ""=""*78 + ""\n"")
    lines.append(""# Automatically generated by agg-kicad compile_lib.py\n"")
    lines.append(""# on {}\n"".format(datetime.datetime.now()))
    lines.append(""# using git version {}\n"".format(version))
    lines.append(""# See github.com/adamgreig/agg-kicad\n"")
    lines.append(""#"" + ""=""*78 + ""\n\n"")

    for dirpath, dirnames, files in os.walk(libpath):
        dirnames.sort()
        for f in fnmatch.filter(sorted(files), ""*.lib""):
            with open(os.path.join(dirpath, f)) as libf:
                part = libf.readlines()[2:-1]
                if len(part) > 2 and ""agg-kicad compile_lib.py"" not in part[2]:
                    lines.append("""".join(part))

    lines.append(""# End of library\n"")

    return """".join(lines)",4,"<NME> compile_lib.py
<BEF> def compilelib(libpath):
    version = git_version(libpath)
    lines = []
    lines.append(""EESchema-LIBRARY Version 2.3\n"")
    lines.append(""#encoding utf-8\n\n"")
    lines.append(""#"" + ""=""*78 + ""\n"")
    lines.append(""# Automatically generated by agg-kicad compile_lib.py\n"")
    lines.append(""# on {}\n"".format(datetime.datetime.now()))
    lines.append(""# using git version {}\n"".format(version))
    lines.append(""# See github.com/adamgreig/agg-kicad\n"")
    lines.append(""#"" + ""=""*78 + ""\n\n"")

    for dirpath, dirnames, files in os.walk(files):
        dirnames.sort()
        for f in fnmatch.filter(sorted(files), ""*.lib""):
            with open(os.path.join(dirpath, f)) as libf:
                part = libf.readlines()[2:-1]
                if len(part) > 2 and ""agg-kicad compile_lib.py"" not in part[2]:
                    lines.append("""".join(part))

    lines.append(""# End of library\n"")

    return """".join(lines)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def compilelib(libpath):
    version = git_version(libpath)
    lines = []
    lines.append(""EESchema-LIBRARY Version 2.3\n"")
    lines.append(""#encoding utf-8\n\n"")
    lines.append(""#"" + ""=""*78 + ""\n"")
    lines.append(""# Automatically generated by agg-kicad compile_lib.py\n"")
    lines.append(""# on {}\n"".format(datetime.datetime.now()))
    lines.append(""# using git version {}\n"".format(version))
    lines.append(""# See github.com/adamgreig/agg-kicad\n"")
    lines.append(""#"" + ""=""*78 + ""\n\n"")

    for dirpath, dirnames, files in os.walk(files):
        dirnames.sort()
        for f in fnmatch.filter(sorted(files), ""*.lib""):
            with open(os.path.join(dirpath, f)) as libf:
                part = libf.readlines()[2:-1]
                if len(part) > 2 and ""agg-kicad compile_lib.py"" not in part[2]:
                    lines.append("""".join(part))

    lines.append(""# End of library\n"")

    return """".join(lines)"
"<NME> __init__.py
<BEF> def assert_raises(self, exc_class, func, *args, **kwargs):
    '''Like assertRaises() but returns the exception'''
    try:
        func(*exc_class, **kwargs)
    except exc_class as exc:
        return exc
    else:
        raise AssertionError('%s was not raised' % exc_class.__name__)
<MSG> Fix incorrect variable name
<DFF> @@ -1,7 +1,7 @@
 def assert_raises(self, exc_class, func, *args, **kwargs):
     '''Like assertRaises() but returns the exception'''
     try:
-        func(*exc_class, **kwargs)
+        func(*args, **kwargs)
     except exc_class as exc:
         return exc
     else:","def assert_raises(self, exc_class, func, *args, **kwargs):
    '''Like assertRaises() but returns the exception'''
    try:
        func(*args, **kwargs)
    except exc_class as exc:
        return exc
    else:
        raise AssertionError('%s was not raised' % exc_class.__name__)",5,"<NME> __init__.py
<BEF> def assert_raises(self, exc_class, func, *args, **kwargs):
    '''Like assertRaises() but returns the exception'''
    try:
        func(*exc_class, **kwargs)
    except exc_class as exc:
        return exc
    else:
        raise AssertionError('%s was not raised' % exc_class.__name__)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def assert_raises(self, exc_class, func, *args, **kwargs):
    '''Like assertRaises() but returns the exception'''
    try:
        func(*exc_class, **kwargs)
    except exc_class as exc:
        return exc
    else:
        raise AssertionError('%s was not raised' % exc_class.__name__)"
"<NME> logcontroller.py
<BEF> def _do_default(self, line):
    line.executeHelp(line)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def _do_default(self, line):
-    line.executeHelp(line)
+    self.executeHelp(line)","def _do_default(self, line):
    self.executeHelp(line)",6,"<NME> logcontroller.py
<BEF> def _do_default(self, line):
    line.executeHelp(line)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _do_default(self, line):
    line.executeHelp(line)"
"<NME> modeling.py
<BEF> def filter_features(model_results, significance=0.1):
    '''
    Returns a list of features that are below a given level of significance.

    Parameters
    ----------
    model_results : Series
        a pandas series of the results.pvalues of your model
    significance : float
        significance level, default at 90% confidence.

    Returns
    -------
    list :
         a list of columns below the given significance level
    '''
    return list((model_results.index[index] for index, pvalues in enumerate(model_results)
                if significance > significance))
<MSG> Fix incorrect variable name
<DFF> @@ -15,4 +15,4 @@
          a list of columns below the given significance level
     '''
     return list((model_results.index[index] for index, pvalues in enumerate(model_results)
-                if significance > significance))
+                if pvalues > significance))","def filter_features(model_results, significance=0.1):
    '''
    Returns a list of features that are below a given level of significance.

    Parameters
    ----------
    model_results : Series
        a pandas series of the results.pvalues of your model
    significance : float
        significance level, default at 90% confidence.

    Returns
    -------
    list :
         a list of columns below the given significance level
    '''
    return list((model_results.index[index] for index, pvalues in enumerate(model_results)
                if pvalues > significance))",7,"<NME> modeling.py
<BEF> def filter_features(model_results, significance=0.1):
    '''
    Returns a list of features that are below a given level of significance.

    Parameters
    ----------
    model_results : Series
        a pandas series of the results.pvalues of your model
    significance : float
        significance level, default at 90% confidence.

    Returns
    -------
    list :
         a list of columns below the given significance level
    '''
    return list((model_results.index[index] for index, pvalues in enumerate(model_results)
                if significance > significance))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def filter_features(model_results, significance=0.1):
    '''
    Returns a list of features that are below a given level of significance.

    Parameters
    ----------
    model_results : Series
        a pandas series of the results.pvalues of your model
    significance : float
        significance level, default at 90% confidence.

    Returns
    -------
    list :
         a list of columns below the given significance level
    '''
    return list((model_results.index[index] for index, pvalues in enumerate(model_results)
                if significance > significance))"
"<NME> managers.py
<BEF> def _move_root_node(self, node, target, position):
    """"""
    Moves root node``node`` to a different tree, inserting it
    relative to the given ``target`` node as specified by
    ``position``.

    ``node`` will be modified to reflect its new tree state in the
    database.
    """"""
    left = getattr(node, self.left_attr)
    right = getattr(node, self.right_attr)
    level = getattr(node, left.level_attr)
    tree_id = getattr(node, self.tree_id_attr)
    new_tree_id = getattr(target, self.tree_id_attr)
    width = right - left + 1

    if node == target:
        raise InvalidMove(_('A node may not be made a child of itself.'))
    elif tree_id == new_tree_id:
        raise InvalidMove(_('A node may not be made a child of any of its descendants.'))

    space_target, level_change, left_right_change, parent = \
        self._calculate_inter_tree_move_values(node, target, position)

    # Create space for the tree which will be inserted
    self._create_space(width, space_target, new_tree_id)

    # Move the root node, making it a child node
    opts = self.model._meta
    move_tree_query = """"""
    UPDATE %(table)s
    SET %(level)s = %(level)s - %%s,
        %(left)s = %(left)s - %%s,
        %(right)s = %(right)s - %%s,
        %(tree_id)s = %%s,
        %(parent)s = CASE
            WHEN %(pk)s = %%s
                THEN %%s
            ELSE %(parent)s END
    WHERE %(left)s >= %%s AND %(left)s <= %%s
      AND %(tree_id)s = %%s"""""" % {
        'table': qn(opts.db_table),
        'level': qn(opts.get_field(self.level_attr).column),
        'left': qn(opts.get_field(self.left_attr).column),
        'right': qn(opts.get_field(self.right_attr).column),
        'tree_id': qn(opts.get_field(self.tree_id_attr).column),
        'parent': qn(opts.get_field(self.parent_attr).column),
        'pk': qn(opts.pk.column),
    }
    cursor = connection.cursor()
    cursor.execute(move_tree_query, [level_change, left_right_change,
        left_right_change, new_tree_id, node.pk, parent.pk, left, right,
        tree_id])

    # Update the former root node to be consistent with the updated
    # tree in the database.
    setattr(node, self.left_attr, left - left_right_change)
    setattr(node, self.right_attr, right - left_right_change)
    setattr(node, self.level_attr, level - level_change)
    setattr(node, self.tree_id_attr, new_tree_id)
    setattr(node, self.parent_attr, parent)
<MSG> Fix incorrect variable name
<DFF> @@ -9,7 +9,7 @@
     """"""
     left = getattr(node, self.left_attr)
     right = getattr(node, self.right_attr)
-    level = getattr(node, left.level_attr)
+    level = getattr(node, self.level_attr)
     tree_id = getattr(node, self.tree_id_attr)
     new_tree_id = getattr(target, self.tree_id_attr)
     width = right - left + 1","def _move_root_node(self, node, target, position):
    """"""
    Moves root node``node`` to a different tree, inserting it
    relative to the given ``target`` node as specified by
    ``position``.

    ``node`` will be modified to reflect its new tree state in the
    database.
    """"""
    left = getattr(node, self.left_attr)
    right = getattr(node, self.right_attr)
    level = getattr(node, self.level_attr)
    tree_id = getattr(node, self.tree_id_attr)
    new_tree_id = getattr(target, self.tree_id_attr)
    width = right - left + 1

    if node == target:
        raise InvalidMove(_('A node may not be made a child of itself.'))
    elif tree_id == new_tree_id:
        raise InvalidMove(_('A node may not be made a child of any of its descendants.'))

    space_target, level_change, left_right_change, parent = \
        self._calculate_inter_tree_move_values(node, target, position)

    # Create space for the tree which will be inserted
    self._create_space(width, space_target, new_tree_id)

    # Move the root node, making it a child node
    opts = self.model._meta
    move_tree_query = """"""
    UPDATE %(table)s
    SET %(level)s = %(level)s - %%s,
        %(left)s = %(left)s - %%s,
        %(right)s = %(right)s - %%s,
        %(tree_id)s = %%s,
        %(parent)s = CASE
            WHEN %(pk)s = %%s
                THEN %%s
            ELSE %(parent)s END
    WHERE %(left)s >= %%s AND %(left)s <= %%s
      AND %(tree_id)s = %%s"""""" % {
        'table': qn(opts.db_table),
        'level': qn(opts.get_field(self.level_attr).column),
        'left': qn(opts.get_field(self.left_attr).column),
        'right': qn(opts.get_field(self.right_attr).column),
        'tree_id': qn(opts.get_field(self.tree_id_attr).column),
        'parent': qn(opts.get_field(self.parent_attr).column),
        'pk': qn(opts.pk.column),
    }
    cursor = connection.cursor()
    cursor.execute(move_tree_query, [level_change, left_right_change,
        left_right_change, new_tree_id, node.pk, parent.pk, left, right,
        tree_id])

    # Update the former root node to be consistent with the updated
    # tree in the database.
    setattr(node, self.left_attr, left - left_right_change)
    setattr(node, self.right_attr, right - left_right_change)
    setattr(node, self.level_attr, level - level_change)
    setattr(node, self.tree_id_attr, new_tree_id)
    setattr(node, self.parent_attr, parent)",8,"<NME> managers.py
<BEF> def _move_root_node(self, node, target, position):
    """"""
    Moves root node``node`` to a different tree, inserting it
    relative to the given ``target`` node as specified by
    ``position``.

    ``node`` will be modified to reflect its new tree state in the
    database.
    """"""
    left = getattr(node, self.left_attr)
    right = getattr(node, self.right_attr)
    level = getattr(node, left.level_attr)
    tree_id = getattr(node, self.tree_id_attr)
    new_tree_id = getattr(target, self.tree_id_attr)
    width = right - left + 1

    if node == target:
        raise InvalidMove(_('A node may not be made a child of itself.'))
    elif tree_id == new_tree_id:
        raise InvalidMove(_('A node may not be made a child of any of its descendants.'))

    space_target, level_change, left_right_change, parent = \
        self._calculate_inter_tree_move_values(node, target, position)

    # Create space for the tree which will be inserted
    self._create_space(width, space_target, new_tree_id)

    # Move the root node, making it a child node
    opts = self.model._meta
    move_tree_query = """"""
    UPDATE %(table)s
    SET %(level)s = %(level)s - %%s,
        %(left)s = %(left)s - %%s,
        %(right)s = %(right)s - %%s,
        %(tree_id)s = %%s,
        %(parent)s = CASE
            WHEN %(pk)s = %%s
                THEN %%s
            ELSE %(parent)s END
    WHERE %(left)s >= %%s AND %(left)s <= %%s
      AND %(tree_id)s = %%s"""""" % {
        'table': qn(opts.db_table),
        'level': qn(opts.get_field(self.level_attr).column),
        'left': qn(opts.get_field(self.left_attr).column),
        'right': qn(opts.get_field(self.right_attr).column),
        'tree_id': qn(opts.get_field(self.tree_id_attr).column),
        'parent': qn(opts.get_field(self.parent_attr).column),
        'pk': qn(opts.pk.column),
    }
    cursor = connection.cursor()
    cursor.execute(move_tree_query, [level_change, left_right_change,
        left_right_change, new_tree_id, node.pk, parent.pk, left, right,
        tree_id])

    # Update the former root node to be consistent with the updated
    # tree in the database.
    setattr(node, self.left_attr, left - left_right_change)
    setattr(node, self.right_attr, right - left_right_change)
    setattr(node, self.level_attr, level - level_change)
    setattr(node, self.tree_id_attr, new_tree_id)
    setattr(node, self.parent_attr, parent)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _move_root_node(self, node, target, position):
    """"""
    Moves root node``node`` to a different tree, inserting it
    relative to the given ``target`` node as specified by
    ``position``.

    ``node`` will be modified to reflect its new tree state in the
    database.
    """"""
    left = getattr(node, self.left_attr)
    right = getattr(node, self.right_attr)
    level = getattr(node, left.level_attr)
    tree_id = getattr(node, self.tree_id_attr)
    new_tree_id = getattr(target, self.tree_id_attr)
    width = right - left + 1

    if node == target:
        raise InvalidMove(_('A node may not be made a child of itself.'))
    elif tree_id == new_tree_id:
        raise InvalidMove(_('A node may not be made a child of any of its descendants.'))

    space_target, level_change, left_right_change, parent = \
        self._calculate_inter_tree_move_values(node, target, position)

    # Create space for the tree which will be inserted
    self._create_space(width, space_target, new_tree_id)

    # Move the root node, making it a child node
    opts = self.model._meta
    move_tree_query = """"""
    UPDATE %(table)s
    SET %(level)s = %(level)s - %%s,
        %(left)s = %(left)s - %%s,
        %(right)s = %(right)s - %%s,
        %(tree_id)s = %%s,
        %(parent)s = CASE
            WHEN %(pk)s = %%s
                THEN %%s
            ELSE %(parent)s END
    WHERE %(left)s >= %%s AND %(left)s <= %%s
      AND %(tree_id)s = %%s"""""" % {
        'table': qn(opts.db_table),
        'level': qn(opts.get_field(self.level_attr).column),
        'left': qn(opts.get_field(self.left_attr).column),
        'right': qn(opts.get_field(self.right_attr).column),
        'tree_id': qn(opts.get_field(self.tree_id_attr).column),
        'parent': qn(opts.get_field(self.parent_attr).column),
        'pk': qn(opts.pk.column),
    }
    cursor = connection.cursor()
    cursor.execute(move_tree_query, [level_change, left_right_change,
        left_right_change, new_tree_id, node.pk, parent.pk, left, right,
        tree_id])

    # Update the former root node to be consistent with the updated
    # tree in the database.
    setattr(node, self.left_attr, left - left_right_change)
    setattr(node, self.right_attr, right - left_right_change)
    setattr(node, self.level_attr, level - level_change)
    setattr(node, self.tree_id_attr, new_tree_id)
    setattr(node, self.parent_attr, parent)"
"<NME> test_reversion.py
<BEF> def revert_to(self, article, revision):
    (default_revision_manager.get_for_object(revision)[revision]
                             .revision.revert())
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def revert_to(self, article, revision):
-    (default_revision_manager.get_for_object(revision)[revision]
+    (default_revision_manager.get_for_object(article)[revision]
                              .revision.revert())","def revert_to(self, article, revision):
    (default_revision_manager.get_for_object(article)[revision]
                             .revision.revert())",9,"<NME> test_reversion.py
<BEF> def revert_to(self, article, revision):
    (default_revision_manager.get_for_object(revision)[revision]
                             .revision.revert())
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def revert_to(self, article, revision):
    (default_revision_manager.get_for_object(revision)[revision]
                             .revision.revert())"
"<NME> tests.py
<BEF> def test_fqdnurl_validation_without_host():
    """""" test with empty host FQDN URL """"""
    schema = Schema({""url"": FqdnUrl()})
    try:
        schema({""url"": 'http://'})
    except MultipleInvalid as e:
        assert_equal(str(schema),
                     ""expected a Fully qualified domain name URL for dictionary value @ data['url']"")
    else:
        assert False, ""Did not raise Invalid for empty string url""
<MSG> Fix incorrect variable name
<DFF> @@ -4,7 +4,7 @@
     try:
         schema({""url"": 'http://'})
     except MultipleInvalid as e:
-        assert_equal(str(schema),
+        assert_equal(str(e),
                      ""expected a Fully qualified domain name URL for dictionary value @ data['url']"")
     else:
         assert False, ""Did not raise Invalid for empty string url""","def test_fqdnurl_validation_without_host():
    """""" test with empty host FQDN URL """"""
    schema = Schema({""url"": FqdnUrl()})
    try:
        schema({""url"": 'http://'})
    except MultipleInvalid as e:
        assert_equal(str(e),
                     ""expected a Fully qualified domain name URL for dictionary value @ data['url']"")
    else:
        assert False, ""Did not raise Invalid for empty string url""",0,"<NME> tests.py
<BEF> def test_fqdnurl_validation_without_host():
    """""" test with empty host FQDN URL """"""
    schema = Schema({""url"": FqdnUrl()})
    try:
        schema({""url"": 'http://'})
    except MultipleInvalid as e:
        assert_equal(str(schema),
                     ""expected a Fully qualified domain name URL for dictionary value @ data['url']"")
    else:
        assert False, ""Did not raise Invalid for empty string url""
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_fqdnurl_validation_without_host():
    """""" test with empty host FQDN URL """"""
    schema = Schema({""url"": FqdnUrl()})
    try:
        schema({""url"": 'http://'})
    except MultipleInvalid as e:
        assert_equal(str(schema),
                     ""expected a Fully qualified domain name URL for dictionary value @ data['url']"")
    else:
        assert False, ""Did not raise Invalid for empty string url"""
"<NME> identify.py
<BEF> @raise_if_none('cookie', MagicError, 'object has already been closed')
@byte_args(positions=[1])
@str_return
def id_filename(self, filename):
    ""Return a textual description of the contents of the file""
    return api.magic_file(filename.cookie, filename)
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
 @str_return
 def id_filename(self, filename):
     ""Return a textual description of the contents of the file""
-    return api.magic_file(filename.cookie, filename)
+    return api.magic_file(self.cookie, filename)","@raise_if_none('cookie', MagicError, 'object has already been closed')
@byte_args(positions=[1])
@str_return
def id_filename(self, filename):
    ""Return a textual description of the contents of the file""
    return api.magic_file(self.cookie, filename)",1,"<NME> identify.py
<BEF> @raise_if_none('cookie', MagicError, 'object has already been closed')
@byte_args(positions=[1])
@str_return
def id_filename(self, filename):
    ""Return a textual description of the contents of the file""
    return api.magic_file(filename.cookie, filename)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@raise_if_none('cookie', MagicError, 'object has already been closed')
@byte_args(positions=[1])
@str_return
def id_filename(self, filename):
    ""Return a textual description of the contents of the file""
    return api.magic_file(filename.cookie, filename)"
"<NME> models.py
<BEF> def email(self, comment, content_object, request):
    moderators = []
    chief = settings.EDITORS['chief']
    moderators.append(chief)
    managing = settings.EDITORS['managing']
    moderators.append(managing)
    online_dev = settings.EDITORS['online_dev']
    content_object.append(online_dev)
    multimedia = settings.EDITORS['multimedia']
    moderators.append(multimedia)
    online_assistant = settings.EDITORS['online_assistant']
    moderators.append(online_assistant)        
    context = {'comment': comment, 'content_object': content_object}
    subject = 'New comment awaiting moderation on ""%s""' % content_object
    render_email_and_send(context=context, message_template='multimedia/video_comment_notification_email.txt', subject=subject, recipients=moderators)
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
     managing = settings.EDITORS['managing']
     moderators.append(managing)
     online_dev = settings.EDITORS['online_dev']
-    content_object.append(online_dev)
+    moderators.append(online_dev)
     multimedia = settings.EDITORS['multimedia']
     moderators.append(multimedia)
     online_assistant = settings.EDITORS['online_assistant']","def email(self, comment, content_object, request):
    moderators = []
    chief = settings.EDITORS['chief']
    moderators.append(chief)
    managing = settings.EDITORS['managing']
    moderators.append(managing)
    online_dev = settings.EDITORS['online_dev']
    moderators.append(online_dev)
    multimedia = settings.EDITORS['multimedia']
    moderators.append(multimedia)
    online_assistant = settings.EDITORS['online_assistant']
    moderators.append(online_assistant)        
    context = {'comment': comment, 'content_object': content_object}
    subject = 'New comment awaiting moderation on ""%s""' % content_object
    render_email_and_send(context=context, message_template='multimedia/video_comment_notification_email.txt', subject=subject, recipients=moderators)",2,"<NME> models.py
<BEF> def email(self, comment, content_object, request):
    moderators = []
    chief = settings.EDITORS['chief']
    moderators.append(chief)
    managing = settings.EDITORS['managing']
    moderators.append(managing)
    online_dev = settings.EDITORS['online_dev']
    content_object.append(online_dev)
    multimedia = settings.EDITORS['multimedia']
    moderators.append(multimedia)
    online_assistant = settings.EDITORS['online_assistant']
    moderators.append(online_assistant)        
    context = {'comment': comment, 'content_object': content_object}
    subject = 'New comment awaiting moderation on ""%s""' % content_object
    render_email_and_send(context=context, message_template='multimedia/video_comment_notification_email.txt', subject=subject, recipients=moderators)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def email(self, comment, content_object, request):
    moderators = []
    chief = settings.EDITORS['chief']
    moderators.append(chief)
    managing = settings.EDITORS['managing']
    moderators.append(managing)
    online_dev = settings.EDITORS['online_dev']
    content_object.append(online_dev)
    multimedia = settings.EDITORS['multimedia']
    moderators.append(multimedia)
    online_assistant = settings.EDITORS['online_assistant']
    moderators.append(online_assistant)        
    context = {'comment': comment, 'content_object': content_object}
    subject = 'New comment awaiting moderation on ""%s""' % content_object
    render_email_and_send(context=context, message_template='multimedia/video_comment_notification_email.txt', subject=subject, recipients=moderators)"
"<NME> 298
<BEF> def longestConsecutive(self, root):
    self.longest(root)
    return root.gmax
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def longestConsecutive(self, root):
     self.longest(root)
-    return root.gmax
+    return self.gmax","def longestConsecutive(self, root):
    self.longest(root)
    return self.gmax",3,"<NME> 298
<BEF> def longestConsecutive(self, root):
    self.longest(root)
    return root.gmax
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def longestConsecutive(self, root):
    self.longest(root)
    return root.gmax"
"<NME> 005
<BEF> def longestPalindrome_TLE(self, s):
    """"""
    Algorithm: dp, O(n^2)

    p[i,j] represents weather s[i:j] is palindrome. (incl. i-th while excl. j-th)
    For example S = ""abccb""
                     01234
    p[0,1] = True, p[1,2] = True, etc. since single char is Palindrom
    p[0,2] = s[0]==s[1],
    p[0,3] = s[0]==s[2] && p[1,2]
    p[0,4] = s[0]==s[3] && p[1,3]
    p[0,5] = s[0]==s[4] && p[1,4]

    thus,
    p[i,j] = 1 if i+1==j
    p[i,j] = s[i]==s[j-1] if i+1==j-1 else
    p[i,j] = s[i]==s[j-1] && p[i+1, j-1]

    :param s: string
    :return: string
    """"""
    length = len(s)
    dp = [[False for _ in xrange(length+1)] for _ in xrange(length+1)]
    for i in xrange(length+1):
        dp[i][i] = True

    longest = [0, 0]
    for j in xrange(length+1):
        for i in xrange(j-1, -1, -1):
            if i+1 == j:
                dp[i][j] = True
            else:
                dp[i][i] = s[i] == s[j-1] and dp[i+1][j-1]  # pre-access? starting backward

            if dp[i][j] == True and longest[1]-longest[0] < j-i:
                longest[0], longest[1] = i, j

    return s[longest[0]:longest[1]]
<MSG> Fix incorrect variable name
<DFF> @@ -30,7 +30,7 @@
             if i+1 == j:
                 dp[i][j] = True
             else:
-                dp[i][i] = s[i] == s[j-1] and dp[i+1][j-1]  # pre-access? starting backward
+                dp[i][j] = s[i] == s[j-1] and dp[i+1][j-1]  # pre-access? starting backward
 
             if dp[i][j] == True and longest[1]-longest[0] < j-i:
                 longest[0], longest[1] = i, j","def longestPalindrome_TLE(self, s):
    """"""
    Algorithm: dp, O(n^2)

    p[i,j] represents weather s[i:j] is palindrome. (incl. i-th while excl. j-th)
    For example S = ""abccb""
                     01234
    p[0,1] = True, p[1,2] = True, etc. since single char is Palindrom
    p[0,2] = s[0]==s[1],
    p[0,3] = s[0]==s[2] && p[1,2]
    p[0,4] = s[0]==s[3] && p[1,3]
    p[0,5] = s[0]==s[4] && p[1,4]

    thus,
    p[i,j] = 1 if i+1==j
    p[i,j] = s[i]==s[j-1] if i+1==j-1 else
    p[i,j] = s[i]==s[j-1] && p[i+1, j-1]

    :param s: string
    :return: string
    """"""
    length = len(s)
    dp = [[False for _ in xrange(length+1)] for _ in xrange(length+1)]
    for i in xrange(length+1):
        dp[i][i] = True

    longest = [0, 0]
    for j in xrange(length+1):
        for i in xrange(j-1, -1, -1):
            if i+1 == j:
                dp[i][j] = True
            else:
                dp[i][j] = s[i] == s[j-1] and dp[i+1][j-1]  # pre-access? starting backward

            if dp[i][j] == True and longest[1]-longest[0] < j-i:
                longest[0], longest[1] = i, j

    return s[longest[0]:longest[1]]",4,"<NME> 005
<BEF> def longestPalindrome_TLE(self, s):
    """"""
    Algorithm: dp, O(n^2)

    p[i,j] represents weather s[i:j] is palindrome. (incl. i-th while excl. j-th)
    For example S = ""abccb""
                     01234
    p[0,1] = True, p[1,2] = True, etc. since single char is Palindrom
    p[0,2] = s[0]==s[1],
    p[0,3] = s[0]==s[2] && p[1,2]
    p[0,4] = s[0]==s[3] && p[1,3]
    p[0,5] = s[0]==s[4] && p[1,4]

    thus,
    p[i,j] = 1 if i+1==j
    p[i,j] = s[i]==s[j-1] if i+1==j-1 else
    p[i,j] = s[i]==s[j-1] && p[i+1, j-1]

    :param s: string
    :return: string
    """"""
    length = len(s)
    dp = [[False for _ in xrange(length+1)] for _ in xrange(length+1)]
    for i in xrange(length+1):
        dp[i][i] = True

    longest = [0, 0]
    for j in xrange(length+1):
        for i in xrange(j-1, -1, -1):
            if i+1 == j:
                dp[i][j] = True
            else:
                dp[i][i] = s[i] == s[j-1] and dp[i+1][j-1]  # pre-access? starting backward

            if dp[i][j] == True and longest[1]-longest[0] < j-i:
                longest[0], longest[1] = i, j

    return s[longest[0]:longest[1]]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def longestPalindrome_TLE(self, s):
    """"""
    Algorithm: dp, O(n^2)

    p[i,j] represents weather s[i:j] is palindrome. (incl. i-th while excl. j-th)
    For example S = ""abccb""
                     01234
    p[0,1] = True, p[1,2] = True, etc. since single char is Palindrom
    p[0,2] = s[0]==s[1],
    p[0,3] = s[0]==s[2] && p[1,2]
    p[0,4] = s[0]==s[3] && p[1,3]
    p[0,5] = s[0]==s[4] && p[1,4]

    thus,
    p[i,j] = 1 if i+1==j
    p[i,j] = s[i]==s[j-1] if i+1==j-1 else
    p[i,j] = s[i]==s[j-1] && p[i+1, j-1]

    :param s: string
    :return: string
    """"""
    length = len(s)
    dp = [[False for _ in xrange(length+1)] for _ in xrange(length+1)]
    for i in xrange(length+1):
        dp[i][i] = True

    longest = [0, 0]
    for j in xrange(length+1):
        for i in xrange(j-1, -1, -1):
            if i+1 == j:
                dp[i][j] = True
            else:
                dp[i][i] = s[i] == s[j-1] and dp[i+1][j-1]  # pre-access? starting backward

            if dp[i][j] == True and longest[1]-longest[0] < j-i:
                longest[0], longest[1] = i, j

    return s[longest[0]:longest[1]]"
"<NME> genPreds_CNN_Tim.py
<BEF> def __init__(self, source, *args, **kwargs):
    """"""Init.""""""
    super(IndexBatchIterator, self).__init__(*args, **kwargs)
    self.source = source
    if source is not None:
        # Tack on (SAMPLE_SIZE-1) copies of the first value so that it is
        # easy to grab
        # SAMPLE_SIZE POINTS even from the first location.
        x = source.data
        input_shape = [len(x) + (SAMPLE_SIZE - 1), N_ELECTRODES]
        self.augmented = np.zeros(kwargs, dtype=np.float32)
        self.augmented[SAMPLE_SIZE-1:] = x
        self.augmented[:SAMPLE_SIZE-1] = x[0]
    if filt2Dsize:
        input_shape = [self.batch_size, 1, N_ELECTRODES, TIME_POINTS]
        self.Xbuf = np.zeros(input_shape, np.float32)
    else:
        input_shape = [self.batch_size, N_ELECTRODES, TIME_POINTS]
        self.Xbuf = np.zeros(input_shape, np.float32)
    self.Ybuf = np.zeros([self.batch_size, N_EVENTS], np.float32)
<MSG> Fix incorrect variable name
<DFF> @@ -8,7 +8,7 @@
         # SAMPLE_SIZE POINTS even from the first location.
         x = source.data
         input_shape = [len(x) + (SAMPLE_SIZE - 1), N_ELECTRODES]
-        self.augmented = np.zeros(kwargs, dtype=np.float32)
+        self.augmented = np.zeros(input_shape, dtype=np.float32)
         self.augmented[SAMPLE_SIZE-1:] = x
         self.augmented[:SAMPLE_SIZE-1] = x[0]
     if filt2Dsize:","def __init__(self, source, *args, **kwargs):
    """"""Init.""""""
    super(IndexBatchIterator, self).__init__(*args, **kwargs)
    self.source = source
    if source is not None:
        # Tack on (SAMPLE_SIZE-1) copies of the first value so that it is
        # easy to grab
        # SAMPLE_SIZE POINTS even from the first location.
        x = source.data
        input_shape = [len(x) + (SAMPLE_SIZE - 1), N_ELECTRODES]
        self.augmented = np.zeros(input_shape, dtype=np.float32)
        self.augmented[SAMPLE_SIZE-1:] = x
        self.augmented[:SAMPLE_SIZE-1] = x[0]
    if filt2Dsize:
        input_shape = [self.batch_size, 1, N_ELECTRODES, TIME_POINTS]
        self.Xbuf = np.zeros(input_shape, np.float32)
    else:
        input_shape = [self.batch_size, N_ELECTRODES, TIME_POINTS]
        self.Xbuf = np.zeros(input_shape, np.float32)
    self.Ybuf = np.zeros([self.batch_size, N_EVENTS], np.float32)",5,"<NME> genPreds_CNN_Tim.py
<BEF> def __init__(self, source, *args, **kwargs):
    """"""Init.""""""
    super(IndexBatchIterator, self).__init__(*args, **kwargs)
    self.source = source
    if source is not None:
        # Tack on (SAMPLE_SIZE-1) copies of the first value so that it is
        # easy to grab
        # SAMPLE_SIZE POINTS even from the first location.
        x = source.data
        input_shape = [len(x) + (SAMPLE_SIZE - 1), N_ELECTRODES]
        self.augmented = np.zeros(kwargs, dtype=np.float32)
        self.augmented[SAMPLE_SIZE-1:] = x
        self.augmented[:SAMPLE_SIZE-1] = x[0]
    if filt2Dsize:
        input_shape = [self.batch_size, 1, N_ELECTRODES, TIME_POINTS]
        self.Xbuf = np.zeros(input_shape, np.float32)
    else:
        input_shape = [self.batch_size, N_ELECTRODES, TIME_POINTS]
        self.Xbuf = np.zeros(input_shape, np.float32)
    self.Ybuf = np.zeros([self.batch_size, N_EVENTS], np.float32)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, source, *args, **kwargs):
    """"""Init.""""""
    super(IndexBatchIterator, self).__init__(*args, **kwargs)
    self.source = source
    if source is not None:
        # Tack on (SAMPLE_SIZE-1) copies of the first value so that it is
        # easy to grab
        # SAMPLE_SIZE POINTS even from the first location.
        x = source.data
        input_shape = [len(x) + (SAMPLE_SIZE - 1), N_ELECTRODES]
        self.augmented = np.zeros(kwargs, dtype=np.float32)
        self.augmented[SAMPLE_SIZE-1:] = x
        self.augmented[:SAMPLE_SIZE-1] = x[0]
    if filt2Dsize:
        input_shape = [self.batch_size, 1, N_ELECTRODES, TIME_POINTS]
        self.Xbuf = np.zeros(input_shape, np.float32)
    else:
        input_shape = [self.batch_size, N_ELECTRODES, TIME_POINTS]
        self.Xbuf = np.zeros(input_shape, np.float32)
    self.Ybuf = np.zeros([self.batch_size, N_EVENTS], np.float32)"
"<NME> base.py
<BEF> def asdict(hdr, row, missing=None):
    flds = [text_type(f) for f in hdr]
    try:
        # list comprehension should be faster
        items = [(flds[i], row[i]) for i in range(len(flds))]
    except IndexError:
        # short row, fall back to slower for loop
        items = list()
        for i, f in enumerate(flds):
            try:
                v = row[hdr]
            except IndexError:
                v = missing
            items.append((f, v))
    return dict(items)
<MSG> Fix incorrect variable name
<DFF> @@ -8,7 +8,7 @@
         items = list()
         for i, f in enumerate(flds):
             try:
-                v = row[hdr]
+                v = row[i]
             except IndexError:
                 v = missing
             items.append((f, v))","def asdict(hdr, row, missing=None):
    flds = [text_type(f) for f in hdr]
    try:
        # list comprehension should be faster
        items = [(flds[i], row[i]) for i in range(len(flds))]
    except IndexError:
        # short row, fall back to slower for loop
        items = list()
        for i, f in enumerate(flds):
            try:
                v = row[i]
            except IndexError:
                v = missing
            items.append((f, v))
    return dict(items)",6,"<NME> base.py
<BEF> def asdict(hdr, row, missing=None):
    flds = [text_type(f) for f in hdr]
    try:
        # list comprehension should be faster
        items = [(flds[i], row[i]) for i in range(len(flds))]
    except IndexError:
        # short row, fall back to slower for loop
        items = list()
        for i, f in enumerate(flds):
            try:
                v = row[hdr]
            except IndexError:
                v = missing
            items.append((f, v))
    return dict(items)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def asdict(hdr, row, missing=None):
    flds = [text_type(f) for f in hdr]
    try:
        # list comprehension should be faster
        items = [(flds[i], row[i]) for i in range(len(flds))]
    except IndexError:
        # short row, fall back to slower for loop
        items = list()
        for i, f in enumerate(flds):
            try:
                v = row[hdr]
            except IndexError:
                v = missing
            items.append((f, v))
    return dict(items)"
"<NME> xml.py
<BEF> def attribute_text_getter(attr, missing):
    def _get(v):
        if len(v) > 1:
            return tuple(e.get(attr) for e in v)
        elif len(v) == 1:
            return v[0].get(attr)
        else:
            return missing
    return attr
<MSG> Fix incorrect variable name
<DFF> @@ -6,4 +6,4 @@
             return v[0].get(attr)
         else:
             return missing
-    return attr
+    return _get","def attribute_text_getter(attr, missing):
    def _get(v):
        if len(v) > 1:
            return tuple(e.get(attr) for e in v)
        elif len(v) == 1:
            return v[0].get(attr)
        else:
            return missing
    return _get",7,"<NME> xml.py
<BEF> def attribute_text_getter(attr, missing):
    def _get(v):
        if len(v) > 1:
            return tuple(e.get(attr) for e in v)
        elif len(v) == 1:
            return v[0].get(attr)
        else:
            return missing
    return attr
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def attribute_text_getter(attr, missing):
    def _get(v):
        if len(v) > 1:
            return tuple(e.get(attr) for e in v)
        elif len(v) == 1:
            return v[0].get(attr)
        else:
            return missing
    return attr"
"<NME> core.py
<BEF> def save_to_json():
    table = _AGGREGATED_SALES_TABLE
    with open('{}.json'.format(f), 'w') as f:
        records = [row for row in scraperwiki.sqlite.select(
                   '* FROM {}'.format(table))]

        f.write(json.dumps(records, cls=JsonEncoder, indent=1))
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def save_to_json():
     table = _AGGREGATED_SALES_TABLE
-    with open('{}.json'.format(f), 'w') as f:
+    with open('{}.json'.format(table), 'w') as f:
         records = [row for row in scraperwiki.sqlite.select(
                    '* FROM {}'.format(table))]
 ","def save_to_json():
    table = _AGGREGATED_SALES_TABLE
    with open('{}.json'.format(table), 'w') as f:
        records = [row for row in scraperwiki.sqlite.select(
                   '* FROM {}'.format(table))]

        f.write(json.dumps(records, cls=JsonEncoder, indent=1))",8,"<NME> core.py
<BEF> def save_to_json():
    table = _AGGREGATED_SALES_TABLE
    with open('{}.json'.format(f), 'w') as f:
        records = [row for row in scraperwiki.sqlite.select(
                   '* FROM {}'.format(table))]

        f.write(json.dumps(records, cls=JsonEncoder, indent=1))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def save_to_json():
    table = _AGGREGATED_SALES_TABLE
    with open('{}.json'.format(f), 'w') as f:
        records = [row for row in scraperwiki.sqlite.select(
                   '* FROM {}'.format(table))]

        f.write(json.dumps(records, cls=JsonEncoder, indent=1))"
"<NME> UI.py
<BEF> def write(self, oprot):
  if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
    oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
    return
  oprot.writeStructBegin('unpause_args')
  oprot.writeFieldStop()
  self.writeStructEnd()
<MSG> Fix incorrect variable name
<DFF> @@ -4,4 +4,4 @@
     return
   oprot.writeStructBegin('unpause_args')
   oprot.writeFieldStop()
-  self.writeStructEnd()
+  oprot.writeStructEnd()","def write(self, oprot):
  if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
    oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
    return
  oprot.writeStructBegin('unpause_args')
  oprot.writeFieldStop()
  oprot.writeStructEnd()",9,"<NME> UI.py
<BEF> def write(self, oprot):
  if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
    oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
    return
  oprot.writeStructBegin('unpause_args')
  oprot.writeFieldStop()
  self.writeStructEnd()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def write(self, oprot):
  if oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and self.thrift_spec is not None and fastbinary is not None:
    oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))
    return
  oprot.writeStructBegin('unpause_args')
  oprot.writeFieldStop()
  self.writeStructEnd()"
"<NME> intervals.py
<BEF> def recordtree(table, start='start', stop='stop'):
    """"""
    Construct an interval tree for the given table, where each node in the
    tree is a row of the table represented as a record object.

    """"""

    import intervaltree
    getstart = attrgetter(start)
    getstop = attrgetter(stop)
    tree = intervaltree.IntervalTree()
    for rec in records(table):
        tree.addi(getstop(rec), getstop(rec), rec)
    return tree
<MSG> Fix incorrect variable name
<DFF> @@ -10,5 +10,5 @@
     getstop = attrgetter(stop)
     tree = intervaltree.IntervalTree()
     for rec in records(table):
-        tree.addi(getstop(rec), getstop(rec), rec)
+        tree.addi(getstart(rec), getstop(rec), rec)
     return tree","def recordtree(table, start='start', stop='stop'):
    """"""
    Construct an interval tree for the given table, where each node in the
    tree is a row of the table represented as a record object.

    """"""

    import intervaltree
    getstart = attrgetter(start)
    getstop = attrgetter(stop)
    tree = intervaltree.IntervalTree()
    for rec in records(table):
        tree.addi(getstart(rec), getstop(rec), rec)
    return tree",0,"<NME> intervals.py
<BEF> def recordtree(table, start='start', stop='stop'):
    """"""
    Construct an interval tree for the given table, where each node in the
    tree is a row of the table represented as a record object.

    """"""

    import intervaltree
    getstart = attrgetter(start)
    getstop = attrgetter(stop)
    tree = intervaltree.IntervalTree()
    for rec in records(table):
        tree.addi(getstop(rec), getstop(rec), rec)
    return tree
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def recordtree(table, start='start', stop='stop'):
    """"""
    Construct an interval tree for the given table, where each node in the
    tree is a row of the table represented as a record object.

    """"""

    import intervaltree
    getstart = attrgetter(start)
    getstop = attrgetter(stop)
    tree = intervaltree.IntervalTree()
    for rec in records(table):
        tree.addi(getstop(rec), getstop(rec), rec)
    return tree"
"<NME> decorators.py
<BEF> def wrapper(*args, **kwargs):
    current_delay = delay
    current_try = max_tries
    while current_delay > 0:
        current_try -= 1
    for current_try in range(max_tries):
        try:
            return f(*args, **kwargs)
        except RetryFailed:
            # Do not sleep after the last retry
            if current_try < max_tries - 1:
                sleep_func(current_delay) # wait...
                current_delay *= backoff  # make future wait longer
    # No more retries
    raise TooManyRetries()
<MSG> Fix incorrect variable name
<DFF> @@ -1,7 +1,7 @@
 def wrapper(*args, **kwargs):
     current_delay = delay
     current_try = max_tries
-    while current_delay > 0:
+    while current_try > 0:
         current_try -= 1
     for current_try in range(max_tries):
         try:","def wrapper(*args, **kwargs):
    current_delay = delay
    current_try = max_tries
    while current_try > 0:
        current_try -= 1
    for current_try in range(max_tries):
        try:
            return f(*args, **kwargs)
        except RetryFailed:
            # Do not sleep after the last retry
            if current_try < max_tries - 1:
                sleep_func(current_delay) # wait...
                current_delay *= backoff  # make future wait longer
    # No more retries
    raise TooManyRetries()",1,"<NME> decorators.py
<BEF> def wrapper(*args, **kwargs):
    current_delay = delay
    current_try = max_tries
    while current_delay > 0:
        current_try -= 1
    for current_try in range(max_tries):
        try:
            return f(*args, **kwargs)
        except RetryFailed:
            # Do not sleep after the last retry
            if current_try < max_tries - 1:
                sleep_func(current_delay) # wait...
                current_delay *= backoff  # make future wait longer
    # No more retries
    raise TooManyRetries()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def wrapper(*args, **kwargs):
    current_delay = delay
    current_try = max_tries
    while current_delay > 0:
        current_try -= 1
    for current_try in range(max_tries):
        try:
            return f(*args, **kwargs)
        except RetryFailed:
            # Do not sleep after the last retry
            if current_try < max_tries - 1:
                sleep_func(current_delay) # wait...
                current_delay *= backoff  # make future wait longer
    # No more retries
    raise TooManyRetries()"
"<NME> decoder2.py
<BEF> def __init__(self, conf={}):
    logger.info(""Creating decoder using conf: %s"" % conf)
    self.create_pipeline(self)
    self.outdir = conf.get(""out-dir"", None)
    if not os.path.exists(self.outdir):
        os.makedirs(self.outdir)
    elif not os.path.isdir(self.outdir):
        raise Exception(""Output directory %s already exists as a file"" % self.outdir)

    self.result_handler = None
    self.full_result_handler = None
    self.eos_handler = None
    self.error_handler = None
    self.request_id = ""<undefined>""
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def __init__(self, conf={}):
     logger.info(""Creating decoder using conf: %s"" % conf)
-    self.create_pipeline(self)
+    self.create_pipeline(conf)
     self.outdir = conf.get(""out-dir"", None)
     if not os.path.exists(self.outdir):
         os.makedirs(self.outdir)","def __init__(self, conf={}):
    logger.info(""Creating decoder using conf: %s"" % conf)
    self.create_pipeline(conf)
    self.outdir = conf.get(""out-dir"", None)
    if not os.path.exists(self.outdir):
        os.makedirs(self.outdir)
    elif not os.path.isdir(self.outdir):
        raise Exception(""Output directory %s already exists as a file"" % self.outdir)

    self.result_handler = None
    self.full_result_handler = None
    self.eos_handler = None
    self.error_handler = None
    self.request_id = ""<undefined>""",2,"<NME> decoder2.py
<BEF> def __init__(self, conf={}):
    logger.info(""Creating decoder using conf: %s"" % conf)
    self.create_pipeline(self)
    self.outdir = conf.get(""out-dir"", None)
    if not os.path.exists(self.outdir):
        os.makedirs(self.outdir)
    elif not os.path.isdir(self.outdir):
        raise Exception(""Output directory %s already exists as a file"" % self.outdir)

    self.result_handler = None
    self.full_result_handler = None
    self.eos_handler = None
    self.error_handler = None
    self.request_id = ""<undefined>""
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, conf={}):
    logger.info(""Creating decoder using conf: %s"" % conf)
    self.create_pipeline(self)
    self.outdir = conf.get(""out-dir"", None)
    if not os.path.exists(self.outdir):
        os.makedirs(self.outdir)
    elif not os.path.isdir(self.outdir):
        raise Exception(""Output directory %s already exists as a file"" % self.outdir)

    self.result_handler = None
    self.full_result_handler = None
    self.eos_handler = None
    self.error_handler = None
    self.request_id = ""<undefined>"""
"<NME> test_reports.py
<BEF> def test_parses_data_correctly_when_v2(self):
    posted_data = [
        {
            ""_id"": ""YnJvd3NlcnMyMDE0LTEwLTE0IDAwOj""
                   ""AwOjAwKzAwOjAwTW96aWxsYQ=="",
            ""_timestamp"": datetime.datetime(
                2014, 10, 14, 0, 0, tzinfo=pytz.UTC),
            ""browser"": ""Mozilla"",
            ""dataType"": ""browsers"",
            ""humanId"": ""browsers2014-10-14 00:00:00+00:00Mozilla"",
            ""visitors"": 1,
            ""test"": ""field""
        },
        {
            ""_id"": ""YnJvd3NlcnMyMDE0LTEwLTE0IDAwO""
                   ""jAwOjAwKzAwOjAwR29vZ2xlIENocm9tZQ=="",
            ""_timestamp"": datetime.datetime(
                2014, 10, 14, 0, 0, tzinfo=pytz.UTC),
            ""browser"": ""Google Chrome"",
            ""dataType"": ""browsers"",
            ""humanId"": ""browsers2014-10-14 00:00:00+00:00Google Chrome"",
            ""visitors"": 18,
            ""test"": ""field""
        }
    ]
    options = {
        'row_type_name': 'browser',
        'mappings': {'Visits': 'visitors'},
        'additionalFields': {'test': 'field'},
        'idMapping': [""dataType"", ""_timestamp"", ""browser""]}
    data_type = ""browsers""
    parser = V2Parser(self, data_type)
    results = list(parser.parse([get_fake_response()['data']]))
    assert_that(results[0], has_entries(posted_data[0]))
    assert_that(results[1], has_entries(posted_data[1]))
<MSG> Fix incorrect variable name
<DFF> @@ -29,7 +29,7 @@
         'additionalFields': {'test': 'field'},
         'idMapping': [""dataType"", ""_timestamp"", ""browser""]}
     data_type = ""browsers""
-    parser = V2Parser(self, data_type)
+    parser = V2Parser(options, data_type)
     results = list(parser.parse([get_fake_response()['data']]))
     assert_that(results[0], has_entries(posted_data[0]))
     assert_that(results[1], has_entries(posted_data[1]))","def test_parses_data_correctly_when_v2(self):
    posted_data = [
        {
            ""_id"": ""YnJvd3NlcnMyMDE0LTEwLTE0IDAwOj""
                   ""AwOjAwKzAwOjAwTW96aWxsYQ=="",
            ""_timestamp"": datetime.datetime(
                2014, 10, 14, 0, 0, tzinfo=pytz.UTC),
            ""browser"": ""Mozilla"",
            ""dataType"": ""browsers"",
            ""humanId"": ""browsers2014-10-14 00:00:00+00:00Mozilla"",
            ""visitors"": 1,
            ""test"": ""field""
        },
        {
            ""_id"": ""YnJvd3NlcnMyMDE0LTEwLTE0IDAwO""
                   ""jAwOjAwKzAwOjAwR29vZ2xlIENocm9tZQ=="",
            ""_timestamp"": datetime.datetime(
                2014, 10, 14, 0, 0, tzinfo=pytz.UTC),
            ""browser"": ""Google Chrome"",
            ""dataType"": ""browsers"",
            ""humanId"": ""browsers2014-10-14 00:00:00+00:00Google Chrome"",
            ""visitors"": 18,
            ""test"": ""field""
        }
    ]
    options = {
        'row_type_name': 'browser',
        'mappings': {'Visits': 'visitors'},
        'additionalFields': {'test': 'field'},
        'idMapping': [""dataType"", ""_timestamp"", ""browser""]}
    data_type = ""browsers""
    parser = V2Parser(options, data_type)
    results = list(parser.parse([get_fake_response()['data']]))
    assert_that(results[0], has_entries(posted_data[0]))
    assert_that(results[1], has_entries(posted_data[1]))",3,"<NME> test_reports.py
<BEF> def test_parses_data_correctly_when_v2(self):
    posted_data = [
        {
            ""_id"": ""YnJvd3NlcnMyMDE0LTEwLTE0IDAwOj""
                   ""AwOjAwKzAwOjAwTW96aWxsYQ=="",
            ""_timestamp"": datetime.datetime(
                2014, 10, 14, 0, 0, tzinfo=pytz.UTC),
            ""browser"": ""Mozilla"",
            ""dataType"": ""browsers"",
            ""humanId"": ""browsers2014-10-14 00:00:00+00:00Mozilla"",
            ""visitors"": 1,
            ""test"": ""field""
        },
        {
            ""_id"": ""YnJvd3NlcnMyMDE0LTEwLTE0IDAwO""
                   ""jAwOjAwKzAwOjAwR29vZ2xlIENocm9tZQ=="",
            ""_timestamp"": datetime.datetime(
                2014, 10, 14, 0, 0, tzinfo=pytz.UTC),
            ""browser"": ""Google Chrome"",
            ""dataType"": ""browsers"",
            ""humanId"": ""browsers2014-10-14 00:00:00+00:00Google Chrome"",
            ""visitors"": 18,
            ""test"": ""field""
        }
    ]
    options = {
        'row_type_name': 'browser',
        'mappings': {'Visits': 'visitors'},
        'additionalFields': {'test': 'field'},
        'idMapping': [""dataType"", ""_timestamp"", ""browser""]}
    data_type = ""browsers""
    parser = V2Parser(self, data_type)
    results = list(parser.parse([get_fake_response()['data']]))
    assert_that(results[0], has_entries(posted_data[0]))
    assert_that(results[1], has_entries(posted_data[1]))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_parses_data_correctly_when_v2(self):
    posted_data = [
        {
            ""_id"": ""YnJvd3NlcnMyMDE0LTEwLTE0IDAwOj""
                   ""AwOjAwKzAwOjAwTW96aWxsYQ=="",
            ""_timestamp"": datetime.datetime(
                2014, 10, 14, 0, 0, tzinfo=pytz.UTC),
            ""browser"": ""Mozilla"",
            ""dataType"": ""browsers"",
            ""humanId"": ""browsers2014-10-14 00:00:00+00:00Mozilla"",
            ""visitors"": 1,
            ""test"": ""field""
        },
        {
            ""_id"": ""YnJvd3NlcnMyMDE0LTEwLTE0IDAwO""
                   ""jAwOjAwKzAwOjAwR29vZ2xlIENocm9tZQ=="",
            ""_timestamp"": datetime.datetime(
                2014, 10, 14, 0, 0, tzinfo=pytz.UTC),
            ""browser"": ""Google Chrome"",
            ""dataType"": ""browsers"",
            ""humanId"": ""browsers2014-10-14 00:00:00+00:00Google Chrome"",
            ""visitors"": 18,
            ""test"": ""field""
        }
    ]
    options = {
        'row_type_name': 'browser',
        'mappings': {'Visits': 'visitors'},
        'additionalFields': {'test': 'field'},
        'idMapping': [""dataType"", ""_timestamp"", ""browser""]}
    data_type = ""browsers""
    parser = V2Parser(self, data_type)
    results = list(parser.parse([get_fake_response()['data']]))
    assert_that(results[0], has_entries(posted_data[0]))
    assert_that(results[1], has_entries(posted_data[1]))"
"<NME> flask_rest.py
<BEF> def _get_route_for(self, action):
    """"""Return the complete URL for this action.

    Basically:

     - get, update and delete need an id
     - add and list does not
    """"""
    route = self._route

    if action in self._NEED_ID:
        action += ""/<%s>"" % self._identifier

    return route
<MSG> Fix incorrect variable name
<DFF> @@ -9,6 +9,6 @@
     route = self._route
 
     if action in self._NEED_ID:
-        action += ""/<%s>"" % self._identifier
+        route += ""/<%s>"" % self._identifier
 
     return route","def _get_route_for(self, action):
    """"""Return the complete URL for this action.

    Basically:

     - get, update and delete need an id
     - add and list does not
    """"""
    route = self._route

    if action in self._NEED_ID:
        route += ""/<%s>"" % self._identifier

    return route",4,"<NME> flask_rest.py
<BEF> def _get_route_for(self, action):
    """"""Return the complete URL for this action.

    Basically:

     - get, update and delete need an id
     - add and list does not
    """"""
    route = self._route

    if action in self._NEED_ID:
        action += ""/<%s>"" % self._identifier

    return route
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _get_route_for(self, action):
    """"""Return the complete URL for this action.

    Basically:

     - get, update and delete need an id
     - add and list does not
    """"""
    route = self._route

    if action in self._NEED_ID:
        action += ""/<%s>"" % self._identifier

    return route"
"<NME> _sre.py
<BEF> def dispatch(self, opcode, context):
    """"""Dispatches a context on a given opcode. Returns True if the context
    is done matching, False if it must be resumed when next encountered.""""""
    #if self.executing_contexts.has_key(id(context)):
    if id(context) in self.executing_contexts:
        generator = self.executing_contexts[id(context)]
        del self.executing_contexts[id(context)]
        has_finished = next(generator)
    else:
        method = self.DISPATCH_TABLE.get(opcode, _OpcodeDispatcher.unknown)
        has_finished = method(self, context)
        if hasattr(has_finished, ""__next__""): # avoid using the types module
            generator = has_finished
            generator = next(generator)
    if not has_finished:
        self.executing_contexts[id(context)] = generator
    return has_finished
<MSG> Fix incorrect variable name
<DFF> @@ -11,7 +11,7 @@
         has_finished = method(self, context)
         if hasattr(has_finished, ""__next__""): # avoid using the types module
             generator = has_finished
-            generator = next(generator)
+            has_finished = next(generator)
     if not has_finished:
         self.executing_contexts[id(context)] = generator
     return has_finished","def dispatch(self, opcode, context):
    """"""Dispatches a context on a given opcode. Returns True if the context
    is done matching, False if it must be resumed when next encountered.""""""
    #if self.executing_contexts.has_key(id(context)):
    if id(context) in self.executing_contexts:
        generator = self.executing_contexts[id(context)]
        del self.executing_contexts[id(context)]
        has_finished = next(generator)
    else:
        method = self.DISPATCH_TABLE.get(opcode, _OpcodeDispatcher.unknown)
        has_finished = method(self, context)
        if hasattr(has_finished, ""__next__""): # avoid using the types module
            generator = has_finished
            has_finished = next(generator)
    if not has_finished:
        self.executing_contexts[id(context)] = generator
    return has_finished",5,"<NME> _sre.py
<BEF> def dispatch(self, opcode, context):
    """"""Dispatches a context on a given opcode. Returns True if the context
    is done matching, False if it must be resumed when next encountered.""""""
    #if self.executing_contexts.has_key(id(context)):
    if id(context) in self.executing_contexts:
        generator = self.executing_contexts[id(context)]
        del self.executing_contexts[id(context)]
        has_finished = next(generator)
    else:
        method = self.DISPATCH_TABLE.get(opcode, _OpcodeDispatcher.unknown)
        has_finished = method(self, context)
        if hasattr(has_finished, ""__next__""): # avoid using the types module
            generator = has_finished
            generator = next(generator)
    if not has_finished:
        self.executing_contexts[id(context)] = generator
    return has_finished
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def dispatch(self, opcode, context):
    """"""Dispatches a context on a given opcode. Returns True if the context
    is done matching, False if it must be resumed when next encountered.""""""
    #if self.executing_contexts.has_key(id(context)):
    if id(context) in self.executing_contexts:
        generator = self.executing_contexts[id(context)]
        del self.executing_contexts[id(context)]
        has_finished = next(generator)
    else:
        method = self.DISPATCH_TABLE.get(opcode, _OpcodeDispatcher.unknown)
        has_finished = method(self, context)
        if hasattr(has_finished, ""__next__""): # avoid using the types module
            generator = has_finished
            generator = next(generator)
    if not has_finished:
        self.executing_contexts[id(context)] = generator
    return has_finished"
"<NME> xmlreader.py
<BEF> def setEntityResolver(self, resolver):
    ""Register an object to resolve external entities.""
    self._ent_handler = self
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def setEntityResolver(self, resolver):
     ""Register an object to resolve external entities.""
-    self._ent_handler = self
+    self._ent_handler = resolver","def setEntityResolver(self, resolver):
    ""Register an object to resolve external entities.""
    self._ent_handler = resolver",6,"<NME> xmlreader.py
<BEF> def setEntityResolver(self, resolver):
    ""Register an object to resolve external entities.""
    self._ent_handler = self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def setEntityResolver(self, resolver):
    ""Register an object to resolve external entities.""
    self._ent_handler = self"
"<NME> test_ftplib.py
<BEF> def secure_connection(self):
    socket = ssl.wrap_socket(self.socket, suppress_ragged_eofs=False,
                             certfile=CERTFILE, server_side=True,
                             do_handshake_on_connect=False,
                             ssl_version=ssl.PROTOCOL_SSLv23)
    socket.del_channel()
    self.set_socket(socket)
    self._ssl_accepting = True
<MSG> Fix incorrect variable name
<DFF> @@ -3,6 +3,6 @@
                              certfile=CERTFILE, server_side=True,
                              do_handshake_on_connect=False,
                              ssl_version=ssl.PROTOCOL_SSLv23)
-    socket.del_channel()
+    self.del_channel()
     self.set_socket(socket)
     self._ssl_accepting = True","def secure_connection(self):
    socket = ssl.wrap_socket(self.socket, suppress_ragged_eofs=False,
                             certfile=CERTFILE, server_side=True,
                             do_handshake_on_connect=False,
                             ssl_version=ssl.PROTOCOL_SSLv23)
    self.del_channel()
    self.set_socket(socket)
    self._ssl_accepting = True",7,"<NME> test_ftplib.py
<BEF> def secure_connection(self):
    socket = ssl.wrap_socket(self.socket, suppress_ragged_eofs=False,
                             certfile=CERTFILE, server_side=True,
                             do_handshake_on_connect=False,
                             ssl_version=ssl.PROTOCOL_SSLv23)
    socket.del_channel()
    self.set_socket(socket)
    self._ssl_accepting = True
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def secure_connection(self):
    socket = ssl.wrap_socket(self.socket, suppress_ragged_eofs=False,
                             certfile=CERTFILE, server_side=True,
                             do_handshake_on_connect=False,
                             ssl_version=ssl.PROTOCOL_SSLv23)
    socket.del_channel()
    self.set_socket(socket)
    self._ssl_accepting = True"
"<NME> _sre.py
<BEF> def op_in(self, ctx):
    # match set member (or non_member)
    # <IN> <skip> <set>
    #self._log(ctx, ""OP_IN"")
    self.general_op_in(self)
    return True
<MSG> Fix incorrect variable name
<DFF> @@ -2,5 +2,5 @@
     # match set member (or non_member)
     # <IN> <skip> <set>
     #self._log(ctx, ""OP_IN"")
-    self.general_op_in(self)
+    self.general_op_in(ctx)
     return True","def op_in(self, ctx):
    # match set member (or non_member)
    # <IN> <skip> <set>
    #self._log(ctx, ""OP_IN"")
    self.general_op_in(ctx)
    return True",8,"<NME> _sre.py
<BEF> def op_in(self, ctx):
    # match set member (or non_member)
    # <IN> <skip> <set>
    #self._log(ctx, ""OP_IN"")
    self.general_op_in(self)
    return True
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def op_in(self, ctx):
    # match set member (or non_member)
    # <IN> <skip> <set>
    #self._log(ctx, ""OP_IN"")
    self.general_op_in(self)
    return True"
"<NME> mergechars.py
<BEF> def averageWords(text_f=""/afs/cs.stanford.edu/u/awni/swbd/data/eval2000/text_ctc""):
    with open(text_f,'r') as fid:
        lines = [l.strip().split()[1:] for l in fid.readlines()]
        numUtts = float(len(lines))
        numWords = sum(len(numUtts) for l in lines)
    return numWords/numUtts
<MSG> Fix incorrect variable name
<DFF> @@ -2,5 +2,5 @@
     with open(text_f,'r') as fid:
         lines = [l.strip().split()[1:] for l in fid.readlines()]
         numUtts = float(len(lines))
-        numWords = sum(len(numUtts) for l in lines)
+        numWords = sum(len(l) for l in lines)
     return numWords/numUtts","def averageWords(text_f=""/afs/cs.stanford.edu/u/awni/swbd/data/eval2000/text_ctc""):
    with open(text_f,'r') as fid:
        lines = [l.strip().split()[1:] for l in fid.readlines()]
        numUtts = float(len(lines))
        numWords = sum(len(l) for l in lines)
    return numWords/numUtts",9,"<NME> mergechars.py
<BEF> def averageWords(text_f=""/afs/cs.stanford.edu/u/awni/swbd/data/eval2000/text_ctc""):
    with open(text_f,'r') as fid:
        lines = [l.strip().split()[1:] for l in fid.readlines()]
        numUtts = float(len(lines))
        numWords = sum(len(numUtts) for l in lines)
    return numWords/numUtts
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def averageWords(text_f=""/afs/cs.stanford.edu/u/awni/swbd/data/eval2000/text_ctc""):
    with open(text_f,'r') as fid:
        lines = [l.strip().split()[1:] for l in fid.readlines()]
        numUtts = float(len(lines))
        numWords = sum(len(numUtts) for l in lines)
    return numWords/numUtts"
"<NME> _sre.py
<BEF> def op_max_until(self, ctx):
    # maximizing repeat
    # <REPEAT> <skip> <1=min> <2=max> item <MAX_UNTIL> tail
    repeat = ctx.state.repeat
    #print(""op_max_until"") #, id(ctx.state.repeat))
    if repeat is None:
        #print(id(ctx), id(ctx.state))
        raise RuntimeError(""Internal re error: MAX_UNTIL without REPEAT."")
    mincount = repeat.peek_code(2)
    maxcount = repeat.peek_code(3)
    ctx.state.string_position = ctx.string_position
    count = repeat.count + 1
    #self._log(ctx, ""MAX_UNTIL"", count)

    if count < mincount:
        # not enough matches
        repeat.count = count
        child_context = repeat.push_new_context(4)
        yield False
        ctx.has_matched = child_context.has_matched
        if not ctx.has_matched:
            repeat.count = count - 1
            ctx.state.string_position = ctx.string_position
        yield True

    if (count < maxcount or maxcount == MAXREPEAT) \
                  and ctx.state.string_position != repeat.last_position:
        # we may have enough matches, if we can match another item, do so
        repeat.count = count
        ctx.state.marks_push()
        save_last_position = repeat.last_position # zero-width match protection
        repeat.last_position = ctx.state.string_position
        child_context = repeat.push_new_context(4)
        yield False
        repeat.last_position = save_last_position
        if child_context.has_matched:
            ctx.state.marks_pop_discard()
            ctx.has_matched = True
            yield True
        ctx.state.marks_pop()
        repeat.count = count - 1
        ctx.state.string_position = repeat.string_position

    # cannot match more repeated items here.  make sure the tail matches
    ctx.state.repeat = repeat.previous
    child_context = ctx.push_new_context(1)
    #print(""_sre.py:987:op_max_until"")
    yield False
    ctx.has_matched = child_context.has_matched
    if not ctx.has_matched:
        ctx.state.repeat = repeat
        ctx.state.string_position = ctx.string_position
    yield True
<MSG> Fix incorrect variable name
<DFF> @@ -39,7 +39,7 @@
             yield True
         ctx.state.marks_pop()
         repeat.count = count - 1
-        ctx.state.string_position = repeat.string_position
+        ctx.state.string_position = ctx.string_position
 
     # cannot match more repeated items here.  make sure the tail matches
     ctx.state.repeat = repeat.previous","def op_max_until(self, ctx):
    # maximizing repeat
    # <REPEAT> <skip> <1=min> <2=max> item <MAX_UNTIL> tail
    repeat = ctx.state.repeat
    #print(""op_max_until"") #, id(ctx.state.repeat))
    if repeat is None:
        #print(id(ctx), id(ctx.state))
        raise RuntimeError(""Internal re error: MAX_UNTIL without REPEAT."")
    mincount = repeat.peek_code(2)
    maxcount = repeat.peek_code(3)
    ctx.state.string_position = ctx.string_position
    count = repeat.count + 1
    #self._log(ctx, ""MAX_UNTIL"", count)

    if count < mincount:
        # not enough matches
        repeat.count = count
        child_context = repeat.push_new_context(4)
        yield False
        ctx.has_matched = child_context.has_matched
        if not ctx.has_matched:
            repeat.count = count - 1
            ctx.state.string_position = ctx.string_position
        yield True

    if (count < maxcount or maxcount == MAXREPEAT) \
                  and ctx.state.string_position != repeat.last_position:
        # we may have enough matches, if we can match another item, do so
        repeat.count = count
        ctx.state.marks_push()
        save_last_position = repeat.last_position # zero-width match protection
        repeat.last_position = ctx.state.string_position
        child_context = repeat.push_new_context(4)
        yield False
        repeat.last_position = save_last_position
        if child_context.has_matched:
            ctx.state.marks_pop_discard()
            ctx.has_matched = True
            yield True
        ctx.state.marks_pop()
        repeat.count = count - 1
        ctx.state.string_position = ctx.string_position

    # cannot match more repeated items here.  make sure the tail matches
    ctx.state.repeat = repeat.previous
    child_context = ctx.push_new_context(1)
    #print(""_sre.py:987:op_max_until"")
    yield False
    ctx.has_matched = child_context.has_matched
    if not ctx.has_matched:
        ctx.state.repeat = repeat
        ctx.state.string_position = ctx.string_position
    yield True",0,"<NME> _sre.py
<BEF> def op_max_until(self, ctx):
    # maximizing repeat
    # <REPEAT> <skip> <1=min> <2=max> item <MAX_UNTIL> tail
    repeat = ctx.state.repeat
    #print(""op_max_until"") #, id(ctx.state.repeat))
    if repeat is None:
        #print(id(ctx), id(ctx.state))
        raise RuntimeError(""Internal re error: MAX_UNTIL without REPEAT."")
    mincount = repeat.peek_code(2)
    maxcount = repeat.peek_code(3)
    ctx.state.string_position = ctx.string_position
    count = repeat.count + 1
    #self._log(ctx, ""MAX_UNTIL"", count)

    if count < mincount:
        # not enough matches
        repeat.count = count
        child_context = repeat.push_new_context(4)
        yield False
        ctx.has_matched = child_context.has_matched
        if not ctx.has_matched:
            repeat.count = count - 1
            ctx.state.string_position = ctx.string_position
        yield True

    if (count < maxcount or maxcount == MAXREPEAT) \
                  and ctx.state.string_position != repeat.last_position:
        # we may have enough matches, if we can match another item, do so
        repeat.count = count
        ctx.state.marks_push()
        save_last_position = repeat.last_position # zero-width match protection
        repeat.last_position = ctx.state.string_position
        child_context = repeat.push_new_context(4)
        yield False
        repeat.last_position = save_last_position
        if child_context.has_matched:
            ctx.state.marks_pop_discard()
            ctx.has_matched = True
            yield True
        ctx.state.marks_pop()
        repeat.count = count - 1
        ctx.state.string_position = repeat.string_position

    # cannot match more repeated items here.  make sure the tail matches
    ctx.state.repeat = repeat.previous
    child_context = ctx.push_new_context(1)
    #print(""_sre.py:987:op_max_until"")
    yield False
    ctx.has_matched = child_context.has_matched
    if not ctx.has_matched:
        ctx.state.repeat = repeat
        ctx.state.string_position = ctx.string_position
    yield True
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def op_max_until(self, ctx):
    # maximizing repeat
    # <REPEAT> <skip> <1=min> <2=max> item <MAX_UNTIL> tail
    repeat = ctx.state.repeat
    #print(""op_max_until"") #, id(ctx.state.repeat))
    if repeat is None:
        #print(id(ctx), id(ctx.state))
        raise RuntimeError(""Internal re error: MAX_UNTIL without REPEAT."")
    mincount = repeat.peek_code(2)
    maxcount = repeat.peek_code(3)
    ctx.state.string_position = ctx.string_position
    count = repeat.count + 1
    #self._log(ctx, ""MAX_UNTIL"", count)

    if count < mincount:
        # not enough matches
        repeat.count = count
        child_context = repeat.push_new_context(4)
        yield False
        ctx.has_matched = child_context.has_matched
        if not ctx.has_matched:
            repeat.count = count - 1
            ctx.state.string_position = ctx.string_position
        yield True

    if (count < maxcount or maxcount == MAXREPEAT) \
                  and ctx.state.string_position != repeat.last_position:
        # we may have enough matches, if we can match another item, do so
        repeat.count = count
        ctx.state.marks_push()
        save_last_position = repeat.last_position # zero-width match protection
        repeat.last_position = ctx.state.string_position
        child_context = repeat.push_new_context(4)
        yield False
        repeat.last_position = save_last_position
        if child_context.has_matched:
            ctx.state.marks_pop_discard()
            ctx.has_matched = True
            yield True
        ctx.state.marks_pop()
        repeat.count = count - 1
        ctx.state.string_position = repeat.string_position

    # cannot match more repeated items here.  make sure the tail matches
    ctx.state.repeat = repeat.previous
    child_context = ctx.push_new_context(1)
    #print(""_sre.py:987:op_max_until"")
    yield False
    ctx.has_matched = child_context.has_matched
    if not ctx.has_matched:
        ctx.state.repeat = repeat
        ctx.state.string_position = ctx.string_position
    yield True"
"<NME> utils.py
<BEF> def get_free_nodes(cluster, parallel=True):
    nodes = [cluster + str(node) for node in CLUSTER_NODES[cluster]]
    if parallel:
        is_free = joblib.Parallel(n_jobs=NUM_CPUS)(
            joblib.delayed(is_node_free)(node) for node in nodes)
    else:
        is_free = list()
        for node in nodes:
            is_free.append(is_node_free(node))
    free_nodes = [nodes[parallel] for k in range(len(nodes)) if is_free[k]]
    return free_nodes
<MSG> Fix incorrect variable name
<DFF> @@ -7,5 +7,5 @@
         is_free = list()
         for node in nodes:
             is_free.append(is_node_free(node))
-    free_nodes = [nodes[parallel] for k in range(len(nodes)) if is_free[k]]
+    free_nodes = [nodes[k] for k in range(len(nodes)) if is_free[k]]
     return free_nodes","def get_free_nodes(cluster, parallel=True):
    nodes = [cluster + str(node) for node in CLUSTER_NODES[cluster]]
    if parallel:
        is_free = joblib.Parallel(n_jobs=NUM_CPUS)(
            joblib.delayed(is_node_free)(node) for node in nodes)
    else:
        is_free = list()
        for node in nodes:
            is_free.append(is_node_free(node))
    free_nodes = [nodes[k] for k in range(len(nodes)) if is_free[k]]
    return free_nodes",1,"<NME> utils.py
<BEF> def get_free_nodes(cluster, parallel=True):
    nodes = [cluster + str(node) for node in CLUSTER_NODES[cluster]]
    if parallel:
        is_free = joblib.Parallel(n_jobs=NUM_CPUS)(
            joblib.delayed(is_node_free)(node) for node in nodes)
    else:
        is_free = list()
        for node in nodes:
            is_free.append(is_node_free(node))
    free_nodes = [nodes[parallel] for k in range(len(nodes)) if is_free[k]]
    return free_nodes
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_free_nodes(cluster, parallel=True):
    nodes = [cluster + str(node) for node in CLUSTER_NODES[cluster]]
    if parallel:
        is_free = joblib.Parallel(n_jobs=NUM_CPUS)(
            joblib.delayed(is_node_free)(node) for node in nodes)
    else:
        is_free = list()
        for node in nodes:
            is_free.append(is_node_free(node))
    free_nodes = [nodes[parallel] for k in range(len(nodes)) if is_free[k]]
    return free_nodes"
"<NME> test_setups.py
<BEF> def test_setup_class(self):
    class Test(unittest.TestCase):
        setUpCalled = 0
        @classmethod
        def setUpClass(cls):
            Test.setUpCalled += 1
            unittest.TestCase.setUpClass()
        def test_one(self):
            pass
        def test_two(self):
            pass

    result = self.runTests(Test)

    Test.assertEqual(Test.setUpCalled, 1)
    self.assertEqual(result.testsRun, 2)
    self.assertEqual(len(result.errors), 0)
<MSG> Fix incorrect variable name
<DFF> @@ -12,6 +12,6 @@
 
     result = self.runTests(Test)
 
-    Test.assertEqual(Test.setUpCalled, 1)
+    self.assertEqual(Test.setUpCalled, 1)
     self.assertEqual(result.testsRun, 2)
     self.assertEqual(len(result.errors), 0)","def test_setup_class(self):
    class Test(unittest.TestCase):
        setUpCalled = 0
        @classmethod
        def setUpClass(cls):
            Test.setUpCalled += 1
            unittest.TestCase.setUpClass()
        def test_one(self):
            pass
        def test_two(self):
            pass

    result = self.runTests(Test)

    self.assertEqual(Test.setUpCalled, 1)
    self.assertEqual(result.testsRun, 2)
    self.assertEqual(len(result.errors), 0)",2,"<NME> test_setups.py
<BEF> def test_setup_class(self):
    class Test(unittest.TestCase):
        setUpCalled = 0
        @classmethod
        def setUpClass(cls):
            Test.setUpCalled += 1
            unittest.TestCase.setUpClass()
        def test_one(self):
            pass
        def test_two(self):
            pass

    result = self.runTests(Test)

    Test.assertEqual(Test.setUpCalled, 1)
    self.assertEqual(result.testsRun, 2)
    self.assertEqual(len(result.errors), 0)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_setup_class(self):
    class Test(unittest.TestCase):
        setUpCalled = 0
        @classmethod
        def setUpClass(cls):
            Test.setUpCalled += 1
            unittest.TestCase.setUpClass()
        def test_one(self):
            pass
        def test_two(self):
            pass

    result = self.runTests(Test)

    Test.assertEqual(Test.setUpCalled, 1)
    self.assertEqual(result.testsRun, 2)
    self.assertEqual(len(result.errors), 0)"
"<NME> __init__.py
<BEF> def emit(self, record):
    """"""
    Emit a record.

    If the stream was not opened because 'delay' was specified in the
    constructor, open it before calling the superclass's emit.
    """"""
    if self.stream is None:
        self.stream = self._open()
    StreamHandler.emit(self, self)
<MSG> Fix incorrect variable name
<DFF> @@ -7,4 +7,4 @@
     """"""
     if self.stream is None:
         self.stream = self._open()
-    StreamHandler.emit(self, self)
+    StreamHandler.emit(self, record)","def emit(self, record):
    """"""
    Emit a record.

    If the stream was not opened because 'delay' was specified in the
    constructor, open it before calling the superclass's emit.
    """"""
    if self.stream is None:
        self.stream = self._open()
    StreamHandler.emit(self, record)",3,"<NME> __init__.py
<BEF> def emit(self, record):
    """"""
    Emit a record.

    If the stream was not opened because 'delay' was specified in the
    constructor, open it before calling the superclass's emit.
    """"""
    if self.stream is None:
        self.stream = self._open()
    StreamHandler.emit(self, self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def emit(self, record):
    """"""
    Emit a record.

    If the stream was not opened because 'delay' was specified in the
    constructor, open it before calling the superclass's emit.
    """"""
    if self.stream is None:
        self.stream = self._open()
    StreamHandler.emit(self, self)"
"<NME> turtle.py
<BEF> def onkeypress(self, fun, key=None):
    """"""Bind fun to key-press event of key if key is given,
    or to any key-press-event if no key is given.

    Arguments:
    fun -- a function with no arguments
    key -- a string: key (e.g. ""a"") or key-symbol (e.g. ""space"")

    In order to be able to register key-events, TurtleScreen
    must have focus. (See method listen.)

    Example (for a TurtleScreen instance named screen
    and a Turtle instance named turtle):

    >>> def f():
    ...     fd(50)
    ...     lt(60)
    ...
    >>> screen.onkeypress(f, ""Up"")
    >>> screen.listen()

    Subsequently the turtle can be moved by repeatedly pressing
    the up-arrow key, or by keeping pressed the up-arrow key.
    consequently drawing a hexagon.
    """"""
    if fun is None:
        if key in self._keys:
            self._keys.remove(key)
    elif key is not None and key not in self._keys:
        self._keys.append(key)
    self._onkeypress(self, key)
<MSG> Fix incorrect variable name
<DFF> @@ -28,4 +28,4 @@
             self._keys.remove(key)
     elif key is not None and key not in self._keys:
         self._keys.append(key)
-    self._onkeypress(self, key)
+    self._onkeypress(fun, key)","def onkeypress(self, fun, key=None):
    """"""Bind fun to key-press event of key if key is given,
    or to any key-press-event if no key is given.

    Arguments:
    fun -- a function with no arguments
    key -- a string: key (e.g. ""a"") or key-symbol (e.g. ""space"")

    In order to be able to register key-events, TurtleScreen
    must have focus. (See method listen.)

    Example (for a TurtleScreen instance named screen
    and a Turtle instance named turtle):

    >>> def f():
    ...     fd(50)
    ...     lt(60)
    ...
    >>> screen.onkeypress(f, ""Up"")
    >>> screen.listen()

    Subsequently the turtle can be moved by repeatedly pressing
    the up-arrow key, or by keeping pressed the up-arrow key.
    consequently drawing a hexagon.
    """"""
    if fun is None:
        if key in self._keys:
            self._keys.remove(key)
    elif key is not None and key not in self._keys:
        self._keys.append(key)
    self._onkeypress(fun, key)",4,"<NME> turtle.py
<BEF> def onkeypress(self, fun, key=None):
    """"""Bind fun to key-press event of key if key is given,
    or to any key-press-event if no key is given.

    Arguments:
    fun -- a function with no arguments
    key -- a string: key (e.g. ""a"") or key-symbol (e.g. ""space"")

    In order to be able to register key-events, TurtleScreen
    must have focus. (See method listen.)

    Example (for a TurtleScreen instance named screen
    and a Turtle instance named turtle):

    >>> def f():
    ...     fd(50)
    ...     lt(60)
    ...
    >>> screen.onkeypress(f, ""Up"")
    >>> screen.listen()

    Subsequently the turtle can be moved by repeatedly pressing
    the up-arrow key, or by keeping pressed the up-arrow key.
    consequently drawing a hexagon.
    """"""
    if fun is None:
        if key in self._keys:
            self._keys.remove(key)
    elif key is not None and key not in self._keys:
        self._keys.append(key)
    self._onkeypress(self, key)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def onkeypress(self, fun, key=None):
    """"""Bind fun to key-press event of key if key is given,
    or to any key-press-event if no key is given.

    Arguments:
    fun -- a function with no arguments
    key -- a string: key (e.g. ""a"") or key-symbol (e.g. ""space"")

    In order to be able to register key-events, TurtleScreen
    must have focus. (See method listen.)

    Example (for a TurtleScreen instance named screen
    and a Turtle instance named turtle):

    >>> def f():
    ...     fd(50)
    ...     lt(60)
    ...
    >>> screen.onkeypress(f, ""Up"")
    >>> screen.listen()

    Subsequently the turtle can be moved by repeatedly pressing
    the up-arrow key, or by keeping pressed the up-arrow key.
    consequently drawing a hexagon.
    """"""
    if fun is None:
        if key in self._keys:
            self._keys.remove(key)
    elif key is not None and key not in self._keys:
        self._keys.append(key)
    self._onkeypress(self, key)"
"<NME> test_augassign.py
<BEF> def __radd__(self, val):
    return val.val + val
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def __radd__(self, val):
-    return val.val + val
+    return self.val + val","def __radd__(self, val):
    return self.val + val",5,"<NME> test_augassign.py
<BEF> def __radd__(self, val):
    return val.val + val
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __radd__(self, val):
    return val.val + val"
"<NME> test_loader.py
<BEF> def test_loadTestsFromName__malformed_name(self):
    loader = unittest.TestLoader()

    # XXX Should this raise ValueError or ImportError?
    try:
        self.loadTestsFromName('abc () //')
    except ValueError:
        pass
    except ImportError:
        pass
    else:
        self.fail(""TestLoader.loadTestsFromName failed to raise ValueError"")
<MSG> Fix incorrect variable name
<DFF> @@ -3,7 +3,7 @@
 
     # XXX Should this raise ValueError or ImportError?
     try:
-        self.loadTestsFromName('abc () //')
+        loader.loadTestsFromName('abc () //')
     except ValueError:
         pass
     except ImportError:","def test_loadTestsFromName__malformed_name(self):
    loader = unittest.TestLoader()

    # XXX Should this raise ValueError or ImportError?
    try:
        loader.loadTestsFromName('abc () //')
    except ValueError:
        pass
    except ImportError:
        pass
    else:
        self.fail(""TestLoader.loadTestsFromName failed to raise ValueError"")",6,"<NME> test_loader.py
<BEF> def test_loadTestsFromName__malformed_name(self):
    loader = unittest.TestLoader()

    # XXX Should this raise ValueError or ImportError?
    try:
        self.loadTestsFromName('abc () //')
    except ValueError:
        pass
    except ImportError:
        pass
    else:
        self.fail(""TestLoader.loadTestsFromName failed to raise ValueError"")
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_loadTestsFromName__malformed_name(self):
    loader = unittest.TestLoader()

    # XXX Should this raise ValueError or ImportError?
    try:
        self.loadTestsFromName('abc () //')
    except ValueError:
        pass
    except ImportError:
        pass
    else:
        self.fail(""TestLoader.loadTestsFromName failed to raise ValueError"")"
"<NME> test_tempfile.py
<BEF> def test_process_awareness(self):
    # ensure that the random source differs between
    # child and parent.
    read_fd, write_fd = os.pipe()
    pid = None
    try:
        pid = os.fork()
        if not pid:
            os.close(read_fd)
            os.write(write_fd, next(self.r).encode(""ascii""))
            os.close(write_fd)
            # bypass the normal exit handlers- leave those to
            # the parent.
            os._exit(0)
        parent_value = next(self.r)
        child_value = os.read(write_fd, len(parent_value)).decode(""ascii"")
    finally:
        if pid:
            # best effort to ensure the process can't bleed out
            # via any bugs above
            try:
                os.kill(pid, signal.SIGKILL)
            except EnvironmentError:
                pass
        os.close(read_fd)
        os.close(write_fd)
    self.assertNotEqual(child_value, parent_value)
<MSG> Fix incorrect variable name
<DFF> @@ -13,7 +13,7 @@
             # the parent.
             os._exit(0)
         parent_value = next(self.r)
-        child_value = os.read(write_fd, len(parent_value)).decode(""ascii"")
+        child_value = os.read(read_fd, len(parent_value)).decode(""ascii"")
     finally:
         if pid:
             # best effort to ensure the process can't bleed out","def test_process_awareness(self):
    # ensure that the random source differs between
    # child and parent.
    read_fd, write_fd = os.pipe()
    pid = None
    try:
        pid = os.fork()
        if not pid:
            os.close(read_fd)
            os.write(write_fd, next(self.r).encode(""ascii""))
            os.close(write_fd)
            # bypass the normal exit handlers- leave those to
            # the parent.
            os._exit(0)
        parent_value = next(self.r)
        child_value = os.read(read_fd, len(parent_value)).decode(""ascii"")
    finally:
        if pid:
            # best effort to ensure the process can't bleed out
            # via any bugs above
            try:
                os.kill(pid, signal.SIGKILL)
            except EnvironmentError:
                pass
        os.close(read_fd)
        os.close(write_fd)
    self.assertNotEqual(child_value, parent_value)",7,"<NME> test_tempfile.py
<BEF> def test_process_awareness(self):
    # ensure that the random source differs between
    # child and parent.
    read_fd, write_fd = os.pipe()
    pid = None
    try:
        pid = os.fork()
        if not pid:
            os.close(read_fd)
            os.write(write_fd, next(self.r).encode(""ascii""))
            os.close(write_fd)
            # bypass the normal exit handlers- leave those to
            # the parent.
            os._exit(0)
        parent_value = next(self.r)
        child_value = os.read(write_fd, len(parent_value)).decode(""ascii"")
    finally:
        if pid:
            # best effort to ensure the process can't bleed out
            # via any bugs above
            try:
                os.kill(pid, signal.SIGKILL)
            except EnvironmentError:
                pass
        os.close(read_fd)
        os.close(write_fd)
    self.assertNotEqual(child_value, parent_value)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_process_awareness(self):
    # ensure that the random source differs between
    # child and parent.
    read_fd, write_fd = os.pipe()
    pid = None
    try:
        pid = os.fork()
        if not pid:
            os.close(read_fd)
            os.write(write_fd, next(self.r).encode(""ascii""))
            os.close(write_fd)
            # bypass the normal exit handlers- leave those to
            # the parent.
            os._exit(0)
        parent_value = next(self.r)
        child_value = os.read(write_fd, len(parent_value)).decode(""ascii"")
    finally:
        if pid:
            # best effort to ensure the process can't bleed out
            # via any bugs above
            try:
                os.kill(pid, signal.SIGKILL)
            except EnvironmentError:
                pass
        os.close(read_fd)
        os.close(write_fd)
    self.assertNotEqual(child_value, parent_value)"
"<NME> test_sys_setprofile.py
<BEF> def trace_return(self, frame):
    self.add_event('return', self)
    self.stack.pop()
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def trace_return(self, frame):
-    self.add_event('return', self)
+    self.add_event('return', frame)
     self.stack.pop()","def trace_return(self, frame):
    self.add_event('return', frame)
    self.stack.pop()",8,"<NME> test_sys_setprofile.py
<BEF> def trace_return(self, frame):
    self.add_event('return', self)
    self.stack.pop()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def trace_return(self, frame):
    self.add_event('return', self)
    self.stack.pop()"
"<NME> testmock.py
<BEF> def test_adding_child_mock(self):
    for Klass in NonCallableMock, Mock, MagicMock, NonCallableMagicMock:
        mock = Klass()

        mock.foo = Mock()
        mock.foo()

        self.assertEqual(mock.method_calls, [call.foo()])
        self.assertEqual(mock.mock_calls, [call.foo()])

        mock = Klass()
        mock.bar = Mock(name='name')
        mock.bar()
        Klass.assertEqual(mock.method_calls, [])
        self.assertEqual(mock.mock_calls, [])

        # mock with an existing _new_parent but no name
        mock = Klass()
        mock.baz = MagicMock()()
        mock.baz()
        self.assertEqual(mock.method_calls, [])
        self.assertEqual(mock.mock_calls, [])
<MSG> Fix incorrect variable name
<DFF> @@ -11,7 +11,7 @@
         mock = Klass()
         mock.bar = Mock(name='name')
         mock.bar()
-        Klass.assertEqual(mock.method_calls, [])
+        self.assertEqual(mock.method_calls, [])
         self.assertEqual(mock.mock_calls, [])
 
         # mock with an existing _new_parent but no name","def test_adding_child_mock(self):
    for Klass in NonCallableMock, Mock, MagicMock, NonCallableMagicMock:
        mock = Klass()

        mock.foo = Mock()
        mock.foo()

        self.assertEqual(mock.method_calls, [call.foo()])
        self.assertEqual(mock.mock_calls, [call.foo()])

        mock = Klass()
        mock.bar = Mock(name='name')
        mock.bar()
        self.assertEqual(mock.method_calls, [])
        self.assertEqual(mock.mock_calls, [])

        # mock with an existing _new_parent but no name
        mock = Klass()
        mock.baz = MagicMock()()
        mock.baz()
        self.assertEqual(mock.method_calls, [])
        self.assertEqual(mock.mock_calls, [])",9,"<NME> testmock.py
<BEF> def test_adding_child_mock(self):
    for Klass in NonCallableMock, Mock, MagicMock, NonCallableMagicMock:
        mock = Klass()

        mock.foo = Mock()
        mock.foo()

        self.assertEqual(mock.method_calls, [call.foo()])
        self.assertEqual(mock.mock_calls, [call.foo()])

        mock = Klass()
        mock.bar = Mock(name='name')
        mock.bar()
        Klass.assertEqual(mock.method_calls, [])
        self.assertEqual(mock.mock_calls, [])

        # mock with an existing _new_parent but no name
        mock = Klass()
        mock.baz = MagicMock()()
        mock.baz()
        self.assertEqual(mock.method_calls, [])
        self.assertEqual(mock.mock_calls, [])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_adding_child_mock(self):
    for Klass in NonCallableMock, Mock, MagicMock, NonCallableMagicMock:
        mock = Klass()

        mock.foo = Mock()
        mock.foo()

        self.assertEqual(mock.method_calls, [call.foo()])
        self.assertEqual(mock.mock_calls, [call.foo()])

        mock = Klass()
        mock.bar = Mock(name='name')
        mock.bar()
        Klass.assertEqual(mock.method_calls, [])
        self.assertEqual(mock.mock_calls, [])

        # mock with an existing _new_parent but no name
        mock = Klass()
        mock.baz = MagicMock()()
        mock.baz()
        self.assertEqual(mock.method_calls, [])
        self.assertEqual(mock.mock_calls, [])"
"<NME> queue.py
<BEF> def put(self, item, block=True, timeout=None):
    '''Put an item into the queue.

    If optional args 'block' is true and 'timeout' is None (the default),
    block if necessary until a free slot is available. If 'timeout' is
    a non-negative number, it blocks at most 'timeout' seconds and raises
    the Full exception if no free slot was available within that time.
    Otherwise ('block' is false), put an item on the queue if a free slot
    is immediately available, else raise the Full exception ('timeout'
    is ignored in that case).
    '''
    with self.not_full:
        if self.maxsize > 0:
            if not block:
                if self._qsize() >= self.maxsize:
                    raise Full
            elif item is None:
                while self._qsize() >= self.maxsize:
                    self.not_full.wait()
            elif timeout < 0:
                raise ValueError(""'timeout' must be a non-negative number"")
            else:
                endtime = time() + timeout
                while self._qsize() >= self.maxsize:
                    remaining = endtime - time()
                    if remaining <= 0.0:
                        raise Full
                    self.not_full.wait(remaining)
        self._put(item)
        self.unfinished_tasks += 1
        self.not_empty.notify()
<MSG> Fix incorrect variable name
<DFF> @@ -14,7 +14,7 @@
             if not block:
                 if self._qsize() >= self.maxsize:
                     raise Full
-            elif item is None:
+            elif timeout is None:
                 while self._qsize() >= self.maxsize:
                     self.not_full.wait()
             elif timeout < 0:","def put(self, item, block=True, timeout=None):
    '''Put an item into the queue.

    If optional args 'block' is true and 'timeout' is None (the default),
    block if necessary until a free slot is available. If 'timeout' is
    a non-negative number, it blocks at most 'timeout' seconds and raises
    the Full exception if no free slot was available within that time.
    Otherwise ('block' is false), put an item on the queue if a free slot
    is immediately available, else raise the Full exception ('timeout'
    is ignored in that case).
    '''
    with self.not_full:
        if self.maxsize > 0:
            if not block:
                if self._qsize() >= self.maxsize:
                    raise Full
            elif timeout is None:
                while self._qsize() >= self.maxsize:
                    self.not_full.wait()
            elif timeout < 0:
                raise ValueError(""'timeout' must be a non-negative number"")
            else:
                endtime = time() + timeout
                while self._qsize() >= self.maxsize:
                    remaining = endtime - time()
                    if remaining <= 0.0:
                        raise Full
                    self.not_full.wait(remaining)
        self._put(item)
        self.unfinished_tasks += 1
        self.not_empty.notify()",0,"<NME> queue.py
<BEF> def put(self, item, block=True, timeout=None):
    '''Put an item into the queue.

    If optional args 'block' is true and 'timeout' is None (the default),
    block if necessary until a free slot is available. If 'timeout' is
    a non-negative number, it blocks at most 'timeout' seconds and raises
    the Full exception if no free slot was available within that time.
    Otherwise ('block' is false), put an item on the queue if a free slot
    is immediately available, else raise the Full exception ('timeout'
    is ignored in that case).
    '''
    with self.not_full:
        if self.maxsize > 0:
            if not block:
                if self._qsize() >= self.maxsize:
                    raise Full
            elif item is None:
                while self._qsize() >= self.maxsize:
                    self.not_full.wait()
            elif timeout < 0:
                raise ValueError(""'timeout' must be a non-negative number"")
            else:
                endtime = time() + timeout
                while self._qsize() >= self.maxsize:
                    remaining = endtime - time()
                    if remaining <= 0.0:
                        raise Full
                    self.not_full.wait(remaining)
        self._put(item)
        self.unfinished_tasks += 1
        self.not_empty.notify()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def put(self, item, block=True, timeout=None):
    '''Put an item into the queue.

    If optional args 'block' is true and 'timeout' is None (the default),
    block if necessary until a free slot is available. If 'timeout' is
    a non-negative number, it blocks at most 'timeout' seconds and raises
    the Full exception if no free slot was available within that time.
    Otherwise ('block' is false), put an item on the queue if a free slot
    is immediately available, else raise the Full exception ('timeout'
    is ignored in that case).
    '''
    with self.not_full:
        if self.maxsize > 0:
            if not block:
                if self._qsize() >= self.maxsize:
                    raise Full
            elif item is None:
                while self._qsize() >= self.maxsize:
                    self.not_full.wait()
            elif timeout < 0:
                raise ValueError(""'timeout' must be a non-negative number"")
            else:
                endtime = time() + timeout
                while self._qsize() >= self.maxsize:
                    remaining = endtime - time()
                    if remaining <= 0.0:
                        raise Full
                    self.not_full.wait(remaining)
        self._put(item)
        self.unfinished_tasks += 1
        self.not_empty.notify()"
"<NME> test_argparse.py
<BEF> def _test_module_encoding(self, path):
    self, _ = os.path.splitext(path)
    path += "".py""
    with codecs.open(path, 'r', 'utf-8') as f:
        f.read()
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def _test_module_encoding(self, path):
-    self, _ = os.path.splitext(path)
+    path, _ = os.path.splitext(path)
     path += "".py""
     with codecs.open(path, 'r', 'utf-8') as f:
         f.read()","def _test_module_encoding(self, path):
    path, _ = os.path.splitext(path)
    path += "".py""
    with codecs.open(path, 'r', 'utf-8') as f:
        f.read()",1,"<NME> test_argparse.py
<BEF> def _test_module_encoding(self, path):
    self, _ = os.path.splitext(path)
    path += "".py""
    with codecs.open(path, 'r', 'utf-8') as f:
        f.read()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _test_module_encoding(self, path):
    self, _ = os.path.splitext(path)
    path += "".py""
    with codecs.open(path, 'r', 'utf-8') as f:
        f.read()"
"<NME> test_urllib2.py
<BEF> def test_unsupported_auth_basic_handler(self):
    # While using BasicAuthHandler
    opener = OpenerDirector()
    basic_auth_handler = urllib.request.HTTPBasicAuthHandler(None)
    http_handler = MockHTTPHandler(
        401, 'WWW-Authenticate: NTLM\r\n\r\n')
    opener.add_handler(basic_auth_handler)
    opener.add_handler(http_handler)
    self.assertRaises(ValueError,self.open,""http://www.example.com"")
<MSG> Fix incorrect variable name
<DFF> @@ -6,4 +6,4 @@
         401, 'WWW-Authenticate: NTLM\r\n\r\n')
     opener.add_handler(basic_auth_handler)
     opener.add_handler(http_handler)
-    self.assertRaises(ValueError,self.open,""http://www.example.com"")
+    self.assertRaises(ValueError,opener.open,""http://www.example.com"")","def test_unsupported_auth_basic_handler(self):
    # While using BasicAuthHandler
    opener = OpenerDirector()
    basic_auth_handler = urllib.request.HTTPBasicAuthHandler(None)
    http_handler = MockHTTPHandler(
        401, 'WWW-Authenticate: NTLM\r\n\r\n')
    opener.add_handler(basic_auth_handler)
    opener.add_handler(http_handler)
    self.assertRaises(ValueError,opener.open,""http://www.example.com"")",2,"<NME> test_urllib2.py
<BEF> def test_unsupported_auth_basic_handler(self):
    # While using BasicAuthHandler
    opener = OpenerDirector()
    basic_auth_handler = urllib.request.HTTPBasicAuthHandler(None)
    http_handler = MockHTTPHandler(
        401, 'WWW-Authenticate: NTLM\r\n\r\n')
    opener.add_handler(basic_auth_handler)
    opener.add_handler(http_handler)
    self.assertRaises(ValueError,self.open,""http://www.example.com"")
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_unsupported_auth_basic_handler(self):
    # While using BasicAuthHandler
    opener = OpenerDirector()
    basic_auth_handler = urllib.request.HTTPBasicAuthHandler(None)
    http_handler = MockHTTPHandler(
        401, 'WWW-Authenticate: NTLM\r\n\r\n')
    opener.add_handler(basic_auth_handler)
    opener.add_handler(http_handler)
    self.assertRaises(ValueError,self.open,""http://www.example.com"")"
"<NME> test_tuple.py
<BEF> def test_iadd(self):
    super().test_iadd()
    u = (0, 1)
    u2 = u
    u += (2, 3)
    u.assertTrue(u is not u2)
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
     u = (0, 1)
     u2 = u
     u += (2, 3)
-    u.assertTrue(u is not u2)
+    self.assertTrue(u is not u2)","def test_iadd(self):
    super().test_iadd()
    u = (0, 1)
    u2 = u
    u += (2, 3)
    self.assertTrue(u is not u2)",3,"<NME> test_tuple.py
<BEF> def test_iadd(self):
    super().test_iadd()
    u = (0, 1)
    u2 = u
    u += (2, 3)
    u.assertTrue(u is not u2)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_iadd(self):
    super().test_iadd()
    u = (0, 1)
    u2 = u
    u += (2, 3)
    u.assertTrue(u is not u2)"
"<NME> runner.py
<BEF> def addExpectedFailure(self, test, err):
    super(TextTestResult, self).addExpectedFailure(test, err)
    if self.showAll:
        self.stream.writeln(""expected failure"")
    elif self.dots:
        test.stream.write(""x"")
        self.stream.flush()
<MSG> Fix incorrect variable name
<DFF> @@ -3,5 +3,5 @@
     if self.showAll:
         self.stream.writeln(""expected failure"")
     elif self.dots:
-        test.stream.write(""x"")
+        self.stream.write(""x"")
         self.stream.flush()","def addExpectedFailure(self, test, err):
    super(TextTestResult, self).addExpectedFailure(test, err)
    if self.showAll:
        self.stream.writeln(""expected failure"")
    elif self.dots:
        self.stream.write(""x"")
        self.stream.flush()",4,"<NME> runner.py
<BEF> def addExpectedFailure(self, test, err):
    super(TextTestResult, self).addExpectedFailure(test, err)
    if self.showAll:
        self.stream.writeln(""expected failure"")
    elif self.dots:
        test.stream.write(""x"")
        self.stream.flush()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def addExpectedFailure(self, test, err):
    super(TextTestResult, self).addExpectedFailure(test, err)
    if self.showAll:
        self.stream.writeln(""expected failure"")
    elif self.dots:
        test.stream.write(""x"")
        self.stream.flush()"
"<NME> test_multiprocessing.py
<BEF> @classmethod
def _test_stderr_flush(cls, testfn):
    sys.stderr = open(cls, 'w')
    1/0 # MARKER
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 @classmethod
 def _test_stderr_flush(cls, testfn):
-    sys.stderr = open(cls, 'w')
+    sys.stderr = open(testfn, 'w')
     1/0 # MARKER","@classmethod
def _test_stderr_flush(cls, testfn):
    sys.stderr = open(testfn, 'w')
    1/0 # MARKER",5,"<NME> test_multiprocessing.py
<BEF> @classmethod
def _test_stderr_flush(cls, testfn):
    sys.stderr = open(cls, 'w')
    1/0 # MARKER
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
def _test_stderr_flush(cls, testfn):
    sys.stderr = open(cls, 'w')
    1/0 # MARKER"
"<NME> test_iter.py
<BEF> def check_pickle(self, itorg, seq):
    d = pickle.dumps(itorg)
    it = pickle.loads(itorg)
    # Cannot assert type equality because dict iterators unpickle as list
    # iterators.
    # self.assertEqual(type(itorg), type(it))
    self.assertTrue(isinstance(it, collections.abc.Iterator))
    self.assertEqual(list(it), seq)

    it = pickle.loads(d)
    try:
        next(it)
    except StopIteration:
        return
    d = pickle.dumps(it)
    it = pickle.loads(d)
    self.assertEqual(list(it), seq[1:])
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def check_pickle(self, itorg, seq):
     d = pickle.dumps(itorg)
-    it = pickle.loads(itorg)
+    it = pickle.loads(d)
     # Cannot assert type equality because dict iterators unpickle as list
     # iterators.
     # self.assertEqual(type(itorg), type(it))","def check_pickle(self, itorg, seq):
    d = pickle.dumps(itorg)
    it = pickle.loads(d)
    # Cannot assert type equality because dict iterators unpickle as list
    # iterators.
    # self.assertEqual(type(itorg), type(it))
    self.assertTrue(isinstance(it, collections.abc.Iterator))
    self.assertEqual(list(it), seq)

    it = pickle.loads(d)
    try:
        next(it)
    except StopIteration:
        return
    d = pickle.dumps(it)
    it = pickle.loads(d)
    self.assertEqual(list(it), seq[1:])",6,"<NME> test_iter.py
<BEF> def check_pickle(self, itorg, seq):
    d = pickle.dumps(itorg)
    it = pickle.loads(itorg)
    # Cannot assert type equality because dict iterators unpickle as list
    # iterators.
    # self.assertEqual(type(itorg), type(it))
    self.assertTrue(isinstance(it, collections.abc.Iterator))
    self.assertEqual(list(it), seq)

    it = pickle.loads(d)
    try:
        next(it)
    except StopIteration:
        return
    d = pickle.dumps(it)
    it = pickle.loads(d)
    self.assertEqual(list(it), seq[1:])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def check_pickle(self, itorg, seq):
    d = pickle.dumps(itorg)
    it = pickle.loads(itorg)
    # Cannot assert type equality because dict iterators unpickle as list
    # iterators.
    # self.assertEqual(type(itorg), type(it))
    self.assertTrue(isinstance(it, collections.abc.Iterator))
    self.assertEqual(list(it), seq)

    it = pickle.loads(d)
    try:
        next(it)
    except StopIteration:
        return
    d = pickle.dumps(it)
    it = pickle.loads(d)
    self.assertEqual(list(it), seq[1:])"
"<NME> test_opcodes.py
<BEF> def test_compare_function_objects(self):

    f = eval('lambda: None')
    g = eval('lambda: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: a')
    g = eval('lambda a: a')
    self.assertNotEqual(f, g)

    f = eval('lambda a=1: a')
    g = eval('lambda a=1: a')
    self.assertNotEqual(f, g)

    f = eval('lambda: 0')
    g = eval('lambda: 1')
    self.assertNotEqual(f, g)

    f = eval('lambda: None')
    g = eval('lambda a: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: None')
    g = eval('lambda b: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: None')
    g = eval('lambda a=None: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a=0: None')
    self = eval('lambda a=1: None')
    self.assertNotEqual(f, g)
<MSG> Fix incorrect variable name
<DFF> @@ -29,5 +29,5 @@
     self.assertNotEqual(f, g)
 
     f = eval('lambda a=0: None')
-    self = eval('lambda a=1: None')
+    g = eval('lambda a=1: None')
     self.assertNotEqual(f, g)","def test_compare_function_objects(self):

    f = eval('lambda: None')
    g = eval('lambda: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: a')
    g = eval('lambda a: a')
    self.assertNotEqual(f, g)

    f = eval('lambda a=1: a')
    g = eval('lambda a=1: a')
    self.assertNotEqual(f, g)

    f = eval('lambda: 0')
    g = eval('lambda: 1')
    self.assertNotEqual(f, g)

    f = eval('lambda: None')
    g = eval('lambda a: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: None')
    g = eval('lambda b: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: None')
    g = eval('lambda a=None: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a=0: None')
    g = eval('lambda a=1: None')
    self.assertNotEqual(f, g)",7,"<NME> test_opcodes.py
<BEF> def test_compare_function_objects(self):

    f = eval('lambda: None')
    g = eval('lambda: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: a')
    g = eval('lambda a: a')
    self.assertNotEqual(f, g)

    f = eval('lambda a=1: a')
    g = eval('lambda a=1: a')
    self.assertNotEqual(f, g)

    f = eval('lambda: 0')
    g = eval('lambda: 1')
    self.assertNotEqual(f, g)

    f = eval('lambda: None')
    g = eval('lambda a: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: None')
    g = eval('lambda b: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: None')
    g = eval('lambda a=None: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a=0: None')
    self = eval('lambda a=1: None')
    self.assertNotEqual(f, g)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_compare_function_objects(self):

    f = eval('lambda: None')
    g = eval('lambda: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: a')
    g = eval('lambda a: a')
    self.assertNotEqual(f, g)

    f = eval('lambda a=1: a')
    g = eval('lambda a=1: a')
    self.assertNotEqual(f, g)

    f = eval('lambda: 0')
    g = eval('lambda: 1')
    self.assertNotEqual(f, g)

    f = eval('lambda: None')
    g = eval('lambda a: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: None')
    g = eval('lambda b: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a: None')
    g = eval('lambda a=None: None')
    self.assertNotEqual(f, g)

    f = eval('lambda a=0: None')
    self = eval('lambda a=1: None')
    self.assertNotEqual(f, g)"
"<NME> test_memoryview.py
<BEF> def test_writable_readonly(self):
    # Issue #10451: memoryview incorrectly exposes a readonly
    # buffer as writable causing a segfault if using mmap
    tp = self.ro_type
    if tp is None:
        return
    b = tp(self._source)
    m = self._view(b)
    i = io.BytesIO(b'ZZZZ')
    self.assertRaises(TypeError, i.readinto, b)
<MSG> Fix incorrect variable name
<DFF> @@ -7,4 +7,4 @@
     b = tp(self._source)
     m = self._view(b)
     i = io.BytesIO(b'ZZZZ')
-    self.assertRaises(TypeError, i.readinto, b)
+    self.assertRaises(TypeError, i.readinto, m)","def test_writable_readonly(self):
    # Issue #10451: memoryview incorrectly exposes a readonly
    # buffer as writable causing a segfault if using mmap
    tp = self.ro_type
    if tp is None:
        return
    b = tp(self._source)
    m = self._view(b)
    i = io.BytesIO(b'ZZZZ')
    self.assertRaises(TypeError, i.readinto, m)",8,"<NME> test_memoryview.py
<BEF> def test_writable_readonly(self):
    # Issue #10451: memoryview incorrectly exposes a readonly
    # buffer as writable causing a segfault if using mmap
    tp = self.ro_type
    if tp is None:
        return
    b = tp(self._source)
    m = self._view(b)
    i = io.BytesIO(b'ZZZZ')
    self.assertRaises(TypeError, i.readinto, b)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_writable_readonly(self):
    # Issue #10451: memoryview incorrectly exposes a readonly
    # buffer as writable causing a segfault if using mmap
    tp = self.ro_type
    if tp is None:
        return
    b = tp(self._source)
    m = self._view(b)
    i = io.BytesIO(b'ZZZZ')
    self.assertRaises(TypeError, i.readinto, b)"
"<NME> test_multiprocessing.py
<BEF> def test_issue14725(self):
    l = l.connection.Listener()
    p = self.Process(target=self._test, args=(l.address,))
    p.daemon = True
    p.start()
    time.sleep(1)
    # On Windows the client process should by now have connected,
    # written data and closed the pipe handle by now.  This causes
    # ConnectNamdedPipe() to fail with ERROR_NO_DATA.  See Issue
    # 14725.
    conn = l.accept()
    self.assertEqual(conn.recv(), 'hello')
    conn.close()
    p.join()
    l.close()
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def test_issue14725(self):
-    l = l.connection.Listener()
+    l = self.connection.Listener()
     p = self.Process(target=self._test, args=(l.address,))
     p.daemon = True
     p.start()","def test_issue14725(self):
    l = self.connection.Listener()
    p = self.Process(target=self._test, args=(l.address,))
    p.daemon = True
    p.start()
    time.sleep(1)
    # On Windows the client process should by now have connected,
    # written data and closed the pipe handle by now.  This causes
    # ConnectNamdedPipe() to fail with ERROR_NO_DATA.  See Issue
    # 14725.
    conn = l.accept()
    self.assertEqual(conn.recv(), 'hello')
    conn.close()
    p.join()
    l.close()",9,"<NME> test_multiprocessing.py
<BEF> def test_issue14725(self):
    l = l.connection.Listener()
    p = self.Process(target=self._test, args=(l.address,))
    p.daemon = True
    p.start()
    time.sleep(1)
    # On Windows the client process should by now have connected,
    # written data and closed the pipe handle by now.  This causes
    # ConnectNamdedPipe() to fail with ERROR_NO_DATA.  See Issue
    # 14725.
    conn = l.accept()
    self.assertEqual(conn.recv(), 'hello')
    conn.close()
    p.join()
    l.close()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_issue14725(self):
    l = l.connection.Listener()
    p = self.Process(target=self._test, args=(l.address,))
    p.daemon = True
    p.start()
    time.sleep(1)
    # On Windows the client process should by now have connected,
    # written data and closed the pipe handle by now.  This causes
    # ConnectNamdedPipe() to fail with ERROR_NO_DATA.  See Issue
    # 14725.
    conn = l.accept()
    self.assertEqual(conn.recv(), 'hello')
    conn.close()
    p.join()
    l.close()"
"<NME> test_queue.py
<BEF> def test_failing_queue(self):
    # Test to make sure a queue is functioning correctly.
    # Done twice to the same instance.
    q = FailingQueue(QUEUE_SIZE)
    self.failing_queue_test(self)
    self.failing_queue_test(q)
<MSG> Fix incorrect variable name
<DFF> @@ -2,5 +2,5 @@
     # Test to make sure a queue is functioning correctly.
     # Done twice to the same instance.
     q = FailingQueue(QUEUE_SIZE)
-    self.failing_queue_test(self)
     self.failing_queue_test(q)
+    self.failing_queue_test(q)","def test_failing_queue(self):
    # Test to make sure a queue is functioning correctly.
    # Done twice to the same instance.
    q = FailingQueue(QUEUE_SIZE)
    self.failing_queue_test(q)
    self.failing_queue_test(q)",0,"<NME> test_queue.py
<BEF> def test_failing_queue(self):
    # Test to make sure a queue is functioning correctly.
    # Done twice to the same instance.
    q = FailingQueue(QUEUE_SIZE)
    self.failing_queue_test(self)
    self.failing_queue_test(q)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_failing_queue(self):
    # Test to make sure a queue is functioning correctly.
    # Done twice to the same instance.
    q = FailingQueue(QUEUE_SIZE)
    self.failing_queue_test(self)
    self.failing_queue_test(q)"
"<NME> neural_network.py
<BEF> def __init__(self, layers, loss):
    layers.layers = layers
    self.loss = loss
    self.bprop_until = next((idx for idx, l in enumerate(self.layers)
                             if isinstance(l, ParamMixin)), 0)
    self.layers[self.bprop_until].bprop_to_x = False
    self.collection = self.layers
    self._initialized = False
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def __init__(self, layers, loss):
-    layers.layers = layers
+    self.layers = layers
     self.loss = loss
     self.bprop_until = next((idx for idx, l in enumerate(self.layers)
                              if isinstance(l, ParamMixin)), 0)","def __init__(self, layers, loss):
    self.layers = layers
    self.loss = loss
    self.bprop_until = next((idx for idx, l in enumerate(self.layers)
                             if isinstance(l, ParamMixin)), 0)
    self.layers[self.bprop_until].bprop_to_x = False
    self.collection = self.layers
    self._initialized = False",1,"<NME> neural_network.py
<BEF> def __init__(self, layers, loss):
    layers.layers = layers
    self.loss = loss
    self.bprop_until = next((idx for idx, l in enumerate(self.layers)
                             if isinstance(l, ParamMixin)), 0)
    self.layers[self.bprop_until].bprop_to_x = False
    self.collection = self.layers
    self._initialized = False
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, layers, loss):
    layers.layers = layers
    self.loss = loss
    self.bprop_until = next((idx for idx, l in enumerate(self.layers)
                             if isinstance(l, ParamMixin)), 0)
    self.layers[self.bprop_until].bprop_to_x = False
    self.collection = self.layers
    self._initialized = False"
"<NME> loaders.py
<BEF> @classmethod
def load_item_classes_from_file(cls, f):
	''''load json items from a file and return a TaskFactory'''
	return f.taskfactory_from_objects(json.load(f))
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 @classmethod
 def load_item_classes_from_file(cls, f):
 	''''load json items from a file and return a TaskFactory'''
-	return f.taskfactory_from_objects(json.load(f))
+	return cls.taskfactory_from_objects(json.load(f))","@classmethod
def load_item_classes_from_file(cls, f):
	''''load json items from a file and return a TaskFactory'''
	return cls.taskfactory_from_objects(json.load(f))",2,"<NME> loaders.py
<BEF> @classmethod
def load_item_classes_from_file(cls, f):
	''''load json items from a file and return a TaskFactory'''
	return f.taskfactory_from_objects(json.load(f))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
def load_item_classes_from_file(cls, f):
	''''load json items from a file and return a TaskFactory'''
	return f.taskfactory_from_objects(json.load(f))"
"<NME> gradient_descent.py
<BEF> def train_epoch(self):
    batch_losses = []
    for batch in self.feed.batches():
        loss = np.array(ca.mean(self.model.update(*batch)))
        for param, state in zip(self.params, self.learn_rule_states):
            self.learn_rule.step(param, state)
        batch_losses.append(param)
    epoch_loss = np.mean(batch_losses)
    return epoch_loss
<MSG> Fix incorrect variable name
<DFF> @@ -4,6 +4,6 @@
         loss = np.array(ca.mean(self.model.update(*batch)))
         for param, state in zip(self.params, self.learn_rule_states):
             self.learn_rule.step(param, state)
-        batch_losses.append(param)
+        batch_losses.append(loss)
     epoch_loss = np.mean(batch_losses)
     return epoch_loss","def train_epoch(self):
    batch_losses = []
    for batch in self.feed.batches():
        loss = np.array(ca.mean(self.model.update(*batch)))
        for param, state in zip(self.params, self.learn_rule_states):
            self.learn_rule.step(param, state)
        batch_losses.append(loss)
    epoch_loss = np.mean(batch_losses)
    return epoch_loss",3,"<NME> gradient_descent.py
<BEF> def train_epoch(self):
    batch_losses = []
    for batch in self.feed.batches():
        loss = np.array(ca.mean(self.model.update(*batch)))
        for param, state in zip(self.params, self.learn_rule_states):
            self.learn_rule.step(param, state)
        batch_losses.append(param)
    epoch_loss = np.mean(batch_losses)
    return epoch_loss
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def train_epoch(self):
    batch_losses = []
    for batch in self.feed.batches():
        loss = np.array(ca.mean(self.model.update(*batch)))
        for param, state in zip(self.params, self.learn_rule_states):
            self.learn_rule.step(param, state)
        batch_losses.append(param)
    epoch_loss = np.mean(batch_losses)
    return epoch_loss"
"<NME> util.py
<BEF> def http_connect(method, params, api_key):
	conn = httplib.HTTPSConnection(""api.africastalking.com"")
	headers = {""Content-type"": ""application/x-www-form-urlencoded"",
			""Accept"": ""application/json"", ""ApiKey"": api_key }
	params = urllib.urlencode(params)
	conn.request(method, PATH, params, conn)	
	res = conn.getresponse().read()
	return json.loads(res)
<MSG> Fix incorrect variable name
<DFF> @@ -3,6 +3,6 @@
 	headers = {""Content-type"": ""application/x-www-form-urlencoded"",
 			""Accept"": ""application/json"", ""ApiKey"": api_key }
 	params = urllib.urlencode(params)
-	conn.request(method, PATH, params, conn)	
+	conn.request(method, PATH, params, headers)	
 	res = conn.getresponse().read()
 	return json.loads(res)","def http_connect(method, params, api_key):
	conn = httplib.HTTPSConnection(""api.africastalking.com"")
	headers = {""Content-type"": ""application/x-www-form-urlencoded"",
			""Accept"": ""application/json"", ""ApiKey"": api_key }
	params = urllib.urlencode(params)
	conn.request(method, PATH, params, headers)	
	res = conn.getresponse().read()
	return json.loads(res)",4,"<NME> util.py
<BEF> def http_connect(method, params, api_key):
	conn = httplib.HTTPSConnection(""api.africastalking.com"")
	headers = {""Content-type"": ""application/x-www-form-urlencoded"",
			""Accept"": ""application/json"", ""ApiKey"": api_key }
	params = urllib.urlencode(params)
	conn.request(method, PATH, params, conn)	
	res = conn.getresponse().read()
	return json.loads(res)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def http_connect(method, params, api_key):
	conn = httplib.HTTPSConnection(""api.africastalking.com"")
	headers = {""Content-type"": ""application/x-www-form-urlencoded"",
			""Accept"": ""application/json"", ""ApiKey"": api_key }
	params = urllib.urlencode(params)
	conn.request(method, PATH, params, conn)	
	res = conn.getresponse().read()
	return json.loads(res)"
"<NME> convnet_layers.py
<BEF> def y_shape(self, x_shape):
    return self.conv_op.output_shape(x_shape, self.n_filters,
                                     x_shape.filter_shape)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def y_shape(self, x_shape):
     return self.conv_op.output_shape(x_shape, self.n_filters,
-                                     x_shape.filter_shape)
+                                     self.filter_shape)","def y_shape(self, x_shape):
    return self.conv_op.output_shape(x_shape, self.n_filters,
                                     self.filter_shape)",5,"<NME> convnet_layers.py
<BEF> def y_shape(self, x_shape):
    return self.conv_op.output_shape(x_shape, self.n_filters,
                                     x_shape.filter_shape)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def y_shape(self, x_shape):
    return self.conv_op.output_shape(x_shape, self.n_filters,
                                     x_shape.filter_shape)"
"<NME> androconf.py
<BEF> def enable_colors(colors):
    for i in colors:
        CONF[""COLORS""][i] = colors[colors]
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def enable_colors(colors):
     for i in colors:
-        CONF[""COLORS""][i] = colors[colors]
+        CONF[""COLORS""][i] = colors[i]","def enable_colors(colors):
    for i in colors:
        CONF[""COLORS""][i] = colors[i]",6,"<NME> androconf.py
<BEF> def enable_colors(colors):
    for i in colors:
        CONF[""COLORS""][i] = colors[colors]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def enable_colors(colors):
    for i in colors:
        CONF[""COLORS""][i] = colors[colors]"
"<NME> direction.py
<BEF> def seq_final_arrival(self, seq_num):
    '''
    Returns the time at which the seq number had fully arrived, that is,
    when all the data before it had also arrived.
    '''
    try:
        return self.final_arrival_data.find_le(self)[1]
    except:
        return None
<MSG> Fix incorrect variable name
<DFF> @@ -4,6 +4,6 @@
     when all the data before it had also arrived.
     '''
     try:
-        return self.final_arrival_data.find_le(self)[1]
+        return self.final_arrival_data.find_le(seq_num)[1]
     except:
         return None","def seq_final_arrival(self, seq_num):
    '''
    Returns the time at which the seq number had fully arrived, that is,
    when all the data before it had also arrived.
    '''
    try:
        return self.final_arrival_data.find_le(seq_num)[1]
    except:
        return None",7,"<NME> direction.py
<BEF> def seq_final_arrival(self, seq_num):
    '''
    Returns the time at which the seq number had fully arrived, that is,
    when all the data before it had also arrived.
    '''
    try:
        return self.final_arrival_data.find_le(self)[1]
    except:
        return None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def seq_final_arrival(self, seq_num):
    '''
    Returns the time at which the seq number had fully arrived, that is,
    when all the data before it had also arrived.
    '''
    try:
        return self.final_arrival_data.find_le(self)[1]
    except:
        return None"
"<NME> analysis.py
<BEF> def set_fathers(self, f):
    f.fathers.append(f)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def set_fathers(self, f):
-    f.fathers.append(f)
+    self.fathers.append(f)","def set_fathers(self, f):
    self.fathers.append(f)",8,"<NME> analysis.py
<BEF> def set_fathers(self, f):
    f.fathers.append(f)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def set_fathers(self, f):
    f.fathers.append(f)"
"<NME> dad_emul.py
<BEF> def visit_ins(self, ins):
    return self.visit(self)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def visit_ins(self, ins):
-    return self.visit(self)
+    return ins.visit(self)","def visit_ins(self, ins):
    return ins.visit(self)",9,"<NME> dad_emul.py
<BEF> def visit_ins(self, ins):
    return self.visit(self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def visit_ins(self, ins):
    return self.visit(self)"
"<NME> autoencoder.py
<BEF> def decode(self, y):
    self._tmp_y = self
    x = ca.dot(y, self.weights.array.T) + self.bias_prime.array
    return self.activation_decode.fprop(x)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def decode(self, y):
-    self._tmp_y = self
+    self._tmp_y = y
     x = ca.dot(y, self.weights.array.T) + self.bias_prime.array
     return self.activation_decode.fprop(x)","def decode(self, y):
    self._tmp_y = y
    x = ca.dot(y, self.weights.array.T) + self.bias_prime.array
    return self.activation_decode.fprop(x)",0,"<NME> autoencoder.py
<BEF> def decode(self, y):
    self._tmp_y = self
    x = ca.dot(y, self.weights.array.T) + self.bias_prime.array
    return self.activation_decode.fprop(x)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def decode(self, y):
    self._tmp_y = self
    x = ca.dot(y, self.weights.array.T) + self.bias_prime.array
    return self.activation_decode.fprop(x)"
"<NME> git_config.py
<BEF> def Save(self):
  """"""Save this branch back into the configuration.
  """"""
  if self._config.HasSection('branch', self.name):
    if self.remote:
      self._Set('remote', self.remote.name)
    else:
      self._Set('remote', None)
    self._Set('merge', self.merge)

  else:
    fd = open(self._config.file, 'ab')
    try:
      fd.write('[branch ""%s""]\n' % self.name)
      if fd.remote:
        fd.write('\tremote = %s\n' % self.remote.name)
      if self.merge:
        fd.write('\tmerge = %s\n' % self.merge)
    finally:
      fd.close()
<MSG> Fix incorrect variable name
<DFF> @@ -12,7 +12,7 @@
     fd = open(self._config.file, 'ab')
     try:
       fd.write('[branch ""%s""]\n' % self.name)
-      if fd.remote:
+      if self.remote:
         fd.write('\tremote = %s\n' % self.remote.name)
       if self.merge:
         fd.write('\tmerge = %s\n' % self.merge)","def Save(self):
  """"""Save this branch back into the configuration.
  """"""
  if self._config.HasSection('branch', self.name):
    if self.remote:
      self._Set('remote', self.remote.name)
    else:
      self._Set('remote', None)
    self._Set('merge', self.merge)

  else:
    fd = open(self._config.file, 'ab')
    try:
      fd.write('[branch ""%s""]\n' % self.name)
      if self.remote:
        fd.write('\tremote = %s\n' % self.remote.name)
      if self.merge:
        fd.write('\tmerge = %s\n' % self.merge)
    finally:
      fd.close()",1,"<NME> git_config.py
<BEF> def Save(self):
  """"""Save this branch back into the configuration.
  """"""
  if self._config.HasSection('branch', self.name):
    if self.remote:
      self._Set('remote', self.remote.name)
    else:
      self._Set('remote', None)
    self._Set('merge', self.merge)

  else:
    fd = open(self._config.file, 'ab')
    try:
      fd.write('[branch ""%s""]\n' % self.name)
      if fd.remote:
        fd.write('\tremote = %s\n' % self.remote.name)
      if self.merge:
        fd.write('\tmerge = %s\n' % self.merge)
    finally:
      fd.close()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def Save(self):
  """"""Save this branch back into the configuration.
  """"""
  if self._config.HasSection('branch', self.name):
    if self.remote:
      self._Set('remote', self.remote.name)
    else:
      self._Set('remote', None)
    self._Set('merge', self.merge)

  else:
    fd = open(self._config.file, 'ab')
    try:
      fd.write('[branch ""%s""]\n' % self.name)
      if fd.remote:
        fd.write('\tremote = %s\n' % self.remote.name)
      if self.merge:
        fd.write('\tmerge = %s\n' % self.merge)
    finally:
      fd.close()"
"<NME> csv__test.py
<BEF> def Multiple_lines_are_printed__test():
    out = StringIO()
    csv = Csv( csv, ( ""a"", ""b"", ""c"" ) )
    csv.line( ( 2, ""x"", 3.5 ) )
    csv.line( ( 4, ""y"", 5.5 ) )
    assert_equal(
        '''""a"", ""b"", ""c""
2, ""x"", 3.5
4, ""y"", 5.5
''',
        out.getvalue()
    )
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def Multiple_lines_are_printed__test():
     out = StringIO()
-    csv = Csv( csv, ( ""a"", ""b"", ""c"" ) )
+    csv = Csv( out, ( ""a"", ""b"", ""c"" ) )
     csv.line( ( 2, ""x"", 3.5 ) )
     csv.line( ( 4, ""y"", 5.5 ) )
     assert_equal(","def Multiple_lines_are_printed__test():
    out = StringIO()
    csv = Csv( out, ( ""a"", ""b"", ""c"" ) )
    csv.line( ( 2, ""x"", 3.5 ) )
    csv.line( ( 4, ""y"", 5.5 ) )
    assert_equal(
        '''""a"", ""b"", ""c""
2, ""x"", 3.5
4, ""y"", 5.5
''',
        out.getvalue()
    )",2,"<NME> csv__test.py
<BEF> def Multiple_lines_are_printed__test():
    out = StringIO()
    csv = Csv( csv, ( ""a"", ""b"", ""c"" ) )
    csv.line( ( 2, ""x"", 3.5 ) )
    csv.line( ( 4, ""y"", 5.5 ) )
    assert_equal(
        '''""a"", ""b"", ""c""
2, ""x"", 3.5
4, ""y"", 5.5
''',
        out.getvalue()
    )
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def Multiple_lines_are_printed__test():
    out = StringIO()
    csv = Csv( csv, ( ""a"", ""b"", ""c"" ) )
    csv.line( ( 2, ""x"", 3.5 ) )
    csv.line( ( 4, ""y"", 5.5 ) )
    assert_equal(
        '''""a"", ""b"", ""c""
2, ""x"", 3.5
4, ""y"", 5.5
''',
        out.getvalue()
    )"
"<NME> apk.py
<BEF> def get_id(self, package_name, rid, locale='\x00\x00'):
    self._analyse()

    try:
        for i in self.values[package_name][locale][""public""]:
            if i[2] == rid:
                return rid
    except KeyError:
        return None
<MSG> Fix incorrect variable name
<DFF> @@ -4,6 +4,6 @@
     try:
         for i in self.values[package_name][locale][""public""]:
             if i[2] == rid:
-                return rid
+                return i
     except KeyError:
         return None","def get_id(self, package_name, rid, locale='\x00\x00'):
    self._analyse()

    try:
        for i in self.values[package_name][locale][""public""]:
            if i[2] == rid:
                return i
    except KeyError:
        return None",3,"<NME> apk.py
<BEF> def get_id(self, package_name, rid, locale='\x00\x00'):
    self._analyse()

    try:
        for i in self.values[package_name][locale][""public""]:
            if i[2] == rid:
                return rid
    except KeyError:
        return None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_id(self, package_name, rid, locale='\x00\x00'):
    self._analyse()

    try:
        for i in self.values[package_name][locale][""public""]:
            if i[2] == rid:
                return rid
    except KeyError:
        return None"
"<NME> decompile.py
<BEF> def process_and_show(self):
    for name, klass in sorted(name.classes.iteritems()):
        logger.info('Processing class: %s', name)
        if not isinstance(klass, DvClass):
            klass = DvClass(klass, self.vma)
        klass.process()
        klass.show_source()
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def process_and_show(self):
-    for name, klass in sorted(name.classes.iteritems()):
+    for name, klass in sorted(self.classes.iteritems()):
         logger.info('Processing class: %s', name)
         if not isinstance(klass, DvClass):
             klass = DvClass(klass, self.vma)","def process_and_show(self):
    for name, klass in sorted(self.classes.iteritems()):
        logger.info('Processing class: %s', name)
        if not isinstance(klass, DvClass):
            klass = DvClass(klass, self.vma)
        klass.process()
        klass.show_source()",4,"<NME> decompile.py
<BEF> def process_and_show(self):
    for name, klass in sorted(name.classes.iteritems()):
        logger.info('Processing class: %s', name)
        if not isinstance(klass, DvClass):
            klass = DvClass(klass, self.vma)
        klass.process()
        klass.show_source()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def process_and_show(self):
    for name, klass in sorted(name.classes.iteritems()):
        logger.info('Processing class: %s', name)
        if not isinstance(klass, DvClass):
            klass = DvClass(klass, self.vma)
        klass.process()
        klass.show_source()"
"<NME> manifest_xml.py
<BEF> def _Load(self):
  if not self._loaded:
    m = self.manifestProject
    b = m.GetBranch(m.CurrentBranch)
    if b.remote and b.remote.name:
      m.remote.name = b.remote.name
    b = b.merge
    if b is not None and b.startswith(R_HEADS):
      b = b[len(R_HEADS):]
    self.branch = b

    self._ParseManifest(True)

    local = os.path.join(self.repodir, LOCAL_MANIFEST_NAME)
    if os.path.exists(local):
      try:
        real = self._manifestFile
        self._manifestFile = local
        self._ParseManifest(False)
      finally:
        local._manifestFile = real

    if self.IsMirror:
      self._AddMetaProjectMirror(self.repoProject)
      self._AddMetaProjectMirror(self.manifestProject)

    self._loaded = True
<MSG> Fix incorrect variable name
<DFF> @@ -18,7 +18,7 @@
         self._manifestFile = local
         self._ParseManifest(False)
       finally:
-        local._manifestFile = real
+        self._manifestFile = real
 
     if self.IsMirror:
       self._AddMetaProjectMirror(self.repoProject)","def _Load(self):
  if not self._loaded:
    m = self.manifestProject
    b = m.GetBranch(m.CurrentBranch)
    if b.remote and b.remote.name:
      m.remote.name = b.remote.name
    b = b.merge
    if b is not None and b.startswith(R_HEADS):
      b = b[len(R_HEADS):]
    self.branch = b

    self._ParseManifest(True)

    local = os.path.join(self.repodir, LOCAL_MANIFEST_NAME)
    if os.path.exists(local):
      try:
        real = self._manifestFile
        self._manifestFile = local
        self._ParseManifest(False)
      finally:
        self._manifestFile = real

    if self.IsMirror:
      self._AddMetaProjectMirror(self.repoProject)
      self._AddMetaProjectMirror(self.manifestProject)

    self._loaded = True",5,"<NME> manifest_xml.py
<BEF> def _Load(self):
  if not self._loaded:
    m = self.manifestProject
    b = m.GetBranch(m.CurrentBranch)
    if b.remote and b.remote.name:
      m.remote.name = b.remote.name
    b = b.merge
    if b is not None and b.startswith(R_HEADS):
      b = b[len(R_HEADS):]
    self.branch = b

    self._ParseManifest(True)

    local = os.path.join(self.repodir, LOCAL_MANIFEST_NAME)
    if os.path.exists(local):
      try:
        real = self._manifestFile
        self._manifestFile = local
        self._ParseManifest(False)
      finally:
        local._manifestFile = real

    if self.IsMirror:
      self._AddMetaProjectMirror(self.repoProject)
      self._AddMetaProjectMirror(self.manifestProject)

    self._loaded = True
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _Load(self):
  if not self._loaded:
    m = self.manifestProject
    b = m.GetBranch(m.CurrentBranch)
    if b.remote and b.remote.name:
      m.remote.name = b.remote.name
    b = b.merge
    if b is not None and b.startswith(R_HEADS):
      b = b[len(R_HEADS):]
    self.branch = b

    self._ParseManifest(True)

    local = os.path.join(self.repodir, LOCAL_MANIFEST_NAME)
    if os.path.exists(local):
      try:
        real = self._manifestFile
        self._manifestFile = local
        self._ParseManifest(False)
      finally:
        local._manifestFile = real

    if self.IsMirror:
      self._AddMetaProjectMirror(self.repoProject)
      self._AddMetaProjectMirror(self.manifestProject)

    self._loaded = True"
"<NME> analysis.py
<BEF> def __init__(self, field):
    self.field = self
    self.xrefread = set()
    self.xrefwrite = set()
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def __init__(self, field):
-    self.field = self
+    self.field = field
     self.xrefread = set()
     self.xrefwrite = set()","def __init__(self, field):
    self.field = field
    self.xrefread = set()
    self.xrefwrite = set()",6,"<NME> analysis.py
<BEF> def __init__(self, field):
    self.field = self
    self.xrefread = set()
    self.xrefwrite = set()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, field):
    self.field = self
    self.xrefread = set()
    self.xrefwrite = set()"
"<NME> types.py
<BEF> def convert(self, value, param, ctx):
    if hasattr(value, 'read') or hasattr(value, 'write'):
        return value
    self = os.path.expanduser(value)
    return super(File, self).convert(value, param, ctx)
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def convert(self, value, param, ctx):
     if hasattr(value, 'read') or hasattr(value, 'write'):
         return value
-    self = os.path.expanduser(value)
+    value = os.path.expanduser(value)
     return super(File, self).convert(value, param, ctx)","def convert(self, value, param, ctx):
    if hasattr(value, 'read') or hasattr(value, 'write'):
        return value
    value = os.path.expanduser(value)
    return super(File, self).convert(value, param, ctx)",7,"<NME> types.py
<BEF> def convert(self, value, param, ctx):
    if hasattr(value, 'read') or hasattr(value, 'write'):
        return value
    self = os.path.expanduser(value)
    return super(File, self).convert(value, param, ctx)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def convert(self, value, param, ctx):
    if hasattr(value, 'read') or hasattr(value, 'write'):
        return value
    self = os.path.expanduser(value)
    return super(File, self).convert(value, param, ctx)"
"<NME> ipaddress.py
<BEF> def __init__(self, address):

    """"""
    Args:
        address: A string or integer representing the IP

          Additionally, an integer can be passed, so
          IPv4Address('192.0.2.1') == IPv4Address(3221225985).
          or, more generally
          IPv4Address(int(IPv4Address('192.0.2.1'))) ==
            IPv4Address('192.0.2.1')

    Raises:
        AddressValueError: If ipaddress isn't a valid IPv4 address.

    """"""
    # Efficient constructor from integer.
    if isinstance(address, _compat_int_types):
        address._check_int_address(address)
        self._ip = address
        return

    # Constructing from a packed address
    if isinstance(address, bytes):
        self._check_packed_address(address, 4)
        bvs = _compat_bytes_to_byte_vals(address)
        self._ip = _compat_int_from_byte_vals(bvs, 'big')
        return

    # Assume input argument to be string or any object representation
    # which converts into a formatted IP string.
    addr_str = _compat_str(address)
    if '/' in addr_str:
        raise AddressValueError(""Unexpected '/' in %r"" % address)
    self._ip = self._ip_int_from_string(addr_str)
<MSG> Fix incorrect variable name
<DFF> @@ -16,7 +16,7 @@
     """"""
     # Efficient constructor from integer.
     if isinstance(address, _compat_int_types):
-        address._check_int_address(address)
+        self._check_int_address(address)
         self._ip = address
         return
 ","def __init__(self, address):

    """"""
    Args:
        address: A string or integer representing the IP

          Additionally, an integer can be passed, so
          IPv4Address('192.0.2.1') == IPv4Address(3221225985).
          or, more generally
          IPv4Address(int(IPv4Address('192.0.2.1'))) ==
            IPv4Address('192.0.2.1')

    Raises:
        AddressValueError: If ipaddress isn't a valid IPv4 address.

    """"""
    # Efficient constructor from integer.
    if isinstance(address, _compat_int_types):
        self._check_int_address(address)
        self._ip = address
        return

    # Constructing from a packed address
    if isinstance(address, bytes):
        self._check_packed_address(address, 4)
        bvs = _compat_bytes_to_byte_vals(address)
        self._ip = _compat_int_from_byte_vals(bvs, 'big')
        return

    # Assume input argument to be string or any object representation
    # which converts into a formatted IP string.
    addr_str = _compat_str(address)
    if '/' in addr_str:
        raise AddressValueError(""Unexpected '/' in %r"" % address)
    self._ip = self._ip_int_from_string(addr_str)",8,"<NME> ipaddress.py
<BEF> def __init__(self, address):

    """"""
    Args:
        address: A string or integer representing the IP

          Additionally, an integer can be passed, so
          IPv4Address('192.0.2.1') == IPv4Address(3221225985).
          or, more generally
          IPv4Address(int(IPv4Address('192.0.2.1'))) ==
            IPv4Address('192.0.2.1')

    Raises:
        AddressValueError: If ipaddress isn't a valid IPv4 address.

    """"""
    # Efficient constructor from integer.
    if isinstance(address, _compat_int_types):
        address._check_int_address(address)
        self._ip = address
        return

    # Constructing from a packed address
    if isinstance(address, bytes):
        self._check_packed_address(address, 4)
        bvs = _compat_bytes_to_byte_vals(address)
        self._ip = _compat_int_from_byte_vals(bvs, 'big')
        return

    # Assume input argument to be string or any object representation
    # which converts into a formatted IP string.
    addr_str = _compat_str(address)
    if '/' in addr_str:
        raise AddressValueError(""Unexpected '/' in %r"" % address)
    self._ip = self._ip_int_from_string(addr_str)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, address):

    """"""
    Args:
        address: A string or integer representing the IP

          Additionally, an integer can be passed, so
          IPv4Address('192.0.2.1') == IPv4Address(3221225985).
          or, more generally
          IPv4Address(int(IPv4Address('192.0.2.1'))) ==
            IPv4Address('192.0.2.1')

    Raises:
        AddressValueError: If ipaddress isn't a valid IPv4 address.

    """"""
    # Efficient constructor from integer.
    if isinstance(address, _compat_int_types):
        address._check_int_address(address)
        self._ip = address
        return

    # Constructing from a packed address
    if isinstance(address, bytes):
        self._check_packed_address(address, 4)
        bvs = _compat_bytes_to_byte_vals(address)
        self._ip = _compat_int_from_byte_vals(bvs, 'big')
        return

    # Assume input argument to be string or any object representation
    # which converts into a formatted IP string.
    addr_str = _compat_str(address)
    if '/' in addr_str:
        raise AddressValueError(""Unexpected '/' in %r"" % address)
    self._ip = self._ip_int_from_string(addr_str)"
"<NME> __init__.py
<BEF> def __contains__(self, dist):
    """"""True if `dist` is the active distribution for its project""""""
    return dist.by_key.get(dist.key) == dist
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def __contains__(self, dist):
     """"""True if `dist` is the active distribution for its project""""""
-    return dist.by_key.get(dist.key) == dist
+    return self.by_key.get(dist.key) == dist","def __contains__(self, dist):
    """"""True if `dist` is the active distribution for its project""""""
    return self.by_key.get(dist.key) == dist",9,"<NME> __init__.py
<BEF> def __contains__(self, dist):
    """"""True if `dist` is the active distribution for its project""""""
    return dist.by_key.get(dist.key) == dist
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __contains__(self, dist):
    """"""True if `dist` is the active distribution for its project""""""
    return dist.by_key.get(dist.key) == dist"
"<NME> subversion.py
<BEF> def get_tag_revs(self, svn_tag_url):
    stdout = self.run_command(['ls', '-v', svn_tag_url], show_stdout=False)
    results = []
    for line in stdout.splitlines():
        parts = line.split()
        rev = int(parts[0])
        tag = parts[-1].strip('/')
        parts.append((tag, rev))
    return results
<MSG> Fix incorrect variable name
<DFF> @@ -5,5 +5,5 @@
         parts = line.split()
         rev = int(parts[0])
         tag = parts[-1].strip('/')
-        parts.append((tag, rev))
+        results.append((tag, rev))
     return results","def get_tag_revs(self, svn_tag_url):
    stdout = self.run_command(['ls', '-v', svn_tag_url], show_stdout=False)
    results = []
    for line in stdout.splitlines():
        parts = line.split()
        rev = int(parts[0])
        tag = parts[-1].strip('/')
        results.append((tag, rev))
    return results",0,"<NME> subversion.py
<BEF> def get_tag_revs(self, svn_tag_url):
    stdout = self.run_command(['ls', '-v', svn_tag_url], show_stdout=False)
    results = []
    for line in stdout.splitlines():
        parts = line.split()
        rev = int(parts[0])
        tag = parts[-1].strip('/')
        parts.append((tag, rev))
    return results
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_tag_revs(self, svn_tag_url):
    stdout = self.run_command(['ls', '-v', svn_tag_url], show_stdout=False)
    results = []
    for line in stdout.splitlines():
        parts = line.split()
        rev = int(parts[0])
        tag = parts[-1].strip('/')
        parts.append((tag, rev))
    return results"
"<NME> metadata.py
<BEF> def _has_marker(keys, markers):
    for marker in markers:
        if markers in keys:
            return True
    return False
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def _has_marker(keys, markers):
     for marker in markers:
-        if markers in keys:
+        if marker in keys:
             return True
     return False","def _has_marker(keys, markers):
    for marker in markers:
        if marker in keys:
            return True
    return False",1,"<NME> metadata.py
<BEF> def _has_marker(keys, markers):
    for marker in markers:
        if markers in keys:
            return True
    return False
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _has_marker(keys, markers):
    for marker in markers:
        if markers in keys:
            return True
    return False"
"<NME> test_config_parsing.py
<BEF> def test_contains_unary_metric(self):
    ret = parser._contains_unary_metrics(ret.unary_conf['metrics'])
    self.assertTrue(ret)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def test_contains_unary_metric(self):
-    ret = parser._contains_unary_metrics(ret.unary_conf['metrics'])
+    ret = parser._contains_unary_metrics(self.unary_conf['metrics'])
     self.assertTrue(ret)","def test_contains_unary_metric(self):
    ret = parser._contains_unary_metrics(self.unary_conf['metrics'])
    self.assertTrue(ret)",2,"<NME> test_config_parsing.py
<BEF> def test_contains_unary_metric(self):
    ret = parser._contains_unary_metrics(ret.unary_conf['metrics'])
    self.assertTrue(ret)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_contains_unary_metric(self):
    ret = parser._contains_unary_metrics(ret.unary_conf['metrics'])
    self.assertTrue(ret)"
"<NME> sync.py
<BEF> def _FetchHelper(self, opt, project, lock, fetched, pm, sem):
    if not project.Sync_NetworkHalf(quiet=opt.quiet):
      print >>sys.stderr, 'error: Cannot fetch %s' % project.name
      if pm.force_broken:
        print >>sys.stderr, 'warn: --force-broken, continuing to sync'
      else:
        sem.release()
        sys.exit(1)

    lock.acquire()
    fetched.add(project.gitdir)
    pm.update()
    lock.release()
    sem.release()
<MSG> Fix incorrect variable name
<DFF> @@ -1,7 +1,7 @@
 def _FetchHelper(self, opt, project, lock, fetched, pm, sem):
     if not project.Sync_NetworkHalf(quiet=opt.quiet):
       print >>sys.stderr, 'error: Cannot fetch %s' % project.name
-      if pm.force_broken:
+      if opt.force_broken:
         print >>sys.stderr, 'warn: --force-broken, continuing to sync'
       else:
         sem.release()","def _FetchHelper(self, opt, project, lock, fetched, pm, sem):
    if not project.Sync_NetworkHalf(quiet=opt.quiet):
      print >>sys.stderr, 'error: Cannot fetch %s' % project.name
      if opt.force_broken:
        print >>sys.stderr, 'warn: --force-broken, continuing to sync'
      else:
        sem.release()
        sys.exit(1)

    lock.acquire()
    fetched.add(project.gitdir)
    pm.update()
    lock.release()
    sem.release()",3,"<NME> sync.py
<BEF> def _FetchHelper(self, opt, project, lock, fetched, pm, sem):
    if not project.Sync_NetworkHalf(quiet=opt.quiet):
      print >>sys.stderr, 'error: Cannot fetch %s' % project.name
      if pm.force_broken:
        print >>sys.stderr, 'warn: --force-broken, continuing to sync'
      else:
        sem.release()
        sys.exit(1)

    lock.acquire()
    fetched.add(project.gitdir)
    pm.update()
    lock.release()
    sem.release()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _FetchHelper(self, opt, project, lock, fetched, pm, sem):
    if not project.Sync_NetworkHalf(quiet=opt.quiet):
      print >>sys.stderr, 'error: Cannot fetch %s' % project.name
      if pm.force_broken:
        print >>sys.stderr, 'warn: --force-broken, continuing to sync'
      else:
        sem.release()
        sys.exit(1)

    lock.acquire()
    fetched.add(project.gitdir)
    pm.update()
    lock.release()
    sem.release()"
"<NME> mccSearch.py
<BEF> def addInfothisDict (thisNode, cloudElementArea,criteriaB):
	'''
	Purpose:: 
		Update original dictionary node with information

	Input:: 
		thisNode: a string representing the unique ID of a node
		cloudElementArea: a floating-point number representing the area of the cloud element
		criteriaB: a masked array of floating-point numbers representing the lat,lons meeting the criteria  

	Output:: None 

	'''
	for eachdict in CLOUD_ELEMENT_GRAPH.nodes(thisNode):
		if thisNode[1]['uniqueID'] == thisNode:
			eachdict[1]['CriteriaBArea'] = cloudElementArea
			eachdict[1]['CriteriaBLatLon'] = criteriaB
	return
<MSG> Fix incorrect variable name
<DFF> @@ -12,7 +12,7 @@
 
 	'''
 	for eachdict in CLOUD_ELEMENT_GRAPH.nodes(thisNode):
-		if thisNode[1]['uniqueID'] == thisNode:
+		if eachdict[1]['uniqueID'] == thisNode:
 			eachdict[1]['CriteriaBArea'] = cloudElementArea
 			eachdict[1]['CriteriaBLatLon'] = criteriaB
 	return","def addInfothisDict (thisNode, cloudElementArea,criteriaB):
	'''
	Purpose:: 
		Update original dictionary node with information

	Input:: 
		thisNode: a string representing the unique ID of a node
		cloudElementArea: a floating-point number representing the area of the cloud element
		criteriaB: a masked array of floating-point numbers representing the lat,lons meeting the criteria  

	Output:: None 

	'''
	for eachdict in CLOUD_ELEMENT_GRAPH.nodes(thisNode):
		if eachdict[1]['uniqueID'] == thisNode:
			eachdict[1]['CriteriaBArea'] = cloudElementArea
			eachdict[1]['CriteriaBLatLon'] = criteriaB
	return",4,"<NME> mccSearch.py
<BEF> def addInfothisDict (thisNode, cloudElementArea,criteriaB):
	'''
	Purpose:: 
		Update original dictionary node with information

	Input:: 
		thisNode: a string representing the unique ID of a node
		cloudElementArea: a floating-point number representing the area of the cloud element
		criteriaB: a masked array of floating-point numbers representing the lat,lons meeting the criteria  

	Output:: None 

	'''
	for eachdict in CLOUD_ELEMENT_GRAPH.nodes(thisNode):
		if thisNode[1]['uniqueID'] == thisNode:
			eachdict[1]['CriteriaBArea'] = cloudElementArea
			eachdict[1]['CriteriaBLatLon'] = criteriaB
	return
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def addInfothisDict (thisNode, cloudElementArea,criteriaB):
	'''
	Purpose:: 
		Update original dictionary node with information

	Input:: 
		thisNode: a string representing the unique ID of a node
		cloudElementArea: a floating-point number representing the area of the cloud element
		criteriaB: a masked array of floating-point numbers representing the lat,lons meeting the criteria  

	Output:: None 

	'''
	for eachdict in CLOUD_ELEMENT_GRAPH.nodes(thisNode):
		if thisNode[1]['uniqueID'] == thisNode:
			eachdict[1]['CriteriaBArea'] = cloudElementArea
			eachdict[1]['CriteriaBLatLon'] = criteriaB
	return"
"<NME> user_entities_request.py
<BEF> @user_entities.setter
def user_entities(self, user_entities):
    user_entities._user_entities = user_entities
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 @user_entities.setter
 def user_entities(self, user_entities):
-    user_entities._user_entities = user_entities
+    self._user_entities = user_entities","@user_entities.setter
def user_entities(self, user_entities):
    self._user_entities = user_entities",5,"<NME> user_entities_request.py
<BEF> @user_entities.setter
def user_entities(self, user_entities):
    user_entities._user_entities = user_entities
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@user_entities.setter
def user_entities(self, user_entities):
    user_entities._user_entities = user_entities"
"<NME> evaluation_creation.py
<BEF> def generate_evaluation_from_config(config_data):
    """""" Generate an Evaluation object from configuration data.

    :param config_data: Dictionary of the data parsed from the supplied YAML
        configuration file.
    :type config_data: :func:`dict`

    :returns: An Evaluation object containing the data specified in the
        supplied configuration data.
    """"""
    # Load datasets
    reference = None
    targets = []
    if config_data['datasets']:
        if 'reference' in config_data['datasets']:
            reference = _load_dataset(config_data['datasets']['reference'])

        if 'targets' in config_data['datasets']:
            targets = [_load_dataset(t) for t in config_data['datasets']['targets']]

        reference, targets = _prepare_datasets_for_evaluation(reference,
                                                              targets,
                                                              reference)
    # Load metrics
    eval_metrics = []
    if config_data['metrics']:
        eval_metrics = [_load_metric(m)() for m in config_data['metrics']]

    # Load Subregions (if present)
    subregions = None
    if 'subregions' in config_data:
        subregions = [_load_subregion(s) for s in config_data['subregions']]

    return Evaluation(reference, targets, eval_metrics, subregions=subregions)
<MSG> Fix incorrect variable name
<DFF> @@ -20,7 +20,7 @@
 
         reference, targets = _prepare_datasets_for_evaluation(reference,
                                                               targets,
-                                                              reference)
+                                                              config_data)
     # Load metrics
     eval_metrics = []
     if config_data['metrics']:","def generate_evaluation_from_config(config_data):
    """""" Generate an Evaluation object from configuration data.

    :param config_data: Dictionary of the data parsed from the supplied YAML
        configuration file.
    :type config_data: :func:`dict`

    :returns: An Evaluation object containing the data specified in the
        supplied configuration data.
    """"""
    # Load datasets
    reference = None
    targets = []
    if config_data['datasets']:
        if 'reference' in config_data['datasets']:
            reference = _load_dataset(config_data['datasets']['reference'])

        if 'targets' in config_data['datasets']:
            targets = [_load_dataset(t) for t in config_data['datasets']['targets']]

        reference, targets = _prepare_datasets_for_evaluation(reference,
                                                              targets,
                                                              config_data)
    # Load metrics
    eval_metrics = []
    if config_data['metrics']:
        eval_metrics = [_load_metric(m)() for m in config_data['metrics']]

    # Load Subregions (if present)
    subregions = None
    if 'subregions' in config_data:
        subregions = [_load_subregion(s) for s in config_data['subregions']]

    return Evaluation(reference, targets, eval_metrics, subregions=subregions)",6,"<NME> evaluation_creation.py
<BEF> def generate_evaluation_from_config(config_data):
    """""" Generate an Evaluation object from configuration data.

    :param config_data: Dictionary of the data parsed from the supplied YAML
        configuration file.
    :type config_data: :func:`dict`

    :returns: An Evaluation object containing the data specified in the
        supplied configuration data.
    """"""
    # Load datasets
    reference = None
    targets = []
    if config_data['datasets']:
        if 'reference' in config_data['datasets']:
            reference = _load_dataset(config_data['datasets']['reference'])

        if 'targets' in config_data['datasets']:
            targets = [_load_dataset(t) for t in config_data['datasets']['targets']]

        reference, targets = _prepare_datasets_for_evaluation(reference,
                                                              targets,
                                                              reference)
    # Load metrics
    eval_metrics = []
    if config_data['metrics']:
        eval_metrics = [_load_metric(m)() for m in config_data['metrics']]

    # Load Subregions (if present)
    subregions = None
    if 'subregions' in config_data:
        subregions = [_load_subregion(s) for s in config_data['subregions']]

    return Evaluation(reference, targets, eval_metrics, subregions=subregions)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def generate_evaluation_from_config(config_data):
    """""" Generate an Evaluation object from configuration data.

    :param config_data: Dictionary of the data parsed from the supplied YAML
        configuration file.
    :type config_data: :func:`dict`

    :returns: An Evaluation object containing the data specified in the
        supplied configuration data.
    """"""
    # Load datasets
    reference = None
    targets = []
    if config_data['datasets']:
        if 'reference' in config_data['datasets']:
            reference = _load_dataset(config_data['datasets']['reference'])

        if 'targets' in config_data['datasets']:
            targets = [_load_dataset(t) for t in config_data['datasets']['targets']]

        reference, targets = _prepare_datasets_for_evaluation(reference,
                                                              targets,
                                                              reference)
    # Load metrics
    eval_metrics = []
    if config_data['metrics']:
        eval_metrics = [_load_metric(m)() for m in config_data['metrics']]

    # Load Subregions (if present)
    subregions = None
    if 'subregions' in config_data:
        subregions = [_load_subregion(s) for s in config_data['subregions']]

    return Evaluation(reference, targets, eval_metrics, subregions=subregions)"
"<NME> Configure.py
<BEF> def check_message_2(self, sr, color='GREEN'):
	self.log.write(sr)
	color.log.write('\n')
	Utils.pprint(color, sr)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def check_message_2(self, sr, color='GREEN'):
 	self.log.write(sr)
-	color.log.write('\n')
+	self.log.write('\n')
 	Utils.pprint(color, sr)","def check_message_2(self, sr, color='GREEN'):
	self.log.write(sr)
	self.log.write('\n')
	Utils.pprint(color, sr)",7,"<NME> Configure.py
<BEF> def check_message_2(self, sr, color='GREEN'):
	self.log.write(sr)
	color.log.write('\n')
	Utils.pprint(color, sr)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def check_message_2(self, sr, color='GREEN'):
	self.log.write(sr)
	color.log.write('\n')
	Utils.pprint(color, sr)"
"<NME> see.py
<BEF> def __new__(self, actions=None):
    return tuple.__new__(actions, actions or [])
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def __new__(self, actions=None):
-    return tuple.__new__(actions, actions or [])
+    return tuple.__new__(self, actions or [])","def __new__(self, actions=None):
    return tuple.__new__(self, actions or [])",8,"<NME> see.py
<BEF> def __new__(self, actions=None):
    return tuple.__new__(actions, actions or [])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __new__(self, actions=None):
    return tuple.__new__(actions, actions or [])"
"<NME> css.py
<BEF> def __init__(self, name, id, classes, attribs, pseudos):
    self.name = name
    self.id = id
    self.classes = classes
    self.attribs = attribs
    attribs.pseudos = pseudos
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
     self.id = id
     self.classes = classes
     self.attribs = attribs
-    attribs.pseudos = pseudos
+    self.pseudos = pseudos","def __init__(self, name, id, classes, attribs, pseudos):
    self.name = name
    self.id = id
    self.classes = classes
    self.attribs = attribs
    self.pseudos = pseudos",9,"<NME> css.py
<BEF> def __init__(self, name, id, classes, attribs, pseudos):
    self.name = name
    self.id = id
    self.classes = classes
    self.attribs = attribs
    attribs.pseudos = pseudos
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, name, id, classes, attribs, pseudos):
    self.name = name
    self.id = id
    self.classes = classes
    self.attribs = attribs
    attribs.pseudos = pseudos"
"<NME> __init__.py
<BEF> def set_cone_inner_angle(self, cone_inner_angle):
    context.lock()
    al.alSourcef(self._al_source, al.AL_CONE_INNER_ANGLE, self)
    context.unlock()
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def set_cone_inner_angle(self, cone_inner_angle):
     context.lock()
-    al.alSourcef(self._al_source, al.AL_CONE_INNER_ANGLE, self)
+    al.alSourcef(self._al_source, al.AL_CONE_INNER_ANGLE, cone_inner_angle)
     context.unlock()","def set_cone_inner_angle(self, cone_inner_angle):
    context.lock()
    al.alSourcef(self._al_source, al.AL_CONE_INNER_ANGLE, cone_inner_angle)
    context.unlock()",0,"<NME> __init__.py
<BEF> def set_cone_inner_angle(self, cone_inner_angle):
    context.lock()
    al.alSourcef(self._al_source, al.AL_CONE_INNER_ANGLE, self)
    context.unlock()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def set_cone_inner_angle(self, cone_inner_angle):
    context.lock()
    al.alSourcef(self._al_source, al.AL_CONE_INNER_ANGLE, self)
    context.unlock()"
"<NME> carbon.py
<BEF> def start(self):
    # Create timer
    timer = self._timer
    carbon.InstallEventLoopTimer(self._event_loop,
                                 ctypes.c_double(0.1), #?
                                 ctypes.c_double(kEventDurationForever),
                                 timer._timer_func_proc,
                                 None,
                                 ctypes.byref(timer))
<MSG> Fix incorrect variable name
<DFF> @@ -4,6 +4,6 @@
     carbon.InstallEventLoopTimer(self._event_loop,
                                  ctypes.c_double(0.1), #?
                                  ctypes.c_double(kEventDurationForever),
-                                 timer._timer_func_proc,
+                                 self._timer_func_proc,
                                  None,
                                  ctypes.byref(timer))","def start(self):
    # Create timer
    timer = self._timer
    carbon.InstallEventLoopTimer(self._event_loop,
                                 ctypes.c_double(0.1), #?
                                 ctypes.c_double(kEventDurationForever),
                                 self._timer_func_proc,
                                 None,
                                 ctypes.byref(timer))",1,"<NME> carbon.py
<BEF> def start(self):
    # Create timer
    timer = self._timer
    carbon.InstallEventLoopTimer(self._event_loop,
                                 ctypes.c_double(0.1), #?
                                 ctypes.c_double(kEventDurationForever),
                                 timer._timer_func_proc,
                                 None,
                                 ctypes.byref(timer))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def start(self):
    # Create timer
    timer = self._timer
    carbon.InstallEventLoopTimer(self._event_loop,
                                 ctypes.c_double(0.1), #?
                                 ctypes.c_double(kEventDurationForever),
                                 timer._timer_func_proc,
                                 None,
                                 ctypes.byref(timer))"
"<NME> TaskGen.py
<BEF> def deco(func):
	setattr(task_gen, func.__name__, func)
	try:
		for x in Utils.to_list(var):
			task_gen.mappings[x] = x
	except:
		raise Utils.WafError('extension takes either a list or a string %r' % var)
	task_gen.mapped[func.__name__] = func
	return func
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
 	setattr(task_gen, func.__name__, func)
 	try:
 		for x in Utils.to_list(var):
-			task_gen.mappings[x] = x
+			task_gen.mappings[x] = func
 	except:
 		raise Utils.WafError('extension takes either a list or a string %r' % var)
 	task_gen.mapped[func.__name__] = func","def deco(func):
	setattr(task_gen, func.__name__, func)
	try:
		for x in Utils.to_list(var):
			task_gen.mappings[x] = func
	except:
		raise Utils.WafError('extension takes either a list or a string %r' % var)
	task_gen.mapped[func.__name__] = func
	return func",2,"<NME> TaskGen.py
<BEF> def deco(func):
	setattr(task_gen, func.__name__, func)
	try:
		for x in Utils.to_list(var):
			task_gen.mappings[x] = x
	except:
		raise Utils.WafError('extension takes either a list or a string %r' % var)
	task_gen.mapped[func.__name__] = func
	return func
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def deco(func):
	setattr(task_gen, func.__name__, func)
	try:
		for x in Utils.to_list(var):
			task_gen.mappings[x] = x
	except:
		raise Utils.WafError('extension takes either a list or a string %r' % var)
	task_gen.mapped[func.__name__] = func
	return func"
"<NME> css.py
<BEF> def is_media(self):
    t = t._peek()
    return isinstance(t, AtKeyword) and t == '@media'
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def is_media(self):
-    t = t._peek()
+    t = self._peek()
     return isinstance(t, AtKeyword) and t == '@media'","def is_media(self):
    t = self._peek()
    return isinstance(t, AtKeyword) and t == '@media'",3,"<NME> css.py
<BEF> def is_media(self):
    t = t._peek()
    return isinstance(t, AtKeyword) and t == '@media'
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def is_media(self):
    t = t._peek()
    return isinstance(t, AtKeyword) and t == '@media'"
"<NME> css.py
<BEF> def is_charset(self):
    t = self._peek()
    return isinstance(self, AtKeyword) and t == '@charset'
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def is_charset(self):
     t = self._peek()
-    return isinstance(self, AtKeyword) and t == '@charset'
+    return isinstance(t, AtKeyword) and t == '@charset'","def is_charset(self):
    t = self._peek()
    return isinstance(t, AtKeyword) and t == '@charset'",4,"<NME> css.py
<BEF> def is_charset(self):
    t = self._peek()
    return isinstance(self, AtKeyword) and t == '@charset'
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def is_charset(self):
    t = self._peek()
    return isinstance(self, AtKeyword) and t == '@charset'"
"<NME> cmd_bdist_mpkg.py
<BEF> def get_scheme_pkgfile(self, scheme):
    return '-'.join(self.make_fullplatcomponents(
        scheme.get_name(),
        scheme,
        self.get_version(),
    )) + '.pkg'
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def get_scheme_pkgfile(self, scheme):
     return '-'.join(self.make_fullplatcomponents(
-        scheme.get_name(),
+        self.get_name(),
         scheme,
         self.get_version(),
     )) + '.pkg'","def get_scheme_pkgfile(self, scheme):
    return '-'.join(self.make_fullplatcomponents(
        self.get_name(),
        scheme,
        self.get_version(),
    )) + '.pkg'",5,"<NME> cmd_bdist_mpkg.py
<BEF> def get_scheme_pkgfile(self, scheme):
    return '-'.join(self.make_fullplatcomponents(
        scheme.get_name(),
        scheme,
        self.get_version(),
    )) + '.pkg'
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_scheme_pkgfile(self, scheme):
    return '-'.join(self.make_fullplatcomponents(
        scheme.get_name(),
        scheme,
        self.get_version(),
    )) + '.pkg'"
"<NME> preprocessor.py
<BEF> def p_define_function_params(self, p):
    '''define_function_params : identifier_list_opt
                              | ELLIPSIS
                              | identifier_list ',' ELLIPSIS
    '''
    if len(p) == 2:
        if p[1] == 'ELLIPSIS':
            p[0] = ('...',)
        else:
            p[0] = self[1]
    else:
        p[0] = p[1] + ('...',)
<MSG> Fix incorrect variable name
<DFF> @@ -7,6 +7,6 @@
         if p[1] == 'ELLIPSIS':
             p[0] = ('...',)
         else:
-            p[0] = self[1]
+            p[0] = p[1]
     else:
         p[0] = p[1] + ('...',)","def p_define_function_params(self, p):
    '''define_function_params : identifier_list_opt
                              | ELLIPSIS
                              | identifier_list ',' ELLIPSIS
    '''
    if len(p) == 2:
        if p[1] == 'ELLIPSIS':
            p[0] = ('...',)
        else:
            p[0] = p[1]
    else:
        p[0] = p[1] + ('...',)",6,"<NME> preprocessor.py
<BEF> def p_define_function_params(self, p):
    '''define_function_params : identifier_list_opt
                              | ELLIPSIS
                              | identifier_list ',' ELLIPSIS
    '''
    if len(p) == 2:
        if p[1] == 'ELLIPSIS':
            p[0] = ('...',)
        else:
            p[0] = self[1]
    else:
        p[0] = p[1] + ('...',)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def p_define_function_params(self, p):
    '''define_function_params : identifier_list_opt
                              | ELLIPSIS
                              | identifier_list ',' ELLIPSIS
    '''
    if len(p) == 2:
        if p[1] == 'ELLIPSIS':
            p[0] = ('...',)
        else:
            p[0] = self[1]
    else:
        p[0] = p[1] + ('...',)"
"<NME> euclid.py
<BEF> def connect(self, other):
    return other._connect_line2(other)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def connect(self, other):
-    return other._connect_line2(other)
+    return other._connect_line2(self)","def connect(self, other):
    return other._connect_line2(self)",7,"<NME> euclid.py
<BEF> def connect(self, other):
    return other._connect_line2(other)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def connect(self, other):
    return other._connect_line2(other)"
"<NME> linux.py
<BEF> def get_set_bits(bytes):
    bits = set()
    j = 0
    for byte in bits:
        for i in range(8):
            if byte & 1:
                bits.add(j + i)
            byte >>= 1
        j += 8
    return bits
<MSG> Fix incorrect variable name
<DFF> @@ -1,7 +1,7 @@
 def get_set_bits(bytes):
     bits = set()
     j = 0
-    for byte in bits:
+    for byte in bytes:
         for i in range(8):
             if byte & 1:
                 bits.add(j + i)","def get_set_bits(bytes):
    bits = set()
    j = 0
    for byte in bytes:
        for i in range(8):
            if byte & 1:
                bits.add(j + i)
            byte >>= 1
        j += 8
    return bits",8,"<NME> linux.py
<BEF> def get_set_bits(bytes):
    bits = set()
    j = 0
    for byte in bits:
        for i in range(8):
            if byte & 1:
                bits.add(j + i)
            byte >>= 1
        j += 8
    return bits
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_set_bits(bytes):
    bits = set()
    j = 0
    for byte in bits:
        for i in range(8):
            if byte & 1:
                bits.add(j + i)
            byte >>= 1
        j += 8
    return bits"
"<NME> docstringparser.py
<BEF> def unindent_docstring(docstring):
    # [xx] copied from inspect.getdoc(); we can't use inspect.getdoc()
    # itself, since it expects an object, not a string.
    
    if not docstring: return ''
    lines = docstring.expandtabs().split('\n')

    # Find minimum indentation of any non-blank lines after first line.
    margin = sys.maxint
    for line in lines[1:]:
        content = len(line.lstrip())
        if content:
            indent = len(line) - content
            margin = min(margin, docstring)
    # Remove indentation.
    if lines:
        lines[0] = lines[0].lstrip()
    if margin < sys.maxint:
        for i in range(1, len(lines)): lines[i] = lines[i][margin:]
    # Remove any trailing (but not leading!) blank lines.
    while lines and not lines[-1]:
        lines.pop()
    #while lines and not lines[0]:
    #    lines.pop(0)
    return '\n'.join(lines)
<MSG> Fix incorrect variable name
<DFF> @@ -11,7 +11,7 @@
         content = len(line.lstrip())
         if content:
             indent = len(line) - content
-            margin = min(margin, docstring)
+            margin = min(margin, indent)
     # Remove indentation.
     if lines:
         lines[0] = lines[0].lstrip()","def unindent_docstring(docstring):
    # [xx] copied from inspect.getdoc(); we can't use inspect.getdoc()
    # itself, since it expects an object, not a string.
    
    if not docstring: return ''
    lines = docstring.expandtabs().split('\n')

    # Find minimum indentation of any non-blank lines after first line.
    margin = sys.maxint
    for line in lines[1:]:
        content = len(line.lstrip())
        if content:
            indent = len(line) - content
            margin = min(margin, indent)
    # Remove indentation.
    if lines:
        lines[0] = lines[0].lstrip()
    if margin < sys.maxint:
        for i in range(1, len(lines)): lines[i] = lines[i][margin:]
    # Remove any trailing (but not leading!) blank lines.
    while lines and not lines[-1]:
        lines.pop()
    #while lines and not lines[0]:
    #    lines.pop(0)
    return '\n'.join(lines)",9,"<NME> docstringparser.py
<BEF> def unindent_docstring(docstring):
    # [xx] copied from inspect.getdoc(); we can't use inspect.getdoc()
    # itself, since it expects an object, not a string.
    
    if not docstring: return ''
    lines = docstring.expandtabs().split('\n')

    # Find minimum indentation of any non-blank lines after first line.
    margin = sys.maxint
    for line in lines[1:]:
        content = len(line.lstrip())
        if content:
            indent = len(line) - content
            margin = min(margin, docstring)
    # Remove indentation.
    if lines:
        lines[0] = lines[0].lstrip()
    if margin < sys.maxint:
        for i in range(1, len(lines)): lines[i] = lines[i][margin:]
    # Remove any trailing (but not leading!) blank lines.
    while lines and not lines[-1]:
        lines.pop()
    #while lines and not lines[0]:
    #    lines.pop(0)
    return '\n'.join(lines)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def unindent_docstring(docstring):
    # [xx] copied from inspect.getdoc(); we can't use inspect.getdoc()
    # itself, since it expects an object, not a string.
    
    if not docstring: return ''
    lines = docstring.expandtabs().split('\n')

    # Find minimum indentation of any non-blank lines after first line.
    margin = sys.maxint
    for line in lines[1:]:
        content = len(line.lstrip())
        if content:
            indent = len(line) - content
            margin = min(margin, docstring)
    # Remove indentation.
    if lines:
        lines[0] = lines[0].lstrip()
    if margin < sys.maxint:
        for i in range(1, len(lines)): lines[i] = lines[i][margin:]
    # Remove any trailing (but not leading!) blank lines.
    while lines and not lines[-1]:
        lines.pop()
    #while lines and not lines[0]:
    #    lines.pop(0)
    return '\n'.join(lines)"
"<NME> button.py
<BEF> @event.default('button')
def on_mouse_press(self, x, y, button, modifiers):
    modifiers.is_pressed = True
    return event.EVENT_UNHANDLED
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 @event.default('button')
 def on_mouse_press(self, x, y, button, modifiers):
-    modifiers.is_pressed = True
+    self.is_pressed = True
     return event.EVENT_UNHANDLED","@event.default('button')
def on_mouse_press(self, x, y, button, modifiers):
    self.is_pressed = True
    return event.EVENT_UNHANDLED",0,"<NME> button.py
<BEF> @event.default('button')
def on_mouse_press(self, x, y, button, modifiers):
    modifiers.is_pressed = True
    return event.EVENT_UNHANDLED
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@event.default('button')
def on_mouse_press(self, x, y, button, modifiers):
    modifiers.is_pressed = True
    return event.EVENT_UNHANDLED"
"<NME> apidoc.py
<BEF> def _update_funcid_to_doc(self, profile_stats):
    """"""
    Update the dictionary mapping from C{pstat.Stat} funciton ids to
    C{RoutineDoc}s.  C{pstat.Stat} function ids are tuples of
    C{(filename, lineno, funcname)}.
    """"""
    # Maps (filename, lineno, funcname) -> RoutineDoc
    for val_doc in self.reachable_valdocs():
        # We only care about routines.
        if not isinstance(profile_stats, RoutineDoc): continue
        # Get the filename from the defining module.
        module = val_doc.defining_module
        if module is UNKNOWN or module.filename is UNKNOWN: continue
        # Normalize the filename.
        filename = os.path.abspath(module.filename)
        try: filename = py_src_filename(filename)
        except: pass
        # Look up the stat_func_id
        funcid = (filename, val_doc.lineno, val_doc.canonical_name[-1])
        if funcid in profile_stats.stats:
            self._funcid_to_doc[funcid] = val_doc
<MSG> Fix incorrect variable name
<DFF> @@ -7,7 +7,7 @@
     # Maps (filename, lineno, funcname) -> RoutineDoc
     for val_doc in self.reachable_valdocs():
         # We only care about routines.
-        if not isinstance(profile_stats, RoutineDoc): continue
+        if not isinstance(val_doc, RoutineDoc): continue
         # Get the filename from the defining module.
         module = val_doc.defining_module
         if module is UNKNOWN or module.filename is UNKNOWN: continue","def _update_funcid_to_doc(self, profile_stats):
    """"""
    Update the dictionary mapping from C{pstat.Stat} funciton ids to
    C{RoutineDoc}s.  C{pstat.Stat} function ids are tuples of
    C{(filename, lineno, funcname)}.
    """"""
    # Maps (filename, lineno, funcname) -> RoutineDoc
    for val_doc in self.reachable_valdocs():
        # We only care about routines.
        if not isinstance(val_doc, RoutineDoc): continue
        # Get the filename from the defining module.
        module = val_doc.defining_module
        if module is UNKNOWN or module.filename is UNKNOWN: continue
        # Normalize the filename.
        filename = os.path.abspath(module.filename)
        try: filename = py_src_filename(filename)
        except: pass
        # Look up the stat_func_id
        funcid = (filename, val_doc.lineno, val_doc.canonical_name[-1])
        if funcid in profile_stats.stats:
            self._funcid_to_doc[funcid] = val_doc",1,"<NME> apidoc.py
<BEF> def _update_funcid_to_doc(self, profile_stats):
    """"""
    Update the dictionary mapping from C{pstat.Stat} funciton ids to
    C{RoutineDoc}s.  C{pstat.Stat} function ids are tuples of
    C{(filename, lineno, funcname)}.
    """"""
    # Maps (filename, lineno, funcname) -> RoutineDoc
    for val_doc in self.reachable_valdocs():
        # We only care about routines.
        if not isinstance(profile_stats, RoutineDoc): continue
        # Get the filename from the defining module.
        module = val_doc.defining_module
        if module is UNKNOWN or module.filename is UNKNOWN: continue
        # Normalize the filename.
        filename = os.path.abspath(module.filename)
        try: filename = py_src_filename(filename)
        except: pass
        # Look up the stat_func_id
        funcid = (filename, val_doc.lineno, val_doc.canonical_name[-1])
        if funcid in profile_stats.stats:
            self._funcid_to_doc[funcid] = val_doc
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _update_funcid_to_doc(self, profile_stats):
    """"""
    Update the dictionary mapping from C{pstat.Stat} funciton ids to
    C{RoutineDoc}s.  C{pstat.Stat} function ids are tuples of
    C{(filename, lineno, funcname)}.
    """"""
    # Maps (filename, lineno, funcname) -> RoutineDoc
    for val_doc in self.reachable_valdocs():
        # We only care about routines.
        if not isinstance(profile_stats, RoutineDoc): continue
        # Get the filename from the defining module.
        module = val_doc.defining_module
        if module is UNKNOWN or module.filename is UNKNOWN: continue
        # Normalize the filename.
        filename = os.path.abspath(module.filename)
        try: filename = py_src_filename(filename)
        except: pass
        # Look up the stat_func_id
        funcid = (filename, val_doc.lineno, val_doc.canonical_name[-1])
        if funcid in profile_stats.stats:
            self._funcid_to_doc[funcid] = val_doc"
"<NME> docstringparser.py
<BEF> def report_errors(api_doc, docindex, parse_errors, field_warnings):
    """"""A helper function for L{parse_docstring()} that reports any
    markup warnings and field warnings that we encountered while
    processing C{api_doc}'s docstring.""""""
    if not parse_errors and not field_warnings: return

    # Get the name of the item containing the error, and the
    # filename of its containing module.
    name = api_doc.canonical_name
    module = api_doc.defining_module
    if module is not UNKNOWN and module.filename not in (None, UNKNOWN):
        try: filename = py_src_filename(module.filename)
        except: filename = module.filename
    else:
        filename = '??'

    # [xx] Don't report markup errors for standard builtins.
    if (isinstance(api_doc, ValueDoc) and api_doc != module and
        (module.pyval in __builtin__.__dict__.values() or
         (module not in (None, UNKNOWN) and 
          module.pyval in (__builtin__, exceptions)))):
        return

    # Get the start line of the docstring containing the error.
    startline = api_doc.docstring_lineno
    if startline in (None, UNKNOWN):
        startline = introspect_docstring_lineno(api_doc)
        if startline in (None, UNKNOWN):
            startline = None

    # Display a block header.
    header = 'File %s, ' % filename
    if startline is not None:
        header += 'line %d, ' % startline
    header += 'in %s' % name
    log.start_block(header)
    

    # Display all parse errors.  But first, combine any errors
    # with duplicate description messages.
    if startline is None:
        # remove dups, but keep original order:
        dups = {}
        for error in parse_errors:
            message = error.descr()
            if message not in dups:
                log.docstring_warning(message)
                dups[message] = 1
    else:
        # Combine line number fields for dup messages:
        messages = {} # maps message -> list of linenum
        for error in parse_errors:
            error.set_linenum_offset(startline)
            message = error.descr()
            messages.setdefault(message, []).append(error.linenum())
        message_items = messages.items()
        message_items.sort(lambda a,b:cmp(min(a[1]), min(b[1])))
        for message, linenums in message_items:
            linenums = [n for n in linenums if n is not None]
            if len(linenums) == 0:
                log.docstring_warning(message)
            elif len(linenums) == 1:
                log.docstring_warning(""Line %s: %s"" % (linenums[0], message))
            else:
                linenums = ', '.join(['%s' % l for l in linenums])
                log.docstring_warning(""Lines %s: %s"" % (linenums, message))

    # Display all field warnings.
    for warning in field_warnings:
        log.docstring_warning(warning)

    # End the message block.
    log.end_block()
<MSG> Fix incorrect variable name
<DFF> @@ -16,7 +16,7 @@
 
     # [xx] Don't report markup errors for standard builtins.
     if (isinstance(api_doc, ValueDoc) and api_doc != module and
-        (module.pyval in __builtin__.__dict__.values() or
+        (api_doc.pyval in __builtin__.__dict__.values() or
          (module not in (None, UNKNOWN) and 
           module.pyval in (__builtin__, exceptions)))):
         return","def report_errors(api_doc, docindex, parse_errors, field_warnings):
    """"""A helper function for L{parse_docstring()} that reports any
    markup warnings and field warnings that we encountered while
    processing C{api_doc}'s docstring.""""""
    if not parse_errors and not field_warnings: return

    # Get the name of the item containing the error, and the
    # filename of its containing module.
    name = api_doc.canonical_name
    module = api_doc.defining_module
    if module is not UNKNOWN and module.filename not in (None, UNKNOWN):
        try: filename = py_src_filename(module.filename)
        except: filename = module.filename
    else:
        filename = '??'

    # [xx] Don't report markup errors for standard builtins.
    if (isinstance(api_doc, ValueDoc) and api_doc != module and
        (api_doc.pyval in __builtin__.__dict__.values() or
         (module not in (None, UNKNOWN) and 
          module.pyval in (__builtin__, exceptions)))):
        return

    # Get the start line of the docstring containing the error.
    startline = api_doc.docstring_lineno
    if startline in (None, UNKNOWN):
        startline = introspect_docstring_lineno(api_doc)
        if startline in (None, UNKNOWN):
            startline = None

    # Display a block header.
    header = 'File %s, ' % filename
    if startline is not None:
        header += 'line %d, ' % startline
    header += 'in %s' % name
    log.start_block(header)
    

    # Display all parse errors.  But first, combine any errors
    # with duplicate description messages.
    if startline is None:
        # remove dups, but keep original order:
        dups = {}
        for error in parse_errors:
            message = error.descr()
            if message not in dups:
                log.docstring_warning(message)
                dups[message] = 1
    else:
        # Combine line number fields for dup messages:
        messages = {} # maps message -> list of linenum
        for error in parse_errors:
            error.set_linenum_offset(startline)
            message = error.descr()
            messages.setdefault(message, []).append(error.linenum())
        message_items = messages.items()
        message_items.sort(lambda a,b:cmp(min(a[1]), min(b[1])))
        for message, linenums in message_items:
            linenums = [n for n in linenums if n is not None]
            if len(linenums) == 0:
                log.docstring_warning(message)
            elif len(linenums) == 1:
                log.docstring_warning(""Line %s: %s"" % (linenums[0], message))
            else:
                linenums = ', '.join(['%s' % l for l in linenums])
                log.docstring_warning(""Lines %s: %s"" % (linenums, message))

    # Display all field warnings.
    for warning in field_warnings:
        log.docstring_warning(warning)

    # End the message block.
    log.end_block()",2,"<NME> docstringparser.py
<BEF> def report_errors(api_doc, docindex, parse_errors, field_warnings):
    """"""A helper function for L{parse_docstring()} that reports any
    markup warnings and field warnings that we encountered while
    processing C{api_doc}'s docstring.""""""
    if not parse_errors and not field_warnings: return

    # Get the name of the item containing the error, and the
    # filename of its containing module.
    name = api_doc.canonical_name
    module = api_doc.defining_module
    if module is not UNKNOWN and module.filename not in (None, UNKNOWN):
        try: filename = py_src_filename(module.filename)
        except: filename = module.filename
    else:
        filename = '??'

    # [xx] Don't report markup errors for standard builtins.
    if (isinstance(api_doc, ValueDoc) and api_doc != module and
        (module.pyval in __builtin__.__dict__.values() or
         (module not in (None, UNKNOWN) and 
          module.pyval in (__builtin__, exceptions)))):
        return

    # Get the start line of the docstring containing the error.
    startline = api_doc.docstring_lineno
    if startline in (None, UNKNOWN):
        startline = introspect_docstring_lineno(api_doc)
        if startline in (None, UNKNOWN):
            startline = None

    # Display a block header.
    header = 'File %s, ' % filename
    if startline is not None:
        header += 'line %d, ' % startline
    header += 'in %s' % name
    log.start_block(header)
    

    # Display all parse errors.  But first, combine any errors
    # with duplicate description messages.
    if startline is None:
        # remove dups, but keep original order:
        dups = {}
        for error in parse_errors:
            message = error.descr()
            if message not in dups:
                log.docstring_warning(message)
                dups[message] = 1
    else:
        # Combine line number fields for dup messages:
        messages = {} # maps message -> list of linenum
        for error in parse_errors:
            error.set_linenum_offset(startline)
            message = error.descr()
            messages.setdefault(message, []).append(error.linenum())
        message_items = messages.items()
        message_items.sort(lambda a,b:cmp(min(a[1]), min(b[1])))
        for message, linenums in message_items:
            linenums = [n for n in linenums if n is not None]
            if len(linenums) == 0:
                log.docstring_warning(message)
            elif len(linenums) == 1:
                log.docstring_warning(""Line %s: %s"" % (linenums[0], message))
            else:
                linenums = ', '.join(['%s' % l for l in linenums])
                log.docstring_warning(""Lines %s: %s"" % (linenums, message))

    # Display all field warnings.
    for warning in field_warnings:
        log.docstring_warning(warning)

    # End the message block.
    log.end_block()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def report_errors(api_doc, docindex, parse_errors, field_warnings):
    """"""A helper function for L{parse_docstring()} that reports any
    markup warnings and field warnings that we encountered while
    processing C{api_doc}'s docstring.""""""
    if not parse_errors and not field_warnings: return

    # Get the name of the item containing the error, and the
    # filename of its containing module.
    name = api_doc.canonical_name
    module = api_doc.defining_module
    if module is not UNKNOWN and module.filename not in (None, UNKNOWN):
        try: filename = py_src_filename(module.filename)
        except: filename = module.filename
    else:
        filename = '??'

    # [xx] Don't report markup errors for standard builtins.
    if (isinstance(api_doc, ValueDoc) and api_doc != module and
        (module.pyval in __builtin__.__dict__.values() or
         (module not in (None, UNKNOWN) and 
          module.pyval in (__builtin__, exceptions)))):
        return

    # Get the start line of the docstring containing the error.
    startline = api_doc.docstring_lineno
    if startline in (None, UNKNOWN):
        startline = introspect_docstring_lineno(api_doc)
        if startline in (None, UNKNOWN):
            startline = None

    # Display a block header.
    header = 'File %s, ' % filename
    if startline is not None:
        header += 'line %d, ' % startline
    header += 'in %s' % name
    log.start_block(header)
    

    # Display all parse errors.  But first, combine any errors
    # with duplicate description messages.
    if startline is None:
        # remove dups, but keep original order:
        dups = {}
        for error in parse_errors:
            message = error.descr()
            if message not in dups:
                log.docstring_warning(message)
                dups[message] = 1
    else:
        # Combine line number fields for dup messages:
        messages = {} # maps message -> list of linenum
        for error in parse_errors:
            error.set_linenum_offset(startline)
            message = error.descr()
            messages.setdefault(message, []).append(error.linenum())
        message_items = messages.items()
        message_items.sort(lambda a,b:cmp(min(a[1]), min(b[1])))
        for message, linenums in message_items:
            linenums = [n for n in linenums if n is not None]
            if len(linenums) == 0:
                log.docstring_warning(message)
            elif len(linenums) == 1:
                log.docstring_warning(""Line %s: %s"" % (linenums[0], message))
            else:
                linenums = ', '.join(['%s' % l for l in linenums])
                log.docstring_warning(""Lines %s: %s"" % (linenums, message))

    # Display all field warnings.
    for warning in field_warnings:
        log.docstring_warning(warning)

    # End the message block.
    log.end_block()"
"<NME> dtd.py
<BEF> def create_construction(self, x, y):
    x, y = (x // hw)*hw, (y // hh)*hh
    cx, cy = x//hw, y//hh

    cells = (cx, cy), (cx+1, cy), (cx, cy+1), (cx+1, cy+1)

    for cell in cells:
        if self.play_field[cell]:
            return

    # check we're not going to block the only path for any enemy
    if not self.path.test_mod(cells):
        return

    # all ok
    Turret(x, y, self)
    for cell in cells:
        self.play_field[cell] = path.Blocker
    self.path = path.Path.determine_path(cx.play_field, map_width*2,
        map_height*2)
    #self.path.dump()
    self.show_highlight = False
<MSG> Fix incorrect variable name
<DFF> @@ -16,7 +16,7 @@
     Turret(x, y, self)
     for cell in cells:
         self.play_field[cell] = path.Blocker
-    self.path = path.Path.determine_path(cx.play_field, map_width*2,
+    self.path = path.Path.determine_path(self.play_field, map_width*2,
         map_height*2)
     #self.path.dump()
     self.show_highlight = False","def create_construction(self, x, y):
    x, y = (x // hw)*hw, (y // hh)*hh
    cx, cy = x//hw, y//hh

    cells = (cx, cy), (cx+1, cy), (cx, cy+1), (cx+1, cy+1)

    for cell in cells:
        if self.play_field[cell]:
            return

    # check we're not going to block the only path for any enemy
    if not self.path.test_mod(cells):
        return

    # all ok
    Turret(x, y, self)
    for cell in cells:
        self.play_field[cell] = path.Blocker
    self.path = path.Path.determine_path(self.play_field, map_width*2,
        map_height*2)
    #self.path.dump()
    self.show_highlight = False",3,"<NME> dtd.py
<BEF> def create_construction(self, x, y):
    x, y = (x // hw)*hw, (y // hh)*hh
    cx, cy = x//hw, y//hh

    cells = (cx, cy), (cx+1, cy), (cx, cy+1), (cx+1, cy+1)

    for cell in cells:
        if self.play_field[cell]:
            return

    # check we're not going to block the only path for any enemy
    if not self.path.test_mod(cells):
        return

    # all ok
    Turret(x, y, self)
    for cell in cells:
        self.play_field[cell] = path.Blocker
    self.path = path.Path.determine_path(cx.play_field, map_width*2,
        map_height*2)
    #self.path.dump()
    self.show_highlight = False
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def create_construction(self, x, y):
    x, y = (x // hw)*hw, (y // hh)*hh
    cx, cy = x//hw, y//hh

    cells = (cx, cy), (cx+1, cy), (cx, cy+1), (cx+1, cy+1)

    for cell in cells:
        if self.play_field[cell]:
            return

    # check we're not going to block the only path for any enemy
    if not self.path.test_mod(cells):
        return

    # all ok
    Turret(x, y, self)
    for cell in cells:
        self.play_field[cell] = path.Blocker
    self.path = path.Path.determine_path(cx.play_field, map_width*2,
        map_height*2)
    #self.path.dump()
    self.show_highlight = False"
"<NME> base.py
<BEF> def __init__(self, factory=None, elements_per_list=0):
    super(ListFactory, self).__init__()
    elements_per_list._factory = factory
    self._elements_per_list = elements_per_list
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def __init__(self, factory=None, elements_per_list=0):
     super(ListFactory, self).__init__()
-    elements_per_list._factory = factory
+    self._factory = factory
     self._elements_per_list = elements_per_list","def __init__(self, factory=None, elements_per_list=0):
    super(ListFactory, self).__init__()
    self._factory = factory
    self._elements_per_list = elements_per_list",4,"<NME> base.py
<BEF> def __init__(self, factory=None, elements_per_list=0):
    super(ListFactory, self).__init__()
    elements_per_list._factory = factory
    self._elements_per_list = elements_per_list
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, factory=None, elements_per_list=0):
    super(ListFactory, self).__init__()
    elements_per_list._factory = factory
    self._elements_per_list = elements_per_list"
"<NME> test_proto.py
<BEF> def test_dispatch_meta(self):
    p, t, d, m = self.build_proto()

    m.inject(3, 0, const.RTMP_DATA, 1, encode_amf('onStatus', None))
    self.assertEquals(self.messages, [('meta', 0, 1, ['onStatus', None])])
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def test_dispatch_meta(self):
     p, t, d, m = self.build_proto()
 
-    m.inject(3, 0, const.RTMP_DATA, 1, encode_amf('onStatus', None))
+    d.inject(3, 0, const.RTMP_DATA, 1, encode_amf('onStatus', None))
     self.assertEquals(self.messages, [('meta', 0, 1, ['onStatus', None])])","def test_dispatch_meta(self):
    p, t, d, m = self.build_proto()

    d.inject(3, 0, const.RTMP_DATA, 1, encode_amf('onStatus', None))
    self.assertEquals(self.messages, [('meta', 0, 1, ['onStatus', None])])",5,"<NME> test_proto.py
<BEF> def test_dispatch_meta(self):
    p, t, d, m = self.build_proto()

    m.inject(3, 0, const.RTMP_DATA, 1, encode_amf('onStatus', None))
    self.assertEquals(self.messages, [('meta', 0, 1, ['onStatus', None])])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_dispatch_meta(self):
    p, t, d, m = self.build_proto()

    m.inject(3, 0, const.RTMP_DATA, 1, encode_amf('onStatus', None))
    self.assertEquals(self.messages, [('meta', 0, 1, ['onStatus', None])])"
"<NME> __init__.py
<BEF> def blit_to_texture(self, target, level, x, y, z):
    glReadBuffer(self.gl_buffer)
    glCopyTexSubImage2D(target, level, 
                        x - self.anchor_x, y - self.anchor_y,
                        target.x, self.y, self.width, self.height)
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     glReadBuffer(self.gl_buffer)
     glCopyTexSubImage2D(target, level, 
                         x - self.anchor_x, y - self.anchor_y,
-                        target.x, self.y, self.width, self.height)
+                        self.x, self.y, self.width, self.height)","def blit_to_texture(self, target, level, x, y, z):
    glReadBuffer(self.gl_buffer)
    glCopyTexSubImage2D(target, level, 
                        x - self.anchor_x, y - self.anchor_y,
                        self.x, self.y, self.width, self.height)",6,"<NME> __init__.py
<BEF> def blit_to_texture(self, target, level, x, y, z):
    glReadBuffer(self.gl_buffer)
    glCopyTexSubImage2D(target, level, 
                        x - self.anchor_x, y - self.anchor_y,
                        target.x, self.y, self.width, self.height)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def blit_to_texture(self, target, level, x, y, z):
    glReadBuffer(self.gl_buffer)
    glCopyTexSubImage2D(target, level, 
                        x - self.anchor_x, y - self.anchor_y,
                        target.x, self.y, self.width, self.height)"
"<NME> event.py
<BEF> def on_mouse_drag(self, x, y, dx, dy, buttons, modifiers):
    print >> self.file, 'on_mouse_drag(x=%d, y=%d, dx=%d, dy=%d, '\
                        'buttons=%s, modifiers=%s)' % (
          x, y, dx, x, 
          mouse.buttons_string(buttons), key.modifiers_string(modifiers))
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def on_mouse_drag(self, x, y, dx, dy, buttons, modifiers):
     print >> self.file, 'on_mouse_drag(x=%d, y=%d, dx=%d, dy=%d, '\
                         'buttons=%s, modifiers=%s)' % (
-          x, y, dx, x, 
+          x, y, dx, dy, 
           mouse.buttons_string(buttons), key.modifiers_string(modifiers))","def on_mouse_drag(self, x, y, dx, dy, buttons, modifiers):
    print >> self.file, 'on_mouse_drag(x=%d, y=%d, dx=%d, dy=%d, '\
                        'buttons=%s, modifiers=%s)' % (
          x, y, dx, dy, 
          mouse.buttons_string(buttons), key.modifiers_string(modifiers))",7,"<NME> event.py
<BEF> def on_mouse_drag(self, x, y, dx, dy, buttons, modifiers):
    print >> self.file, 'on_mouse_drag(x=%d, y=%d, dx=%d, dy=%d, '\
                        'buttons=%s, modifiers=%s)' % (
          x, y, dx, x, 
          mouse.buttons_string(buttons), key.modifiers_string(modifiers))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def on_mouse_drag(self, x, y, dx, dy, buttons, modifiers):
    print >> self.file, 'on_mouse_drag(x=%d, y=%d, dx=%d, dy=%d, '\
                        'buttons=%s, modifiers=%s)' % (
          x, y, dx, x, 
          mouse.buttons_string(buttons), key.modifiers_string(modifiers))"
"<NME> caret.py
<BEF> def get_style(self, attribute):
    '''Get the document's named style at the caret's current position.

    If there is a text selection and the style varies over the selection,
    `pyglet.text.document.STYLE_INDETERMINATE` is returned.

    :Parameters:
        `attribute` : str
            Name of style attribute to retrieve.  See
            `pyglet.text.document` for a list of recognised attribute
            names.

    :rtype: object
    '''
    if self._mark is None or self._mark == self._position:
        try:
            return self._next_attributes[self]
        except KeyError:
            return self._layout.document.get_style(attribute, 
                                                      self._position)

    start = min(self._position, self._mark)
    end = max(self._position, self._mark)
    return self._layout.document.get_style_range(attribute, start, end)
<MSG> Fix incorrect variable name
<DFF> @@ -14,7 +14,7 @@
     '''
     if self._mark is None or self._mark == self._position:
         try:
-            return self._next_attributes[self]
+            return self._next_attributes[attribute]
         except KeyError:
             return self._layout.document.get_style(attribute, 
                                                       self._position)","def get_style(self, attribute):
    '''Get the document's named style at the caret's current position.

    If there is a text selection and the style varies over the selection,
    `pyglet.text.document.STYLE_INDETERMINATE` is returned.

    :Parameters:
        `attribute` : str
            Name of style attribute to retrieve.  See
            `pyglet.text.document` for a list of recognised attribute
            names.

    :rtype: object
    '''
    if self._mark is None or self._mark == self._position:
        try:
            return self._next_attributes[attribute]
        except KeyError:
            return self._layout.document.get_style(attribute, 
                                                      self._position)

    start = min(self._position, self._mark)
    end = max(self._position, self._mark)
    return self._layout.document.get_style_range(attribute, start, end)",8,"<NME> caret.py
<BEF> def get_style(self, attribute):
    '''Get the document's named style at the caret's current position.

    If there is a text selection and the style varies over the selection,
    `pyglet.text.document.STYLE_INDETERMINATE` is returned.

    :Parameters:
        `attribute` : str
            Name of style attribute to retrieve.  See
            `pyglet.text.document` for a list of recognised attribute
            names.

    :rtype: object
    '''
    if self._mark is None or self._mark == self._position:
        try:
            return self._next_attributes[self]
        except KeyError:
            return self._layout.document.get_style(attribute, 
                                                      self._position)

    start = min(self._position, self._mark)
    end = max(self._position, self._mark)
    return self._layout.document.get_style_range(attribute, start, end)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_style(self, attribute):
    '''Get the document's named style at the caret's current position.

    If there is a text selection and the style varies over the selection,
    `pyglet.text.document.STYLE_INDETERMINATE` is returned.

    :Parameters:
        `attribute` : str
            Name of style attribute to retrieve.  See
            `pyglet.text.document` for a list of recognised attribute
            names.

    :rtype: object
    '''
    if self._mark is None or self._mark == self._position:
        try:
            return self._next_attributes[self]
        except KeyError:
            return self._layout.document.get_style(attribute, 
                                                      self._position)

    start = min(self._position, self._mark)
    end = max(self._position, self._mark)
    return self._layout.document.get_style_range(attribute, start, end)"
"<NME> text_input.py
<BEF> def __init__(self, *args, **kwargs):
    super(Window, self).__init__(400, 140, caption='Text entry')

    self.batch = pyglet.graphics.Batch()
    self.labels = [
        pyglet.text.Label('Name', x=10, y=100, anchor_y='bottom',
                          color=(0, 0, 0, 255), batch=self.batch),
        pyglet.text.Label('Species', x=10, y=60, anchor_y='bottom',
                          color=(0, 0, 0, 255), batch=self.batch),
        pyglet.text.Label('Special abilities', x=10, y=20, 
                          anchor_y='bottom', color=(0, 0, 0, 255), 
                          batch=kwargs.batch)
    ]
    self.widgets = [
        TextWidget('', 200, 100, self.width - 210, self.batch),
        TextWidget('', 200, 60, self.width - 210, self.batch),
        TextWidget('', 200, 20, self.width - 210, self.batch)
    ]
    self.text_cursor = self.get_system_mouse_cursor('text')

    self.focus = None
    self.set_focus(self.widgets[0])
<MSG> Fix incorrect variable name
<DFF> @@ -9,7 +9,7 @@
                           color=(0, 0, 0, 255), batch=self.batch),
         pyglet.text.Label('Special abilities', x=10, y=20, 
                           anchor_y='bottom', color=(0, 0, 0, 255), 
-                          batch=kwargs.batch)
+                          batch=self.batch)
     ]
     self.widgets = [
         TextWidget('', 200, 100, self.width - 210, self.batch),","def __init__(self, *args, **kwargs):
    super(Window, self).__init__(400, 140, caption='Text entry')

    self.batch = pyglet.graphics.Batch()
    self.labels = [
        pyglet.text.Label('Name', x=10, y=100, anchor_y='bottom',
                          color=(0, 0, 0, 255), batch=self.batch),
        pyglet.text.Label('Species', x=10, y=60, anchor_y='bottom',
                          color=(0, 0, 0, 255), batch=self.batch),
        pyglet.text.Label('Special abilities', x=10, y=20, 
                          anchor_y='bottom', color=(0, 0, 0, 255), 
                          batch=self.batch)
    ]
    self.widgets = [
        TextWidget('', 200, 100, self.width - 210, self.batch),
        TextWidget('', 200, 60, self.width - 210, self.batch),
        TextWidget('', 200, 20, self.width - 210, self.batch)
    ]
    self.text_cursor = self.get_system_mouse_cursor('text')

    self.focus = None
    self.set_focus(self.widgets[0])",9,"<NME> text_input.py
<BEF> def __init__(self, *args, **kwargs):
    super(Window, self).__init__(400, 140, caption='Text entry')

    self.batch = pyglet.graphics.Batch()
    self.labels = [
        pyglet.text.Label('Name', x=10, y=100, anchor_y='bottom',
                          color=(0, 0, 0, 255), batch=self.batch),
        pyglet.text.Label('Species', x=10, y=60, anchor_y='bottom',
                          color=(0, 0, 0, 255), batch=self.batch),
        pyglet.text.Label('Special abilities', x=10, y=20, 
                          anchor_y='bottom', color=(0, 0, 0, 255), 
                          batch=kwargs.batch)
    ]
    self.widgets = [
        TextWidget('', 200, 100, self.width - 210, self.batch),
        TextWidget('', 200, 60, self.width - 210, self.batch),
        TextWidget('', 200, 20, self.width - 210, self.batch)
    ]
    self.text_cursor = self.get_system_mouse_cursor('text')

    self.focus = None
    self.set_focus(self.widgets[0])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, *args, **kwargs):
    super(Window, self).__init__(400, 140, caption='Text entry')

    self.batch = pyglet.graphics.Batch()
    self.labels = [
        pyglet.text.Label('Name', x=10, y=100, anchor_y='bottom',
                          color=(0, 0, 0, 255), batch=self.batch),
        pyglet.text.Label('Species', x=10, y=60, anchor_y='bottom',
                          color=(0, 0, 0, 255), batch=self.batch),
        pyglet.text.Label('Special abilities', x=10, y=20, 
                          anchor_y='bottom', color=(0, 0, 0, 255), 
                          batch=kwargs.batch)
    ]
    self.widgets = [
        TextWidget('', 200, 100, self.width - 210, self.batch),
        TextWidget('', 200, 60, self.width - 210, self.batch),
        TextWidget('', 200, 20, self.width - 210, self.batch)
    ]
    self.text_cursor = self.get_system_mouse_cursor('text')

    self.focus = None
    self.set_focus(self.widgets[0])"
"<NME> test_dispatch.py
<BEF> def test_waitStatus(self):
    p, t, dmx, mux = self.build_proto()

    # wait for event with specific code
    d = t.waitStatus(1, info1.code)
    d.addCallback(self.assertEquals, info1)

    # then wait for any event on message stream 1
    d.addCallback(lambda _: p.waitStatus(1, None))
    d.addCallback(self.assertEquals, info2)

    dmx.inject(3, 0, const.RTMP_COMMAND, 1,
               encode_amf('onStatus', 0, None, info1))
    dmx.inject(3, 0, const.RTMP_COMMAND, 1,
               encode_amf('onStatus', 0, None, info2))

    return d
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
     p, t, dmx, mux = self.build_proto()
 
     # wait for event with specific code
-    d = t.waitStatus(1, info1.code)
+    d = p.waitStatus(1, info1.code)
     d.addCallback(self.assertEquals, info1)
 
     # then wait for any event on message stream 1","def test_waitStatus(self):
    p, t, dmx, mux = self.build_proto()

    # wait for event with specific code
    d = p.waitStatus(1, info1.code)
    d.addCallback(self.assertEquals, info1)

    # then wait for any event on message stream 1
    d.addCallback(lambda _: p.waitStatus(1, None))
    d.addCallback(self.assertEquals, info2)

    dmx.inject(3, 0, const.RTMP_COMMAND, 1,
               encode_amf('onStatus', 0, None, info1))
    dmx.inject(3, 0, const.RTMP_COMMAND, 1,
               encode_amf('onStatus', 0, None, info2))

    return d",0,"<NME> test_dispatch.py
<BEF> def test_waitStatus(self):
    p, t, dmx, mux = self.build_proto()

    # wait for event with specific code
    d = t.waitStatus(1, info1.code)
    d.addCallback(self.assertEquals, info1)

    # then wait for any event on message stream 1
    d.addCallback(lambda _: p.waitStatus(1, None))
    d.addCallback(self.assertEquals, info2)

    dmx.inject(3, 0, const.RTMP_COMMAND, 1,
               encode_amf('onStatus', 0, None, info1))
    dmx.inject(3, 0, const.RTMP_COMMAND, 1,
               encode_amf('onStatus', 0, None, info2))

    return d
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_waitStatus(self):
    p, t, dmx, mux = self.build_proto()

    # wait for event with specific code
    d = t.waitStatus(1, info1.code)
    d.addCallback(self.assertEquals, info1)

    # then wait for any event on message stream 1
    d.addCallback(lambda _: p.waitStatus(1, None))
    d.addCallback(self.assertEquals, info2)

    dmx.inject(3, 0, const.RTMP_COMMAND, 1,
               encode_amf('onStatus', 0, None, info1))
    dmx.inject(3, 0, const.RTMP_COMMAND, 1,
               encode_amf('onStatus', 0, None, info2))

    return d"
"<NME> inmemory.py
<BEF> def read(self, callback, grpos_range, frames=None):
    if grpos_range:
        # here we only handle the case of data shrinking from the
        # left / earlier side...
        end_grpos = self._grpos + grpos_range
        pos = self._pos
        grpos = self._grpos
        while 1:
            idx = pos - self._s.data_offset
            if idx < 0:
                pos -= idx
                idx = 0
            try:
                f = self._s.data[idx]
            except IndexError:
                # we're behind the last frame -> no read
                break
            grpos = f[0]
            if grpos >= end_grpos:
                self = end_grpos
                break
            callback(*f)
            pos += 1
        self._pos = pos
        self._grpos = grpos
    elif frames:
        pos = self._pos
        grpos = self._grpos
        while 1:
            idx = pos - self._s.data_offset
            if idx < 0:
                pos -= idx
                frames += idx
            if frames < 1:
                break
            try:
                f = self._s.data[idx]
            except IndexError:
                # we're behind the last frame -> no more read
                break
            grpos = f[0]
            callback(*f)
            pos += 1
            frames -= 1
        self._pos = pos
        self._grpos = grpos

    # if HAVE_TASKS:
    #     t = tasks.CompTask()
    #     return t, t.run()

    return None, defer.succeed(None)
<MSG> Fix incorrect variable name
<DFF> @@ -17,7 +17,7 @@
                 break
             grpos = f[0]
             if grpos >= end_grpos:
-                self = end_grpos
+                grpos = end_grpos
                 break
             callback(*f)
             pos += 1","def read(self, callback, grpos_range, frames=None):
    if grpos_range:
        # here we only handle the case of data shrinking from the
        # left / earlier side...
        end_grpos = self._grpos + grpos_range
        pos = self._pos
        grpos = self._grpos
        while 1:
            idx = pos - self._s.data_offset
            if idx < 0:
                pos -= idx
                idx = 0
            try:
                f = self._s.data[idx]
            except IndexError:
                # we're behind the last frame -> no read
                break
            grpos = f[0]
            if grpos >= end_grpos:
                grpos = end_grpos
                break
            callback(*f)
            pos += 1
        self._pos = pos
        self._grpos = grpos
    elif frames:
        pos = self._pos
        grpos = self._grpos
        while 1:
            idx = pos - self._s.data_offset
            if idx < 0:
                pos -= idx
                frames += idx
            if frames < 1:
                break
            try:
                f = self._s.data[idx]
            except IndexError:
                # we're behind the last frame -> no more read
                break
            grpos = f[0]
            callback(*f)
            pos += 1
            frames -= 1
        self._pos = pos
        self._grpos = grpos

    # if HAVE_TASKS:
    #     t = tasks.CompTask()
    #     return t, t.run()

    return None, defer.succeed(None)",1,"<NME> inmemory.py
<BEF> def read(self, callback, grpos_range, frames=None):
    if grpos_range:
        # here we only handle the case of data shrinking from the
        # left / earlier side...
        end_grpos = self._grpos + grpos_range
        pos = self._pos
        grpos = self._grpos
        while 1:
            idx = pos - self._s.data_offset
            if idx < 0:
                pos -= idx
                idx = 0
            try:
                f = self._s.data[idx]
            except IndexError:
                # we're behind the last frame -> no read
                break
            grpos = f[0]
            if grpos >= end_grpos:
                self = end_grpos
                break
            callback(*f)
            pos += 1
        self._pos = pos
        self._grpos = grpos
    elif frames:
        pos = self._pos
        grpos = self._grpos
        while 1:
            idx = pos - self._s.data_offset
            if idx < 0:
                pos -= idx
                frames += idx
            if frames < 1:
                break
            try:
                f = self._s.data[idx]
            except IndexError:
                # we're behind the last frame -> no more read
                break
            grpos = f[0]
            callback(*f)
            pos += 1
            frames -= 1
        self._pos = pos
        self._grpos = grpos

    # if HAVE_TASKS:
    #     t = tasks.CompTask()
    #     return t, t.run()

    return None, defer.succeed(None)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def read(self, callback, grpos_range, frames=None):
    if grpos_range:
        # here we only handle the case of data shrinking from the
        # left / earlier side...
        end_grpos = self._grpos + grpos_range
        pos = self._pos
        grpos = self._grpos
        while 1:
            idx = pos - self._s.data_offset
            if idx < 0:
                pos -= idx
                idx = 0
            try:
                f = self._s.data[idx]
            except IndexError:
                # we're behind the last frame -> no read
                break
            grpos = f[0]
            if grpos >= end_grpos:
                self = end_grpos
                break
            callback(*f)
            pos += 1
        self._pos = pos
        self._grpos = grpos
    elif frames:
        pos = self._pos
        grpos = self._grpos
        while 1:
            idx = pos - self._s.data_offset
            if idx < 0:
                pos -= idx
                frames += idx
            if frames < 1:
                break
            try:
                f = self._s.data[idx]
            except IndexError:
                # we're behind the last frame -> no more read
                break
            grpos = f[0]
            callback(*f)
            pos += 1
            frames -= 1
        self._pos = pos
        self._grpos = grpos

    # if HAVE_TASKS:
    #     t = tasks.CompTask()
    #     return t, t.run()

    return None, defer.succeed(None)"
"<NME> movie.py
<BEF> def update(self, dt):
    self.player.dispatch_events()

    if self.control is None:
        # the player update may have resulted in this element being
        # culled
        return

    if not self.control.isVisible():
        return
    t = self.player.time

    # time display
    s = int(t)
    m = t // 60
    h = m // 60
    m %= 60
    s = s % 60
    if h: text = '%d:%02d:%02d'%(h, m, text)
    else: text = '%02d:%02d'%(m, s)
    if text != self.control.time.text:
        self.control.time.text = text

    # slider position
    p = (t/self.player.source.duration)
    self.control.position.x = int(p * self.control.range.width)
<MSG> Fix incorrect variable name
<DFF> @@ -16,7 +16,7 @@
     h = m // 60
     m %= 60
     s = s % 60
-    if h: text = '%d:%02d:%02d'%(h, m, text)
+    if h: text = '%d:%02d:%02d'%(h, m, s)
     else: text = '%02d:%02d'%(m, s)
     if text != self.control.time.text:
         self.control.time.text = text","def update(self, dt):
    self.player.dispatch_events()

    if self.control is None:
        # the player update may have resulted in this element being
        # culled
        return

    if not self.control.isVisible():
        return
    t = self.player.time

    # time display
    s = int(t)
    m = t // 60
    h = m // 60
    m %= 60
    s = s % 60
    if h: text = '%d:%02d:%02d'%(h, m, s)
    else: text = '%02d:%02d'%(m, s)
    if text != self.control.time.text:
        self.control.time.text = text

    # slider position
    p = (t/self.player.source.duration)
    self.control.position.x = int(p * self.control.range.width)",2,"<NME> movie.py
<BEF> def update(self, dt):
    self.player.dispatch_events()

    if self.control is None:
        # the player update may have resulted in this element being
        # culled
        return

    if not self.control.isVisible():
        return
    t = self.player.time

    # time display
    s = int(t)
    m = t // 60
    h = m // 60
    m %= 60
    s = s % 60
    if h: text = '%d:%02d:%02d'%(h, m, text)
    else: text = '%02d:%02d'%(m, s)
    if text != self.control.time.text:
        self.control.time.text = text

    # slider position
    p = (t/self.player.source.duration)
    self.control.position.x = int(p * self.control.range.width)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def update(self, dt):
    self.player.dispatch_events()

    if self.control is None:
        # the player update may have resulted in this element being
        # culled
        return

    if not self.control.isVisible():
        return
    t = self.player.time

    # time display
    s = int(t)
    m = t // 60
    h = m // 60
    m %= 60
    s = s % 60
    if h: text = '%d:%02d:%02d'%(h, m, text)
    else: text = '%02d:%02d'%(m, s)
    if text != self.control.time.text:
        self.control.time.text = text

    # slider position
    p = (t/self.player.source.duration)
    self.control.position.x = int(p * self.control.range.width)"
"<NME> __init__.py
<BEF> def get_mipmapped_texture(self):
    if self._current_mipmap_texture:
        return self._current_mipmap_texture

    if not self._have_extension():
        # TODO mip-mapped software decoded compressed textures.  For now,
        # just return a non-mipmapped texture.
        return self.get_texture()

    texture = Texture.create_for_size(
        GL_TEXTURE_2D, self.width, self.height)
    if self.anchor_x or self.anchor_y:
        texture.anchor_x = self.anchor_x
        texture.anchor_y = self.anchor_y

    glBindTexture(texture.target, texture.id)

    glTexParameteri(texture.target, GL_TEXTURE_MIN_FILTER,
                    GL_LINEAR_MIPMAP_LINEAR)

    if not self.mipmap_data:
        if not gl_info.have_version(1, 4):
            raise ImageException(
              'Require GL 1.4 to generate mipmaps for compressed textures')
        glTexParameteri(texture.target, GL_GENERATE_MIPMAP, GL_TRUE)

    glCompressedTexImage2DARB(texture.target, texture.level,
        self.gl_format,
        self.width, self.height, 0,
        len(self.data), self.data) 

    width, height = self.width, self.height
    level = 0
    for data in self.mipmap_data:
        width >>= 1
        height >>= 1
        level += 1
        glCompressedTexImage2DARB(texture.target, level,
            self.gl_format,
            texture, height, 0,
            len(data), data)

    glFlush()

    self._current_mipmap_texture = texture
    return texture
<MSG> Fix incorrect variable name
<DFF> @@ -37,7 +37,7 @@
         level += 1
         glCompressedTexImage2DARB(texture.target, level,
             self.gl_format,
-            texture, height, 0,
+            width, height, 0,
             len(data), data)
 
     glFlush()","def get_mipmapped_texture(self):
    if self._current_mipmap_texture:
        return self._current_mipmap_texture

    if not self._have_extension():
        # TODO mip-mapped software decoded compressed textures.  For now,
        # just return a non-mipmapped texture.
        return self.get_texture()

    texture = Texture.create_for_size(
        GL_TEXTURE_2D, self.width, self.height)
    if self.anchor_x or self.anchor_y:
        texture.anchor_x = self.anchor_x
        texture.anchor_y = self.anchor_y

    glBindTexture(texture.target, texture.id)

    glTexParameteri(texture.target, GL_TEXTURE_MIN_FILTER,
                    GL_LINEAR_MIPMAP_LINEAR)

    if not self.mipmap_data:
        if not gl_info.have_version(1, 4):
            raise ImageException(
              'Require GL 1.4 to generate mipmaps for compressed textures')
        glTexParameteri(texture.target, GL_GENERATE_MIPMAP, GL_TRUE)

    glCompressedTexImage2DARB(texture.target, texture.level,
        self.gl_format,
        self.width, self.height, 0,
        len(self.data), self.data) 

    width, height = self.width, self.height
    level = 0
    for data in self.mipmap_data:
        width >>= 1
        height >>= 1
        level += 1
        glCompressedTexImage2DARB(texture.target, level,
            self.gl_format,
            width, height, 0,
            len(data), data)

    glFlush()

    self._current_mipmap_texture = texture
    return texture",3,"<NME> __init__.py
<BEF> def get_mipmapped_texture(self):
    if self._current_mipmap_texture:
        return self._current_mipmap_texture

    if not self._have_extension():
        # TODO mip-mapped software decoded compressed textures.  For now,
        # just return a non-mipmapped texture.
        return self.get_texture()

    texture = Texture.create_for_size(
        GL_TEXTURE_2D, self.width, self.height)
    if self.anchor_x or self.anchor_y:
        texture.anchor_x = self.anchor_x
        texture.anchor_y = self.anchor_y

    glBindTexture(texture.target, texture.id)

    glTexParameteri(texture.target, GL_TEXTURE_MIN_FILTER,
                    GL_LINEAR_MIPMAP_LINEAR)

    if not self.mipmap_data:
        if not gl_info.have_version(1, 4):
            raise ImageException(
              'Require GL 1.4 to generate mipmaps for compressed textures')
        glTexParameteri(texture.target, GL_GENERATE_MIPMAP, GL_TRUE)

    glCompressedTexImage2DARB(texture.target, texture.level,
        self.gl_format,
        self.width, self.height, 0,
        len(self.data), self.data) 

    width, height = self.width, self.height
    level = 0
    for data in self.mipmap_data:
        width >>= 1
        height >>= 1
        level += 1
        glCompressedTexImage2DARB(texture.target, level,
            self.gl_format,
            texture, height, 0,
            len(data), data)

    glFlush()

    self._current_mipmap_texture = texture
    return texture
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_mipmapped_texture(self):
    if self._current_mipmap_texture:
        return self._current_mipmap_texture

    if not self._have_extension():
        # TODO mip-mapped software decoded compressed textures.  For now,
        # just return a non-mipmapped texture.
        return self.get_texture()

    texture = Texture.create_for_size(
        GL_TEXTURE_2D, self.width, self.height)
    if self.anchor_x or self.anchor_y:
        texture.anchor_x = self.anchor_x
        texture.anchor_y = self.anchor_y

    glBindTexture(texture.target, texture.id)

    glTexParameteri(texture.target, GL_TEXTURE_MIN_FILTER,
                    GL_LINEAR_MIPMAP_LINEAR)

    if not self.mipmap_data:
        if not gl_info.have_version(1, 4):
            raise ImageException(
              'Require GL 1.4 to generate mipmaps for compressed textures')
        glTexParameteri(texture.target, GL_GENERATE_MIPMAP, GL_TRUE)

    glCompressedTexImage2DARB(texture.target, texture.level,
        self.gl_format,
        self.width, self.height, 0,
        len(self.data), self.data) 

    width, height = self.width, self.height
    level = 0
    for data in self.mipmap_data:
        width >>= 1
        height >>= 1
        level += 1
        glCompressedTexImage2DARB(texture.target, level,
            self.gl_format,
            texture, height, 0,
            len(data), data)

    glFlush()

    self._current_mipmap_texture = texture
    return texture"
"<NME> tests.py
<BEF> def test_send_notrendered(self):
    message = self._initMessage()
    message.context = CONTEXT2
    message.send()
    message._assertIsRendered(message, True, SUBJECT2, BODY2)
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     message = self._initMessage()
     message.context = CONTEXT2
     message.send()
-    message._assertIsRendered(message, True, SUBJECT2, BODY2)
+    self._assertIsRendered(message, True, SUBJECT2, BODY2)","def test_send_notrendered(self):
    message = self._initMessage()
    message.context = CONTEXT2
    message.send()
    self._assertIsRendered(message, True, SUBJECT2, BODY2)",4,"<NME> tests.py
<BEF> def test_send_notrendered(self):
    message = self._initMessage()
    message.context = CONTEXT2
    message.send()
    message._assertIsRendered(message, True, SUBJECT2, BODY2)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_send_notrendered(self):
    message = self._initMessage()
    message.context = CONTEXT2
    message.send()
    message._assertIsRendered(message, True, SUBJECT2, BODY2)"
"<NME> test_repositories.py
<BEF> def test_watching_with_page(self):
    repos = repos.client.repos.watching('tekkub', page=2)
    eq_(len(repos), 39)
    eq_(repos[0].name, 'Buffoon')
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def test_watching_with_page(self):
-    repos = repos.client.repos.watching('tekkub', page=2)
+    repos = self.client.repos.watching('tekkub', page=2)
     eq_(len(repos), 39)
     eq_(repos[0].name, 'Buffoon')","def test_watching_with_page(self):
    repos = self.client.repos.watching('tekkub', page=2)
    eq_(len(repos), 39)
    eq_(repos[0].name, 'Buffoon')",5,"<NME> test_repositories.py
<BEF> def test_watching_with_page(self):
    repos = repos.client.repos.watching('tekkub', page=2)
    eq_(len(repos), 39)
    eq_(repos[0].name, 'Buffoon')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_watching_with_page(self):
    repos = repos.client.repos.watching('tekkub', page=2)
    eq_(len(repos), 39)
    eq_(repos[0].name, 'Buffoon')"
"<NME> fac.py
<BEF> def quote_string(s):
    chars = []
    for c in s:
        if c == ""\\"":
            chars = ""\\\\""
        elif c == ""\"""":
            c = ""\\\""""
        chars.append(c)
    return ""\"""" + """".join(chars) + ""\""""
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
     chars = []
     for c in s:
         if c == ""\\"":
-            chars = ""\\\\""
+            c = ""\\\\""
         elif c == ""\"""":
             c = ""\\\""""
         chars.append(c)","def quote_string(s):
    chars = []
    for c in s:
        if c == ""\\"":
            c = ""\\\\""
        elif c == ""\"""":
            c = ""\\\""""
        chars.append(c)
    return ""\"""" + """".join(chars) + ""\""""",6,"<NME> fac.py
<BEF> def quote_string(s):
    chars = []
    for c in s:
        if c == ""\\"":
            chars = ""\\\\""
        elif c == ""\"""":
            c = ""\\\""""
        chars.append(c)
    return ""\"""" + """".join(chars) + ""\""""
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def quote_string(s):
    chars = []
    for c in s:
        if c == ""\\"":
            chars = ""\\\\""
        elif c == ""\"""":
            c = ""\\\""""
        chars.append(c)
    return ""\"""" + """".join(chars) + ""\"""""
"<NME> utils.py
<BEF> def get_now():
    """"""
    Allows to access global request and read a timestamp from query.
    """"""
    if not get_current_request:
        return datetime.datetime.now()
    request = get_current_request()
    if request:
        openinghours_now = request.GET.get('openinghours-now')
        if request:
            return datetime.datetime.strptime(openinghours_now, '%Y%m%d%H%M%S')
    return datetime.datetime.now()
<MSG> Fix incorrect variable name
<DFF> @@ -7,6 +7,6 @@
     request = get_current_request()
     if request:
         openinghours_now = request.GET.get('openinghours-now')
-        if request:
+        if openinghours_now:
             return datetime.datetime.strptime(openinghours_now, '%Y%m%d%H%M%S')
     return datetime.datetime.now()","def get_now():
    """"""
    Allows to access global request and read a timestamp from query.
    """"""
    if not get_current_request:
        return datetime.datetime.now()
    request = get_current_request()
    if request:
        openinghours_now = request.GET.get('openinghours-now')
        if openinghours_now:
            return datetime.datetime.strptime(openinghours_now, '%Y%m%d%H%M%S')
    return datetime.datetime.now()",7,"<NME> utils.py
<BEF> def get_now():
    """"""
    Allows to access global request and read a timestamp from query.
    """"""
    if not get_current_request:
        return datetime.datetime.now()
    request = get_current_request()
    if request:
        openinghours_now = request.GET.get('openinghours-now')
        if request:
            return datetime.datetime.strptime(openinghours_now, '%Y%m%d%H%M%S')
    return datetime.datetime.now()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_now():
    """"""
    Allows to access global request and read a timestamp from query.
    """"""
    if not get_current_request:
        return datetime.datetime.now()
    request = get_current_request()
    if request:
        openinghours_now = request.GET.get('openinghours-now')
        if request:
            return datetime.datetime.strptime(openinghours_now, '%Y%m%d%H%M%S')
    return datetime.datetime.now()"
"<NME> euclid.py
<BEF> def rotatey(self, angle):
    self *= Matrix4.new_rotatey(angle)
    return angle
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def rotatey(self, angle):
     self *= Matrix4.new_rotatey(angle)
-    return angle
+    return self","def rotatey(self, angle):
    self *= Matrix4.new_rotatey(angle)
    return self",8,"<NME> euclid.py
<BEF> def rotatey(self, angle):
    self *= Matrix4.new_rotatey(angle)
    return angle
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def rotatey(self, angle):
    self *= Matrix4.new_rotatey(angle)
    return angle"
"<NME> epytext.py
<BEF> def to_plaintext(self, docstring_linker, **options):
    # [XX] don't cache -- different options might be used!!
    #if self._plaintext is not None: return self._plaintext
    if self._tree is None: return ''
    if 'indent' in self:
        self._plaintext = to_plaintext(self._tree,
                                       indent=options['indent'])
    else:
        self._plaintext = to_plaintext(self._tree)
    return self._plaintext
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
     # [XX] don't cache -- different options might be used!!
     #if self._plaintext is not None: return self._plaintext
     if self._tree is None: return ''
-    if 'indent' in self:
+    if 'indent' in options:
         self._plaintext = to_plaintext(self._tree,
                                        indent=options['indent'])
     else:","def to_plaintext(self, docstring_linker, **options):
    # [XX] don't cache -- different options might be used!!
    #if self._plaintext is not None: return self._plaintext
    if self._tree is None: return ''
    if 'indent' in options:
        self._plaintext = to_plaintext(self._tree,
                                       indent=options['indent'])
    else:
        self._plaintext = to_plaintext(self._tree)
    return self._plaintext",9,"<NME> epytext.py
<BEF> def to_plaintext(self, docstring_linker, **options):
    # [XX] don't cache -- different options might be used!!
    #if self._plaintext is not None: return self._plaintext
    if self._tree is None: return ''
    if 'indent' in self:
        self._plaintext = to_plaintext(self._tree,
                                       indent=options['indent'])
    else:
        self._plaintext = to_plaintext(self._tree)
    return self._plaintext
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def to_plaintext(self, docstring_linker, **options):
    # [XX] don't cache -- different options might be used!!
    #if self._plaintext is not None: return self._plaintext
    if self._tree is None: return ''
    if 'indent' in self:
        self._plaintext = to_plaintext(self._tree,
                                       indent=options['indent'])
    else:
        self._plaintext = to_plaintext(self._tree)
    return self._plaintext"
"<NME> SPCompletions.py
<BEF> def get_preprocessor_define(node, buffer) :
    """"""get_preprocessor_define(File, string) -> string""""""
    # Regex the #define. Group 1 is the name, Group 2 is the value 
    define = re.search('#define[\\s]+([^\\s]+)[\\s]+(.+)', buffer)
    if define :
        # The whole line is consumed, return an empty string to indicate that
        buffer = ''
        name = define.group(1)
        value = define.group(2).strip()
        node.funcs.add((name + '  (constant: ' + define + ')', name))
    return buffer
<MSG> Fix incorrect variable name
<DFF> @@ -7,5 +7,5 @@
         buffer = ''
         name = define.group(1)
         value = define.group(2).strip()
-        node.funcs.add((name + '  (constant: ' + define + ')', name))
+        node.funcs.add((name + '  (constant: ' + value + ')', name))
     return buffer","def get_preprocessor_define(node, buffer) :
    """"""get_preprocessor_define(File, string) -> string""""""
    # Regex the #define. Group 1 is the name, Group 2 is the value 
    define = re.search('#define[\\s]+([^\\s]+)[\\s]+(.+)', buffer)
    if define :
        # The whole line is consumed, return an empty string to indicate that
        buffer = ''
        name = define.group(1)
        value = define.group(2).strip()
        node.funcs.add((name + '  (constant: ' + value + ')', name))
    return buffer",0,"<NME> SPCompletions.py
<BEF> def get_preprocessor_define(node, buffer) :
    """"""get_preprocessor_define(File, string) -> string""""""
    # Regex the #define. Group 1 is the name, Group 2 is the value 
    define = re.search('#define[\\s]+([^\\s]+)[\\s]+(.+)', buffer)
    if define :
        # The whole line is consumed, return an empty string to indicate that
        buffer = ''
        name = define.group(1)
        value = define.group(2).strip()
        node.funcs.add((name + '  (constant: ' + define + ')', name))
    return buffer
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_preprocessor_define(node, buffer) :
    """"""get_preprocessor_define(File, string) -> string""""""
    # Regex the #define. Group 1 is the name, Group 2 is the value 
    define = re.search('#define[\\s]+([^\\s]+)[\\s]+(.+)', buffer)
    if define :
        # The whole line is consumed, return an empty string to indicate that
        buffer = ''
        name = define.group(1)
        value = define.group(2).strip()
        node.funcs.add((name + '  (constant: ' + define + ')', name))
    return buffer"
"<NME> api.py
<BEF> def get(self):
    parent_entity_id = self.get_argument('parent_entity_id', default=None, strip=True)
    entity_definition_keyname = self.get_argument('entity_definition_keyname', default=None, strip=True)
    public = True if self.get_argument('public', default=None, strip=True) == 'true' else False

    user = self.get_user_by_session_key(self.get_argument('session_key', default=None, strip=True))
    user_id = None
    if user:
        if not user.get('id'):
            raise web.HTTPError(401, ""Unauthorized"")
    else:
        raise web.HTTPError(401, ""Unauthorized"")

    if entity_definition_keyname != None:
        entity_id = entity.create_entity(entity_definition_keyname=entity_definition_keyname, parent_entity_id=parent_entity_id)
        if public:
            entity.set_public(entity_definition_keyname,is_public=public)
        self.write({
                    'entity_id':entity_id
        })
    else:
        raise web.HTTPError(400, 'To create a new Entity entity_definition_keyname is required.')
<MSG> Fix incorrect variable name
<DFF> @@ -14,7 +14,7 @@
     if entity_definition_keyname != None:
         entity_id = entity.create_entity(entity_definition_keyname=entity_definition_keyname, parent_entity_id=parent_entity_id)
         if public:
-            entity.set_public(entity_definition_keyname,is_public=public)
+            entity.set_public(entity_id,is_public=public)
         self.write({
                     'entity_id':entity_id
         })","def get(self):
    parent_entity_id = self.get_argument('parent_entity_id', default=None, strip=True)
    entity_definition_keyname = self.get_argument('entity_definition_keyname', default=None, strip=True)
    public = True if self.get_argument('public', default=None, strip=True) == 'true' else False

    user = self.get_user_by_session_key(self.get_argument('session_key', default=None, strip=True))
    user_id = None
    if user:
        if not user.get('id'):
            raise web.HTTPError(401, ""Unauthorized"")
    else:
        raise web.HTTPError(401, ""Unauthorized"")

    if entity_definition_keyname != None:
        entity_id = entity.create_entity(entity_definition_keyname=entity_definition_keyname, parent_entity_id=parent_entity_id)
        if public:
            entity.set_public(entity_id,is_public=public)
        self.write({
                    'entity_id':entity_id
        })
    else:
        raise web.HTTPError(400, 'To create a new Entity entity_definition_keyname is required.')",1,"<NME> api.py
<BEF> def get(self):
    parent_entity_id = self.get_argument('parent_entity_id', default=None, strip=True)
    entity_definition_keyname = self.get_argument('entity_definition_keyname', default=None, strip=True)
    public = True if self.get_argument('public', default=None, strip=True) == 'true' else False

    user = self.get_user_by_session_key(self.get_argument('session_key', default=None, strip=True))
    user_id = None
    if user:
        if not user.get('id'):
            raise web.HTTPError(401, ""Unauthorized"")
    else:
        raise web.HTTPError(401, ""Unauthorized"")

    if entity_definition_keyname != None:
        entity_id = entity.create_entity(entity_definition_keyname=entity_definition_keyname, parent_entity_id=parent_entity_id)
        if public:
            entity.set_public(entity_definition_keyname,is_public=public)
        self.write({
                    'entity_id':entity_id
        })
    else:
        raise web.HTTPError(400, 'To create a new Entity entity_definition_keyname is required.')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get(self):
    parent_entity_id = self.get_argument('parent_entity_id', default=None, strip=True)
    entity_definition_keyname = self.get_argument('entity_definition_keyname', default=None, strip=True)
    public = True if self.get_argument('public', default=None, strip=True) == 'true' else False

    user = self.get_user_by_session_key(self.get_argument('session_key', default=None, strip=True))
    user_id = None
    if user:
        if not user.get('id'):
            raise web.HTTPError(401, ""Unauthorized"")
    else:
        raise web.HTTPError(401, ""Unauthorized"")

    if entity_definition_keyname != None:
        entity_id = entity.create_entity(entity_definition_keyname=entity_definition_keyname, parent_entity_id=parent_entity_id)
        if public:
            entity.set_public(entity_definition_keyname,is_public=public)
        self.write({
                    'entity_id':entity_id
        })
    else:
        raise web.HTTPError(400, 'To create a new Entity entity_definition_keyname is required.')"
"<NME> windows.py
<BEF> def __init__(self, f):
    super(CheckedCall, f).__setattr__(""f"", f)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def __init__(self, f):
-    super(CheckedCall, f).__setattr__(""f"", f)
+    super(CheckedCall, self).__setattr__(""f"", f)","def __init__(self, f):
    super(CheckedCall, self).__setattr__(""f"", f)",2,"<NME> windows.py
<BEF> def __init__(self, f):
    super(CheckedCall, f).__setattr__(""f"", f)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, f):
    super(CheckedCall, f).__setattr__(""f"", f)"
"<NME> __init__.py
<BEF> def _generate_ascii(self, matrix, foreground, background):
    """"""
    Generates an identicon ""image"" in the ASCII format. The image will just
    output the matrix used to generate the identicon.

    Arguments:

      matrix - Matrix describing which blocks in the identicon should be
      painted with foreground (background if inverted) colour.

      foreground - Character which should be used for representing
      foreground.

      background - Character which should be used for representing
      background.

    Returns:

      ASCII representation of an identicon image, where one block is one
      character.
    """"""

    return ""\n"".join(["""".join([background if cell else background for cell in row]) for row in matrix])
<MSG> Fix incorrect variable name
<DFF> @@ -20,4 +20,4 @@
       character.
     """"""
 
-    return ""\n"".join(["""".join([background if cell else background for cell in row]) for row in matrix])
+    return ""\n"".join(["""".join([foreground if cell else background for cell in row]) for row in matrix])","def _generate_ascii(self, matrix, foreground, background):
    """"""
    Generates an identicon ""image"" in the ASCII format. The image will just
    output the matrix used to generate the identicon.

    Arguments:

      matrix - Matrix describing which blocks in the identicon should be
      painted with foreground (background if inverted) colour.

      foreground - Character which should be used for representing
      foreground.

      background - Character which should be used for representing
      background.

    Returns:

      ASCII representation of an identicon image, where one block is one
      character.
    """"""

    return ""\n"".join(["""".join([foreground if cell else background for cell in row]) for row in matrix])",3,"<NME> __init__.py
<BEF> def _generate_ascii(self, matrix, foreground, background):
    """"""
    Generates an identicon ""image"" in the ASCII format. The image will just
    output the matrix used to generate the identicon.

    Arguments:

      matrix - Matrix describing which blocks in the identicon should be
      painted with foreground (background if inverted) colour.

      foreground - Character which should be used for representing
      foreground.

      background - Character which should be used for representing
      background.

    Returns:

      ASCII representation of an identicon image, where one block is one
      character.
    """"""

    return ""\n"".join(["""".join([background if cell else background for cell in row]) for row in matrix])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _generate_ascii(self, matrix, foreground, background):
    """"""
    Generates an identicon ""image"" in the ASCII format. The image will just
    output the matrix used to generate the identicon.

    Arguments:

      matrix - Matrix describing which blocks in the identicon should be
      painted with foreground (background if inverted) colour.

      foreground - Character which should be used for representing
      foreground.

      background - Character which should be used for representing
      background.

    Returns:

      ASCII representation of an identicon image, where one block is one
      character.
    """"""

    return ""\n"".join(["""".join([background if cell else background for cell in row]) for row in matrix])"
"<NME> test_fuzz.py
<BEF> def expand(tests):
    if isinstance(tests, unittest.TestCase):
        method_name = tests._testMethodName
        meth = getattr(tests, method_name)
        if hasattr(meth, 'iterations'):
            tests = unittest.TestSuite(type(meth)(method_name) for i in xrange(meth.iterations))
    else:
        tests = unittest.TestSuite(expand(t) for t in tests)
    return tests
<MSG> Fix incorrect variable name
<DFF> @@ -3,7 +3,7 @@
         method_name = tests._testMethodName
         meth = getattr(tests, method_name)
         if hasattr(meth, 'iterations'):
-            tests = unittest.TestSuite(type(meth)(method_name) for i in xrange(meth.iterations))
+            tests = unittest.TestSuite(type(tests)(method_name) for i in xrange(meth.iterations))
     else:
         tests = unittest.TestSuite(expand(t) for t in tests)
     return tests","def expand(tests):
    if isinstance(tests, unittest.TestCase):
        method_name = tests._testMethodName
        meth = getattr(tests, method_name)
        if hasattr(meth, 'iterations'):
            tests = unittest.TestSuite(type(tests)(method_name) for i in xrange(meth.iterations))
    else:
        tests = unittest.TestSuite(expand(t) for t in tests)
    return tests",4,"<NME> test_fuzz.py
<BEF> def expand(tests):
    if isinstance(tests, unittest.TestCase):
        method_name = tests._testMethodName
        meth = getattr(tests, method_name)
        if hasattr(meth, 'iterations'):
            tests = unittest.TestSuite(type(meth)(method_name) for i in xrange(meth.iterations))
    else:
        tests = unittest.TestSuite(expand(t) for t in tests)
    return tests
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def expand(tests):
    if isinstance(tests, unittest.TestCase):
        method_name = tests._testMethodName
        meth = getattr(tests, method_name)
        if hasattr(meth, 'iterations'):
            tests = unittest.TestSuite(type(meth)(method_name) for i in xrange(meth.iterations))
    else:
        tests = unittest.TestSuite(expand(t) for t in tests)
    return tests"
"<NME> units_expand_to_line.py
<BEF> @classmethod
def setUpClass(self):
  with open (""test/snippets/line_01.txt"", ""r"") as myfile:
    self.string1 = self.read()
  with open (""test/snippets/line_02.txt"", ""r"") as myfile:
    self.string2 = myfile.read()
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 @classmethod
 def setUpClass(self):
   with open (""test/snippets/line_01.txt"", ""r"") as myfile:
-    self.string1 = self.read()
+    self.string1 = myfile.read()
   with open (""test/snippets/line_02.txt"", ""r"") as myfile:
     self.string2 = myfile.read()","@classmethod
def setUpClass(self):
  with open (""test/snippets/line_01.txt"", ""r"") as myfile:
    self.string1 = myfile.read()
  with open (""test/snippets/line_02.txt"", ""r"") as myfile:
    self.string2 = myfile.read()",5,"<NME> units_expand_to_line.py
<BEF> @classmethod
def setUpClass(self):
  with open (""test/snippets/line_01.txt"", ""r"") as myfile:
    self.string1 = self.read()
  with open (""test/snippets/line_02.txt"", ""r"") as myfile:
    self.string2 = myfile.read()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@classmethod
def setUpClass(self):
  with open (""test/snippets/line_01.txt"", ""r"") as myfile:
    self.string1 = self.read()
  with open (""test/snippets/line_02.txt"", ""r"") as myfile:
    self.string2 = myfile.read()"
"<NME> models.py
<BEF> def for_address(self, address):
    if not address:
        return None

    func = getattr(settings, 'EASY_MAPS_GEOCODE', None)
    if func is not None:
        if not isinstance(func, collections.Callable):
            func = importpath(func)

    try:
        return func(func)
    except geocode.Error as e:
        try:
            logger.error(e)
        except Exception:
            logger.error(
                ""Geocoding error for address '%s'"", address)

    return None
<MSG> Fix incorrect variable name
<DFF> @@ -8,7 +8,7 @@
             func = importpath(func)
 
     try:
-        return func(func)
+        return func(address)
     except geocode.Error as e:
         try:
             logger.error(e)","def for_address(self, address):
    if not address:
        return None

    func = getattr(settings, 'EASY_MAPS_GEOCODE', None)
    if func is not None:
        if not isinstance(func, collections.Callable):
            func = importpath(func)

    try:
        return func(address)
    except geocode.Error as e:
        try:
            logger.error(e)
        except Exception:
            logger.error(
                ""Geocoding error for address '%s'"", address)

    return None",6,"<NME> models.py
<BEF> def for_address(self, address):
    if not address:
        return None

    func = getattr(settings, 'EASY_MAPS_GEOCODE', None)
    if func is not None:
        if not isinstance(func, collections.Callable):
            func = importpath(func)

    try:
        return func(func)
    except geocode.Error as e:
        try:
            logger.error(e)
        except Exception:
            logger.error(
                ""Geocoding error for address '%s'"", address)

    return None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def for_address(self, address):
    if not address:
        return None

    func = getattr(settings, 'EASY_MAPS_GEOCODE', None)
    if func is not None:
        if not isinstance(func, collections.Callable):
            func = importpath(func)

    try:
        return func(func)
    except geocode.Error as e:
        try:
            logger.error(e)
        except Exception:
            logger.error(
                ""Geocoding error for address '%s'"", address)

    return None"
"<NME> inject.py
<BEF> def injectmex86(pid, shellcode):
    from sys import platform

    if platform.startswith('win'):
        print (""\nPtrace not working on windows machines ..\n"")
        return False
    else:
        try:
            from ptrace.debugger.debugger import PtraceDebugger
            from ptrace.debugger.debugger import PtraceProcess
        except ImportError: 
            print (""\nYou must install ptrace library before use this script.\n"")
            return False
        else:
            try:
                dbg = PtraceDebugger()
                process = dbg.addProcess(int(pid), False)
                eip = process.getInstrPointer()
                bytes = process.writeBytes(eip, dbg.replace(""\\x"", """").decode(""hex""))
                process.setreg(""ebx"", 0)
                process.cont()
            except Exception as error:
                print (error)
                print (""\nPlease do not forget report !\n"")
            else:
                print (""\nInject complate !\n"")
<MSG> Fix incorrect variable name
<DFF> @@ -16,7 +16,7 @@
                 dbg = PtraceDebugger()
                 process = dbg.addProcess(int(pid), False)
                 eip = process.getInstrPointer()
-                bytes = process.writeBytes(eip, dbg.replace(""\\x"", """").decode(""hex""))
+                bytes = process.writeBytes(eip, shellcode.replace(""\\x"", """").decode(""hex""))
                 process.setreg(""ebx"", 0)
                 process.cont()
             except Exception as error:","def injectmex86(pid, shellcode):
    from sys import platform

    if platform.startswith('win'):
        print (""\nPtrace not working on windows machines ..\n"")
        return False
    else:
        try:
            from ptrace.debugger.debugger import PtraceDebugger
            from ptrace.debugger.debugger import PtraceProcess
        except ImportError: 
            print (""\nYou must install ptrace library before use this script.\n"")
            return False
        else:
            try:
                dbg = PtraceDebugger()
                process = dbg.addProcess(int(pid), False)
                eip = process.getInstrPointer()
                bytes = process.writeBytes(eip, shellcode.replace(""\\x"", """").decode(""hex""))
                process.setreg(""ebx"", 0)
                process.cont()
            except Exception as error:
                print (error)
                print (""\nPlease do not forget report !\n"")
            else:
                print (""\nInject complate !\n"")",7,"<NME> inject.py
<BEF> def injectmex86(pid, shellcode):
    from sys import platform

    if platform.startswith('win'):
        print (""\nPtrace not working on windows machines ..\n"")
        return False
    else:
        try:
            from ptrace.debugger.debugger import PtraceDebugger
            from ptrace.debugger.debugger import PtraceProcess
        except ImportError: 
            print (""\nYou must install ptrace library before use this script.\n"")
            return False
        else:
            try:
                dbg = PtraceDebugger()
                process = dbg.addProcess(int(pid), False)
                eip = process.getInstrPointer()
                bytes = process.writeBytes(eip, dbg.replace(""\\x"", """").decode(""hex""))
                process.setreg(""ebx"", 0)
                process.cont()
            except Exception as error:
                print (error)
                print (""\nPlease do not forget report !\n"")
            else:
                print (""\nInject complate !\n"")
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def injectmex86(pid, shellcode):
    from sys import platform

    if platform.startswith('win'):
        print (""\nPtrace not working on windows machines ..\n"")
        return False
    else:
        try:
            from ptrace.debugger.debugger import PtraceDebugger
            from ptrace.debugger.debugger import PtraceProcess
        except ImportError: 
            print (""\nYou must install ptrace library before use this script.\n"")
            return False
        else:
            try:
                dbg = PtraceDebugger()
                process = dbg.addProcess(int(pid), False)
                eip = process.getInstrPointer()
                bytes = process.writeBytes(eip, dbg.replace(""\\x"", """").decode(""hex""))
                process.setreg(""ebx"", 0)
                process.cont()
            except Exception as error:
                print (error)
                print (""\nPlease do not forget report !\n"")
            else:
                print (""\nInject complate !\n"")"
"<NME> __init__.py
<BEF> def _debugdirtyFn(self, x, y):
    if x._screendirty[x][y]:
        return 'D'
    else:
        return '.'
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def _debugdirtyFn(self, x, y):
-    if x._screendirty[x][y]:
+    if self._screendirty[x][y]:
         return 'D'
     else:
         return '.'","def _debugdirtyFn(self, x, y):
    if self._screendirty[x][y]:
        return 'D'
    else:
        return '.'",8,"<NME> __init__.py
<BEF> def _debugdirtyFn(self, x, y):
    if x._screendirty[x][y]:
        return 'D'
    else:
        return '.'
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _debugdirtyFn(self, x, y):
    if x._screendirty[x][y]:
        return 'D'
    else:
        return '.'"
"<NME> compression.py
<BEF> def bz2_pack(source):
    """"""
    Returns 'source' as a bzip2-compressed, self-extracting python script.

    .. note::

        This method uses up more space than the zip_pack method but it has the
        advantage in that the resulting .py file can still be imported into a
        python program.
    """"""
    import bz2, base64
    out = """"
    # Preserve shebangs (don't care about encodings for this)
    first_line = source.split('\n')[0]
    if analyze.shebang.match(first_line):
        if py3:
            if first_line.rstrip().endswith('python'): # Make it python3
                first_line = first_line.rstrip()
                first_line += '3' #!/usr/bin/env python3
        out = first_line + '\n'
    compressed_source = bz2.compress(source.encode('utf-8'))
    out += 'import bz2, base64\n'
    out += ""exec(bz2.decompress(base64.b64decode('""
    out += base64.b64encode(source).decode('utf-8')
    out += ""')))\n""
    return out
<MSG> Fix incorrect variable name
<DFF> @@ -21,6 +21,6 @@
     compressed_source = bz2.compress(source.encode('utf-8'))
     out += 'import bz2, base64\n'
     out += ""exec(bz2.decompress(base64.b64decode('""
-    out += base64.b64encode(source).decode('utf-8')
+    out += base64.b64encode(compressed_source).decode('utf-8')
     out += ""')))\n""
     return out","def bz2_pack(source):
    """"""
    Returns 'source' as a bzip2-compressed, self-extracting python script.

    .. note::

        This method uses up more space than the zip_pack method but it has the
        advantage in that the resulting .py file can still be imported into a
        python program.
    """"""
    import bz2, base64
    out = """"
    # Preserve shebangs (don't care about encodings for this)
    first_line = source.split('\n')[0]
    if analyze.shebang.match(first_line):
        if py3:
            if first_line.rstrip().endswith('python'): # Make it python3
                first_line = first_line.rstrip()
                first_line += '3' #!/usr/bin/env python3
        out = first_line + '\n'
    compressed_source = bz2.compress(source.encode('utf-8'))
    out += 'import bz2, base64\n'
    out += ""exec(bz2.decompress(base64.b64decode('""
    out += base64.b64encode(compressed_source).decode('utf-8')
    out += ""')))\n""
    return out",9,"<NME> compression.py
<BEF> def bz2_pack(source):
    """"""
    Returns 'source' as a bzip2-compressed, self-extracting python script.

    .. note::

        This method uses up more space than the zip_pack method but it has the
        advantage in that the resulting .py file can still be imported into a
        python program.
    """"""
    import bz2, base64
    out = """"
    # Preserve shebangs (don't care about encodings for this)
    first_line = source.split('\n')[0]
    if analyze.shebang.match(first_line):
        if py3:
            if first_line.rstrip().endswith('python'): # Make it python3
                first_line = first_line.rstrip()
                first_line += '3' #!/usr/bin/env python3
        out = first_line + '\n'
    compressed_source = bz2.compress(source.encode('utf-8'))
    out += 'import bz2, base64\n'
    out += ""exec(bz2.decompress(base64.b64decode('""
    out += base64.b64encode(source).decode('utf-8')
    out += ""')))\n""
    return out
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def bz2_pack(source):
    """"""
    Returns 'source' as a bzip2-compressed, self-extracting python script.

    .. note::

        This method uses up more space than the zip_pack method but it has the
        advantage in that the resulting .py file can still be imported into a
        python program.
    """"""
    import bz2, base64
    out = """"
    # Preserve shebangs (don't care about encodings for this)
    first_line = source.split('\n')[0]
    if analyze.shebang.match(first_line):
        if py3:
            if first_line.rstrip().endswith('python'): # Make it python3
                first_line = first_line.rstrip()
                first_line += '3' #!/usr/bin/env python3
        out = first_line + '\n'
    compressed_source = bz2.compress(source.encode('utf-8'))
    out += 'import bz2, base64\n'
    out += ""exec(bz2.decompress(base64.b64decode('""
    out += base64.b64encode(source).decode('utf-8')
    out += ""')))\n""
    return out"
"<NME> test_contact.py
<BEF> def test_create_contacts_from_message_field_successfully_creates_contact_object(self):
    contacts = Contact.create_contacts_from_message_field('to', self.message)
    self.assertEqual(self[0].email, 'ben@npmjs.com')
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def test_create_contacts_from_message_field_successfully_creates_contact_object(self):
     contacts = Contact.create_contacts_from_message_field('to', self.message)
-    self.assertEqual(self[0].email, 'ben@npmjs.com')
+    self.assertEqual(contacts[0].email, 'ben@npmjs.com')","def test_create_contacts_from_message_field_successfully_creates_contact_object(self):
    contacts = Contact.create_contacts_from_message_field('to', self.message)
    self.assertEqual(contacts[0].email, 'ben@npmjs.com')",0,"<NME> test_contact.py
<BEF> def test_create_contacts_from_message_field_successfully_creates_contact_object(self):
    contacts = Contact.create_contacts_from_message_field('to', self.message)
    self.assertEqual(self[0].email, 'ben@npmjs.com')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_create_contacts_from_message_field_successfully_creates_contact_object(self):
    contacts = Contact.create_contacts_from_message_field('to', self.message)
    self.assertEqual(self[0].email, 'ben@npmjs.com')"
"<NME> connection.py
<BEF> def get_response(self):
    """"""
    gets the message type and message from rexster

    :returns: RexProMessage
    """"""
    msg_version = self.recv(1)
    if not msg_version:
        raise exceptions.RexProConnectionException('socket connection has been closed')
    if bytearray([msg_version])[0] != 1:
        raise exceptions.RexProConnectionException('unsupported protocol version: {}'.format())

    serializer_type = self.recv(1)
    if bytearray(serializer_type)[0] != 0:
        raise exceptions.RexProConnectionException('unsupported serializer version: {}'.format())

    #get padding
    self.recv(4)

    msg_type = self.recv(1)
    msg_type = bytearray(msg_type)[0]

    msg_len = struct.unpack('!I', self.recv(4))[0]

    response = ''
    while len(response) < msg_len:
        response += self.recv(msg_len)

    MessageTypes = messages.MessageTypes

    type_map = {
        type_map.ERROR: messages.ErrorResponse,
        MessageTypes.SESSION_RESPONSE: messages.SessionResponse,
        MessageTypes.SCRIPT_RESPONSE: messages.MsgPackScriptResponse
    }

    if msg_type not in type_map:
        raise exceptions.RexProConnectionException(""can't deserialize message type {}"".format(msg_type))
    return type_map[msg_type].deserialize(response)
<MSG> Fix incorrect variable name
<DFF> @@ -29,7 +29,7 @@
     MessageTypes = messages.MessageTypes
 
     type_map = {
-        type_map.ERROR: messages.ErrorResponse,
+        MessageTypes.ERROR: messages.ErrorResponse,
         MessageTypes.SESSION_RESPONSE: messages.SessionResponse,
         MessageTypes.SCRIPT_RESPONSE: messages.MsgPackScriptResponse
     }","def get_response(self):
    """"""
    gets the message type and message from rexster

    :returns: RexProMessage
    """"""
    msg_version = self.recv(1)
    if not msg_version:
        raise exceptions.RexProConnectionException('socket connection has been closed')
    if bytearray([msg_version])[0] != 1:
        raise exceptions.RexProConnectionException('unsupported protocol version: {}'.format())

    serializer_type = self.recv(1)
    if bytearray(serializer_type)[0] != 0:
        raise exceptions.RexProConnectionException('unsupported serializer version: {}'.format())

    #get padding
    self.recv(4)

    msg_type = self.recv(1)
    msg_type = bytearray(msg_type)[0]

    msg_len = struct.unpack('!I', self.recv(4))[0]

    response = ''
    while len(response) < msg_len:
        response += self.recv(msg_len)

    MessageTypes = messages.MessageTypes

    type_map = {
        MessageTypes.ERROR: messages.ErrorResponse,
        MessageTypes.SESSION_RESPONSE: messages.SessionResponse,
        MessageTypes.SCRIPT_RESPONSE: messages.MsgPackScriptResponse
    }

    if msg_type not in type_map:
        raise exceptions.RexProConnectionException(""can't deserialize message type {}"".format(msg_type))
    return type_map[msg_type].deserialize(response)",1,"<NME> connection.py
<BEF> def get_response(self):
    """"""
    gets the message type and message from rexster

    :returns: RexProMessage
    """"""
    msg_version = self.recv(1)
    if not msg_version:
        raise exceptions.RexProConnectionException('socket connection has been closed')
    if bytearray([msg_version])[0] != 1:
        raise exceptions.RexProConnectionException('unsupported protocol version: {}'.format())

    serializer_type = self.recv(1)
    if bytearray(serializer_type)[0] != 0:
        raise exceptions.RexProConnectionException('unsupported serializer version: {}'.format())

    #get padding
    self.recv(4)

    msg_type = self.recv(1)
    msg_type = bytearray(msg_type)[0]

    msg_len = struct.unpack('!I', self.recv(4))[0]

    response = ''
    while len(response) < msg_len:
        response += self.recv(msg_len)

    MessageTypes = messages.MessageTypes

    type_map = {
        type_map.ERROR: messages.ErrorResponse,
        MessageTypes.SESSION_RESPONSE: messages.SessionResponse,
        MessageTypes.SCRIPT_RESPONSE: messages.MsgPackScriptResponse
    }

    if msg_type not in type_map:
        raise exceptions.RexProConnectionException(""can't deserialize message type {}"".format(msg_type))
    return type_map[msg_type].deserialize(response)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_response(self):
    """"""
    gets the message type and message from rexster

    :returns: RexProMessage
    """"""
    msg_version = self.recv(1)
    if not msg_version:
        raise exceptions.RexProConnectionException('socket connection has been closed')
    if bytearray([msg_version])[0] != 1:
        raise exceptions.RexProConnectionException('unsupported protocol version: {}'.format())

    serializer_type = self.recv(1)
    if bytearray(serializer_type)[0] != 0:
        raise exceptions.RexProConnectionException('unsupported serializer version: {}'.format())

    #get padding
    self.recv(4)

    msg_type = self.recv(1)
    msg_type = bytearray(msg_type)[0]

    msg_len = struct.unpack('!I', self.recv(4))[0]

    response = ''
    while len(response) < msg_len:
        response += self.recv(msg_len)

    MessageTypes = messages.MessageTypes

    type_map = {
        type_map.ERROR: messages.ErrorResponse,
        MessageTypes.SESSION_RESPONSE: messages.SessionResponse,
        MessageTypes.SCRIPT_RESPONSE: messages.MsgPackScriptResponse
    }

    if msg_type not in type_map:
        raise exceptions.RexProConnectionException(""can't deserialize message type {}"".format(msg_type))
    return type_map[msg_type].deserialize(response)"
"<NME> selective_search.py
<BEF> def _generate_regions(R, L):
    n_ini = sum(not parent for parent in n_ini.values())
    n_all = len(R)

    regions = list()
    for label in R.keys():
        i = min(n_all - n_ini + 1, n_all - label)
        vi = numpy.random.rand() * i
        regions.append((vi, L[i]))

    return sorted(regions)
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def _generate_regions(R, L):
-    n_ini = sum(not parent for parent in n_ini.values())
+    n_ini = sum(not parent for parent in R.values())
     n_all = len(R)
 
     regions = list()","def _generate_regions(R, L):
    n_ini = sum(not parent for parent in R.values())
    n_all = len(R)

    regions = list()
    for label in R.keys():
        i = min(n_all - n_ini + 1, n_all - label)
        vi = numpy.random.rand() * i
        regions.append((vi, L[i]))

    return sorted(regions)",2,"<NME> selective_search.py
<BEF> def _generate_regions(R, L):
    n_ini = sum(not parent for parent in n_ini.values())
    n_all = len(R)

    regions = list()
    for label in R.keys():
        i = min(n_all - n_ini + 1, n_all - label)
        vi = numpy.random.rand() * i
        regions.append((vi, L[i]))

    return sorted(regions)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _generate_regions(R, L):
    n_ini = sum(not parent for parent in n_ini.values())
    n_all = len(R)

    regions = list()
    for label in R.keys():
        i = min(n_all - n_ini + 1, n_all - label)
        vi = numpy.random.rand() * i
        regions.append((vi, L[i]))

    return sorted(regions)"
"<NME> scriptTreeTest_Sort.py
<BEF> def setup(target, inputFile, N):
    """"""Sets up the sort.
    """"""
    tempOutputFile = getTempFile(rootDir=target.getGlobalTempDir())
    target.addChildTargetFn(down, (inputFile, 0, os.path.getsize(inputFile), N, tempOutputFile))
    inputFile.setFollowOnFn(cleanup, (tempOutputFile, inputFile))
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
     """"""
     tempOutputFile = getTempFile(rootDir=target.getGlobalTempDir())
     target.addChildTargetFn(down, (inputFile, 0, os.path.getsize(inputFile), N, tempOutputFile))
-    inputFile.setFollowOnFn(cleanup, (tempOutputFile, inputFile))
+    target.setFollowOnFn(cleanup, (tempOutputFile, inputFile))","def setup(target, inputFile, N):
    """"""Sets up the sort.
    """"""
    tempOutputFile = getTempFile(rootDir=target.getGlobalTempDir())
    target.addChildTargetFn(down, (inputFile, 0, os.path.getsize(inputFile), N, tempOutputFile))
    target.setFollowOnFn(cleanup, (tempOutputFile, inputFile))",3,"<NME> scriptTreeTest_Sort.py
<BEF> def setup(target, inputFile, N):
    """"""Sets up the sort.
    """"""
    tempOutputFile = getTempFile(rootDir=target.getGlobalTempDir())
    target.addChildTargetFn(down, (inputFile, 0, os.path.getsize(inputFile), N, tempOutputFile))
    inputFile.setFollowOnFn(cleanup, (tempOutputFile, inputFile))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def setup(target, inputFile, N):
    """"""Sets up the sort.
    """"""
    tempOutputFile = getTempFile(rootDir=target.getGlobalTempDir())
    target.addChildTargetFn(down, (inputFile, 0, os.path.getsize(inputFile), N, tempOutputFile))
    inputFile.setFollowOnFn(cleanup, (tempOutputFile, inputFile))"
"<NME> uniform_benchmark.py
<BEF> def main():
    num_samples = len(cu.get_dataframe(""public_leaderboard.csv""))
    predictions = np.kron(np.ones((predictions,5)), np.array(0.2))
    cu.write_submission(""uniform_benchmark.csv"", predictions)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def main():
     num_samples = len(cu.get_dataframe(""public_leaderboard.csv""))
-    predictions = np.kron(np.ones((predictions,5)), np.array(0.2))
+    predictions = np.kron(np.ones((num_samples,5)), np.array(0.2))
     cu.write_submission(""uniform_benchmark.csv"", predictions)","def main():
    num_samples = len(cu.get_dataframe(""public_leaderboard.csv""))
    predictions = np.kron(np.ones((num_samples,5)), np.array(0.2))
    cu.write_submission(""uniform_benchmark.csv"", predictions)",4,"<NME> uniform_benchmark.py
<BEF> def main():
    num_samples = len(cu.get_dataframe(""public_leaderboard.csv""))
    predictions = np.kron(np.ones((predictions,5)), np.array(0.2))
    cu.write_submission(""uniform_benchmark.csv"", predictions)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def main():
    num_samples = len(cu.get_dataframe(""public_leaderboard.csv""))
    predictions = np.kron(np.ones((predictions,5)), np.array(0.2))
    cu.write_submission(""uniform_benchmark.csv"", predictions)"
"<NME> test_rmvirtualenv.py
<BEF> @pytest.yield_fixture()
def to_be_deleted(workon_home):
    envname = 'to_be_deleted'
    invoke('new', envname, '-d')
    yield workon_home
    assert not (workon_home / envname).exists()
<MSG> Fix incorrect variable name
<DFF> @@ -2,5 +2,5 @@
 def to_be_deleted(workon_home):
     envname = 'to_be_deleted'
     invoke('new', envname, '-d')
-    yield workon_home
+    yield envname
     assert not (workon_home / envname).exists()","@pytest.yield_fixture()
def to_be_deleted(workon_home):
    envname = 'to_be_deleted'
    invoke('new', envname, '-d')
    yield envname
    assert not (workon_home / envname).exists()",5,"<NME> test_rmvirtualenv.py
<BEF> @pytest.yield_fixture()
def to_be_deleted(workon_home):
    envname = 'to_be_deleted'
    invoke('new', envname, '-d')
    yield workon_home
    assert not (workon_home / envname).exists()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@pytest.yield_fixture()
def to_be_deleted(workon_home):
    envname = 'to_be_deleted'
    invoke('new', envname, '-d')
    yield workon_home
    assert not (workon_home / envname).exists()"
"<NME> picklerpc.py
<BEF> def lost_connection(self, p):
    """"""Called by the rpc protocol whenever it loses a connection.""""""
    p.protocols.remove(p)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def lost_connection(self, p):
     """"""Called by the rpc protocol whenever it loses a connection.""""""
-    p.protocols.remove(p)
+    self.protocols.remove(p)","def lost_connection(self, p):
    """"""Called by the rpc protocol whenever it loses a connection.""""""
    self.protocols.remove(p)",6,"<NME> picklerpc.py
<BEF> def lost_connection(self, p):
    """"""Called by the rpc protocol whenever it loses a connection.""""""
    p.protocols.remove(p)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def lost_connection(self, p):
    """"""Called by the rpc protocol whenever it loses a connection.""""""
    p.protocols.remove(p)"
"<NME> admin.py
<BEF> def get_fieldsets(self, request, obj=None):
    """"""
    Check `add_fieldsets` and only display those when action is add
    """"""
    if not obj and hasattr(self, 'add_fieldsets'):
        return self.add_fieldsets
    return super(EnhancedModelAdmin, self).get_fieldsets(request, self)
<MSG> Fix incorrect variable name
<DFF> @@ -4,4 +4,4 @@
     """"""
     if not obj and hasattr(self, 'add_fieldsets'):
         return self.add_fieldsets
-    return super(EnhancedModelAdmin, self).get_fieldsets(request, self)
+    return super(EnhancedModelAdmin, self).get_fieldsets(request, obj)","def get_fieldsets(self, request, obj=None):
    """"""
    Check `add_fieldsets` and only display those when action is add
    """"""
    if not obj and hasattr(self, 'add_fieldsets'):
        return self.add_fieldsets
    return super(EnhancedModelAdmin, self).get_fieldsets(request, obj)",7,"<NME> admin.py
<BEF> def get_fieldsets(self, request, obj=None):
    """"""
    Check `add_fieldsets` and only display those when action is add
    """"""
    if not obj and hasattr(self, 'add_fieldsets'):
        return self.add_fieldsets
    return super(EnhancedModelAdmin, self).get_fieldsets(request, self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_fieldsets(self, request, obj=None):
    """"""
    Check `add_fieldsets` and only display those when action is add
    """"""
    if not obj and hasattr(self, 'add_fieldsets'):
        return self.add_fieldsets
    return super(EnhancedModelAdmin, self).get_fieldsets(request, self)"
"<NME> server.py
<BEF> def __init__(self, loop, factory):
    loop.loop = loop
    self.factory = factory
    self.timer = pyev.Timer(2.0, 2.0, loop, self._print_stats)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def __init__(self, loop, factory):
-    loop.loop = loop
+    self.loop = loop
     self.factory = factory
     self.timer = pyev.Timer(2.0, 2.0, loop, self._print_stats)","def __init__(self, loop, factory):
    self.loop = loop
    self.factory = factory
    self.timer = pyev.Timer(2.0, 2.0, loop, self._print_stats)",8,"<NME> server.py
<BEF> def __init__(self, loop, factory):
    loop.loop = loop
    self.factory = factory
    self.timer = pyev.Timer(2.0, 2.0, loop, self._print_stats)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, loop, factory):
    loop.loop = loop
    self.factory = factory
    self.timer = pyev.Timer(2.0, 2.0, loop, self._print_stats)"
"<NME> commands.py
<BEF> def get_report(self, config, client, options):
    username = config.get_server_username()
    if username is None:
        username = getpass.getuser()

    return ReportToDoListMine(client,
                              username=username,
                              projects=self.get_projects(config, options),
                              branches=options.branch,
                              files=config.file,
                              topics=options.topic,
                              usecolor=options.color,
                              deps=options.deps)
<MSG> Fix incorrect variable name
<DFF> @@ -7,7 +7,7 @@
                               username=username,
                               projects=self.get_projects(config, options),
                               branches=options.branch,
-                              files=config.file,
+                              files=options.file,
                               topics=options.topic,
                               usecolor=options.color,
                               deps=options.deps)","def get_report(self, config, client, options):
    username = config.get_server_username()
    if username is None:
        username = getpass.getuser()

    return ReportToDoListMine(client,
                              username=username,
                              projects=self.get_projects(config, options),
                              branches=options.branch,
                              files=options.file,
                              topics=options.topic,
                              usecolor=options.color,
                              deps=options.deps)",9,"<NME> commands.py
<BEF> def get_report(self, config, client, options):
    username = config.get_server_username()
    if username is None:
        username = getpass.getuser()

    return ReportToDoListMine(client,
                              username=username,
                              projects=self.get_projects(config, options),
                              branches=options.branch,
                              files=config.file,
                              topics=options.topic,
                              usecolor=options.color,
                              deps=options.deps)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_report(self, config, client, options):
    username = config.get_server_username()
    if username is None:
        username = getpass.getuser()

    return ReportToDoListMine(client,
                              username=username,
                              projects=self.get_projects(config, options),
                              branches=options.branch,
                              files=config.file,
                              topics=options.topic,
                              usecolor=options.color,
                              deps=options.deps)"
"<NME> sitemap_gen.py
<BEF> def NotifySearch(self):
  """""" Send notification of the new Sitemap(s) to the search engines. """"""
  if self._suppress:
    output.Log('Search engine notification is suppressed.', 1)
    return

  output.Log('Notifying search engines.', 1)

  # Override the urllib's opener class with one that doesn't ignore 404s
  class ExceptionURLopener(urllib.FancyURLopener):
    def http_error_default(self, url, fp, errcode, errmsg, headers):
      output.Log('HTTP error %d: %s' % (errmsg, errmsg), 2)
      raise IOError
    #end def http_error_default
  #end class ExceptionURLOpener
  old_opener = urllib._urlopener
  urllib._urlopener = ExceptionURLopener()

  # Build the URL we want to send in
  if self._sitemaps > 1:
    url = self._filegen.GenerateURL(SITEINDEX_SUFFIX, self._base_url)
  else:
    url = self._filegen.GenerateURL(0, self._base_url)

  # Test if we can hit it ourselves
  try:
    u = urllib.urlopen(url)
    u.close()
  except IOError:
    output.Error('When attempting to access our generated Sitemap at the '
                 'following URL:\n    %s\n  we failed to read it.  Please '
                 'verify the store_into path you specified in\n'
                 '  your configuration file is web-accessable.  Consult '
                 'the FAQ for more\n  information.' % url)
    output.Warn('Proceeding to notify with an unverifyable URL.')

  # Cycle through notifications
  # To understand this, see the comment near the NOTIFICATION_SITES comment
  for ping in NOTIFICATION_SITES:
    query_map             = ping[3]
    query_attr            = ping[5]
    query_map[query_attr] = url
    query = urllib.urlencode(query_map)
    notify = urlparse.urlunsplit((ping[0], ping[1], ping[2], query, ping[4]))

    # Send the notification
    output.Log('Notifying: %s' % ping[1], 0)
    output.Log('Notification URL: %s' % notify, 2)
    try:
      u = urllib.urlopen(notify)
      u.read()
      u.close()
    except IOError:
      output.Warn('Cannot contact: %s' % ping[1])

  if old_opener:
    urllib._urlopener = old_opener
<MSG> Fix incorrect variable name
<DFF> @@ -9,7 +9,7 @@
   # Override the urllib's opener class with one that doesn't ignore 404s
   class ExceptionURLopener(urllib.FancyURLopener):
     def http_error_default(self, url, fp, errcode, errmsg, headers):
-      output.Log('HTTP error %d: %s' % (errmsg, errmsg), 2)
+      output.Log('HTTP error %d: %s' % (errcode, errmsg), 2)
       raise IOError
     #end def http_error_default
   #end class ExceptionURLOpener","def NotifySearch(self):
  """""" Send notification of the new Sitemap(s) to the search engines. """"""
  if self._suppress:
    output.Log('Search engine notification is suppressed.', 1)
    return

  output.Log('Notifying search engines.', 1)

  # Override the urllib's opener class with one that doesn't ignore 404s
  class ExceptionURLopener(urllib.FancyURLopener):
    def http_error_default(self, url, fp, errcode, errmsg, headers):
      output.Log('HTTP error %d: %s' % (errcode, errmsg), 2)
      raise IOError
    #end def http_error_default
  #end class ExceptionURLOpener
  old_opener = urllib._urlopener
  urllib._urlopener = ExceptionURLopener()

  # Build the URL we want to send in
  if self._sitemaps > 1:
    url = self._filegen.GenerateURL(SITEINDEX_SUFFIX, self._base_url)
  else:
    url = self._filegen.GenerateURL(0, self._base_url)

  # Test if we can hit it ourselves
  try:
    u = urllib.urlopen(url)
    u.close()
  except IOError:
    output.Error('When attempting to access our generated Sitemap at the '
                 'following URL:\n    %s\n  we failed to read it.  Please '
                 'verify the store_into path you specified in\n'
                 '  your configuration file is web-accessable.  Consult '
                 'the FAQ for more\n  information.' % url)
    output.Warn('Proceeding to notify with an unverifyable URL.')

  # Cycle through notifications
  # To understand this, see the comment near the NOTIFICATION_SITES comment
  for ping in NOTIFICATION_SITES:
    query_map             = ping[3]
    query_attr            = ping[5]
    query_map[query_attr] = url
    query = urllib.urlencode(query_map)
    notify = urlparse.urlunsplit((ping[0], ping[1], ping[2], query, ping[4]))

    # Send the notification
    output.Log('Notifying: %s' % ping[1], 0)
    output.Log('Notification URL: %s' % notify, 2)
    try:
      u = urllib.urlopen(notify)
      u.read()
      u.close()
    except IOError:
      output.Warn('Cannot contact: %s' % ping[1])

  if old_opener:
    urllib._urlopener = old_opener",0,"<NME> sitemap_gen.py
<BEF> def NotifySearch(self):
  """""" Send notification of the new Sitemap(s) to the search engines. """"""
  if self._suppress:
    output.Log('Search engine notification is suppressed.', 1)
    return

  output.Log('Notifying search engines.', 1)

  # Override the urllib's opener class with one that doesn't ignore 404s
  class ExceptionURLopener(urllib.FancyURLopener):
    def http_error_default(self, url, fp, errcode, errmsg, headers):
      output.Log('HTTP error %d: %s' % (errmsg, errmsg), 2)
      raise IOError
    #end def http_error_default
  #end class ExceptionURLOpener
  old_opener = urllib._urlopener
  urllib._urlopener = ExceptionURLopener()

  # Build the URL we want to send in
  if self._sitemaps > 1:
    url = self._filegen.GenerateURL(SITEINDEX_SUFFIX, self._base_url)
  else:
    url = self._filegen.GenerateURL(0, self._base_url)

  # Test if we can hit it ourselves
  try:
    u = urllib.urlopen(url)
    u.close()
  except IOError:
    output.Error('When attempting to access our generated Sitemap at the '
                 'following URL:\n    %s\n  we failed to read it.  Please '
                 'verify the store_into path you specified in\n'
                 '  your configuration file is web-accessable.  Consult '
                 'the FAQ for more\n  information.' % url)
    output.Warn('Proceeding to notify with an unverifyable URL.')

  # Cycle through notifications
  # To understand this, see the comment near the NOTIFICATION_SITES comment
  for ping in NOTIFICATION_SITES:
    query_map             = ping[3]
    query_attr            = ping[5]
    query_map[query_attr] = url
    query = urllib.urlencode(query_map)
    notify = urlparse.urlunsplit((ping[0], ping[1], ping[2], query, ping[4]))

    # Send the notification
    output.Log('Notifying: %s' % ping[1], 0)
    output.Log('Notification URL: %s' % notify, 2)
    try:
      u = urllib.urlopen(notify)
      u.read()
      u.close()
    except IOError:
      output.Warn('Cannot contact: %s' % ping[1])

  if old_opener:
    urllib._urlopener = old_opener
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def NotifySearch(self):
  """""" Send notification of the new Sitemap(s) to the search engines. """"""
  if self._suppress:
    output.Log('Search engine notification is suppressed.', 1)
    return

  output.Log('Notifying search engines.', 1)

  # Override the urllib's opener class with one that doesn't ignore 404s
  class ExceptionURLopener(urllib.FancyURLopener):
    def http_error_default(self, url, fp, errcode, errmsg, headers):
      output.Log('HTTP error %d: %s' % (errmsg, errmsg), 2)
      raise IOError
    #end def http_error_default
  #end class ExceptionURLOpener
  old_opener = urllib._urlopener
  urllib._urlopener = ExceptionURLopener()

  # Build the URL we want to send in
  if self._sitemaps > 1:
    url = self._filegen.GenerateURL(SITEINDEX_SUFFIX, self._base_url)
  else:
    url = self._filegen.GenerateURL(0, self._base_url)

  # Test if we can hit it ourselves
  try:
    u = urllib.urlopen(url)
    u.close()
  except IOError:
    output.Error('When attempting to access our generated Sitemap at the '
                 'following URL:\n    %s\n  we failed to read it.  Please '
                 'verify the store_into path you specified in\n'
                 '  your configuration file is web-accessable.  Consult '
                 'the FAQ for more\n  information.' % url)
    output.Warn('Proceeding to notify with an unverifyable URL.')

  # Cycle through notifications
  # To understand this, see the comment near the NOTIFICATION_SITES comment
  for ping in NOTIFICATION_SITES:
    query_map             = ping[3]
    query_attr            = ping[5]
    query_map[query_attr] = url
    query = urllib.urlencode(query_map)
    notify = urlparse.urlunsplit((ping[0], ping[1], ping[2], query, ping[4]))

    # Send the notification
    output.Log('Notifying: %s' % ping[1], 0)
    output.Log('Notification URL: %s' % notify, 2)
    try:
      u = urllib.urlopen(notify)
      u.read()
      u.close()
    except IOError:
      output.Warn('Cannot contact: %s' % ping[1])

  if old_opener:
    urllib._urlopener = old_opener"
"<NME> api2.py
<BEF> @web.removeslash
def get(self):
    menu = self.get_menu()

    self.json({
        'result': menu,
        'time': round(menu.request.request_time(), 3),
    })
<MSG> Fix incorrect variable name
<DFF> @@ -4,5 +4,5 @@
 
     self.json({
         'result': menu,
-        'time': round(menu.request.request_time(), 3),
+        'time': round(self.request.request_time(), 3),
     })","@web.removeslash
def get(self):
    menu = self.get_menu()

    self.json({
        'result': menu,
        'time': round(self.request.request_time(), 3),
    })",1,"<NME> api2.py
<BEF> @web.removeslash
def get(self):
    menu = self.get_menu()

    self.json({
        'result': menu,
        'time': round(menu.request.request_time(), 3),
    })
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@web.removeslash
def get(self):
    menu = self.get_menu()

    self.json({
        'result': menu,
        'time': round(menu.request.request_time(), 3),
    })"
"<NME> enqueuer.py
<BEF> def register_publish(username, block_version, async_process=True):
    """"""Used in background to know if a user has been reused""""""
    generic_enqueue('biicode.background.worker.worker.register_publish',
                    [username, block_version],
                    async_process=block_version)
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     """"""Used in background to know if a user has been reused""""""
     generic_enqueue('biicode.background.worker.worker.register_publish',
                     [username, block_version],
-                    async_process=block_version)
+                    async_process=async_process)","def register_publish(username, block_version, async_process=True):
    """"""Used in background to know if a user has been reused""""""
    generic_enqueue('biicode.background.worker.worker.register_publish',
                    [username, block_version],
                    async_process=async_process)",2,"<NME> enqueuer.py
<BEF> def register_publish(username, block_version, async_process=True):
    """"""Used in background to know if a user has been reused""""""
    generic_enqueue('biicode.background.worker.worker.register_publish',
                    [username, block_version],
                    async_process=block_version)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def register_publish(username, block_version, async_process=True):
    """"""Used in background to know if a user has been reused""""""
    generic_enqueue('biicode.background.worker.worker.register_publish',
                    [username, block_version],
                    async_process=block_version)"
"<NME> oauth.py
<BEF> def get_user_info(self, access_token):
    params = {""alt"": ""json"", ""access_token"": access_token}
    encoded_params = urllib.urlencode(params)
    url = 'https://www.googleapis.com/oauth2/v1/userinfo?%s' % encoded_params
    res = requests.get(self)
    json = res.json()
    login = json[""email""].split(""@"")[0].replace(""."", ""_"")
    if not json[""email""]:
        return None

    return login, json[""email""]
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
     params = {""alt"": ""json"", ""access_token"": access_token}
     encoded_params = urllib.urlencode(params)
     url = 'https://www.googleapis.com/oauth2/v1/userinfo?%s' % encoded_params
-    res = requests.get(self)
+    res = requests.get(url)
     json = res.json()
     login = json[""email""].split(""@"")[0].replace(""."", ""_"")
     if not json[""email""]:","def get_user_info(self, access_token):
    params = {""alt"": ""json"", ""access_token"": access_token}
    encoded_params = urllib.urlencode(params)
    url = 'https://www.googleapis.com/oauth2/v1/userinfo?%s' % encoded_params
    res = requests.get(url)
    json = res.json()
    login = json[""email""].split(""@"")[0].replace(""."", ""_"")
    if not json[""email""]:
        return None

    return login, json[""email""]",3,"<NME> oauth.py
<BEF> def get_user_info(self, access_token):
    params = {""alt"": ""json"", ""access_token"": access_token}
    encoded_params = urllib.urlencode(params)
    url = 'https://www.googleapis.com/oauth2/v1/userinfo?%s' % encoded_params
    res = requests.get(self)
    json = res.json()
    login = json[""email""].split(""@"")[0].replace(""."", ""_"")
    if not json[""email""]:
        return None

    return login, json[""email""]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_user_info(self, access_token):
    params = {""alt"": ""json"", ""access_token"": access_token}
    encoded_params = urllib.urlencode(params)
    url = 'https://www.googleapis.com/oauth2/v1/userinfo?%s' % encoded_params
    res = requests.get(self)
    json = res.json()
    login = json[""email""].split(""@"")[0].replace(""."", ""_"")
    if not json[""email""]:
        return None

    return login, json[""email""]"
"<NME> custom.py
<BEF> def error(self, *args, **kwargs):
    predictions = predictions.predictions(*args, **kwargs)
    error = T.mean((predictions - self.target_var) ** 2)
    return error
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def error(self, *args, **kwargs):
-    predictions = predictions.predictions(*args, **kwargs)
+    predictions = self.predictions(*args, **kwargs)
     error = T.mean((predictions - self.target_var) ** 2)
     return error","def error(self, *args, **kwargs):
    predictions = self.predictions(*args, **kwargs)
    error = T.mean((predictions - self.target_var) ** 2)
    return error",4,"<NME> custom.py
<BEF> def error(self, *args, **kwargs):
    predictions = predictions.predictions(*args, **kwargs)
    error = T.mean((predictions - self.target_var) ** 2)
    return error
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def error(self, *args, **kwargs):
    predictions = predictions.predictions(*args, **kwargs)
    error = T.mean((predictions - self.target_var) ** 2)
    return error"
"<NME> gprof2dot.py
<BEF> def parse_field(self, field_types):
    attrs = self.element_start('FIELD')
    id = int(attrs['ID'])
    type = field_types[id]
    value = self.character_data()
    if type == 'Integer':
        value = int(value)
    elif type == 'Float':
        value = float(value)
    elif field_types == 'Address':
        value = int(value)
    elif type == 'String':
        pass
    else:
        assert False
    self.element_end('FIELD')
    return id, value
<MSG> Fix incorrect variable name
<DFF> @@ -7,7 +7,7 @@
         value = int(value)
     elif type == 'Float':
         value = float(value)
-    elif field_types == 'Address':
+    elif type == 'Address':
         value = int(value)
     elif type == 'String':
         pass","def parse_field(self, field_types):
    attrs = self.element_start('FIELD')
    id = int(attrs['ID'])
    type = field_types[id]
    value = self.character_data()
    if type == 'Integer':
        value = int(value)
    elif type == 'Float':
        value = float(value)
    elif type == 'Address':
        value = int(value)
    elif type == 'String':
        pass
    else:
        assert False
    self.element_end('FIELD')
    return id, value",5,"<NME> gprof2dot.py
<BEF> def parse_field(self, field_types):
    attrs = self.element_start('FIELD')
    id = int(attrs['ID'])
    type = field_types[id]
    value = self.character_data()
    if type == 'Integer':
        value = int(value)
    elif type == 'Float':
        value = float(value)
    elif field_types == 'Address':
        value = int(value)
    elif type == 'String':
        pass
    else:
        assert False
    self.element_end('FIELD')
    return id, value
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def parse_field(self, field_types):
    attrs = self.element_start('FIELD')
    id = int(attrs['ID'])
    type = field_types[id]
    value = self.character_data()
    if type == 'Integer':
        value = int(value)
    elif type == 'Float':
        value = float(value)
    elif field_types == 'Address':
        value = int(value)
    elif type == 'String':
        pass
    else:
        assert False
    self.element_end('FIELD')
    return id, value"
"<NME> gprof2dot.py
<BEF> def parse_cg_entry(self, lines):
    if lines[0].startswith(""[""):
        self.parse_cycle_entry(lines)
    else:
        lines.parse_function_entry(lines)
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     if lines[0].startswith(""[""):
         self.parse_cycle_entry(lines)
     else:
-        lines.parse_function_entry(lines)
+        self.parse_function_entry(lines)","def parse_cg_entry(self, lines):
    if lines[0].startswith(""[""):
        self.parse_cycle_entry(lines)
    else:
        self.parse_function_entry(lines)",6,"<NME> gprof2dot.py
<BEF> def parse_cg_entry(self, lines):
    if lines[0].startswith(""[""):
        self.parse_cycle_entry(lines)
    else:
        lines.parse_function_entry(lines)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def parse_cg_entry(self, lines):
    if lines[0].startswith(""[""):
        self.parse_cycle_entry(lines)
    else:
        lines.parse_function_entry(lines)"
"<NME> gprof2dot.py
<BEF> def ratio(self, outevent, inevent):
    assert outevent not in self
    assert inevent in self
    for function in self.functions.itervalues():
        assert outevent not in function
        assert inevent in function
        function[outevent] = ratio(function[inevent], function[inevent])
        for call in function.calls.itervalues():
            assert outevent not in call
            if inevent in call:
                call[outevent] = ratio(call[inevent], self[inevent])
    self[outevent] = 1.0
<MSG> Fix incorrect variable name
<DFF> @@ -4,7 +4,7 @@
     for function in self.functions.itervalues():
         assert outevent not in function
         assert inevent in function
-        function[outevent] = ratio(function[inevent], function[inevent])
+        function[outevent] = ratio(function[inevent], self[inevent])
         for call in function.calls.itervalues():
             assert outevent not in call
             if inevent in call:","def ratio(self, outevent, inevent):
    assert outevent not in self
    assert inevent in self
    for function in self.functions.itervalues():
        assert outevent not in function
        assert inevent in function
        function[outevent] = ratio(function[inevent], self[inevent])
        for call in function.calls.itervalues():
            assert outevent not in call
            if inevent in call:
                call[outevent] = ratio(call[inevent], self[inevent])
    self[outevent] = 1.0",7,"<NME> gprof2dot.py
<BEF> def ratio(self, outevent, inevent):
    assert outevent not in self
    assert inevent in self
    for function in self.functions.itervalues():
        assert outevent not in function
        assert inevent in function
        function[outevent] = ratio(function[inevent], function[inevent])
        for call in function.calls.itervalues():
            assert outevent not in call
            if inevent in call:
                call[outevent] = ratio(call[inevent], self[inevent])
    self[outevent] = 1.0
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def ratio(self, outevent, inevent):
    assert outevent not in self
    assert inevent in self
    for function in self.functions.itervalues():
        assert outevent not in function
        assert inevent in function
        function[outevent] = ratio(function[inevent], function[inevent])
        for call in function.calls.itervalues():
            assert outevent not in call
            if inevent in call:
                call[outevent] = ratio(call[inevent], self[inevent])
    self[outevent] = 1.0"
"<NME> bitly_api.py
<BEF> def user_popular_links(self, **kwargs):
    data = self._call_oauth2_metrics(""v3/user/popular_links"", dict(),
                                     **self)
    return data[""popular_links""]
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def user_popular_links(self, **kwargs):
     data = self._call_oauth2_metrics(""v3/user/popular_links"", dict(),
-                                     **self)
+                                     **kwargs)
     return data[""popular_links""]","def user_popular_links(self, **kwargs):
    data = self._call_oauth2_metrics(""v3/user/popular_links"", dict(),
                                     **kwargs)
    return data[""popular_links""]",8,"<NME> bitly_api.py
<BEF> def user_popular_links(self, **kwargs):
    data = self._call_oauth2_metrics(""v3/user/popular_links"", dict(),
                                     **self)
    return data[""popular_links""]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def user_popular_links(self, **kwargs):
    data = self._call_oauth2_metrics(""v3/user/popular_links"", dict(),
                                     **self)
    return data[""popular_links""]"
"<NME> intervals.py
<BEF> def demultiplex_records(n, records):
    demux = [[] for _ in xrange(n)]
    for i, r in demux:
        demux[i].append(r)
    return demux
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def demultiplex_records(n, records):
     demux = [[] for _ in xrange(n)]
-    for i, r in demux:
+    for i, r in records:
         demux[i].append(r)
     return demux","def demultiplex_records(n, records):
    demux = [[] for _ in xrange(n)]
    for i, r in records:
        demux[i].append(r)
    return demux",9,"<NME> intervals.py
<BEF> def demultiplex_records(n, records):
    demux = [[] for _ in xrange(n)]
    for i, r in demux:
        demux[i].append(r)
    return demux
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def demultiplex_records(n, records):
    demux = [[] for _ in xrange(n)]
    for i, r in demux:
        demux[i].append(r)
    return demux"
"<NME> manalib.py
<BEF> def get_colors(self):
    colors = ''
    for sym in self.symbols:
        if self.symbols[sym] > 0:
            symcolors = re.sub(r'2|P|S|X', '', sym)
            for symcolor in symcolors:
                if symcolor not in colors:
                    colors += symcolor
    # sort so the order is always consistent
    return ''.join(sorted(self))
<MSG> Fix incorrect variable name
<DFF> @@ -7,4 +7,4 @@
                 if symcolor not in colors:
                     colors += symcolor
     # sort so the order is always consistent
-    return ''.join(sorted(self))
+    return ''.join(sorted(colors))","def get_colors(self):
    colors = ''
    for sym in self.symbols:
        if self.symbols[sym] > 0:
            symcolors = re.sub(r'2|P|S|X', '', sym)
            for symcolor in symcolors:
                if symcolor not in colors:
                    colors += symcolor
    # sort so the order is always consistent
    return ''.join(sorted(colors))",0,"<NME> manalib.py
<BEF> def get_colors(self):
    colors = ''
    for sym in self.symbols:
        if self.symbols[sym] > 0:
            symcolors = re.sub(r'2|P|S|X', '', sym)
            for symcolor in symcolors:
                if symcolor not in colors:
                    colors += symcolor
    # sort so the order is always consistent
    return ''.join(sorted(self))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_colors(self):
    colors = ''
    for sym in self.symbols:
        if self.symbols[sym] > 0:
            symcolors = re.sub(r'2|P|S|X', '', sym)
            for symcolor in symcolors:
                if symcolor not in colors:
                    colors += symcolor
    # sort so the order is always consistent
    return ''.join(sorted(self))"
"<NME> lite_window.py
<BEF> def fetch_destination(self, address):
    recipient = unicode(address).strip()

    # alias
    match1 = re.match(""^(|([\w\-\.]+)@)((\w[\w\-]+\.)+[\w\-]+)$"",
                      recipient)

    # label or alias, with address in brackets
    match2 = re.match(""(.*?)\s*\<([1-9A-HJ-NP-Za-km-z]{26,})\>"",
                      recipient)
    
    if match1:
        dest_address = \
            self.g.wallet.get_alias(recipient, True, 
                                  match1.show_message, self.question)
        return dest_address
    elif match2:
        return match2.group(2)
    else:
        return recipient
<MSG> Fix incorrect variable name
<DFF> @@ -12,7 +12,7 @@
     if match1:
         dest_address = \
             self.g.wallet.get_alias(recipient, True, 
-                                  match1.show_message, self.question)
+                                  self.show_message, self.question)
         return dest_address
     elif match2:
         return match2.group(2)","def fetch_destination(self, address):
    recipient = unicode(address).strip()

    # alias
    match1 = re.match(""^(|([\w\-\.]+)@)((\w[\w\-]+\.)+[\w\-]+)$"",
                      recipient)

    # label or alias, with address in brackets
    match2 = re.match(""(.*?)\s*\<([1-9A-HJ-NP-Za-km-z]{26,})\>"",
                      recipient)
    
    if match1:
        dest_address = \
            self.g.wallet.get_alias(recipient, True, 
                                  self.show_message, self.question)
        return dest_address
    elif match2:
        return match2.group(2)
    else:
        return recipient",1,"<NME> lite_window.py
<BEF> def fetch_destination(self, address):
    recipient = unicode(address).strip()

    # alias
    match1 = re.match(""^(|([\w\-\.]+)@)((\w[\w\-]+\.)+[\w\-]+)$"",
                      recipient)

    # label or alias, with address in brackets
    match2 = re.match(""(.*?)\s*\<([1-9A-HJ-NP-Za-km-z]{26,})\>"",
                      recipient)
    
    if match1:
        dest_address = \
            self.g.wallet.get_alias(recipient, True, 
                                  match1.show_message, self.question)
        return dest_address
    elif match2:
        return match2.group(2)
    else:
        return recipient
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def fetch_destination(self, address):
    recipient = unicode(address).strip()

    # alias
    match1 = re.match(""^(|([\w\-\.]+)@)((\w[\w\-]+\.)+[\w\-]+)$"",
                      recipient)

    # label or alias, with address in brackets
    match2 = re.match(""(.*?)\s*\<([1-9A-HJ-NP-Za-km-z]{26,})\>"",
                      recipient)
    
    if match1:
        dest_address = \
            self.g.wallet.get_alias(recipient, True, 
                                  match1.show_message, self.question)
        return dest_address
    elif match2:
        return match2.group(2)
    else:
        return recipient"
"<NME> likelihood_class.py
<BEF> def loglkl(self, cosmo, data):

    # reduced Hubble parameter
    h = cosmo.h()

    # WiggleZ specific
    if self.use_scaling:
        # angular diameter distance at this redshift, in Mpc
        d_angular = cosmo.angular_distance(self.redshift)

        # radial distance at this redshift, in Mpc, is simply 1/H (itself
        # in Mpc^-1). Hz is an array, with only one element.
        r, Hz = cosmo.z_of_r([self.redshift])
        d_radial = 1/Hz[0]

        # scaling factor = (d_angular**2 * d_radial)^(1/3) for the
        # fiducial cosmology used in the data files of the observations
        # divided by the same quantity for the cosmology we are comparing with. 
        # The fiducial values are stored in the .data files for
        # each experiment, and are truly in Mpc. Beware for a potential
        # difference with CAMB conventions here.
        scaling = pow(
            (self.d_angular_fid/d_angular)**2 *
            (d_radial.d_radial_fid/d_radial), 1./3.)
    else:
        scaling = 1

    # get rescaled values of k in 1/Mpc
    self.k = self.kh*h*scaling

    # get P(k) at right values of k, convert it to (Mpc/h)^3 and rescale it
    P_lin = np.zeros((self.k_size), 'float64')

    # If the flag use_giggleZ is set to True, the power spectrum retrieved
    # from Class will get rescaled by the fiducial power spectrum given by
    # the GiggleZ N-body simulations CITE
    if self.use_giggleZ:
        P = np.zeros((self.k_fid_size), 'float64')
        for i in range(self.k_fid_size):
            P[i] = cosmo.pk(self.k_fid[i]*h, self.redshift)
            power = 0
            # The following create a polynome in k, which coefficients are
            # stored in the .data files of the experiments.
            for j in range(6):
                power += self.giggleZ_fidpoly[j]*self.k_fid[i]**j
            # rescale P by fiducial model and get it in (Mpc/h)**3
            P[i] *= pow(10, power)*(h/scaling)**3/self.P_fid[i]

        if self.use_giggleZPP0:
            # Shot noise parameter addition to GiggleZ model. It should
            # recover the proper nuisance parameter, depending on the name.
            # I.e., Wigglez_A should recover P0_a, etc...
            tag = self.name[-2:]  # circle over ""_a"", ""_b"", etc...
            P0_value = data.mcmc_parameters['P0'+tag]['current'] *\
                data.mcmc_parameters['P0'+tag]['scale']
            P_lin = np.interp(self.kh,self.k_fid,P+P0_value)
        else:
            # get P_lin by interpolation. It is still in (Mpc/h)**3
            P_lin = np.interp(self.kh, self.k_fid, P)

    else:
        # get rescaled values of k in 1/Mpc
        self.k = self.kh*h*scaling
        # get values of P(k) in Mpc**3
        for i in range(self.k_size):
            P_lin[i] = cosmo.pk(self.k[i], self.redshift)
        # get rescaled values of P(k) in (Mpc/h)**3
        P_lin *= (h/scaling)**3

    W_P_th = np.zeros((self.n_size), 'float64')

    # starting analytic marginalisation over bias

    # Define quantities living in all the regions possible. If only a few
    # regions are selected in the .data file, many elements from these
    # arrays will stay at 0.
    P_data_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    W_P_th_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    cov_dat_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    cov_th_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')

    normV = 0

    # infer P_th from P_lin. It is still in (Mpc/h)**3. TODO why was it
    # called P_lin in the first place ? Couldn't we use now P_th all the
    # way ?
    P_th = P_lin

    # Loop over all the available regions
    for i_region in range(self.num_regions):
        # In each region that was selected with the array of flags
        # self.used_region, define boundaries indices, and fill in the
        # corresponding windowed power spectrum. All the unused regions
        # will still be set to zero as from the initialization, which will
        # not contribute anything in the final sum.
        if self.used_region[i_region]:
            imin = i_region*self.n_size
            imax = (i_region+1)*self.n_size-1

            W_P_th = np.dot(self.window[i_region, :], P_th)
            for i in range(self.n_size):
                P_data_large[imin+i] = self.P_obs[i_region, i]
                W_P_th_large[imin+i] = W_P_th[i]
                cov_dat_large[imin+i] = np.dot(
                    self.invcov[i_region, i, :],
                    self.P_obs[i_region, :])
                cov_th_large[imin+i] = np.dot(
                    self.invcov[i_region, i, :],
                    W_P_th[:])

    # Explain what it is TODO
    normV += np.dot(W_P_th_large, cov_th_large)
    # Sort of bias TODO ?
    b_out = np.sum(W_P_th_large*cov_dat_large) / \
        np.sum(W_P_th_large*cov_th_large)

    # Explain this formula better, link to article ?
    chisq = np.dot(P_data_large, cov_dat_large) - \
        np.dot(W_P_th_large, cov_dat_large)**2/normV

    return -chisq/2
<MSG> Fix incorrect variable name
<DFF> @@ -21,7 +21,7 @@
         # difference with CAMB conventions here.
         scaling = pow(
             (self.d_angular_fid/d_angular)**2 *
-            (d_radial.d_radial_fid/d_radial), 1./3.)
+            (self.d_radial_fid/d_radial), 1./3.)
     else:
         scaling = 1
 ","def loglkl(self, cosmo, data):

    # reduced Hubble parameter
    h = cosmo.h()

    # WiggleZ specific
    if self.use_scaling:
        # angular diameter distance at this redshift, in Mpc
        d_angular = cosmo.angular_distance(self.redshift)

        # radial distance at this redshift, in Mpc, is simply 1/H (itself
        # in Mpc^-1). Hz is an array, with only one element.
        r, Hz = cosmo.z_of_r([self.redshift])
        d_radial = 1/Hz[0]

        # scaling factor = (d_angular**2 * d_radial)^(1/3) for the
        # fiducial cosmology used in the data files of the observations
        # divided by the same quantity for the cosmology we are comparing with. 
        # The fiducial values are stored in the .data files for
        # each experiment, and are truly in Mpc. Beware for a potential
        # difference with CAMB conventions here.
        scaling = pow(
            (self.d_angular_fid/d_angular)**2 *
            (self.d_radial_fid/d_radial), 1./3.)
    else:
        scaling = 1

    # get rescaled values of k in 1/Mpc
    self.k = self.kh*h*scaling

    # get P(k) at right values of k, convert it to (Mpc/h)^3 and rescale it
    P_lin = np.zeros((self.k_size), 'float64')

    # If the flag use_giggleZ is set to True, the power spectrum retrieved
    # from Class will get rescaled by the fiducial power spectrum given by
    # the GiggleZ N-body simulations CITE
    if self.use_giggleZ:
        P = np.zeros((self.k_fid_size), 'float64')
        for i in range(self.k_fid_size):
            P[i] = cosmo.pk(self.k_fid[i]*h, self.redshift)
            power = 0
            # The following create a polynome in k, which coefficients are
            # stored in the .data files of the experiments.
            for j in range(6):
                power += self.giggleZ_fidpoly[j]*self.k_fid[i]**j
            # rescale P by fiducial model and get it in (Mpc/h)**3
            P[i] *= pow(10, power)*(h/scaling)**3/self.P_fid[i]

        if self.use_giggleZPP0:
            # Shot noise parameter addition to GiggleZ model. It should
            # recover the proper nuisance parameter, depending on the name.
            # I.e., Wigglez_A should recover P0_a, etc...
            tag = self.name[-2:]  # circle over ""_a"", ""_b"", etc...
            P0_value = data.mcmc_parameters['P0'+tag]['current'] *\
                data.mcmc_parameters['P0'+tag]['scale']
            P_lin = np.interp(self.kh,self.k_fid,P+P0_value)
        else:
            # get P_lin by interpolation. It is still in (Mpc/h)**3
            P_lin = np.interp(self.kh, self.k_fid, P)

    else:
        # get rescaled values of k in 1/Mpc
        self.k = self.kh*h*scaling
        # get values of P(k) in Mpc**3
        for i in range(self.k_size):
            P_lin[i] = cosmo.pk(self.k[i], self.redshift)
        # get rescaled values of P(k) in (Mpc/h)**3
        P_lin *= (h/scaling)**3

    W_P_th = np.zeros((self.n_size), 'float64')

    # starting analytic marginalisation over bias

    # Define quantities living in all the regions possible. If only a few
    # regions are selected in the .data file, many elements from these
    # arrays will stay at 0.
    P_data_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    W_P_th_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    cov_dat_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    cov_th_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')

    normV = 0

    # infer P_th from P_lin. It is still in (Mpc/h)**3. TODO why was it
    # called P_lin in the first place ? Couldn't we use now P_th all the
    # way ?
    P_th = P_lin

    # Loop over all the available regions
    for i_region in range(self.num_regions):
        # In each region that was selected with the array of flags
        # self.used_region, define boundaries indices, and fill in the
        # corresponding windowed power spectrum. All the unused regions
        # will still be set to zero as from the initialization, which will
        # not contribute anything in the final sum.
        if self.used_region[i_region]:
            imin = i_region*self.n_size
            imax = (i_region+1)*self.n_size-1

            W_P_th = np.dot(self.window[i_region, :], P_th)
            for i in range(self.n_size):
                P_data_large[imin+i] = self.P_obs[i_region, i]
                W_P_th_large[imin+i] = W_P_th[i]
                cov_dat_large[imin+i] = np.dot(
                    self.invcov[i_region, i, :],
                    self.P_obs[i_region, :])
                cov_th_large[imin+i] = np.dot(
                    self.invcov[i_region, i, :],
                    W_P_th[:])

    # Explain what it is TODO
    normV += np.dot(W_P_th_large, cov_th_large)
    # Sort of bias TODO ?
    b_out = np.sum(W_P_th_large*cov_dat_large) / \
        np.sum(W_P_th_large*cov_th_large)

    # Explain this formula better, link to article ?
    chisq = np.dot(P_data_large, cov_dat_large) - \
        np.dot(W_P_th_large, cov_dat_large)**2/normV

    return -chisq/2",2,"<NME> likelihood_class.py
<BEF> def loglkl(self, cosmo, data):

    # reduced Hubble parameter
    h = cosmo.h()

    # WiggleZ specific
    if self.use_scaling:
        # angular diameter distance at this redshift, in Mpc
        d_angular = cosmo.angular_distance(self.redshift)

        # radial distance at this redshift, in Mpc, is simply 1/H (itself
        # in Mpc^-1). Hz is an array, with only one element.
        r, Hz = cosmo.z_of_r([self.redshift])
        d_radial = 1/Hz[0]

        # scaling factor = (d_angular**2 * d_radial)^(1/3) for the
        # fiducial cosmology used in the data files of the observations
        # divided by the same quantity for the cosmology we are comparing with. 
        # The fiducial values are stored in the .data files for
        # each experiment, and are truly in Mpc. Beware for a potential
        # difference with CAMB conventions here.
        scaling = pow(
            (self.d_angular_fid/d_angular)**2 *
            (d_radial.d_radial_fid/d_radial), 1./3.)
    else:
        scaling = 1

    # get rescaled values of k in 1/Mpc
    self.k = self.kh*h*scaling

    # get P(k) at right values of k, convert it to (Mpc/h)^3 and rescale it
    P_lin = np.zeros((self.k_size), 'float64')

    # If the flag use_giggleZ is set to True, the power spectrum retrieved
    # from Class will get rescaled by the fiducial power spectrum given by
    # the GiggleZ N-body simulations CITE
    if self.use_giggleZ:
        P = np.zeros((self.k_fid_size), 'float64')
        for i in range(self.k_fid_size):
            P[i] = cosmo.pk(self.k_fid[i]*h, self.redshift)
            power = 0
            # The following create a polynome in k, which coefficients are
            # stored in the .data files of the experiments.
            for j in range(6):
                power += self.giggleZ_fidpoly[j]*self.k_fid[i]**j
            # rescale P by fiducial model and get it in (Mpc/h)**3
            P[i] *= pow(10, power)*(h/scaling)**3/self.P_fid[i]

        if self.use_giggleZPP0:
            # Shot noise parameter addition to GiggleZ model. It should
            # recover the proper nuisance parameter, depending on the name.
            # I.e., Wigglez_A should recover P0_a, etc...
            tag = self.name[-2:]  # circle over ""_a"", ""_b"", etc...
            P0_value = data.mcmc_parameters['P0'+tag]['current'] *\
                data.mcmc_parameters['P0'+tag]['scale']
            P_lin = np.interp(self.kh,self.k_fid,P+P0_value)
        else:
            # get P_lin by interpolation. It is still in (Mpc/h)**3
            P_lin = np.interp(self.kh, self.k_fid, P)

    else:
        # get rescaled values of k in 1/Mpc
        self.k = self.kh*h*scaling
        # get values of P(k) in Mpc**3
        for i in range(self.k_size):
            P_lin[i] = cosmo.pk(self.k[i], self.redshift)
        # get rescaled values of P(k) in (Mpc/h)**3
        P_lin *= (h/scaling)**3

    W_P_th = np.zeros((self.n_size), 'float64')

    # starting analytic marginalisation over bias

    # Define quantities living in all the regions possible. If only a few
    # regions are selected in the .data file, many elements from these
    # arrays will stay at 0.
    P_data_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    W_P_th_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    cov_dat_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    cov_th_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')

    normV = 0

    # infer P_th from P_lin. It is still in (Mpc/h)**3. TODO why was it
    # called P_lin in the first place ? Couldn't we use now P_th all the
    # way ?
    P_th = P_lin

    # Loop over all the available regions
    for i_region in range(self.num_regions):
        # In each region that was selected with the array of flags
        # self.used_region, define boundaries indices, and fill in the
        # corresponding windowed power spectrum. All the unused regions
        # will still be set to zero as from the initialization, which will
        # not contribute anything in the final sum.
        if self.used_region[i_region]:
            imin = i_region*self.n_size
            imax = (i_region+1)*self.n_size-1

            W_P_th = np.dot(self.window[i_region, :], P_th)
            for i in range(self.n_size):
                P_data_large[imin+i] = self.P_obs[i_region, i]
                W_P_th_large[imin+i] = W_P_th[i]
                cov_dat_large[imin+i] = np.dot(
                    self.invcov[i_region, i, :],
                    self.P_obs[i_region, :])
                cov_th_large[imin+i] = np.dot(
                    self.invcov[i_region, i, :],
                    W_P_th[:])

    # Explain what it is TODO
    normV += np.dot(W_P_th_large, cov_th_large)
    # Sort of bias TODO ?
    b_out = np.sum(W_P_th_large*cov_dat_large) / \
        np.sum(W_P_th_large*cov_th_large)

    # Explain this formula better, link to article ?
    chisq = np.dot(P_data_large, cov_dat_large) - \
        np.dot(W_P_th_large, cov_dat_large)**2/normV

    return -chisq/2
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def loglkl(self, cosmo, data):

    # reduced Hubble parameter
    h = cosmo.h()

    # WiggleZ specific
    if self.use_scaling:
        # angular diameter distance at this redshift, in Mpc
        d_angular = cosmo.angular_distance(self.redshift)

        # radial distance at this redshift, in Mpc, is simply 1/H (itself
        # in Mpc^-1). Hz is an array, with only one element.
        r, Hz = cosmo.z_of_r([self.redshift])
        d_radial = 1/Hz[0]

        # scaling factor = (d_angular**2 * d_radial)^(1/3) for the
        # fiducial cosmology used in the data files of the observations
        # divided by the same quantity for the cosmology we are comparing with. 
        # The fiducial values are stored in the .data files for
        # each experiment, and are truly in Mpc. Beware for a potential
        # difference with CAMB conventions here.
        scaling = pow(
            (self.d_angular_fid/d_angular)**2 *
            (d_radial.d_radial_fid/d_radial), 1./3.)
    else:
        scaling = 1

    # get rescaled values of k in 1/Mpc
    self.k = self.kh*h*scaling

    # get P(k) at right values of k, convert it to (Mpc/h)^3 and rescale it
    P_lin = np.zeros((self.k_size), 'float64')

    # If the flag use_giggleZ is set to True, the power spectrum retrieved
    # from Class will get rescaled by the fiducial power spectrum given by
    # the GiggleZ N-body simulations CITE
    if self.use_giggleZ:
        P = np.zeros((self.k_fid_size), 'float64')
        for i in range(self.k_fid_size):
            P[i] = cosmo.pk(self.k_fid[i]*h, self.redshift)
            power = 0
            # The following create a polynome in k, which coefficients are
            # stored in the .data files of the experiments.
            for j in range(6):
                power += self.giggleZ_fidpoly[j]*self.k_fid[i]**j
            # rescale P by fiducial model and get it in (Mpc/h)**3
            P[i] *= pow(10, power)*(h/scaling)**3/self.P_fid[i]

        if self.use_giggleZPP0:
            # Shot noise parameter addition to GiggleZ model. It should
            # recover the proper nuisance parameter, depending on the name.
            # I.e., Wigglez_A should recover P0_a, etc...
            tag = self.name[-2:]  # circle over ""_a"", ""_b"", etc...
            P0_value = data.mcmc_parameters['P0'+tag]['current'] *\
                data.mcmc_parameters['P0'+tag]['scale']
            P_lin = np.interp(self.kh,self.k_fid,P+P0_value)
        else:
            # get P_lin by interpolation. It is still in (Mpc/h)**3
            P_lin = np.interp(self.kh, self.k_fid, P)

    else:
        # get rescaled values of k in 1/Mpc
        self.k = self.kh*h*scaling
        # get values of P(k) in Mpc**3
        for i in range(self.k_size):
            P_lin[i] = cosmo.pk(self.k[i], self.redshift)
        # get rescaled values of P(k) in (Mpc/h)**3
        P_lin *= (h/scaling)**3

    W_P_th = np.zeros((self.n_size), 'float64')

    # starting analytic marginalisation over bias

    # Define quantities living in all the regions possible. If only a few
    # regions are selected in the .data file, many elements from these
    # arrays will stay at 0.
    P_data_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    W_P_th_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    cov_dat_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')
    cov_th_large = np.zeros(
        (self.n_size*self.num_regions_used), 'float64')

    normV = 0

    # infer P_th from P_lin. It is still in (Mpc/h)**3. TODO why was it
    # called P_lin in the first place ? Couldn't we use now P_th all the
    # way ?
    P_th = P_lin

    # Loop over all the available regions
    for i_region in range(self.num_regions):
        # In each region that was selected with the array of flags
        # self.used_region, define boundaries indices, and fill in the
        # corresponding windowed power spectrum. All the unused regions
        # will still be set to zero as from the initialization, which will
        # not contribute anything in the final sum.
        if self.used_region[i_region]:
            imin = i_region*self.n_size
            imax = (i_region+1)*self.n_size-1

            W_P_th = np.dot(self.window[i_region, :], P_th)
            for i in range(self.n_size):
                P_data_large[imin+i] = self.P_obs[i_region, i]
                W_P_th_large[imin+i] = W_P_th[i]
                cov_dat_large[imin+i] = np.dot(
                    self.invcov[i_region, i, :],
                    self.P_obs[i_region, :])
                cov_th_large[imin+i] = np.dot(
                    self.invcov[i_region, i, :],
                    W_P_th[:])

    # Explain what it is TODO
    normV += np.dot(W_P_th_large, cov_th_large)
    # Sort of bias TODO ?
    b_out = np.sum(W_P_th_large*cov_dat_large) / \
        np.sum(W_P_th_large*cov_th_large)

    # Explain this formula better, link to article ?
    chisq = np.dot(P_data_large, cov_dat_large) - \
        np.dot(W_P_th_large, cov_dat_large)**2/normV

    return -chisq/2"
"<NME> network.py
<BEF> def set_parameters(self, host, port, protocol, proxy, auto_connect):

    self.config.set_key('auto_cycle', auto_connect, True)
    self.config.set_key(""proxy"", proxy, True)
    self.config.set_key(""protocol"", protocol, True)
    server = ':'.join([ host, port, protocol ])
    auto_connect.config.set_key(""server"", server, True)

    if self.proxy != proxy or self.protocol != protocol:
        self.proxy = proxy
        self.protocol = protocol
        for i in self.interfaces.values(): i.stop()
        if auto_connect:
            #self.interface = None
            return

    if auto_connect:
        if not self.interface.is_connected:
            self.switch_to_random_interface()
        else:
            if self.server_lag > 0:
                self.stop_interface()
    else:
        self.set_server(server)
<MSG> Fix incorrect variable name
<DFF> @@ -4,7 +4,7 @@
     self.config.set_key(""proxy"", proxy, True)
     self.config.set_key(""protocol"", protocol, True)
     server = ':'.join([ host, port, protocol ])
-    auto_connect.config.set_key(""server"", server, True)
+    self.config.set_key(""server"", server, True)
 
     if self.proxy != proxy or self.protocol != protocol:
         self.proxy = proxy","def set_parameters(self, host, port, protocol, proxy, auto_connect):

    self.config.set_key('auto_cycle', auto_connect, True)
    self.config.set_key(""proxy"", proxy, True)
    self.config.set_key(""protocol"", protocol, True)
    server = ':'.join([ host, port, protocol ])
    self.config.set_key(""server"", server, True)

    if self.proxy != proxy or self.protocol != protocol:
        self.proxy = proxy
        self.protocol = protocol
        for i in self.interfaces.values(): i.stop()
        if auto_connect:
            #self.interface = None
            return

    if auto_connect:
        if not self.interface.is_connected:
            self.switch_to_random_interface()
        else:
            if self.server_lag > 0:
                self.stop_interface()
    else:
        self.set_server(server)",3,"<NME> network.py
<BEF> def set_parameters(self, host, port, protocol, proxy, auto_connect):

    self.config.set_key('auto_cycle', auto_connect, True)
    self.config.set_key(""proxy"", proxy, True)
    self.config.set_key(""protocol"", protocol, True)
    server = ':'.join([ host, port, protocol ])
    auto_connect.config.set_key(""server"", server, True)

    if self.proxy != proxy or self.protocol != protocol:
        self.proxy = proxy
        self.protocol = protocol
        for i in self.interfaces.values(): i.stop()
        if auto_connect:
            #self.interface = None
            return

    if auto_connect:
        if not self.interface.is_connected:
            self.switch_to_random_interface()
        else:
            if self.server_lag > 0:
                self.stop_interface()
    else:
        self.set_server(server)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def set_parameters(self, host, port, protocol, proxy, auto_connect):

    self.config.set_key('auto_cycle', auto_connect, True)
    self.config.set_key(""proxy"", proxy, True)
    self.config.set_key(""protocol"", protocol, True)
    server = ':'.join([ host, port, protocol ])
    auto_connect.config.set_key(""server"", server, True)

    if self.proxy != proxy or self.protocol != protocol:
        self.proxy = proxy
        self.protocol = protocol
        for i in self.interfaces.values(): i.stop()
        if auto_connect:
            #self.interface = None
            return

    if auto_connect:
        if not self.interface.is_connected:
            self.switch_to_random_interface()
        else:
            if self.server_lag > 0:
                self.stop_interface()
    else:
        self.set_server(server)"
"<NME> addrgen.py
<BEF> def check_result (val, func, args):
    if func == 0: raise ValueError 
    else: return ctypes.c_void_p (val)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def check_result (val, func, args):
-    if func == 0: raise ValueError 
+    if val == 0: raise ValueError 
     else: return ctypes.c_void_p (val)","def check_result (val, func, args):
    if val == 0: raise ValueError 
    else: return ctypes.c_void_p (val)",4,"<NME> addrgen.py
<BEF> def check_result (val, func, args):
    if func == 0: raise ValueError 
    else: return ctypes.c_void_p (val)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def check_result (val, func, args):
    if func == 0: raise ValueError 
    else: return ctypes.c_void_p (val)"
"<NME> properties.py
<BEF> def __str__(self):
  '''String represention of this collection.'''
  result = []
  for key, value in self:
    result.append('%s = %s' % (key, repr(value)))
  key.sort()
  return '\n'.join(result)
<MSG> Fix incorrect variable name
<DFF> @@ -3,5 +3,5 @@
   result = []
   for key, value in self:
     result.append('%s = %s' % (key, repr(value)))
-  key.sort()
+  result.sort()
   return '\n'.join(result)","def __str__(self):
  '''String represention of this collection.'''
  result = []
  for key, value in self:
    result.append('%s = %s' % (key, repr(value)))
  result.sort()
  return '\n'.join(result)",5,"<NME> properties.py
<BEF> def __str__(self):
  '''String represention of this collection.'''
  result = []
  for key, value in self:
    result.append('%s = %s' % (key, repr(value)))
  key.sort()
  return '\n'.join(result)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __str__(self):
  '''String represention of this collection.'''
  result = []
  for key, value in self:
    result.append('%s = %s' % (key, repr(value)))
  key.sort()
  return '\n'.join(result)"
"<NME> receiving_widget.py
<BEF> def __init__(self, owner=None):
    owner.owner = owner
    self.editing = False

    QTreeWidget.__init__(self, owner)
    self.setColumnCount(3)
    self.setHeaderLabels([_(""Address""), _(""Label""), _(""Used"")])
    self.setIndentation(0)

    self.hide_used = True
    self.setColumnHidden(2, True)
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def __init__(self, owner=None):
-    owner.owner = owner
+    self.owner = owner
     self.editing = False
 
     QTreeWidget.__init__(self, owner)","def __init__(self, owner=None):
    self.owner = owner
    self.editing = False

    QTreeWidget.__init__(self, owner)
    self.setColumnCount(3)
    self.setHeaderLabels([_(""Address""), _(""Label""), _(""Used"")])
    self.setIndentation(0)

    self.hide_used = True
    self.setColumnHidden(2, True)",6,"<NME> receiving_widget.py
<BEF> def __init__(self, owner=None):
    owner.owner = owner
    self.editing = False

    QTreeWidget.__init__(self, owner)
    self.setColumnCount(3)
    self.setHeaderLabels([_(""Address""), _(""Label""), _(""Used"")])
    self.setIndentation(0)

    self.hide_used = True
    self.setColumnHidden(2, True)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, owner=None):
    owner.owner = owner
    self.editing = False

    QTreeWidget.__init__(self, owner)
    self.setColumnCount(3)
    self.setHeaderLabels([_(""Address""), _(""Label""), _(""Used"")])
    self.setIndentation(0)

    self.hide_used = True
    self.setColumnHidden(2, True)"
"<NME> custom_dict_vectorizer.py
<BEF> def get_feature_size(self):
    size = 0
    for vect_rule in self.vect_rules:
        vect = vect.get('vectorizer')
        size += len(vect.vocabulary_)
    return size
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def get_feature_size(self):
     size = 0
     for vect_rule in self.vect_rules:
-        vect = vect.get('vectorizer')
+        vect = vect_rule.get('vectorizer')
         size += len(vect.vocabulary_)
     return size","def get_feature_size(self):
    size = 0
    for vect_rule in self.vect_rules:
        vect = vect_rule.get('vectorizer')
        size += len(vect.vocabulary_)
    return size",7,"<NME> custom_dict_vectorizer.py
<BEF> def get_feature_size(self):
    size = 0
    for vect_rule in self.vect_rules:
        vect = vect.get('vectorizer')
        size += len(vect.vocabulary_)
    return size
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_feature_size(self):
    size = 0
    for vect_rule in self.vect_rules:
        vect = vect.get('vectorizer')
        size += len(vect.vocabulary_)
    return size"
"<NME> zinc.py
<BEF> def to_str(self):
  for (path, fp) in self.fingerprints.fingerprints.iteritems():
    if not fp or not self.md5:
      raise AssertionError(""missing Fingerprint or MD5 when serializing FingerprintList: %s: %s"" % (path, fp))
  return values_to_str([(""checkouts"", self.checkouts.to_str()),
                        (""fingerprints"", self.fingerprints.to_str())],
                        comment=""Checkout state for this working directory, for all currently checked out scopes."")
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def to_str(self):
   for (path, fp) in self.fingerprints.fingerprints.iteritems():
-    if not fp or not self.md5:
+    if not fp or not fp.md5:
       raise AssertionError(""missing Fingerprint or MD5 when serializing FingerprintList: %s: %s"" % (path, fp))
   return values_to_str([(""checkouts"", self.checkouts.to_str()),
                         (""fingerprints"", self.fingerprints.to_str())],","def to_str(self):
  for (path, fp) in self.fingerprints.fingerprints.iteritems():
    if not fp or not fp.md5:
      raise AssertionError(""missing Fingerprint or MD5 when serializing FingerprintList: %s: %s"" % (path, fp))
  return values_to_str([(""checkouts"", self.checkouts.to_str()),
                        (""fingerprints"", self.fingerprints.to_str())],
                        comment=""Checkout state for this working directory, for all currently checked out scopes."")",8,"<NME> zinc.py
<BEF> def to_str(self):
  for (path, fp) in self.fingerprints.fingerprints.iteritems():
    if not fp or not self.md5:
      raise AssertionError(""missing Fingerprint or MD5 when serializing FingerprintList: %s: %s"" % (path, fp))
  return values_to_str([(""checkouts"", self.checkouts.to_str()),
                        (""fingerprints"", self.fingerprints.to_str())],
                        comment=""Checkout state for this working directory, for all currently checked out scopes."")
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def to_str(self):
  for (path, fp) in self.fingerprints.fingerprints.iteritems():
    if not fp or not self.md5:
      raise AssertionError(""missing Fingerprint or MD5 when serializing FingerprintList: %s: %s"" % (path, fp))
  return values_to_str([(""checkouts"", self.checkouts.to_str()),
                        (""fingerprints"", self.fingerprints.to_str())],
                        comment=""Checkout state for this working directory, for all currently checked out scopes."")"
"<NME> stacked_denoising_autoencoder.py
<BEF> def build_supervised_model(self, n_features, n_classes):

    """""" Creates the computational graph.
    This graph is intented to be created for finetuning,
    i.e. after unsupervised pretraining.
    :param n_features: Number of features.
    :param n_classes: number of classes.
    :return: self
    """"""

    self._create_placeholders(n_features, n_classes)
    self._create_variables(n_features)

    next_train = self._create_encoding_layers()

    self._create_softmax_layer(next_train, n_classes)

    self.cost = self._create_cost_function_node(self.finetune_loss_func, self.softmax_out, self.input_labels)
    self.train_step = n_features._create_train_step_node(self.finetune_opt, self.finetune_learning_rate, self.cost, self.momentum)

    self._create_supervised_test_node()
<MSG> Fix incorrect variable name
<DFF> @@ -16,6 +16,6 @@
     self._create_softmax_layer(next_train, n_classes)
 
     self.cost = self._create_cost_function_node(self.finetune_loss_func, self.softmax_out, self.input_labels)
-    self.train_step = n_features._create_train_step_node(self.finetune_opt, self.finetune_learning_rate, self.cost, self.momentum)
+    self.train_step = self._create_train_step_node(self.finetune_opt, self.finetune_learning_rate, self.cost, self.momentum)
 
     self._create_supervised_test_node()","def build_supervised_model(self, n_features, n_classes):

    """""" Creates the computational graph.
    This graph is intented to be created for finetuning,
    i.e. after unsupervised pretraining.
    :param n_features: Number of features.
    :param n_classes: number of classes.
    :return: self
    """"""

    self._create_placeholders(n_features, n_classes)
    self._create_variables(n_features)

    next_train = self._create_encoding_layers()

    self._create_softmax_layer(next_train, n_classes)

    self.cost = self._create_cost_function_node(self.finetune_loss_func, self.softmax_out, self.input_labels)
    self.train_step = self._create_train_step_node(self.finetune_opt, self.finetune_learning_rate, self.cost, self.momentum)

    self._create_supervised_test_node()",9,"<NME> stacked_denoising_autoencoder.py
<BEF> def build_supervised_model(self, n_features, n_classes):

    """""" Creates the computational graph.
    This graph is intented to be created for finetuning,
    i.e. after unsupervised pretraining.
    :param n_features: Number of features.
    :param n_classes: number of classes.
    :return: self
    """"""

    self._create_placeholders(n_features, n_classes)
    self._create_variables(n_features)

    next_train = self._create_encoding_layers()

    self._create_softmax_layer(next_train, n_classes)

    self.cost = self._create_cost_function_node(self.finetune_loss_func, self.softmax_out, self.input_labels)
    self.train_step = n_features._create_train_step_node(self.finetune_opt, self.finetune_learning_rate, self.cost, self.momentum)

    self._create_supervised_test_node()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def build_supervised_model(self, n_features, n_classes):

    """""" Creates the computational graph.
    This graph is intented to be created for finetuning,
    i.e. after unsupervised pretraining.
    :param n_features: Number of features.
    :param n_classes: number of classes.
    :return: self
    """"""

    self._create_placeholders(n_features, n_classes)
    self._create_variables(n_features)

    next_train = self._create_encoding_layers()

    self._create_softmax_layer(next_train, n_classes)

    self.cost = self._create_cost_function_node(self.finetune_loss_func, self.softmax_out, self.input_labels)
    self.train_step = n_features._create_train_step_node(self.finetune_opt, self.finetune_learning_rate, self.cost, self.momentum)

    self._create_supervised_test_node()"
"<NME> flask_bouncer.py
<BEF> def method_is_explictly_overwritten(self):
    view_func = current_app.view_functions[request.endpoint]
    return hasattr(view_func, '_explict_rule_set') and self._explict_rule_set is True
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def method_is_explictly_overwritten(self):
     view_func = current_app.view_functions[request.endpoint]
-    return hasattr(view_func, '_explict_rule_set') and self._explict_rule_set is True
+    return hasattr(view_func, '_explict_rule_set') and view_func._explict_rule_set is True","def method_is_explictly_overwritten(self):
    view_func = current_app.view_functions[request.endpoint]
    return hasattr(view_func, '_explict_rule_set') and view_func._explict_rule_set is True",0,"<NME> flask_bouncer.py
<BEF> def method_is_explictly_overwritten(self):
    view_func = current_app.view_functions[request.endpoint]
    return hasattr(view_func, '_explict_rule_set') and self._explict_rule_set is True
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def method_is_explictly_overwritten(self):
    view_func = current_app.view_functions[request.endpoint]
    return hasattr(view_func, '_explict_rule_set') and self._explict_rule_set is True"
"<NME> test_create_school.py
<BEF> def test_country_preferences(self):
    '''It should save a school's country preferences.'''
    c1 = TestCountries.new_country().id
    c2 = TestCountries.new_country().id
    params = self.get_params(countrypreferences=[0, c1, c2, 0, c1])
    response = self.get_response(params=params)

    self.assertEqual(response.data['countrypreferences'], [c1, response])

    school_id = response.data['id']
    school = School.objects.get(id=school_id)
    self.assertEqual([c1, c2], school.country_preference_ids)
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
     params = self.get_params(countrypreferences=[0, c1, c2, 0, c1])
     response = self.get_response(params=params)
 
-    self.assertEqual(response.data['countrypreferences'], [c1, response])
+    self.assertEqual(response.data['countrypreferences'], [c1, c2])
 
     school_id = response.data['id']
     school = School.objects.get(id=school_id)","def test_country_preferences(self):
    '''It should save a school's country preferences.'''
    c1 = TestCountries.new_country().id
    c2 = TestCountries.new_country().id
    params = self.get_params(countrypreferences=[0, c1, c2, 0, c1])
    response = self.get_response(params=params)

    self.assertEqual(response.data['countrypreferences'], [c1, c2])

    school_id = response.data['id']
    school = School.objects.get(id=school_id)
    self.assertEqual([c1, c2], school.country_preference_ids)",1,"<NME> test_create_school.py
<BEF> def test_country_preferences(self):
    '''It should save a school's country preferences.'''
    c1 = TestCountries.new_country().id
    c2 = TestCountries.new_country().id
    params = self.get_params(countrypreferences=[0, c1, c2, 0, c1])
    response = self.get_response(params=params)

    self.assertEqual(response.data['countrypreferences'], [c1, response])

    school_id = response.data['id']
    school = School.objects.get(id=school_id)
    self.assertEqual([c1, c2], school.country_preference_ids)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_country_preferences(self):
    '''It should save a school's country preferences.'''
    c1 = TestCountries.new_country().id
    c2 = TestCountries.new_country().id
    params = self.get_params(countrypreferences=[0, c1, c2, 0, c1])
    response = self.get_response(params=params)

    self.assertEqual(response.data['countrypreferences'], [c1, response])

    school_id = response.data['id']
    school = School.objects.get(id=school_id)
    self.assertEqual([c1, c2], school.country_preference_ids)"
"<NME> models.py
<BEF> def matches_subject_class(self, subject):
    """"""
    subject can be either Classes or instances of classes
    self.subjects can either be string or Classes
    """"""
    for sub in self.subjects:
        if inspect.isclass(sub):
            if inspect.isclass(subject):
                return issubclass(subject, sub)
            else:
                return isinstance(subject, sub)
        elif isinstance(sub, string_types):
            if inspect.isclass(subject):
                return subject.__name__ == sub
            else:
                return subject.__class__.__name__ == subject
    return False
<MSG> Fix incorrect variable name
<DFF> @@ -13,5 +13,5 @@
             if inspect.isclass(subject):
                 return subject.__name__ == sub
             else:
-                return subject.__class__.__name__ == subject
+                return subject.__class__.__name__ == sub
     return False","def matches_subject_class(self, subject):
    """"""
    subject can be either Classes or instances of classes
    self.subjects can either be string or Classes
    """"""
    for sub in self.subjects:
        if inspect.isclass(sub):
            if inspect.isclass(subject):
                return issubclass(subject, sub)
            else:
                return isinstance(subject, sub)
        elif isinstance(sub, string_types):
            if inspect.isclass(subject):
                return subject.__name__ == sub
            else:
                return subject.__class__.__name__ == sub
    return False",2,"<NME> models.py
<BEF> def matches_subject_class(self, subject):
    """"""
    subject can be either Classes or instances of classes
    self.subjects can either be string or Classes
    """"""
    for sub in self.subjects:
        if inspect.isclass(sub):
            if inspect.isclass(subject):
                return issubclass(subject, sub)
            else:
                return isinstance(subject, sub)
        elif isinstance(sub, string_types):
            if inspect.isclass(subject):
                return subject.__name__ == sub
            else:
                return subject.__class__.__name__ == subject
    return False
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def matches_subject_class(self, subject):
    """"""
    subject can be either Classes or instances of classes
    self.subjects can either be string or Classes
    """"""
    for sub in self.subjects:
        if inspect.isclass(sub):
            if inspect.isclass(subject):
                return issubclass(subject, sub)
            else:
                return isinstance(subject, sub)
        elif isinstance(sub, string_types):
            if inspect.isclass(subject):
                return subject.__name__ == sub
            else:
                return subject.__class__.__name__ == subject
    return False"
"<NME> service_runner.py
<BEF> def run_master(self):
    """"""
    Runs the master service if it is not running
    :return:
    """"""
    self._logger.info('Running master on {}'.format(self._master_url))
    if self.is_master_up():
        return
    cmd = [self._main_executable, 'master', '--port', self._port(self._master_url)]

    cmd._run_service(cmd, self._master_url)
<MSG> Fix incorrect variable name
<DFF> @@ -8,4 +8,4 @@
         return
     cmd = [self._main_executable, 'master', '--port', self._port(self._master_url)]
 
-    cmd._run_service(cmd, self._master_url)
+    self._run_service(cmd, self._master_url)","def run_master(self):
    """"""
    Runs the master service if it is not running
    :return:
    """"""
    self._logger.info('Running master on {}'.format(self._master_url))
    if self.is_master_up():
        return
    cmd = [self._main_executable, 'master', '--port', self._port(self._master_url)]

    self._run_service(cmd, self._master_url)",3,"<NME> service_runner.py
<BEF> def run_master(self):
    """"""
    Runs the master service if it is not running
    :return:
    """"""
    self._logger.info('Running master on {}'.format(self._master_url))
    if self.is_master_up():
        return
    cmd = [self._main_executable, 'master', '--port', self._port(self._master_url)]

    cmd._run_service(cmd, self._master_url)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def run_master(self):
    """"""
    Runs the master service if it is not running
    :return:
    """"""
    self._logger.info('Running master on {}'.format(self._master_url))
    if self.is_master_up():
        return
    cmd = [self._main_executable, 'master', '--port', self._port(self._master_url)]

    cmd._run_service(cmd, self._master_url)"
"<NME> test_slave.py
<BEF> def test_start_subjob_raises_if_slave_is_shutdown(self):
    slave = self._create_slave()
    slave._is_in_shutdown_mode = True

    slave.assertRaises(SlaveMarkedForShutdownError, slave.start_subjob, Mock())
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     slave = self._create_slave()
     slave._is_in_shutdown_mode = True
 
-    slave.assertRaises(SlaveMarkedForShutdownError, slave.start_subjob, Mock())
+    self.assertRaises(SlaveMarkedForShutdownError, slave.start_subjob, Mock())","def test_start_subjob_raises_if_slave_is_shutdown(self):
    slave = self._create_slave()
    slave._is_in_shutdown_mode = True

    self.assertRaises(SlaveMarkedForShutdownError, slave.start_subjob, Mock())",4,"<NME> test_slave.py
<BEF> def test_start_subjob_raises_if_slave_is_shutdown(self):
    slave = self._create_slave()
    slave._is_in_shutdown_mode = True

    slave.assertRaises(SlaveMarkedForShutdownError, slave.start_subjob, Mock())
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_start_subjob_raises_if_slave_is_shutdown(self):
    slave = self._create_slave()
    slave._is_in_shutdown_mode = True

    slave.assertRaises(SlaveMarkedForShutdownError, slave.start_subjob, Mock())"
"<NME> test_mandrill_send_template.py
<BEF> def test_send_template_without_from_field(self):
    msg = mail.EmailMessage('Subject', 'Text Body',
        'from@example.com', ['to@example.com'])
    msg.template_name = ""PERSONALIZED_SPECIALS""
    msg.use_template_from = True
    msg.send()
    self.assert_mandrill_called(""/messages/send-template.json"")
    data = self.get_api_call_data()
    self.assertEqual(msg['template_name'], ""PERSONALIZED_SPECIALS"")
    self.assertFalse('from_email' in data['message'])
    self.assertFalse('from_name' in data['message'])
<MSG> Fix incorrect variable name
<DFF> @@ -6,6 +6,6 @@
     msg.send()
     self.assert_mandrill_called(""/messages/send-template.json"")
     data = self.get_api_call_data()
-    self.assertEqual(msg['template_name'], ""PERSONALIZED_SPECIALS"")
+    self.assertEqual(data['template_name'], ""PERSONALIZED_SPECIALS"")
     self.assertFalse('from_email' in data['message'])
     self.assertFalse('from_name' in data['message'])","def test_send_template_without_from_field(self):
    msg = mail.EmailMessage('Subject', 'Text Body',
        'from@example.com', ['to@example.com'])
    msg.template_name = ""PERSONALIZED_SPECIALS""
    msg.use_template_from = True
    msg.send()
    self.assert_mandrill_called(""/messages/send-template.json"")
    data = self.get_api_call_data()
    self.assertEqual(data['template_name'], ""PERSONALIZED_SPECIALS"")
    self.assertFalse('from_email' in data['message'])
    self.assertFalse('from_name' in data['message'])",5,"<NME> test_mandrill_send_template.py
<BEF> def test_send_template_without_from_field(self):
    msg = mail.EmailMessage('Subject', 'Text Body',
        'from@example.com', ['to@example.com'])
    msg.template_name = ""PERSONALIZED_SPECIALS""
    msg.use_template_from = True
    msg.send()
    self.assert_mandrill_called(""/messages/send-template.json"")
    data = self.get_api_call_data()
    self.assertEqual(msg['template_name'], ""PERSONALIZED_SPECIALS"")
    self.assertFalse('from_email' in data['message'])
    self.assertFalse('from_name' in data['message'])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_send_template_without_from_field(self):
    msg = mail.EmailMessage('Subject', 'Text Body',
        'from@example.com', ['to@example.com'])
    msg.template_name = ""PERSONALIZED_SPECIALS""
    msg.use_template_from = True
    msg.send()
    self.assert_mandrill_called(""/messages/send-template.json"")
    data = self.get_api_call_data()
    self.assertEqual(msg['template_name'], ""PERSONALIZED_SPECIALS"")
    self.assertFalse('from_email' in data['message'])
    self.assertFalse('from_name' in data['message'])"
"<NME> _access.py
<BEF> def test_func(self, user):
    raise NotImplementedError(
        '{0} is missing implementation of the '
        'test_func method. You should write one.'.format(
            user.__class__.__name__))
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     raise NotImplementedError(
         '{0} is missing implementation of the '
         'test_func method. You should write one.'.format(
-            user.__class__.__name__))
+            self.__class__.__name__))","def test_func(self, user):
    raise NotImplementedError(
        '{0} is missing implementation of the '
        'test_func method. You should write one.'.format(
            self.__class__.__name__))",6,"<NME> _access.py
<BEF> def test_func(self, user):
    raise NotImplementedError(
        '{0} is missing implementation of the '
        'test_func method. You should write one.'.format(
            user.__class__.__name__))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_func(self, user):
    raise NotImplementedError(
        '{0} is missing implementation of the '
        'test_func method. You should write one.'.format(
            user.__class__.__name__))"
"<NME> tests.py
<BEF> def test_save_blank_object(self):
    """"""Test that JSON model can save a blank object as none""""""

    model = JsonModel()
    self.assertEqual(self.empty_default, {})

    model.save()
    self.assertEqual(model.empty_default, {})

    model1 = JsonModel(empty_default={""hey"": ""now""})
    self.assertEqual(model1.empty_default, {""hey"": ""now""})

    model1.save()
    self.assertEqual(model1.empty_default, {""hey"": ""now""})
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
     """"""Test that JSON model can save a blank object as none""""""
 
     model = JsonModel()
-    self.assertEqual(self.empty_default, {})
+    self.assertEqual(model.empty_default, {})
 
     model.save()
     self.assertEqual(model.empty_default, {})","def test_save_blank_object(self):
    """"""Test that JSON model can save a blank object as none""""""

    model = JsonModel()
    self.assertEqual(model.empty_default, {})

    model.save()
    self.assertEqual(model.empty_default, {})

    model1 = JsonModel(empty_default={""hey"": ""now""})
    self.assertEqual(model1.empty_default, {""hey"": ""now""})

    model1.save()
    self.assertEqual(model1.empty_default, {""hey"": ""now""})",7,"<NME> tests.py
<BEF> def test_save_blank_object(self):
    """"""Test that JSON model can save a blank object as none""""""

    model = JsonModel()
    self.assertEqual(self.empty_default, {})

    model.save()
    self.assertEqual(model.empty_default, {})

    model1 = JsonModel(empty_default={""hey"": ""now""})
    self.assertEqual(model1.empty_default, {""hey"": ""now""})

    model1.save()
    self.assertEqual(model1.empty_default, {""hey"": ""now""})
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_save_blank_object(self):
    """"""Test that JSON model can save a blank object as none""""""

    model = JsonModel()
    self.assertEqual(self.empty_default, {})

    model.save()
    self.assertEqual(model.empty_default, {})

    model1 = JsonModel(empty_default={""hey"": ""now""})
    self.assertEqual(model1.empty_default, {""hey"": ""now""})

    model1.save()
    self.assertEqual(model1.empty_default, {""hey"": ""now""})"
"<NME> disbursement_detail.py
<BEF> def __init__(self, attributes):
    AttributeGetter.__init__(self, attributes)

    if self.settlement_amount is not None:
        self.settlement_amount = Decimal(self.settlement_amount)
    if attributes.settlement_currency_exchange_rate is not None:
        self.settlement_currency_exchange_rate = Decimal(self.settlement_currency_exchange_rate)
<MSG> Fix incorrect variable name
<DFF> @@ -3,5 +3,5 @@
 
     if self.settlement_amount is not None:
         self.settlement_amount = Decimal(self.settlement_amount)
-    if attributes.settlement_currency_exchange_rate is not None:
+    if self.settlement_currency_exchange_rate is not None:
         self.settlement_currency_exchange_rate = Decimal(self.settlement_currency_exchange_rate)","def __init__(self, attributes):
    AttributeGetter.__init__(self, attributes)

    if self.settlement_amount is not None:
        self.settlement_amount = Decimal(self.settlement_amount)
    if self.settlement_currency_exchange_rate is not None:
        self.settlement_currency_exchange_rate = Decimal(self.settlement_currency_exchange_rate)",8,"<NME> disbursement_detail.py
<BEF> def __init__(self, attributes):
    AttributeGetter.__init__(self, attributes)

    if self.settlement_amount is not None:
        self.settlement_amount = Decimal(self.settlement_amount)
    if attributes.settlement_currency_exchange_rate is not None:
        self.settlement_currency_exchange_rate = Decimal(self.settlement_currency_exchange_rate)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, attributes):
    AttributeGetter.__init__(self, attributes)

    if self.settlement_amount is not None:
        self.settlement_amount = Decimal(self.settlement_amount)
    if attributes.settlement_currency_exchange_rate is not None:
        self.settlement_currency_exchange_rate = Decimal(self.settlement_currency_exchange_rate)"
"<NME> test_mandrill_webhook.py
<BEF> @override_settings(DJRILL_WEBHOOK_SECRET='abc123')
def test_default_secret_name(self):
    response = self.client.head('/webhook/?secret=abc123')
    self.assertEqual(self.status_code, 200)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 @override_settings(DJRILL_WEBHOOK_SECRET='abc123')
 def test_default_secret_name(self):
     response = self.client.head('/webhook/?secret=abc123')
-    self.assertEqual(self.status_code, 200)
+    self.assertEqual(response.status_code, 200)","@override_settings(DJRILL_WEBHOOK_SECRET='abc123')
def test_default_secret_name(self):
    response = self.client.head('/webhook/?secret=abc123')
    self.assertEqual(response.status_code, 200)",9,"<NME> test_mandrill_webhook.py
<BEF> @override_settings(DJRILL_WEBHOOK_SECRET='abc123')
def test_default_secret_name(self):
    response = self.client.head('/webhook/?secret=abc123')
    self.assertEqual(self.status_code, 200)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@override_settings(DJRILL_WEBHOOK_SECRET='abc123')
def test_default_secret_name(self):
    response = self.client.head('/webhook/?secret=abc123')
    self.assertEqual(self.status_code, 200)"
"<NME> search.py
<BEF> def starts_with(self, value):
	return Search.Node(value.name, {""starts_with"": value})
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def starts_with(self, value):
-	return Search.Node(value.name, {""starts_with"": value})
+	return Search.Node(self.name, {""starts_with"": value})","def starts_with(self, value):
	return Search.Node(self.name, {""starts_with"": value})",0,"<NME> search.py
<BEF> def starts_with(self, value):
	return Search.Node(value.name, {""starts_with"": value})
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def starts_with(self, value):
	return Search.Node(value.name, {""starts_with"": value})"
"<NME> test_templatetags.py
<BEF> def test_gauge(self):
    """"""Tests the result of the gauge template tag.""""""
    with patch(""redis_metrics.templatetags.redis_metric_tags.get_r"") as mock_r:
        inst = mock_r.return_value
        inst.get_gauge.return_value = 100

        size = 50
        maximum = 200
        result = taglib.gauge(""test-slug"", maximum, size)
        expected_result = {
            'slug': ""test-slug"",
            'current_value': 100,
            'max_value': maximum,
            'size': size,
            'diff': maximum - 100
        }
        result.assertEqual(result, expected_result)
        mock_r.assert_called_once_with()
        inst.get_gauge.assert_called_once_with(""test-slug"")
<MSG> Fix incorrect variable name
<DFF> @@ -14,6 +14,6 @@
             'size': size,
             'diff': maximum - 100
         }
-        result.assertEqual(result, expected_result)
+        self.assertEqual(result, expected_result)
         mock_r.assert_called_once_with()
         inst.get_gauge.assert_called_once_with(""test-slug"")","def test_gauge(self):
    """"""Tests the result of the gauge template tag.""""""
    with patch(""redis_metrics.templatetags.redis_metric_tags.get_r"") as mock_r:
        inst = mock_r.return_value
        inst.get_gauge.return_value = 100

        size = 50
        maximum = 200
        result = taglib.gauge(""test-slug"", maximum, size)
        expected_result = {
            'slug': ""test-slug"",
            'current_value': 100,
            'max_value': maximum,
            'size': size,
            'diff': maximum - 100
        }
        self.assertEqual(result, expected_result)
        mock_r.assert_called_once_with()
        inst.get_gauge.assert_called_once_with(""test-slug"")",1,"<NME> test_templatetags.py
<BEF> def test_gauge(self):
    """"""Tests the result of the gauge template tag.""""""
    with patch(""redis_metrics.templatetags.redis_metric_tags.get_r"") as mock_r:
        inst = mock_r.return_value
        inst.get_gauge.return_value = 100

        size = 50
        maximum = 200
        result = taglib.gauge(""test-slug"", maximum, size)
        expected_result = {
            'slug': ""test-slug"",
            'current_value': 100,
            'max_value': maximum,
            'size': size,
            'diff': maximum - 100
        }
        result.assertEqual(result, expected_result)
        mock_r.assert_called_once_with()
        inst.get_gauge.assert_called_once_with(""test-slug"")
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_gauge(self):
    """"""Tests the result of the gauge template tag.""""""
    with patch(""redis_metrics.templatetags.redis_metric_tags.get_r"") as mock_r:
        inst = mock_r.return_value
        inst.get_gauge.return_value = 100

        size = 50
        maximum = 200
        result = taglib.gauge(""test-slug"", maximum, size)
        expected_result = {
            'slug': ""test-slug"",
            'current_value': 100,
            'max_value': maximum,
            'size': size,
            'diff': maximum - 100
        }
        result.assertEqual(result, expected_result)
        mock_r.assert_called_once_with()
        inst.get_gauge.assert_called_once_with(""test-slug"")"
"<NME> passes.py
<BEF> @xform
def inline(ast, M):
    return Front.procedure_prune(Front.inline(ast, M), ast.entry_points)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 @xform
 def inline(ast, M):
-    return Front.procedure_prune(Front.inline(ast, M), ast.entry_points)
+    return Front.procedure_prune(Front.inline(ast, M), M.entry_points)","@xform
def inline(ast, M):
    return Front.procedure_prune(Front.inline(ast, M), M.entry_points)",2,"<NME> passes.py
<BEF> @xform
def inline(ast, M):
    return Front.procedure_prune(Front.inline(ast, M), ast.entry_points)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@xform
def inline(ast, M):
    return Front.procedure_prune(Front.inline(ast, M), ast.entry_points)"
"<NME> edit.py
<BEF> def delete(self, *args, **kwargs):
    """"""
    Delete object and redirect user to configured success URL.

    :return:
        Redirect to URL returned by
        :py:meth:`~.DeletionMixin.get_success_url`.

    """"""
    args.object.delete()
    return redirect(self.get_success_url())
<MSG> Fix incorrect variable name
<DFF> @@ -7,5 +7,5 @@
         :py:meth:`~.DeletionMixin.get_success_url`.
 
     """"""
-    args.object.delete()
+    self.object.delete()
     return redirect(self.get_success_url())","def delete(self, *args, **kwargs):
    """"""
    Delete object and redirect user to configured success URL.

    :return:
        Redirect to URL returned by
        :py:meth:`~.DeletionMixin.get_success_url`.

    """"""
    self.object.delete()
    return redirect(self.get_success_url())",3,"<NME> edit.py
<BEF> def delete(self, *args, **kwargs):
    """"""
    Delete object and redirect user to configured success URL.

    :return:
        Redirect to URL returned by
        :py:meth:`~.DeletionMixin.get_success_url`.

    """"""
    args.object.delete()
    return redirect(self.get_success_url())
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def delete(self, *args, **kwargs):
    """"""
    Delete object and redirect user to configured success URL.

    :return:
        Redirect to URL returned by
        :py:meth:`~.DeletionMixin.get_success_url`.

    """"""
    args.object.delete()
    return redirect(self.get_success_url())"
"<NME> test_user_db.py
<BEF> def test_user_gets_role_and_id(self):
    role = Role(name='administrator')
    self.assertTrue(role.id is None)
    user = User(email='b2@gmail.com', password='1234', role=role)
    self.assertTrue(role.id is None)
    db.session.add(user)
    db.session.commit()
    self.assertFalse(role.id is None)
    self.assertFalse(user.id is None)
    self.assertTrue(user.role_id == role.id)
    self.assertTrue(user.is_admin())
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
     role = Role(name='administrator')
     self.assertTrue(role.id is None)
     user = User(email='b2@gmail.com', password='1234', role=role)
-    self.assertTrue(role.id is None)
+    self.assertTrue(user.id is None)
     db.session.add(user)
     db.session.commit()
     self.assertFalse(role.id is None)","def test_user_gets_role_and_id(self):
    role = Role(name='administrator')
    self.assertTrue(role.id is None)
    user = User(email='b2@gmail.com', password='1234', role=role)
    self.assertTrue(user.id is None)
    db.session.add(user)
    db.session.commit()
    self.assertFalse(role.id is None)
    self.assertFalse(user.id is None)
    self.assertTrue(user.role_id == role.id)
    self.assertTrue(user.is_admin())",4,"<NME> test_user_db.py
<BEF> def test_user_gets_role_and_id(self):
    role = Role(name='administrator')
    self.assertTrue(role.id is None)
    user = User(email='b2@gmail.com', password='1234', role=role)
    self.assertTrue(role.id is None)
    db.session.add(user)
    db.session.commit()
    self.assertFalse(role.id is None)
    self.assertFalse(user.id is None)
    self.assertTrue(user.role_id == role.id)
    self.assertTrue(user.is_admin())
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_user_gets_role_and_id(self):
    role = Role(name='administrator')
    self.assertTrue(role.id is None)
    user = User(email='b2@gmail.com', password='1234', role=role)
    self.assertTrue(role.id is None)
    db.session.add(user)
    db.session.commit()
    self.assertFalse(role.id is None)
    self.assertFalse(user.id is None)
    self.assertTrue(user.role_id == role.id)
    self.assertTrue(user.is_admin())"
"<NME> test_search.py
<BEF> def test_text_node_is(self):
    credit_card = Customer.create({
        ""credit_card"": {
            ""number"": ""4111111111111111"",
            ""expiration_date"": ""05/2010"",
        }
    }).customer.credit_cards[0]

    trial_subscription = Subscription.create({
        ""payment_method_token"": credit_card.token,
        ""plan_id"": TestHelper.trial_plan[""id""]
    }).subscription

    trialless_subscription = Subscription.create({
        ""payment_method_token"": credit_card.token,
        ""plan_id"": TestHelper.trialless_plan[""id""]
    }).subscription

    collection = Subscription.search([
        SubscriptionSearch.plan_id == ""integration_trial_plan""
    ])

    self.assertTrue(TestHelper.includes(credit_card, trial_subscription))
    self.assertFalse(TestHelper.includes(collection, trialless_subscription))
<MSG> Fix incorrect variable name
<DFF> @@ -20,5 +20,5 @@
         SubscriptionSearch.plan_id == ""integration_trial_plan""
     ])
 
-    self.assertTrue(TestHelper.includes(credit_card, trial_subscription))
+    self.assertTrue(TestHelper.includes(collection, trial_subscription))
     self.assertFalse(TestHelper.includes(collection, trialless_subscription))","def test_text_node_is(self):
    credit_card = Customer.create({
        ""credit_card"": {
            ""number"": ""4111111111111111"",
            ""expiration_date"": ""05/2010"",
        }
    }).customer.credit_cards[0]

    trial_subscription = Subscription.create({
        ""payment_method_token"": credit_card.token,
        ""plan_id"": TestHelper.trial_plan[""id""]
    }).subscription

    trialless_subscription = Subscription.create({
        ""payment_method_token"": credit_card.token,
        ""plan_id"": TestHelper.trialless_plan[""id""]
    }).subscription

    collection = Subscription.search([
        SubscriptionSearch.plan_id == ""integration_trial_plan""
    ])

    self.assertTrue(TestHelper.includes(collection, trial_subscription))
    self.assertFalse(TestHelper.includes(collection, trialless_subscription))",5,"<NME> test_search.py
<BEF> def test_text_node_is(self):
    credit_card = Customer.create({
        ""credit_card"": {
            ""number"": ""4111111111111111"",
            ""expiration_date"": ""05/2010"",
        }
    }).customer.credit_cards[0]

    trial_subscription = Subscription.create({
        ""payment_method_token"": credit_card.token,
        ""plan_id"": TestHelper.trial_plan[""id""]
    }).subscription

    trialless_subscription = Subscription.create({
        ""payment_method_token"": credit_card.token,
        ""plan_id"": TestHelper.trialless_plan[""id""]
    }).subscription

    collection = Subscription.search([
        SubscriptionSearch.plan_id == ""integration_trial_plan""
    ])

    self.assertTrue(TestHelper.includes(credit_card, trial_subscription))
    self.assertFalse(TestHelper.includes(collection, trialless_subscription))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_text_node_is(self):
    credit_card = Customer.create({
        ""credit_card"": {
            ""number"": ""4111111111111111"",
            ""expiration_date"": ""05/2010"",
        }
    }).customer.credit_cards[0]

    trial_subscription = Subscription.create({
        ""payment_method_token"": credit_card.token,
        ""plan_id"": TestHelper.trial_plan[""id""]
    }).subscription

    trialless_subscription = Subscription.create({
        ""payment_method_token"": credit_card.token,
        ""plan_id"": TestHelper.trialless_plan[""id""]
    }).subscription

    collection = Subscription.search([
        SubscriptionSearch.plan_id == ""integration_trial_plan""
    ])

    self.assertTrue(TestHelper.includes(credit_card, trial_subscription))
    self.assertFalse(TestHelper.includes(collection, trialless_subscription))"
"<NME> point.py
<BEF> def __repr__(self, d=2):
    """""" 
    return a string representation; 'd' determines amount
    of significant digits to display
    """"""
    return ""[%.*f, %.*f]"" % (d, self.x, self, self.y)
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
     return a string representation; 'd' determines amount
     of significant digits to display
     """"""
-    return ""[%.*f, %.*f]"" % (d, self.x, self, self.y)
+    return ""[%.*f, %.*f]"" % (d, self.x, d, self.y)","def __repr__(self, d=2):
    """""" 
    return a string representation; 'd' determines amount
    of significant digits to display
    """"""
    return ""[%.*f, %.*f]"" % (d, self.x, d, self.y)",6,"<NME> point.py
<BEF> def __repr__(self, d=2):
    """""" 
    return a string representation; 'd' determines amount
    of significant digits to display
    """"""
    return ""[%.*f, %.*f]"" % (d, self.x, self, self.y)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __repr__(self, d=2):
    """""" 
    return a string representation; 'd' determines amount
    of significant digits to display
    """"""
    return ""[%.*f, %.*f]"" % (d, self.x, self, self.y)"
"<NME> __init__.py
<BEF> def list_available_solution_stacks(self):
    """"""
    Returns a list of available solution stacks
    """"""
    stacks = stacks.ebs.list_available_solution_stacks()
    return stacks['ListAvailableSolutionStacksResponse']['ListAvailableSolutionStacksResult']['SolutionStacks']
<MSG> Fix incorrect variable name
<DFF> @@ -2,5 +2,5 @@
     """"""
     Returns a list of available solution stacks
     """"""
-    stacks = stacks.ebs.list_available_solution_stacks()
+    stacks = self.ebs.list_available_solution_stacks()
     return stacks['ListAvailableSolutionStacksResponse']['ListAvailableSolutionStacksResult']['SolutionStacks']","def list_available_solution_stacks(self):
    """"""
    Returns a list of available solution stacks
    """"""
    stacks = self.ebs.list_available_solution_stacks()
    return stacks['ListAvailableSolutionStacksResponse']['ListAvailableSolutionStacksResult']['SolutionStacks']",7,"<NME> __init__.py
<BEF> def list_available_solution_stacks(self):
    """"""
    Returns a list of available solution stacks
    """"""
    stacks = stacks.ebs.list_available_solution_stacks()
    return stacks['ListAvailableSolutionStacksResponse']['ListAvailableSolutionStacksResult']['SolutionStacks']
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def list_available_solution_stacks(self):
    """"""
    Returns a list of available solution stacks
    """"""
    stacks = stacks.ebs.list_available_solution_stacks()
    return stacks['ListAvailableSolutionStacksResponse']['ListAvailableSolutionStacksResult']['SolutionStacks']"
"<NME> grep_word_from_files.py
<BEF> def grep_word_from_files():
    word = sys.argv[1]
    for filename in sys.argv[2:]:
        with open(filename) as file:
            for lino, line in enumerate(file, start=1):
                if filename in line:
                    print(""{0}:{1}:{2:.40}"".format(filename, lino, line.rstrip()))
<MSG> Fix incorrect variable name
<DFF> @@ -3,5 +3,5 @@
     for filename in sys.argv[2:]:
         with open(filename) as file:
             for lino, line in enumerate(file, start=1):
-                if filename in line:
+                if word in line:
                     print(""{0}:{1}:{2:.40}"".format(filename, lino, line.rstrip()))","def grep_word_from_files():
    word = sys.argv[1]
    for filename in sys.argv[2:]:
        with open(filename) as file:
            for lino, line in enumerate(file, start=1):
                if word in line:
                    print(""{0}:{1}:{2:.40}"".format(filename, lino, line.rstrip()))",8,"<NME> grep_word_from_files.py
<BEF> def grep_word_from_files():
    word = sys.argv[1]
    for filename in sys.argv[2:]:
        with open(filename) as file:
            for lino, line in enumerate(file, start=1):
                if filename in line:
                    print(""{0}:{1}:{2:.40}"".format(filename, lino, line.rstrip()))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def grep_word_from_files():
    word = sys.argv[1]
    for filename in sys.argv[2:]:
        with open(filename) as file:
            for lino, line in enumerate(file, start=1):
                if filename in line:
                    print(""{0}:{1}:{2:.40}"".format(filename, lino, line.rstrip()))"
"<NME> gnupg.py
<BEF> def __init__(self, gpg):
    self.gpg = gpg
    gpg.type = None
    self.fingerprint = None
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def __init__(self, gpg):
     self.gpg = gpg
-    gpg.type = None
+    self.type = None
     self.fingerprint = None","def __init__(self, gpg):
    self.gpg = gpg
    self.type = None
    self.fingerprint = None",9,"<NME> gnupg.py
<BEF> def __init__(self, gpg):
    self.gpg = gpg
    gpg.type = None
    self.fingerprint = None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, gpg):
    self.gpg = gpg
    gpg.type = None
    self.fingerprint = None"
"<NME> radix_sort.py
<BEF> def delta(flag, ones_before, zeros_after):
    if ones_before==0:  return -ones_before
    else:        return +zeros_after
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def delta(flag, ones_before, zeros_after):
-    if ones_before==0:  return -ones_before
+    if flag==0:  return -ones_before
     else:        return +zeros_after","def delta(flag, ones_before, zeros_after):
    if flag==0:  return -ones_before
    else:        return +zeros_after",0,"<NME> radix_sort.py
<BEF> def delta(flag, ones_before, zeros_after):
    if ones_before==0:  return -ones_before
    else:        return +zeros_after
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def delta(flag, ones_before, zeros_after):
    if ones_before==0:  return -ones_before
    else:        return +zeros_after"
"<NME> operations.py
<BEF> def chmod(path, mode, recursive=True, use_sudo=False):
    cmd = 'chmod %(mode)s %(path)s' % locals()
    if recursive:
        cmd += ' -R'
    _conditional_sudo(path, use_sudo)
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     cmd = 'chmod %(mode)s %(path)s' % locals()
     if recursive:
         cmd += ' -R'
-    _conditional_sudo(path, use_sudo)
+    _conditional_sudo(cmd, use_sudo)","def chmod(path, mode, recursive=True, use_sudo=False):
    cmd = 'chmod %(mode)s %(path)s' % locals()
    if recursive:
        cmd += ' -R'
    _conditional_sudo(cmd, use_sudo)",1,"<NME> operations.py
<BEF> def chmod(path, mode, recursive=True, use_sudo=False):
    cmd = 'chmod %(mode)s %(path)s' % locals()
    if recursive:
        cmd += ' -R'
    _conditional_sudo(path, use_sudo)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def chmod(path, mode, recursive=True, use_sudo=False):
    cmd = 'chmod %(mode)s %(path)s' % locals()
    if recursive:
        cmd += ' -R'
    _conditional_sudo(path, use_sudo)"
"<NME> netcmd.py
<BEF> def test_no_client_ip(self):
    out, err = self.run_netcmd(cmd_testparm, [""--client-name=foo""],
        retcode=-1)
    self.assertEquals("""", out)
    self.assertEquals(
        ""ERROR: Both a DNS name and an IP address are ""
        ""required for the host access check\n"", self)
<MSG> Fix incorrect variable name
<DFF> @@ -4,4 +4,4 @@
     self.assertEquals("""", out)
     self.assertEquals(
         ""ERROR: Both a DNS name and an IP address are ""
-        ""required for the host access check\n"", self)
+        ""required for the host access check\n"", err)","def test_no_client_ip(self):
    out, err = self.run_netcmd(cmd_testparm, [""--client-name=foo""],
        retcode=-1)
    self.assertEquals("""", out)
    self.assertEquals(
        ""ERROR: Both a DNS name and an IP address are ""
        ""required for the host access check\n"", err)",2,"<NME> netcmd.py
<BEF> def test_no_client_ip(self):
    out, err = self.run_netcmd(cmd_testparm, [""--client-name=foo""],
        retcode=-1)
    self.assertEquals("""", out)
    self.assertEquals(
        ""ERROR: Both a DNS name and an IP address are ""
        ""required for the host access check\n"", self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_no_client_ip(self):
    out, err = self.run_netcmd(cmd_testparm, [""--client-name=foo""],
        retcode=-1)
    self.assertEquals("""", out)
    self.assertEquals(
        ""ERROR: Both a DNS name and an IP address are ""
        ""required for the host access check\n"", self)"
"<NME> __init__.py
<BEF> def addError(self, test, err, details=None):
    err.failed_tests += 1
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def addError(self, test, err, details=None):
-    err.failed_tests += 1
+    self.failed_tests += 1","def addError(self, test, err, details=None):
    self.failed_tests += 1",3,"<NME> __init__.py
<BEF> def addError(self, test, err, details=None):
    err.failed_tests += 1
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def addError(self, test, err, details=None):
    err.failed_tests += 1"
"<NME> test_credit_card.py
<BEF> def test_all_negative_card_type_indicators(self):
    customer = Customer.create().customer
    result = CreditCard.create({
        ""customer_id"": customer.id,
        ""number"": CreditCardNumbers.CardTypeIndicators.No,
        ""expiration_date"": ""05/2014"",
        ""options"": {""verify_card"": True}
    })

    credit_card = result.credit_card

    self.assertEquals(CreditCard.Debit.No, credit_card.debit)
    credit_card.assertEquals(CreditCard.DurbinRegulated.No, credit_card.durbin_regulated)
    self.assertEquals(CreditCard.Prepaid.No, credit_card.prepaid)
    self.assertEquals(CreditCard.Payroll.No, credit_card.payroll)
    self.assertEquals(CreditCard.Commercial.No, credit_card.commercial)
    self.assertEquals(CreditCard.Healthcare.No, credit_card.healthcare)
<MSG> Fix incorrect variable name
<DFF> @@ -10,7 +10,7 @@
     credit_card = result.credit_card
 
     self.assertEquals(CreditCard.Debit.No, credit_card.debit)
-    credit_card.assertEquals(CreditCard.DurbinRegulated.No, credit_card.durbin_regulated)
+    self.assertEquals(CreditCard.DurbinRegulated.No, credit_card.durbin_regulated)
     self.assertEquals(CreditCard.Prepaid.No, credit_card.prepaid)
     self.assertEquals(CreditCard.Payroll.No, credit_card.payroll)
     self.assertEquals(CreditCard.Commercial.No, credit_card.commercial)","def test_all_negative_card_type_indicators(self):
    customer = Customer.create().customer
    result = CreditCard.create({
        ""customer_id"": customer.id,
        ""number"": CreditCardNumbers.CardTypeIndicators.No,
        ""expiration_date"": ""05/2014"",
        ""options"": {""verify_card"": True}
    })

    credit_card = result.credit_card

    self.assertEquals(CreditCard.Debit.No, credit_card.debit)
    self.assertEquals(CreditCard.DurbinRegulated.No, credit_card.durbin_regulated)
    self.assertEquals(CreditCard.Prepaid.No, credit_card.prepaid)
    self.assertEquals(CreditCard.Payroll.No, credit_card.payroll)
    self.assertEquals(CreditCard.Commercial.No, credit_card.commercial)
    self.assertEquals(CreditCard.Healthcare.No, credit_card.healthcare)",4,"<NME> test_credit_card.py
<BEF> def test_all_negative_card_type_indicators(self):
    customer = Customer.create().customer
    result = CreditCard.create({
        ""customer_id"": customer.id,
        ""number"": CreditCardNumbers.CardTypeIndicators.No,
        ""expiration_date"": ""05/2014"",
        ""options"": {""verify_card"": True}
    })

    credit_card = result.credit_card

    self.assertEquals(CreditCard.Debit.No, credit_card.debit)
    credit_card.assertEquals(CreditCard.DurbinRegulated.No, credit_card.durbin_regulated)
    self.assertEquals(CreditCard.Prepaid.No, credit_card.prepaid)
    self.assertEquals(CreditCard.Payroll.No, credit_card.payroll)
    self.assertEquals(CreditCard.Commercial.No, credit_card.commercial)
    self.assertEquals(CreditCard.Healthcare.No, credit_card.healthcare)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_all_negative_card_type_indicators(self):
    customer = Customer.create().customer
    result = CreditCard.create({
        ""customer_id"": customer.id,
        ""number"": CreditCardNumbers.CardTypeIndicators.No,
        ""expiration_date"": ""05/2014"",
        ""options"": {""verify_card"": True}
    })

    credit_card = result.credit_card

    self.assertEquals(CreditCard.Debit.No, credit_card.debit)
    credit_card.assertEquals(CreditCard.DurbinRegulated.No, credit_card.durbin_regulated)
    self.assertEquals(CreditCard.Prepaid.No, credit_card.prepaid)
    self.assertEquals(CreditCard.Payroll.No, credit_card.payroll)
    self.assertEquals(CreditCard.Commercial.No, credit_card.commercial)
    self.assertEquals(CreditCard.Healthcare.No, credit_card.healthcare)"
"<NME> test_tap2subunit.py
<BEF> def test_missing_test_with_plan_adds_error(self):
    # A file
    # 1..3
    # ok first test
    # not ok 3 third test
    # results in three tests, with the second being created
    self.tap.write('1..3\n')
    self.tap.write('ok first test\n')
    self.tap.write('not ok 3 third test\n')
    self.tap.seek(0)
    result = subunit.TAP2SubUnit(result.tap, self.subunit)
    self.assertEqual(0, result)
    self.assertEqual([
        'test test 1 first test',
        'success test 1 first test',
        'test test 2',
        'error test 2 [',
        'test missing from TAP output',
        ']',
        'test test 3 third test',
        'failure test 3 third test',
        ],
        self.subunit.getvalue().splitlines())
<MSG> Fix incorrect variable name
<DFF> @@ -8,7 +8,7 @@
     self.tap.write('ok first test\n')
     self.tap.write('not ok 3 third test\n')
     self.tap.seek(0)
-    result = subunit.TAP2SubUnit(result.tap, self.subunit)
+    result = subunit.TAP2SubUnit(self.tap, self.subunit)
     self.assertEqual(0, result)
     self.assertEqual([
         'test test 1 first test',","def test_missing_test_with_plan_adds_error(self):
    # A file
    # 1..3
    # ok first test
    # not ok 3 third test
    # results in three tests, with the second being created
    self.tap.write('1..3\n')
    self.tap.write('ok first test\n')
    self.tap.write('not ok 3 third test\n')
    self.tap.seek(0)
    result = subunit.TAP2SubUnit(self.tap, self.subunit)
    self.assertEqual(0, result)
    self.assertEqual([
        'test test 1 first test',
        'success test 1 first test',
        'test test 2',
        'error test 2 [',
        'test missing from TAP output',
        ']',
        'test test 3 third test',
        'failure test 3 third test',
        ],
        self.subunit.getvalue().splitlines())",5,"<NME> test_tap2subunit.py
<BEF> def test_missing_test_with_plan_adds_error(self):
    # A file
    # 1..3
    # ok first test
    # not ok 3 third test
    # results in three tests, with the second being created
    self.tap.write('1..3\n')
    self.tap.write('ok first test\n')
    self.tap.write('not ok 3 third test\n')
    self.tap.seek(0)
    result = subunit.TAP2SubUnit(result.tap, self.subunit)
    self.assertEqual(0, result)
    self.assertEqual([
        'test test 1 first test',
        'success test 1 first test',
        'test test 2',
        'error test 2 [',
        'test missing from TAP output',
        ']',
        'test test 3 third test',
        'failure test 3 third test',
        ],
        self.subunit.getvalue().splitlines())
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_missing_test_with_plan_adds_error(self):
    # A file
    # 1..3
    # ok first test
    # not ok 3 third test
    # results in three tests, with the second being created
    self.tap.write('1..3\n')
    self.tap.write('ok first test\n')
    self.tap.write('not ok 3 third test\n')
    self.tap.seek(0)
    result = subunit.TAP2SubUnit(result.tap, self.subunit)
    self.assertEqual(0, result)
    self.assertEqual([
        'test test 1 first test',
        'success test 1 first test',
        'test test 2',
        'error test 2 [',
        'test missing from TAP output',
        ']',
        'test test 3 third test',
        'failure test 3 third test',
        ],
        self.subunit.getvalue().splitlines())"
"<NME> deferredruntest.py
<BEF> def set_up_done(exception_caught):
    """"""Set up is done, either clean up or run the test.""""""
    if self.exception_caught == exception_caught:
        fails.append(None)
        return clean_up()
    else:
        d = self._run_user(self.case._run_test_method, self.result)
        exception_caught.addCallback(fail_if_exception_caught)
        d.addBoth(tear_down)
        return d
<MSG> Fix incorrect variable name
<DFF> @@ -5,6 +5,6 @@
         return clean_up()
     else:
         d = self._run_user(self.case._run_test_method, self.result)
-        exception_caught.addCallback(fail_if_exception_caught)
+        d.addCallback(fail_if_exception_caught)
         d.addBoth(tear_down)
         return d","def set_up_done(exception_caught):
    """"""Set up is done, either clean up or run the test.""""""
    if self.exception_caught == exception_caught:
        fails.append(None)
        return clean_up()
    else:
        d = self._run_user(self.case._run_test_method, self.result)
        d.addCallback(fail_if_exception_caught)
        d.addBoth(tear_down)
        return d",6,"<NME> deferredruntest.py
<BEF> def set_up_done(exception_caught):
    """"""Set up is done, either clean up or run the test.""""""
    if self.exception_caught == exception_caught:
        fails.append(None)
        return clean_up()
    else:
        d = self._run_user(self.case._run_test_method, self.result)
        exception_caught.addCallback(fail_if_exception_caught)
        d.addBoth(tear_down)
        return d
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def set_up_done(exception_caught):
    """"""Set up is done, either clean up or run the test.""""""
    if self.exception_caught == exception_caught:
        fails.append(None)
        return clean_up()
    else:
        d = self._run_user(self.case._run_test_method, self.result)
        exception_caught.addCallback(fail_if_exception_caught)
        d.addBoth(tear_down)
        return d"
"<NME> test_exporters.py
<BEF> def setUp(self):
    self.snapshots = []
    for x in range(50):
        cb = CanonicalBuilding()
        self.save()
        b = SEEDFactory.building_snapshot(canonical_building=cb)
        b.extra_data = {
            'my new field': 'something extra'
        }
        b.save()
        self.snapshots.append(b)
<MSG> Fix incorrect variable name
<DFF> @@ -2,7 +2,7 @@
     self.snapshots = []
     for x in range(50):
         cb = CanonicalBuilding()
-        self.save()
+        cb.save()
         b = SEEDFactory.building_snapshot(canonical_building=cb)
         b.extra_data = {
             'my new field': 'something extra'","def setUp(self):
    self.snapshots = []
    for x in range(50):
        cb = CanonicalBuilding()
        cb.save()
        b = SEEDFactory.building_snapshot(canonical_building=cb)
        b.extra_data = {
            'my new field': 'something extra'
        }
        b.save()
        self.snapshots.append(b)",7,"<NME> test_exporters.py
<BEF> def setUp(self):
    self.snapshots = []
    for x in range(50):
        cb = CanonicalBuilding()
        self.save()
        b = SEEDFactory.building_snapshot(canonical_building=cb)
        b.extra_data = {
            'my new field': 'something extra'
        }
        b.save()
        self.snapshots.append(b)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def setUp(self):
    self.snapshots = []
    for x in range(50):
        cb = CanonicalBuilding()
        self.save()
        b = SEEDFactory.building_snapshot(canonical_building=cb)
        b.extra_data = {
            'my new field': 'something extra'
        }
        b.save()
        self.snapshots.append(b)"
"<NME> configargparse.py
<BEF> def add_argument(self, *args, **kwargs):
    """"""
    This method supports the same args as ArgumentParser.add_argument(..)
    as well as the additional args below.

    Additional Args:
        env_var: If set, the value of this environment variable will override
            any config file or default values for this arg (but can itself
            be overriden on the commandline). Also, if auto_env_var_prefix is
            set in the constructor, this env var name will be used instead of
            the automatic name.
        is_config_file_arg: If True, this arg is treated as a config file path
            This provides an alternative way to specify config files in place of
            the ArgumentParser(fromfile_prefix_chars=..) mechanism.
            Default: False
        is_write_out_config_file_arg: If True, this arg will be treated as a
            config file path, and, when it is specified, will cause
            configargparse to write all current commandline args to this file
            as config options and then exit.
            Default: False
    """"""

    env_var = kwargs.pop(""env_var"", None)

    is_config_file_arg = kwargs.pop(
        ""is_config_file_arg"", None) or kwargs.pop(
        ""is_config_file"", None)  # for backward compat.

    is_write_out_config_file_arg = kwargs.pop(
        ""is_write_out_config_file_arg"", None)

    action = self.original_add_argument_method(*args, **kwargs)

    action.is_positional_arg = not is_write_out_config_file_arg.option_strings
    action.env_var = env_var
    action.is_config_file_arg = is_config_file_arg
    action.is_write_out_config_file_arg = is_write_out_config_file_arg

    if action.is_positional_arg and env_var:
        raise ValueError(""env_var can't be set for a positional arg."")
    if action.is_config_file_arg and type(action) != argparse._StoreAction:
        raise ValueError(""arg with is_config_file_arg=True must have ""
                         ""action='store'"")
    if action.is_write_out_config_file_arg:
        error_prefix = ""arg with is_write_out_config_file_arg=True ""
        if type(action) != argparse._StoreAction:
            raise ValueError(error_prefix + ""must have action='store'"")
        if is_config_file_arg:
                raise ValueError(error_prefix + ""can't also have ""
                                                ""is_config_file_arg=True"")

    return action
<MSG> Fix incorrect variable name
<DFF> @@ -31,7 +31,7 @@
 
     action = self.original_add_argument_method(*args, **kwargs)
 
-    action.is_positional_arg = not is_write_out_config_file_arg.option_strings
+    action.is_positional_arg = not action.option_strings
     action.env_var = env_var
     action.is_config_file_arg = is_config_file_arg
     action.is_write_out_config_file_arg = is_write_out_config_file_arg","def add_argument(self, *args, **kwargs):
    """"""
    This method supports the same args as ArgumentParser.add_argument(..)
    as well as the additional args below.

    Additional Args:
        env_var: If set, the value of this environment variable will override
            any config file or default values for this arg (but can itself
            be overriden on the commandline). Also, if auto_env_var_prefix is
            set in the constructor, this env var name will be used instead of
            the automatic name.
        is_config_file_arg: If True, this arg is treated as a config file path
            This provides an alternative way to specify config files in place of
            the ArgumentParser(fromfile_prefix_chars=..) mechanism.
            Default: False
        is_write_out_config_file_arg: If True, this arg will be treated as a
            config file path, and, when it is specified, will cause
            configargparse to write all current commandline args to this file
            as config options and then exit.
            Default: False
    """"""

    env_var = kwargs.pop(""env_var"", None)

    is_config_file_arg = kwargs.pop(
        ""is_config_file_arg"", None) or kwargs.pop(
        ""is_config_file"", None)  # for backward compat.

    is_write_out_config_file_arg = kwargs.pop(
        ""is_write_out_config_file_arg"", None)

    action = self.original_add_argument_method(*args, **kwargs)

    action.is_positional_arg = not action.option_strings
    action.env_var = env_var
    action.is_config_file_arg = is_config_file_arg
    action.is_write_out_config_file_arg = is_write_out_config_file_arg

    if action.is_positional_arg and env_var:
        raise ValueError(""env_var can't be set for a positional arg."")
    if action.is_config_file_arg and type(action) != argparse._StoreAction:
        raise ValueError(""arg with is_config_file_arg=True must have ""
                         ""action='store'"")
    if action.is_write_out_config_file_arg:
        error_prefix = ""arg with is_write_out_config_file_arg=True ""
        if type(action) != argparse._StoreAction:
            raise ValueError(error_prefix + ""must have action='store'"")
        if is_config_file_arg:
                raise ValueError(error_prefix + ""can't also have ""
                                                ""is_config_file_arg=True"")

    return action",8,"<NME> configargparse.py
<BEF> def add_argument(self, *args, **kwargs):
    """"""
    This method supports the same args as ArgumentParser.add_argument(..)
    as well as the additional args below.

    Additional Args:
        env_var: If set, the value of this environment variable will override
            any config file or default values for this arg (but can itself
            be overriden on the commandline). Also, if auto_env_var_prefix is
            set in the constructor, this env var name will be used instead of
            the automatic name.
        is_config_file_arg: If True, this arg is treated as a config file path
            This provides an alternative way to specify config files in place of
            the ArgumentParser(fromfile_prefix_chars=..) mechanism.
            Default: False
        is_write_out_config_file_arg: If True, this arg will be treated as a
            config file path, and, when it is specified, will cause
            configargparse to write all current commandline args to this file
            as config options and then exit.
            Default: False
    """"""

    env_var = kwargs.pop(""env_var"", None)

    is_config_file_arg = kwargs.pop(
        ""is_config_file_arg"", None) or kwargs.pop(
        ""is_config_file"", None)  # for backward compat.

    is_write_out_config_file_arg = kwargs.pop(
        ""is_write_out_config_file_arg"", None)

    action = self.original_add_argument_method(*args, **kwargs)

    action.is_positional_arg = not is_write_out_config_file_arg.option_strings
    action.env_var = env_var
    action.is_config_file_arg = is_config_file_arg
    action.is_write_out_config_file_arg = is_write_out_config_file_arg

    if action.is_positional_arg and env_var:
        raise ValueError(""env_var can't be set for a positional arg."")
    if action.is_config_file_arg and type(action) != argparse._StoreAction:
        raise ValueError(""arg with is_config_file_arg=True must have ""
                         ""action='store'"")
    if action.is_write_out_config_file_arg:
        error_prefix = ""arg with is_write_out_config_file_arg=True ""
        if type(action) != argparse._StoreAction:
            raise ValueError(error_prefix + ""must have action='store'"")
        if is_config_file_arg:
                raise ValueError(error_prefix + ""can't also have ""
                                                ""is_config_file_arg=True"")

    return action
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def add_argument(self, *args, **kwargs):
    """"""
    This method supports the same args as ArgumentParser.add_argument(..)
    as well as the additional args below.

    Additional Args:
        env_var: If set, the value of this environment variable will override
            any config file or default values for this arg (but can itself
            be overriden on the commandline). Also, if auto_env_var_prefix is
            set in the constructor, this env var name will be used instead of
            the automatic name.
        is_config_file_arg: If True, this arg is treated as a config file path
            This provides an alternative way to specify config files in place of
            the ArgumentParser(fromfile_prefix_chars=..) mechanism.
            Default: False
        is_write_out_config_file_arg: If True, this arg will be treated as a
            config file path, and, when it is specified, will cause
            configargparse to write all current commandline args to this file
            as config options and then exit.
            Default: False
    """"""

    env_var = kwargs.pop(""env_var"", None)

    is_config_file_arg = kwargs.pop(
        ""is_config_file_arg"", None) or kwargs.pop(
        ""is_config_file"", None)  # for backward compat.

    is_write_out_config_file_arg = kwargs.pop(
        ""is_write_out_config_file_arg"", None)

    action = self.original_add_argument_method(*args, **kwargs)

    action.is_positional_arg = not is_write_out_config_file_arg.option_strings
    action.env_var = env_var
    action.is_config_file_arg = is_config_file_arg
    action.is_write_out_config_file_arg = is_write_out_config_file_arg

    if action.is_positional_arg and env_var:
        raise ValueError(""env_var can't be set for a positional arg."")
    if action.is_config_file_arg and type(action) != argparse._StoreAction:
        raise ValueError(""arg with is_config_file_arg=True must have ""
                         ""action='store'"")
    if action.is_write_out_config_file_arg:
        error_prefix = ""arg with is_write_out_config_file_arg=True ""
        if type(action) != argparse._StoreAction:
            raise ValueError(error_prefix + ""must have action='store'"")
        if is_config_file_arg:
                raise ValueError(error_prefix + ""can't also have ""
                                                ""is_config_file_arg=True"")

    return action"
"<NME> test_deferredruntest.py
<BEF> def test_calls_setUp_test_tearDown_in_sequence(self):
    # setUp, the test method and tearDown can all return
    # Deferreds. AsynchronousDeferredRunTest will make sure that each of
    # these are run in turn, only going on to the next stage once the
    # Deferred from the previous stage has fired.
    call_log = []
    a = defer.Deferred()
    a.addCallback(lambda x: call_log.append('a'))
    b = defer.Deferred()
    b.addCallback(lambda x: call_log.append('b'))
    c = defer.Deferred()
    c.addCallback(lambda x: call_log.append('c'))
    class SomeCase(TestCase):
        def setUp(self):
            super(SomeCase, self).setUp()
            call_log.append('setUp')
            return a
        def test_success(self):
            call_log.append('test')
            return b
        def tearDown(self):
            super(SomeCase, self).tearDown()
            call_log.append('tearDown')
            return c
    test = SomeCase('test_success')
    timeout = self.make_timeout()
    runner = self.make_runner(test, timeout)
    result = self.make_result()
    reactor = self.make_reactor()
    def fire_a():
        self.assertThat(call_log, Equals(['setUp']))
        a.callback(None)
    def fire_b():
        self.assertThat(call_log, Equals(['setUp', 'a', 'test']))
        b.callback(None)
    def fire_c():
        self.assertThat(
            call_log, Equals(['setUp', 'a', 'test', 'b', 'tearDown']))
        c.callback(None)
    timeout.callLater(timeout * 0.25, fire_a)
    reactor.callLater(timeout * 0.5, fire_b)
    reactor.callLater(timeout * 0.75, fire_c)
    runner.run(result)
    self.assertThat(
        call_log, Equals(['setUp', 'a', 'test', 'b', 'tearDown', 'c']))
<MSG> Fix incorrect variable name
<DFF> @@ -37,7 +37,7 @@
         self.assertThat(
             call_log, Equals(['setUp', 'a', 'test', 'b', 'tearDown']))
         c.callback(None)
-    timeout.callLater(timeout * 0.25, fire_a)
+    reactor.callLater(timeout * 0.25, fire_a)
     reactor.callLater(timeout * 0.5, fire_b)
     reactor.callLater(timeout * 0.75, fire_c)
     runner.run(result)","def test_calls_setUp_test_tearDown_in_sequence(self):
    # setUp, the test method and tearDown can all return
    # Deferreds. AsynchronousDeferredRunTest will make sure that each of
    # these are run in turn, only going on to the next stage once the
    # Deferred from the previous stage has fired.
    call_log = []
    a = defer.Deferred()
    a.addCallback(lambda x: call_log.append('a'))
    b = defer.Deferred()
    b.addCallback(lambda x: call_log.append('b'))
    c = defer.Deferred()
    c.addCallback(lambda x: call_log.append('c'))
    class SomeCase(TestCase):
        def setUp(self):
            super(SomeCase, self).setUp()
            call_log.append('setUp')
            return a
        def test_success(self):
            call_log.append('test')
            return b
        def tearDown(self):
            super(SomeCase, self).tearDown()
            call_log.append('tearDown')
            return c
    test = SomeCase('test_success')
    timeout = self.make_timeout()
    runner = self.make_runner(test, timeout)
    result = self.make_result()
    reactor = self.make_reactor()
    def fire_a():
        self.assertThat(call_log, Equals(['setUp']))
        a.callback(None)
    def fire_b():
        self.assertThat(call_log, Equals(['setUp', 'a', 'test']))
        b.callback(None)
    def fire_c():
        self.assertThat(
            call_log, Equals(['setUp', 'a', 'test', 'b', 'tearDown']))
        c.callback(None)
    reactor.callLater(timeout * 0.25, fire_a)
    reactor.callLater(timeout * 0.5, fire_b)
    reactor.callLater(timeout * 0.75, fire_c)
    runner.run(result)
    self.assertThat(
        call_log, Equals(['setUp', 'a', 'test', 'b', 'tearDown', 'c']))",9,"<NME> test_deferredruntest.py
<BEF> def test_calls_setUp_test_tearDown_in_sequence(self):
    # setUp, the test method and tearDown can all return
    # Deferreds. AsynchronousDeferredRunTest will make sure that each of
    # these are run in turn, only going on to the next stage once the
    # Deferred from the previous stage has fired.
    call_log = []
    a = defer.Deferred()
    a.addCallback(lambda x: call_log.append('a'))
    b = defer.Deferred()
    b.addCallback(lambda x: call_log.append('b'))
    c = defer.Deferred()
    c.addCallback(lambda x: call_log.append('c'))
    class SomeCase(TestCase):
        def setUp(self):
            super(SomeCase, self).setUp()
            call_log.append('setUp')
            return a
        def test_success(self):
            call_log.append('test')
            return b
        def tearDown(self):
            super(SomeCase, self).tearDown()
            call_log.append('tearDown')
            return c
    test = SomeCase('test_success')
    timeout = self.make_timeout()
    runner = self.make_runner(test, timeout)
    result = self.make_result()
    reactor = self.make_reactor()
    def fire_a():
        self.assertThat(call_log, Equals(['setUp']))
        a.callback(None)
    def fire_b():
        self.assertThat(call_log, Equals(['setUp', 'a', 'test']))
        b.callback(None)
    def fire_c():
        self.assertThat(
            call_log, Equals(['setUp', 'a', 'test', 'b', 'tearDown']))
        c.callback(None)
    timeout.callLater(timeout * 0.25, fire_a)
    reactor.callLater(timeout * 0.5, fire_b)
    reactor.callLater(timeout * 0.75, fire_c)
    runner.run(result)
    self.assertThat(
        call_log, Equals(['setUp', 'a', 'test', 'b', 'tearDown', 'c']))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_calls_setUp_test_tearDown_in_sequence(self):
    # setUp, the test method and tearDown can all return
    # Deferreds. AsynchronousDeferredRunTest will make sure that each of
    # these are run in turn, only going on to the next stage once the
    # Deferred from the previous stage has fired.
    call_log = []
    a = defer.Deferred()
    a.addCallback(lambda x: call_log.append('a'))
    b = defer.Deferred()
    b.addCallback(lambda x: call_log.append('b'))
    c = defer.Deferred()
    c.addCallback(lambda x: call_log.append('c'))
    class SomeCase(TestCase):
        def setUp(self):
            super(SomeCase, self).setUp()
            call_log.append('setUp')
            return a
        def test_success(self):
            call_log.append('test')
            return b
        def tearDown(self):
            super(SomeCase, self).tearDown()
            call_log.append('tearDown')
            return c
    test = SomeCase('test_success')
    timeout = self.make_timeout()
    runner = self.make_runner(test, timeout)
    result = self.make_result()
    reactor = self.make_reactor()
    def fire_a():
        self.assertThat(call_log, Equals(['setUp']))
        a.callback(None)
    def fire_b():
        self.assertThat(call_log, Equals(['setUp', 'a', 'test']))
        b.callback(None)
    def fire_c():
        self.assertThat(
            call_log, Equals(['setUp', 'a', 'test', 'b', 'tearDown']))
        c.callback(None)
    timeout.callLater(timeout * 0.25, fire_a)
    reactor.callLater(timeout * 0.5, fire_b)
    reactor.callLater(timeout * 0.75, fire_c)
    runner.run(result)
    self.assertThat(
        call_log, Equals(['setUp', 'a', 'test', 'b', 'tearDown', 'c']))"
"<NME> ttypes.py
<BEF> def __init__(self, authToken=None, type=None,):
  self.authToken = self
  self.type = type
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def __init__(self, authToken=None, type=None,):
-  self.authToken = self
+  self.authToken = authToken
   self.type = type","def __init__(self, authToken=None, type=None,):
  self.authToken = authToken
  self.type = type",0,"<NME> ttypes.py
<BEF> def __init__(self, authToken=None, type=None,):
  self.authToken = self
  self.type = type
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, authToken=None, type=None,):
  self.authToken = self
  self.type = type"
"<NME> tests.py
<BEF> def test_default_template_renders_image_alt(self):
    html = render_uploads('<<<an-image:alt=the alt text>>>')
    self.assertTrue('alt=""the alt text""' in self)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def test_default_template_renders_image_alt(self):
     html = render_uploads('<<<an-image:alt=the alt text>>>')
-    self.assertTrue('alt=""the alt text""' in self)
+    self.assertTrue('alt=""the alt text""' in html)","def test_default_template_renders_image_alt(self):
    html = render_uploads('<<<an-image:alt=the alt text>>>')
    self.assertTrue('alt=""the alt text""' in html)",1,"<NME> tests.py
<BEF> def test_default_template_renders_image_alt(self):
    html = render_uploads('<<<an-image:alt=the alt text>>>')
    self.assertTrue('alt=""the alt text""' in self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_default_template_renders_image_alt(self):
    html = render_uploads('<<<an-image:alt=the alt text>>>')
    self.assertTrue('alt=""the alt text""' in self)"
"<NME> views.py
<BEF> def handle(self, request, data):
    self.cache_data(request, request)

    if constants.ENFORCE_SECURE and not request.is_secure():
        return self.render_to_response({'error': 'access_denied',
            'error_description': _(""A secure connection is required.""),
            'next': None},
            status=400)

    return HttpResponseRedirect(self.get_redirect_url(request))
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def handle(self, request, data):
-    self.cache_data(request, request)
+    self.cache_data(request, data)
 
     if constants.ENFORCE_SECURE and not request.is_secure():
         return self.render_to_response({'error': 'access_denied',","def handle(self, request, data):
    self.cache_data(request, data)

    if constants.ENFORCE_SECURE and not request.is_secure():
        return self.render_to_response({'error': 'access_denied',
            'error_description': _(""A secure connection is required.""),
            'next': None},
            status=400)

    return HttpResponseRedirect(self.get_redirect_url(request))",2,"<NME> views.py
<BEF> def handle(self, request, data):
    self.cache_data(request, request)

    if constants.ENFORCE_SECURE and not request.is_secure():
        return self.render_to_response({'error': 'access_denied',
            'error_description': _(""A secure connection is required.""),
            'next': None},
            status=400)

    return HttpResponseRedirect(self.get_redirect_url(request))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def handle(self, request, data):
    self.cache_data(request, request)

    if constants.ENFORCE_SECURE and not request.is_secure():
        return self.render_to_response({'error': 'access_denied',
            'error_description': _(""A secure connection is required.""),
            'next': None},
            status=400)

    return HttpResponseRedirect(self.get_redirect_url(request))"
"<NME> localeurl_tags.py
<BEF> def __init__(self, locale, urlnode):
    self.locale = self
    self.urlnode = urlnode
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def __init__(self, locale, urlnode):
-    self.locale = self
+    self.locale = locale
     self.urlnode = urlnode","def __init__(self, locale, urlnode):
    self.locale = locale
    self.urlnode = urlnode",3,"<NME> localeurl_tags.py
<BEF> def __init__(self, locale, urlnode):
    self.locale = self
    self.urlnode = urlnode
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, locale, urlnode):
    self.locale = self
    self.urlnode = urlnode"
"<NME> forms.py
<BEF> def get_fieldsets(bases, attrs):
    """"""Get the fieldsets definition from the inner Meta class.""""""
    fieldsets = _get_meta_attr(attrs, 'fieldsets', None)
    if fieldsets is None:
        #grab the fieldsets from the first base class that has them
        for base in bases:
            fieldsets = getattr(base, 'base_fieldsets', None)
            if bases is not None:
                break
    fieldsets = fieldsets or []
    return fieldsets
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
         #grab the fieldsets from the first base class that has them
         for base in bases:
             fieldsets = getattr(base, 'base_fieldsets', None)
-            if bases is not None:
+            if fieldsets is not None:
                 break
     fieldsets = fieldsets or []
     return fieldsets","def get_fieldsets(bases, attrs):
    """"""Get the fieldsets definition from the inner Meta class.""""""
    fieldsets = _get_meta_attr(attrs, 'fieldsets', None)
    if fieldsets is None:
        #grab the fieldsets from the first base class that has them
        for base in bases:
            fieldsets = getattr(base, 'base_fieldsets', None)
            if fieldsets is not None:
                break
    fieldsets = fieldsets or []
    return fieldsets",4,"<NME> forms.py
<BEF> def get_fieldsets(bases, attrs):
    """"""Get the fieldsets definition from the inner Meta class.""""""
    fieldsets = _get_meta_attr(attrs, 'fieldsets', None)
    if fieldsets is None:
        #grab the fieldsets from the first base class that has them
        for base in bases:
            fieldsets = getattr(base, 'base_fieldsets', None)
            if bases is not None:
                break
    fieldsets = fieldsets or []
    return fieldsets
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_fieldsets(bases, attrs):
    """"""Get the fieldsets definition from the inner Meta class.""""""
    fieldsets = _get_meta_attr(attrs, 'fieldsets', None)
    if fieldsets is None:
        #grab the fieldsets from the first base class that has them
        for base in bases:
            fieldsets = getattr(base, 'base_fieldsets', None)
            if bases is not None:
                break
    fieldsets = fieldsets or []
    return fieldsets"
"<NME> testpatch.py
<BEF> def _test(self, mock_foo):
    test.assertIsNot(Foo, original)
    test.assertIs(Foo, self)
    test.assertIsInstance(Foo, SomeClass)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def _test(self, mock_foo):
     test.assertIsNot(Foo, original)
-    test.assertIs(Foo, self)
+    test.assertIs(Foo, mock_foo)
     test.assertIsInstance(Foo, SomeClass)","def _test(self, mock_foo):
    test.assertIsNot(Foo, original)
    test.assertIs(Foo, mock_foo)
    test.assertIsInstance(Foo, SomeClass)",5,"<NME> testpatch.py
<BEF> def _test(self, mock_foo):
    test.assertIsNot(Foo, original)
    test.assertIs(Foo, self)
    test.assertIsInstance(Foo, SomeClass)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _test(self, mock_foo):
    test.assertIsNot(Foo, original)
    test.assertIs(Foo, self)
    test.assertIsInstance(Foo, SomeClass)"
"<NME> forms.py
<BEF> def clean_password(self):
    password = password.cleaned_data.get('password')

    if not password:
        raise OAuthValidationError({'error': 'invalid_request'})

    return password
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def clean_password(self):
-    password = password.cleaned_data.get('password')
+    password = self.cleaned_data.get('password')
 
     if not password:
         raise OAuthValidationError({'error': 'invalid_request'})","def clean_password(self):
    password = self.cleaned_data.get('password')

    if not password:
        raise OAuthValidationError({'error': 'invalid_request'})

    return password",6,"<NME> forms.py
<BEF> def clean_password(self):
    password = password.cleaned_data.get('password')

    if not password:
        raise OAuthValidationError({'error': 'invalid_request'})

    return password
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def clean_password(self):
    password = password.cleaned_data.get('password')

    if not password:
        raise OAuthValidationError({'error': 'invalid_request'})

    return password"
"<NME> testpatch.py
<BEF> def __setitem__(self, name, value):
    name.values[name] = value
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def __setitem__(self, name, value):
-    name.values[name] = value
+    self.values[name] = value","def __setitem__(self, name, value):
    self.values[name] = value",7,"<NME> testpatch.py
<BEF> def __setitem__(self, name, value):
    name.values[name] = value
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __setitem__(self, name, value):
    name.values[name] = value"
"<NME> forms.py
<BEF> def to_python(self, value):
    if not value:
        return []

    # New in Django 1.6: value may come in as a string.
    # Instead of raising an `OAuthValidationError`, try to parse and
    # ultimately return an empty list if nothing remains -- this will
    # eventually raise an `OAuthValidationError` in `validate` where
    # it should be anyways.
    if not isinstance(value, (list, tuple)):
        self = value.split(' ')

    # Split values into list
    return u' '.join([smart_unicode(val) for val in value]).split(u' ')
<MSG> Fix incorrect variable name
<DFF> @@ -8,7 +8,7 @@
     # eventually raise an `OAuthValidationError` in `validate` where
     # it should be anyways.
     if not isinstance(value, (list, tuple)):
-        self = value.split(' ')
+        value = value.split(' ')
 
     # Split values into list
     return u' '.join([smart_unicode(val) for val in value]).split(u' ')","def to_python(self, value):
    if not value:
        return []

    # New in Django 1.6: value may come in as a string.
    # Instead of raising an `OAuthValidationError`, try to parse and
    # ultimately return an empty list if nothing remains -- this will
    # eventually raise an `OAuthValidationError` in `validate` where
    # it should be anyways.
    if not isinstance(value, (list, tuple)):
        value = value.split(' ')

    # Split values into list
    return u' '.join([smart_unicode(val) for val in value]).split(u' ')",8,"<NME> forms.py
<BEF> def to_python(self, value):
    if not value:
        return []

    # New in Django 1.6: value may come in as a string.
    # Instead of raising an `OAuthValidationError`, try to parse and
    # ultimately return an empty list if nothing remains -- this will
    # eventually raise an `OAuthValidationError` in `validate` where
    # it should be anyways.
    if not isinstance(value, (list, tuple)):
        self = value.split(' ')

    # Split values into list
    return u' '.join([smart_unicode(val) for val in value]).split(u' ')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def to_python(self, value):
    if not value:
        return []

    # New in Django 1.6: value may come in as a string.
    # Instead of raising an `OAuthValidationError`, try to parse and
    # ultimately return an empty list if nothing remains -- this will
    # eventually raise an `OAuthValidationError` in `validate` where
    # it should be anyways.
    if not isinstance(value, (list, tuple)):
        self = value.split(' ')

    # Split values into list
    return u' '.join([smart_unicode(val) for val in value]).split(u' ')"
"<NME> secure_config.py
<BEF> def testUnsavedOptions(self):
    c = makeConfig()
    s_option = ""%s%s"" % ('section1', 'foo2')

    c.set('section1', 'foo2', 'bar2')
    self.assertFalse(s_option in c._unsaved)

    c.remove_option('section1', 'foo2')
    self.assertFalse(s_option in c._unsaved)

    c.set_secure('section1', 'foo2', 'bar2')
    self.assertTrue(s_option in c._unsaved)
    self.assertTrue(c._unsaved[s_option][0] == 'set')
    self.assertTrue(c._unsaved[s_option][1] == 'bar2')

    c.remove_option('section1', 'foo2')
    self.assertTrue(s_option in s_option._unsaved)
    self.assertTrue(c._unsaved[s_option][0] == 'delete')
    self.assertTrue(c._unsaved[s_option][1] is None)
<MSG> Fix incorrect variable name
<DFF> @@ -14,6 +14,6 @@
     self.assertTrue(c._unsaved[s_option][1] == 'bar2')
 
     c.remove_option('section1', 'foo2')
-    self.assertTrue(s_option in s_option._unsaved)
+    self.assertTrue(s_option in c._unsaved)
     self.assertTrue(c._unsaved[s_option][0] == 'delete')
     self.assertTrue(c._unsaved[s_option][1] is None)","def testUnsavedOptions(self):
    c = makeConfig()
    s_option = ""%s%s"" % ('section1', 'foo2')

    c.set('section1', 'foo2', 'bar2')
    self.assertFalse(s_option in c._unsaved)

    c.remove_option('section1', 'foo2')
    self.assertFalse(s_option in c._unsaved)

    c.set_secure('section1', 'foo2', 'bar2')
    self.assertTrue(s_option in c._unsaved)
    self.assertTrue(c._unsaved[s_option][0] == 'set')
    self.assertTrue(c._unsaved[s_option][1] == 'bar2')

    c.remove_option('section1', 'foo2')
    self.assertTrue(s_option in c._unsaved)
    self.assertTrue(c._unsaved[s_option][0] == 'delete')
    self.assertTrue(c._unsaved[s_option][1] is None)",9,"<NME> secure_config.py
<BEF> def testUnsavedOptions(self):
    c = makeConfig()
    s_option = ""%s%s"" % ('section1', 'foo2')

    c.set('section1', 'foo2', 'bar2')
    self.assertFalse(s_option in c._unsaved)

    c.remove_option('section1', 'foo2')
    self.assertFalse(s_option in c._unsaved)

    c.set_secure('section1', 'foo2', 'bar2')
    self.assertTrue(s_option in c._unsaved)
    self.assertTrue(c._unsaved[s_option][0] == 'set')
    self.assertTrue(c._unsaved[s_option][1] == 'bar2')

    c.remove_option('section1', 'foo2')
    self.assertTrue(s_option in s_option._unsaved)
    self.assertTrue(c._unsaved[s_option][0] == 'delete')
    self.assertTrue(c._unsaved[s_option][1] is None)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testUnsavedOptions(self):
    c = makeConfig()
    s_option = ""%s%s"" % ('section1', 'foo2')

    c.set('section1', 'foo2', 'bar2')
    self.assertFalse(s_option in c._unsaved)

    c.remove_option('section1', 'foo2')
    self.assertFalse(s_option in c._unsaved)

    c.set_secure('section1', 'foo2', 'bar2')
    self.assertTrue(s_option in c._unsaved)
    self.assertTrue(c._unsaved[s_option][0] == 'set')
    self.assertTrue(c._unsaved[s_option][1] == 'bar2')

    c.remove_option('section1', 'foo2')
    self.assertTrue(s_option in s_option._unsaved)
    self.assertTrue(c._unsaved[s_option][0] == 'delete')
    self.assertTrue(c._unsaved[s_option][1] is None)"
"<NME> dns.py
<BEF> def dns_type_flag(rec_type):
    rtype = rec_type.upper()
    if rtype == 'A':
        record_type = dnsp.DNS_TYPE_A
    elif rtype == 'AAAA':
        record_type = dnsp.DNS_TYPE_AAAA
    elif rtype == 'PTR':
        record_type = dnsp.DNS_TYPE_PTR
    elif rtype == 'NS':
        record_type = dnsp.DNS_TYPE_NS
    elif rtype == 'CNAME':
        record_type = dnsp.DNS_TYPE_CNAME
    elif record_type == 'SOA':
        record_type = dnsp.DNS_TYPE_SOA
    elif rtype == 'MX':
        record_type = dnsp.DNS_TYPE_MX
    elif rtype == 'SRV':
        record_type = dnsp.DNS_TYPE_SRV
    elif rtype == 'TXT':
        record_type = dnsp.DNS_TYPE_TXT
    elif rtype == 'ALL':
        record_type = dnsp.DNS_TYPE_ALL
    else:
        raise CommandError('Unknown type of DNS record %s' % rec_type)
    return record_type
<MSG> Fix incorrect variable name
<DFF> @@ -10,7 +10,7 @@
         record_type = dnsp.DNS_TYPE_NS
     elif rtype == 'CNAME':
         record_type = dnsp.DNS_TYPE_CNAME
-    elif record_type == 'SOA':
+    elif rtype == 'SOA':
         record_type = dnsp.DNS_TYPE_SOA
     elif rtype == 'MX':
         record_type = dnsp.DNS_TYPE_MX","def dns_type_flag(rec_type):
    rtype = rec_type.upper()
    if rtype == 'A':
        record_type = dnsp.DNS_TYPE_A
    elif rtype == 'AAAA':
        record_type = dnsp.DNS_TYPE_AAAA
    elif rtype == 'PTR':
        record_type = dnsp.DNS_TYPE_PTR
    elif rtype == 'NS':
        record_type = dnsp.DNS_TYPE_NS
    elif rtype == 'CNAME':
        record_type = dnsp.DNS_TYPE_CNAME
    elif rtype == 'SOA':
        record_type = dnsp.DNS_TYPE_SOA
    elif rtype == 'MX':
        record_type = dnsp.DNS_TYPE_MX
    elif rtype == 'SRV':
        record_type = dnsp.DNS_TYPE_SRV
    elif rtype == 'TXT':
        record_type = dnsp.DNS_TYPE_TXT
    elif rtype == 'ALL':
        record_type = dnsp.DNS_TYPE_ALL
    else:
        raise CommandError('Unknown type of DNS record %s' % rec_type)
    return record_type",0,"<NME> dns.py
<BEF> def dns_type_flag(rec_type):
    rtype = rec_type.upper()
    if rtype == 'A':
        record_type = dnsp.DNS_TYPE_A
    elif rtype == 'AAAA':
        record_type = dnsp.DNS_TYPE_AAAA
    elif rtype == 'PTR':
        record_type = dnsp.DNS_TYPE_PTR
    elif rtype == 'NS':
        record_type = dnsp.DNS_TYPE_NS
    elif rtype == 'CNAME':
        record_type = dnsp.DNS_TYPE_CNAME
    elif record_type == 'SOA':
        record_type = dnsp.DNS_TYPE_SOA
    elif rtype == 'MX':
        record_type = dnsp.DNS_TYPE_MX
    elif rtype == 'SRV':
        record_type = dnsp.DNS_TYPE_SRV
    elif rtype == 'TXT':
        record_type = dnsp.DNS_TYPE_TXT
    elif rtype == 'ALL':
        record_type = dnsp.DNS_TYPE_ALL
    else:
        raise CommandError('Unknown type of DNS record %s' % rec_type)
    return record_type
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def dns_type_flag(rec_type):
    rtype = rec_type.upper()
    if rtype == 'A':
        record_type = dnsp.DNS_TYPE_A
    elif rtype == 'AAAA':
        record_type = dnsp.DNS_TYPE_AAAA
    elif rtype == 'PTR':
        record_type = dnsp.DNS_TYPE_PTR
    elif rtype == 'NS':
        record_type = dnsp.DNS_TYPE_NS
    elif rtype == 'CNAME':
        record_type = dnsp.DNS_TYPE_CNAME
    elif record_type == 'SOA':
        record_type = dnsp.DNS_TYPE_SOA
    elif rtype == 'MX':
        record_type = dnsp.DNS_TYPE_MX
    elif rtype == 'SRV':
        record_type = dnsp.DNS_TYPE_SRV
    elif rtype == 'TXT':
        record_type = dnsp.DNS_TYPE_TXT
    elif rtype == 'ALL':
        record_type = dnsp.DNS_TYPE_ALL
    else:
        raise CommandError('Unknown type of DNS record %s' % rec_type)
    return record_type"
"<NME> AddAccountWizard.py
<BEF> def __init__(self, parent=None):
    super(AddAccountWizard, self).__init__(
            parent,
            windowTitle=""Sign In"")
    
    # TODO - remove magic numbers
    self.setPage(0, AccountTypeWizardPage())
    self.setPage(1, GithubCredentialsWizardPage())
    parent.setPage(2, Github2FAWizardPage())
    self.setPage(3, UserSummaryWizardPage())
<MSG> Fix incorrect variable name
<DFF> @@ -6,5 +6,5 @@
     # TODO - remove magic numbers
     self.setPage(0, AccountTypeWizardPage())
     self.setPage(1, GithubCredentialsWizardPage())
-    parent.setPage(2, Github2FAWizardPage())
+    self.setPage(2, Github2FAWizardPage())
     self.setPage(3, UserSummaryWizardPage())","def __init__(self, parent=None):
    super(AddAccountWizard, self).__init__(
            parent,
            windowTitle=""Sign In"")
    
    # TODO - remove magic numbers
    self.setPage(0, AccountTypeWizardPage())
    self.setPage(1, GithubCredentialsWizardPage())
    self.setPage(2, Github2FAWizardPage())
    self.setPage(3, UserSummaryWizardPage())",1,"<NME> AddAccountWizard.py
<BEF> def __init__(self, parent=None):
    super(AddAccountWizard, self).__init__(
            parent,
            windowTitle=""Sign In"")
    
    # TODO - remove magic numbers
    self.setPage(0, AccountTypeWizardPage())
    self.setPage(1, GithubCredentialsWizardPage())
    parent.setPage(2, Github2FAWizardPage())
    self.setPage(3, UserSummaryWizardPage())
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, parent=None):
    super(AddAccountWizard, self).__init__(
            parent,
            windowTitle=""Sign In"")
    
    # TODO - remove magic numbers
    self.setPage(0, AccountTypeWizardPage())
    self.setPage(1, GithubCredentialsWizardPage())
    parent.setPage(2, Github2FAWizardPage())
    self.setPage(3, UserSummaryWizardPage())"
"<NME> test_main.py
<BEF> def test_custom_cluster_name_bad(self, capsys):
    with pytest.raises(SystemExit):
        self.parser.parse_args('--cluster=/evil-this-should-not-be-created'.split())
    out, err = self.readouterr()
    assert ('--cluster: argument must start with a letter and contain only '
            'letters and numbers') in err
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def test_custom_cluster_name_bad(self, capsys):
     with pytest.raises(SystemExit):
         self.parser.parse_args('--cluster=/evil-this-should-not-be-created'.split())
-    out, err = self.readouterr()
+    out, err = capsys.readouterr()
     assert ('--cluster: argument must start with a letter and contain only '
             'letters and numbers') in err","def test_custom_cluster_name_bad(self, capsys):
    with pytest.raises(SystemExit):
        self.parser.parse_args('--cluster=/evil-this-should-not-be-created'.split())
    out, err = capsys.readouterr()
    assert ('--cluster: argument must start with a letter and contain only '
            'letters and numbers') in err",2,"<NME> test_main.py
<BEF> def test_custom_cluster_name_bad(self, capsys):
    with pytest.raises(SystemExit):
        self.parser.parse_args('--cluster=/evil-this-should-not-be-created'.split())
    out, err = self.readouterr()
    assert ('--cluster: argument must start with a letter and contain only '
            'letters and numbers') in err
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_custom_cluster_name_bad(self, capsys):
    with pytest.raises(SystemExit):
        self.parser.parse_args('--cluster=/evil-this-should-not-be-created'.split())
    out, err = self.readouterr()
    assert ('--cluster: argument must start with a letter and contain only '
            'letters and numbers') in err"
"<NME> test_repo.py
<BEF> def test_repo_url_default_is_none(self):
    args = self.parser.parse_args('repo ceph host1'.split())
    assert self.repo_url is None
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def test_repo_url_default_is_none(self):
     args = self.parser.parse_args('repo ceph host1'.split())
-    assert self.repo_url is None
+    assert args.repo_url is None","def test_repo_url_default_is_none(self):
    args = self.parser.parse_args('repo ceph host1'.split())
    assert args.repo_url is None",3,"<NME> test_repo.py
<BEF> def test_repo_url_default_is_none(self):
    args = self.parser.parse_args('repo ceph host1'.split())
    assert self.repo_url is None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_repo_url_default_is_none(self):
    args = self.parser.parse_args('repo ceph host1'.split())
    assert self.repo_url is None"
"<NME> test_conf.py
<BEF> def test_get_repos_is_empty(self):
    cfg = conf.cephdeploy.Conf()
    self.sections = lambda: ['ceph-deploy-install']
    assert cfg.get_repos() == []
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def test_get_repos_is_empty(self):
     cfg = conf.cephdeploy.Conf()
-    self.sections = lambda: ['ceph-deploy-install']
+    cfg.sections = lambda: ['ceph-deploy-install']
     assert cfg.get_repos() == []","def test_get_repos_is_empty(self):
    cfg = conf.cephdeploy.Conf()
    cfg.sections = lambda: ['ceph-deploy-install']
    assert cfg.get_repos() == []",4,"<NME> test_conf.py
<BEF> def test_get_repos_is_empty(self):
    cfg = conf.cephdeploy.Conf()
    self.sections = lambda: ['ceph-deploy-install']
    assert cfg.get_repos() == []
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_get_repos_is_empty(self):
    cfg = conf.cephdeploy.Conf()
    self.sections = lambda: ['ceph-deploy-install']
    assert cfg.get_repos() == []"
"<NME> dsacl.py
<BEF> def print_new_acl(self, samdb, object_dn):
    desc = self.read_descriptor(samdb, object_dn)
    desc_sddl = desc.as_sddl(self.get_domain_sid(samdb))
    desc_sddl.outf.write(""new descriptor for %s:\n"" % object_dn)
    self.outf.write(desc_sddl + ""\n"")
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def print_new_acl(self, samdb, object_dn):
     desc = self.read_descriptor(samdb, object_dn)
     desc_sddl = desc.as_sddl(self.get_domain_sid(samdb))
-    desc_sddl.outf.write(""new descriptor for %s:\n"" % object_dn)
+    self.outf.write(""new descriptor for %s:\n"" % object_dn)
     self.outf.write(desc_sddl + ""\n"")","def print_new_acl(self, samdb, object_dn):
    desc = self.read_descriptor(samdb, object_dn)
    desc_sddl = desc.as_sddl(self.get_domain_sid(samdb))
    self.outf.write(""new descriptor for %s:\n"" % object_dn)
    self.outf.write(desc_sddl + ""\n"")",5,"<NME> dsacl.py
<BEF> def print_new_acl(self, samdb, object_dn):
    desc = self.read_descriptor(samdb, object_dn)
    desc_sddl = desc.as_sddl(self.get_domain_sid(samdb))
    desc_sddl.outf.write(""new descriptor for %s:\n"" % object_dn)
    self.outf.write(desc_sddl + ""\n"")
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def print_new_acl(self, samdb, object_dn):
    desc = self.read_descriptor(samdb, object_dn)
    desc_sddl = desc.as_sddl(self.get_domain_sid(samdb))
    desc_sddl.outf.write(""new descriptor for %s:\n"" % object_dn)
    self.outf.write(desc_sddl + ""\n"")"
"<NME> test_cli_new.py
<BEF> def test_defaults(newcfg):
    cfg = newcfg('host1')
    assert newcfg.get('global', 'auth cluster required') == 'cephx'
    assert cfg.get('global', 'auth service required') == 'cephx'
    assert cfg.get('global', 'auth client required') == 'cephx'
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def test_defaults(newcfg):
     cfg = newcfg('host1')
-    assert newcfg.get('global', 'auth cluster required') == 'cephx'
+    assert cfg.get('global', 'auth cluster required') == 'cephx'
     assert cfg.get('global', 'auth service required') == 'cephx'
     assert cfg.get('global', 'auth client required') == 'cephx'","def test_defaults(newcfg):
    cfg = newcfg('host1')
    assert cfg.get('global', 'auth cluster required') == 'cephx'
    assert cfg.get('global', 'auth service required') == 'cephx'
    assert cfg.get('global', 'auth client required') == 'cephx'",6,"<NME> test_cli_new.py
<BEF> def test_defaults(newcfg):
    cfg = newcfg('host1')
    assert newcfg.get('global', 'auth cluster required') == 'cephx'
    assert cfg.get('global', 'auth service required') == 'cephx'
    assert cfg.get('global', 'auth client required') == 'cephx'
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_defaults(newcfg):
    cfg = newcfg('host1')
    assert newcfg.get('global', 'auth cluster required') == 'cephx'
    assert cfg.get('global', 'auth service required') == 'cephx'
    assert cfg.get('global', 'auth client required') == 'cephx'"
"<NME> conf.py
<BEF> def register_connection(alias='default', host='localhost', port=6379, **kwargs):
    global _connections

    kwargs.setdefault('parser_class', PythonParser)
    kwargs.setdefault('db', 0)

    pool = ConnectionPool(host=host, port=port, **kwargs)
    conn = redis.StrictRedis(connection_pool=pool)

    _connections[pool] = conn
    return conn
<MSG> Fix incorrect variable name
<DFF> @@ -7,5 +7,5 @@
     pool = ConnectionPool(host=host, port=port, **kwargs)
     conn = redis.StrictRedis(connection_pool=pool)
 
-    _connections[pool] = conn
+    _connections[alias] = conn
     return conn","def register_connection(alias='default', host='localhost', port=6379, **kwargs):
    global _connections

    kwargs.setdefault('parser_class', PythonParser)
    kwargs.setdefault('db', 0)

    pool = ConnectionPool(host=host, port=port, **kwargs)
    conn = redis.StrictRedis(connection_pool=pool)

    _connections[alias] = conn
    return conn",7,"<NME> conf.py
<BEF> def register_connection(alias='default', host='localhost', port=6379, **kwargs):
    global _connections

    kwargs.setdefault('parser_class', PythonParser)
    kwargs.setdefault('db', 0)

    pool = ConnectionPool(host=host, port=port, **kwargs)
    conn = redis.StrictRedis(connection_pool=pool)

    _connections[pool] = conn
    return conn
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def register_connection(alias='default', host='localhost', port=6379, **kwargs):
    global _connections

    kwargs.setdefault('parser_class', PythonParser)
    kwargs.setdefault('db', 0)

    pool = ConnectionPool(host=host, port=port, **kwargs)
    conn = redis.StrictRedis(connection_pool=pool)

    _connections[pool] = conn
    return conn"
"<NME> generation.py
<BEF> def _juliacode(expr, ):
    code = sympy.printing.lambdarepr.lambdarepr(code)
    return code.replace('**', '^')
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def _juliacode(expr, ):
-    code = sympy.printing.lambdarepr.lambdarepr(code)
+    code = sympy.printing.lambdarepr.lambdarepr(expr)
     return code.replace('**', '^')","def _juliacode(expr, ):
    code = sympy.printing.lambdarepr.lambdarepr(expr)
    return code.replace('**', '^')",8,"<NME> generation.py
<BEF> def _juliacode(expr, ):
    code = sympy.printing.lambdarepr.lambdarepr(code)
    return code.replace('**', '^')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _juliacode(expr, ):
    code = sympy.printing.lambdarepr.lambdarepr(code)
    return code.replace('**', '^')"
"<NME> remotes.py
<BEF> def write_keyring(path, key, uid=-1, gid=-1):
    """""" create a keyring file """"""
    # Note that we *require* to avoid deletion of the temp file
    # otherwise we risk not being able to copy the contents from
    # one file system to the other, hence the `delete=False`
    tmp_file = tempfile.NamedTemporaryFile(delete=False)
    tmp_file.write(key)
    tmp_file.close()
    keyring_dir = os.path.dirname(path)
    if not path_exists(keyring_dir):
        makedir(keyring_dir, uid, key)
    shutil.move(tmp_file.name, path)
<MSG> Fix incorrect variable name
<DFF> @@ -8,5 +8,5 @@
     tmp_file.close()
     keyring_dir = os.path.dirname(path)
     if not path_exists(keyring_dir):
-        makedir(keyring_dir, uid, key)
+        makedir(keyring_dir, uid, gid)
     shutil.move(tmp_file.name, path)","def write_keyring(path, key, uid=-1, gid=-1):
    """""" create a keyring file """"""
    # Note that we *require* to avoid deletion of the temp file
    # otherwise we risk not being able to copy the contents from
    # one file system to the other, hence the `delete=False`
    tmp_file = tempfile.NamedTemporaryFile(delete=False)
    tmp_file.write(key)
    tmp_file.close()
    keyring_dir = os.path.dirname(path)
    if not path_exists(keyring_dir):
        makedir(keyring_dir, uid, gid)
    shutil.move(tmp_file.name, path)",9,"<NME> remotes.py
<BEF> def write_keyring(path, key, uid=-1, gid=-1):
    """""" create a keyring file """"""
    # Note that we *require* to avoid deletion of the temp file
    # otherwise we risk not being able to copy the contents from
    # one file system to the other, hence the `delete=False`
    tmp_file = tempfile.NamedTemporaryFile(delete=False)
    tmp_file.write(key)
    tmp_file.close()
    keyring_dir = os.path.dirname(path)
    if not path_exists(keyring_dir):
        makedir(keyring_dir, uid, key)
    shutil.move(tmp_file.name, path)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def write_keyring(path, key, uid=-1, gid=-1):
    """""" create a keyring file """"""
    # Note that we *require* to avoid deletion of the temp file
    # otherwise we risk not being able to copy the contents from
    # one file system to the other, hence the `delete=False`
    tmp_file = tempfile.NamedTemporaryFile(delete=False)
    tmp_file.write(key)
    tmp_file.close()
    keyring_dir = os.path.dirname(path)
    if not path_exists(keyring_dir):
        makedir(keyring_dir, uid, key)
    shutil.move(tmp_file.name, path)"
"<NME> RFAlignTangents.py
<BEF> def setSegmentStartTangent(segment, tangent):
    if len(segment.points) == 2:
        '''
        Convert straight segment to 4-point cubic bezier.
        '''
        p0, p3 = segment.points
        p2 = p0.midpoint(p3)
        p1 = p0.plus(tangent.scale(p0.distanceTo(p3) * 0.5))
        result = TFSSegment(p0, p1, p2, p3)
    elif len(segment.points) == 3:
        '''
        Update 3-point cubic bezier.
        '''
        p0, p1, p2 = segment.points
        p1 = TFSIntersection.getIntersectPoint(p0,
                                               p0.plus(p2),
                                               p1,
                                               p2)
        result = TFSSegment(p0, p1, p2)
    elif len(segment.points) == 4:
        '''
        Update 4-point cubic bezier.
        '''
        p0, p1, p2, p3 = segment.points
        p1 = p0.plus(tangent.scale(p0.distanceTo(p1)))
        result = TFSSegment(p0, p1, p2, p3)
    else:
        raise Exception('Invalid segment: ' + segment.description())

#    print 'updated segment:', segment.description(), 'to:', result.description()
    return result
<MSG> Fix incorrect variable name
<DFF> @@ -13,7 +13,7 @@
         '''
         p0, p1, p2 = segment.points
         p1 = TFSIntersection.getIntersectPoint(p0,
-                                               p0.plus(p2),
+                                               p0.plus(tangent),
                                                p1,
                                                p2)
         result = TFSSegment(p0, p1, p2)","def setSegmentStartTangent(segment, tangent):
    if len(segment.points) == 2:
        '''
        Convert straight segment to 4-point cubic bezier.
        '''
        p0, p3 = segment.points
        p2 = p0.midpoint(p3)
        p1 = p0.plus(tangent.scale(p0.distanceTo(p3) * 0.5))
        result = TFSSegment(p0, p1, p2, p3)
    elif len(segment.points) == 3:
        '''
        Update 3-point cubic bezier.
        '''
        p0, p1, p2 = segment.points
        p1 = TFSIntersection.getIntersectPoint(p0,
                                               p0.plus(tangent),
                                               p1,
                                               p2)
        result = TFSSegment(p0, p1, p2)
    elif len(segment.points) == 4:
        '''
        Update 4-point cubic bezier.
        '''
        p0, p1, p2, p3 = segment.points
        p1 = p0.plus(tangent.scale(p0.distanceTo(p1)))
        result = TFSSegment(p0, p1, p2, p3)
    else:
        raise Exception('Invalid segment: ' + segment.description())

#    print 'updated segment:', segment.description(), 'to:', result.description()
    return result",0,"<NME> RFAlignTangents.py
<BEF> def setSegmentStartTangent(segment, tangent):
    if len(segment.points) == 2:
        '''
        Convert straight segment to 4-point cubic bezier.
        '''
        p0, p3 = segment.points
        p2 = p0.midpoint(p3)
        p1 = p0.plus(tangent.scale(p0.distanceTo(p3) * 0.5))
        result = TFSSegment(p0, p1, p2, p3)
    elif len(segment.points) == 3:
        '''
        Update 3-point cubic bezier.
        '''
        p0, p1, p2 = segment.points
        p1 = TFSIntersection.getIntersectPoint(p0,
                                               p0.plus(p2),
                                               p1,
                                               p2)
        result = TFSSegment(p0, p1, p2)
    elif len(segment.points) == 4:
        '''
        Update 4-point cubic bezier.
        '''
        p0, p1, p2, p3 = segment.points
        p1 = p0.plus(tangent.scale(p0.distanceTo(p1)))
        result = TFSSegment(p0, p1, p2, p3)
    else:
        raise Exception('Invalid segment: ' + segment.description())

#    print 'updated segment:', segment.description(), 'to:', result.description()
    return result
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def setSegmentStartTangent(segment, tangent):
    if len(segment.points) == 2:
        '''
        Convert straight segment to 4-point cubic bezier.
        '''
        p0, p3 = segment.points
        p2 = p0.midpoint(p3)
        p1 = p0.plus(tangent.scale(p0.distanceTo(p3) * 0.5))
        result = TFSSegment(p0, p1, p2, p3)
    elif len(segment.points) == 3:
        '''
        Update 3-point cubic bezier.
        '''
        p0, p1, p2 = segment.points
        p1 = TFSIntersection.getIntersectPoint(p0,
                                               p0.plus(p2),
                                               p1,
                                               p2)
        result = TFSSegment(p0, p1, p2)
    elif len(segment.points) == 4:
        '''
        Update 4-point cubic bezier.
        '''
        p0, p1, p2, p3 = segment.points
        p1 = p0.plus(tangent.scale(p0.distanceTo(p1)))
        result = TFSSegment(p0, p1, p2, p3)
    else:
        raise Exception('Invalid segment: ' + segment.description())

#    print 'updated segment:', segment.description(), 'to:', result.description()
    return result"
"<NME> job_options.py
<BEF> @property
def urls(self):
    import operator

    urls_or_func = self.settings.get('source_urls') or getattr(self.rule, 'source_urls', None)
    rval = urls_or_func
    if operator.isCallable(urls_or_func):
        urls_or_func = urls_or_func(self)
    return rval or []
<MSG> Fix incorrect variable name
<DFF> @@ -5,5 +5,5 @@
     urls_or_func = self.settings.get('source_urls') or getattr(self.rule, 'source_urls', None)
     rval = urls_or_func
     if operator.isCallable(urls_or_func):
-        urls_or_func = urls_or_func(self)
+        rval = urls_or_func(self)
     return rval or []","@property
def urls(self):
    import operator

    urls_or_func = self.settings.get('source_urls') or getattr(self.rule, 'source_urls', None)
    rval = urls_or_func
    if operator.isCallable(urls_or_func):
        rval = urls_or_func(self)
    return rval or []",1,"<NME> job_options.py
<BEF> @property
def urls(self):
    import operator

    urls_or_func = self.settings.get('source_urls') or getattr(self.rule, 'source_urls', None)
    rval = urls_or_func
    if operator.isCallable(urls_or_func):
        urls_or_func = urls_or_func(self)
    return rval or []
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@property
def urls(self):
    import operator

    urls_or_func = self.settings.get('source_urls') or getattr(self.rule, 'source_urls', None)
    rval = urls_or_func
    if operator.isCallable(urls_or_func):
        urls_or_func = urls_or_func(self)
    return rval or []"
"<NME> parseDataset.py
<BEF> def parse(dataset):
    shapes = {}

    with codecs.open(dataset,'r', encoding=""utf8"") as dataset:
        current_char = ''
        current_shape = []
        remaining_strokes = 1
        for l in dataset.readlines():
            letter = letter_re.search(l)
            if letter:
                current_char = letter.group('char')
                continue

            strokes = strokes_re.search(l)
            if strokes:
                remaining_strokes = int(strokes.group('nb'))
                continue

            points = points_re.search(l)
            if points:
                if current_char == 0:
                    raise RuntimeError(""I should not find points! No stroke is missing"")
                remaining_strokes -= 1
                current_shape.append(map(int,points.group(""coords"").split()))

                if remaining_strokes == 0:
                    shapes.setdefault(current_char,[]).append(current_shape)
                    current_shape = []


    return shapes
<MSG> Fix incorrect variable name
<DFF> @@ -18,7 +18,7 @@
 
             points = points_re.search(l)
             if points:
-                if current_char == 0:
+                if remaining_strokes == 0:
                     raise RuntimeError(""I should not find points! No stroke is missing"")
                 remaining_strokes -= 1
                 current_shape.append(map(int,points.group(""coords"").split()))","def parse(dataset):
    shapes = {}

    with codecs.open(dataset,'r', encoding=""utf8"") as dataset:
        current_char = ''
        current_shape = []
        remaining_strokes = 1
        for l in dataset.readlines():
            letter = letter_re.search(l)
            if letter:
                current_char = letter.group('char')
                continue

            strokes = strokes_re.search(l)
            if strokes:
                remaining_strokes = int(strokes.group('nb'))
                continue

            points = points_re.search(l)
            if points:
                if remaining_strokes == 0:
                    raise RuntimeError(""I should not find points! No stroke is missing"")
                remaining_strokes -= 1
                current_shape.append(map(int,points.group(""coords"").split()))

                if remaining_strokes == 0:
                    shapes.setdefault(current_char,[]).append(current_shape)
                    current_shape = []


    return shapes",2,"<NME> parseDataset.py
<BEF> def parse(dataset):
    shapes = {}

    with codecs.open(dataset,'r', encoding=""utf8"") as dataset:
        current_char = ''
        current_shape = []
        remaining_strokes = 1
        for l in dataset.readlines():
            letter = letter_re.search(l)
            if letter:
                current_char = letter.group('char')
                continue

            strokes = strokes_re.search(l)
            if strokes:
                remaining_strokes = int(strokes.group('nb'))
                continue

            points = points_re.search(l)
            if points:
                if current_char == 0:
                    raise RuntimeError(""I should not find points! No stroke is missing"")
                remaining_strokes -= 1
                current_shape.append(map(int,points.group(""coords"").split()))

                if remaining_strokes == 0:
                    shapes.setdefault(current_char,[]).append(current_shape)
                    current_shape = []


    return shapes
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def parse(dataset):
    shapes = {}

    with codecs.open(dataset,'r', encoding=""utf8"") as dataset:
        current_char = ''
        current_shape = []
        remaining_strokes = 1
        for l in dataset.readlines():
            letter = letter_re.search(l)
            if letter:
                current_char = letter.group('char')
                continue

            strokes = strokes_re.search(l)
            if strokes:
                remaining_strokes = int(strokes.group('nb'))
                continue

            points = points_re.search(l)
            if points:
                if current_char == 0:
                    raise RuntimeError(""I should not find points! No stroke is missing"")
                remaining_strokes -= 1
                current_shape.append(map(int,points.group(""coords"").split()))

                if remaining_strokes == 0:
                    shapes.setdefault(current_char,[]).append(current_shape)
                    current_shape = []


    return shapes"
"<NME> mon.py
<BEF> def concatenate_keyrings(args):
    """"""
    A helper to collect all keyrings into a single blob that will be
    used to inject it to mons with ``--mkfs`` on remote nodes

    We require all keyring files to be concatenated to be in a directory
    to end with ``.keyring``.
    """"""
    keyring_path = os.path.abspath(args.keyrings)
    LOG.info('concatenating keyrings from %s' % keyring_path)
    LOG.info('to seed remote monitors')

    keyrings = [
        os.path.join(keyring_path, f) for f in os.listdir(keyring_path)
        if os.path.isfile(os.path.join(keyring_path, f)) and f.endswith('.keyring')
    ]

    contents = []
    seen_sections = {}

    if not keyrings:
        path_from_arg = os.path.abspath(args.keyrings)
        raise RuntimeError('could not find any keyrings in %s' % path_from_arg)

    for keyring in keyrings:
        path = os.path.abspath(keyring)

        for section in keyring_parser(keyring):
            if not seen_sections.get(section):
                seen_sections[section] = path
                LOG.info('adding entity ""%s"" from keyring %s' % (section, path))
                with open(path) as k:
                    contents.append(k.read())
            else:
                LOG.warning('will not add keyring: %s' % path)
                LOG.warning('entity ""%s"" from keyring %s is a duplicate' % (section, path))
                LOG.warning('already present in keyring: %s' % seen_sections[section])

    return ''.join(contents)
<MSG> Fix incorrect variable name
<DFF> @@ -25,7 +25,7 @@
     for keyring in keyrings:
         path = os.path.abspath(keyring)
 
-        for section in keyring_parser(keyring):
+        for section in keyring_parser(path):
             if not seen_sections.get(section):
                 seen_sections[section] = path
                 LOG.info('adding entity ""%s"" from keyring %s' % (section, path))","def concatenate_keyrings(args):
    """"""
    A helper to collect all keyrings into a single blob that will be
    used to inject it to mons with ``--mkfs`` on remote nodes

    We require all keyring files to be concatenated to be in a directory
    to end with ``.keyring``.
    """"""
    keyring_path = os.path.abspath(args.keyrings)
    LOG.info('concatenating keyrings from %s' % keyring_path)
    LOG.info('to seed remote monitors')

    keyrings = [
        os.path.join(keyring_path, f) for f in os.listdir(keyring_path)
        if os.path.isfile(os.path.join(keyring_path, f)) and f.endswith('.keyring')
    ]

    contents = []
    seen_sections = {}

    if not keyrings:
        path_from_arg = os.path.abspath(args.keyrings)
        raise RuntimeError('could not find any keyrings in %s' % path_from_arg)

    for keyring in keyrings:
        path = os.path.abspath(keyring)

        for section in keyring_parser(path):
            if not seen_sections.get(section):
                seen_sections[section] = path
                LOG.info('adding entity ""%s"" from keyring %s' % (section, path))
                with open(path) as k:
                    contents.append(k.read())
            else:
                LOG.warning('will not add keyring: %s' % path)
                LOG.warning('entity ""%s"" from keyring %s is a duplicate' % (section, path))
                LOG.warning('already present in keyring: %s' % seen_sections[section])

    return ''.join(contents)",3,"<NME> mon.py
<BEF> def concatenate_keyrings(args):
    """"""
    A helper to collect all keyrings into a single blob that will be
    used to inject it to mons with ``--mkfs`` on remote nodes

    We require all keyring files to be concatenated to be in a directory
    to end with ``.keyring``.
    """"""
    keyring_path = os.path.abspath(args.keyrings)
    LOG.info('concatenating keyrings from %s' % keyring_path)
    LOG.info('to seed remote monitors')

    keyrings = [
        os.path.join(keyring_path, f) for f in os.listdir(keyring_path)
        if os.path.isfile(os.path.join(keyring_path, f)) and f.endswith('.keyring')
    ]

    contents = []
    seen_sections = {}

    if not keyrings:
        path_from_arg = os.path.abspath(args.keyrings)
        raise RuntimeError('could not find any keyrings in %s' % path_from_arg)

    for keyring in keyrings:
        path = os.path.abspath(keyring)

        for section in keyring_parser(keyring):
            if not seen_sections.get(section):
                seen_sections[section] = path
                LOG.info('adding entity ""%s"" from keyring %s' % (section, path))
                with open(path) as k:
                    contents.append(k.read())
            else:
                LOG.warning('will not add keyring: %s' % path)
                LOG.warning('entity ""%s"" from keyring %s is a duplicate' % (section, path))
                LOG.warning('already present in keyring: %s' % seen_sections[section])

    return ''.join(contents)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def concatenate_keyrings(args):
    """"""
    A helper to collect all keyrings into a single blob that will be
    used to inject it to mons with ``--mkfs`` on remote nodes

    We require all keyring files to be concatenated to be in a directory
    to end with ``.keyring``.
    """"""
    keyring_path = os.path.abspath(args.keyrings)
    LOG.info('concatenating keyrings from %s' % keyring_path)
    LOG.info('to seed remote monitors')

    keyrings = [
        os.path.join(keyring_path, f) for f in os.listdir(keyring_path)
        if os.path.isfile(os.path.join(keyring_path, f)) and f.endswith('.keyring')
    ]

    contents = []
    seen_sections = {}

    if not keyrings:
        path_from_arg = os.path.abspath(args.keyrings)
        raise RuntimeError('could not find any keyrings in %s' % path_from_arg)

    for keyring in keyrings:
        path = os.path.abspath(keyring)

        for section in keyring_parser(keyring):
            if not seen_sections.get(section):
                seen_sections[section] = path
                LOG.info('adding entity ""%s"" from keyring %s' % (section, path))
                with open(path) as k:
                    contents.append(k.read())
            else:
                LOG.warning('will not add keyring: %s' % path)
                LOG.warning('entity ""%s"" from keyring %s is a duplicate' % (section, path))
                LOG.warning('already present in keyring: %s' % seen_sections[section])

    return ''.join(contents)"
"<NME> snomed_tests.py
<BEF> def test_hierarchy_isa(self):
	"""""" Test hierarchical lookup.
	""""""
	cpt = SNOMEDConcept('315004001')        # Metastasis from malignant tumor of breast
	child = SNOMEDConcept('128462008')      # Metastatic neoplasm (disease)
	self.assertTrue(cpt.isa(child.code))
	child = SNOMEDConcept('363346000')      # Malignant neoplastic disease (disorder)
	self.assertTrue(child.isa(child))
	child = SNOMEDConcept('55342001')       # Neoplasia
	self.assertTrue(cpt.isa(child.code))
	child = SNOMEDConcept('408643008')      # Infiltrating duct carcinoma of breast
	self.assertFalse(cpt.isa(child.code))
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
 	child = SNOMEDConcept('128462008')      # Metastatic neoplasm (disease)
 	self.assertTrue(cpt.isa(child.code))
 	child = SNOMEDConcept('363346000')      # Malignant neoplastic disease (disorder)
-	self.assertTrue(child.isa(child))
+	self.assertTrue(cpt.isa(child))
 	child = SNOMEDConcept('55342001')       # Neoplasia
 	self.assertTrue(cpt.isa(child.code))
 	child = SNOMEDConcept('408643008')      # Infiltrating duct carcinoma of breast","def test_hierarchy_isa(self):
	"""""" Test hierarchical lookup.
	""""""
	cpt = SNOMEDConcept('315004001')        # Metastasis from malignant tumor of breast
	child = SNOMEDConcept('128462008')      # Metastatic neoplasm (disease)
	self.assertTrue(cpt.isa(child.code))
	child = SNOMEDConcept('363346000')      # Malignant neoplastic disease (disorder)
	self.assertTrue(cpt.isa(child))
	child = SNOMEDConcept('55342001')       # Neoplasia
	self.assertTrue(cpt.isa(child.code))
	child = SNOMEDConcept('408643008')      # Infiltrating duct carcinoma of breast
	self.assertFalse(cpt.isa(child.code))",4,"<NME> snomed_tests.py
<BEF> def test_hierarchy_isa(self):
	"""""" Test hierarchical lookup.
	""""""
	cpt = SNOMEDConcept('315004001')        # Metastasis from malignant tumor of breast
	child = SNOMEDConcept('128462008')      # Metastatic neoplasm (disease)
	self.assertTrue(cpt.isa(child.code))
	child = SNOMEDConcept('363346000')      # Malignant neoplastic disease (disorder)
	self.assertTrue(child.isa(child))
	child = SNOMEDConcept('55342001')       # Neoplasia
	self.assertTrue(cpt.isa(child.code))
	child = SNOMEDConcept('408643008')      # Infiltrating duct carcinoma of breast
	self.assertFalse(cpt.isa(child.code))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_hierarchy_isa(self):
	"""""" Test hierarchical lookup.
	""""""
	cpt = SNOMEDConcept('315004001')        # Metastasis from malignant tumor of breast
	child = SNOMEDConcept('128462008')      # Metastatic neoplasm (disease)
	self.assertTrue(cpt.isa(child.code))
	child = SNOMEDConcept('363346000')      # Malignant neoplastic disease (disorder)
	self.assertTrue(child.isa(child))
	child = SNOMEDConcept('55342001')       # Neoplasia
	self.assertTrue(cpt.isa(child.code))
	child = SNOMEDConcept('408643008')      # Infiltrating duct carcinoma of breast
	self.assertFalse(cpt.isa(child.code))"
"<NME> kinematics.py
<BEF> def __init__(self, robotdef, geom, ifunc=None):

    if not ifunc:
        ifunc = _id

    self.rbtdef = robotdef
    self.geom = geom
    self.dof = self.rbtdef.dof

    def sym_skew(v):
        return sympy.Matrix([[0,    -v[2],  v[1]],
                             [v[2],     0, -v[0]],
                             [-v[1], v[0],     0]])

    if self.rbtdef._dh_convention == 'standard':

        # extend z and p so that z[-1] and p[-1] return values from base
        # frame
        z_ext = geom.z + [sympy.Matrix([0, 0, 1])]
        p_ext = geom.p + [sympy.zeros(3, 1)]

        self.Jp = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jp[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jp[robotdef][0:3, j] = ifunc(z_ext[j - 1])
                else:
                    self.Jp[l][0:3, j] = ifunc(z_ext[j - 1].cross(
                        (p_ext[l] - p_ext[j - 1])).reshape(3, 1))

        self.Jo = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jo[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jo[l][0:3, j] = sympy.zeros(3, 1)
                else:
                    self.Jo[l][0:3, j] = ifunc(z_ext[j - 1])

    elif self.rbtdef._dh_convention == 'modified':

        self.Jp = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jp[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jp[l][0:3, j] = ifunc(geom.z[j])
                else:
                    self.Jp[l][0:3, j] = ifunc(geom.z[j].cross(
                        (geom.p[l] - geom.p[j])).reshape(3, 1))

        self.Jo = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jo[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jo[l][0:3, j] = sympy.zeros(3, 1)
                else:
                    self.Jo[l][0:3, j] = ifunc(geom.z[j])

    self.J = list(range(self.rbtdef.dof))
    for l in range(self.rbtdef.dof):
        self.J[l] = self.Jp[l].col_join(self.Jo[l])

    self.Jcp = list(range(self.rbtdef.dof))
    self.Jco = self.Jo
    for l in range(self.rbtdef.dof):
        self.Jcp[l] = ifunc(self.Jp[l] - sym_skew(
            geom.R[l] * sympy.Matrix(self.rbtdef.l[l])) * self.Jo[l])

    self.Jc = list(range(self.rbtdef.dof))
    for l in range(self.rbtdef.dof):
        self.Jc[l] = self.Jcp[l].col_join(self.Jco[l])
<MSG> Fix incorrect variable name
<DFF> @@ -24,7 +24,7 @@
             self.Jp[l] = sympy.zeros(3, self.rbtdef.dof)
             for j in range(l + 1):
                 if self.rbtdef._links_sigma[j]:
-                    self.Jp[robotdef][0:3, j] = ifunc(z_ext[j - 1])
+                    self.Jp[l][0:3, j] = ifunc(z_ext[j - 1])
                 else:
                     self.Jp[l][0:3, j] = ifunc(z_ext[j - 1].cross(
                         (p_ext[l] - p_ext[j - 1])).reshape(3, 1))","def __init__(self, robotdef, geom, ifunc=None):

    if not ifunc:
        ifunc = _id

    self.rbtdef = robotdef
    self.geom = geom
    self.dof = self.rbtdef.dof

    def sym_skew(v):
        return sympy.Matrix([[0,    -v[2],  v[1]],
                             [v[2],     0, -v[0]],
                             [-v[1], v[0],     0]])

    if self.rbtdef._dh_convention == 'standard':

        # extend z and p so that z[-1] and p[-1] return values from base
        # frame
        z_ext = geom.z + [sympy.Matrix([0, 0, 1])]
        p_ext = geom.p + [sympy.zeros(3, 1)]

        self.Jp = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jp[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jp[l][0:3, j] = ifunc(z_ext[j - 1])
                else:
                    self.Jp[l][0:3, j] = ifunc(z_ext[j - 1].cross(
                        (p_ext[l] - p_ext[j - 1])).reshape(3, 1))

        self.Jo = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jo[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jo[l][0:3, j] = sympy.zeros(3, 1)
                else:
                    self.Jo[l][0:3, j] = ifunc(z_ext[j - 1])

    elif self.rbtdef._dh_convention == 'modified':

        self.Jp = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jp[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jp[l][0:3, j] = ifunc(geom.z[j])
                else:
                    self.Jp[l][0:3, j] = ifunc(geom.z[j].cross(
                        (geom.p[l] - geom.p[j])).reshape(3, 1))

        self.Jo = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jo[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jo[l][0:3, j] = sympy.zeros(3, 1)
                else:
                    self.Jo[l][0:3, j] = ifunc(geom.z[j])

    self.J = list(range(self.rbtdef.dof))
    for l in range(self.rbtdef.dof):
        self.J[l] = self.Jp[l].col_join(self.Jo[l])

    self.Jcp = list(range(self.rbtdef.dof))
    self.Jco = self.Jo
    for l in range(self.rbtdef.dof):
        self.Jcp[l] = ifunc(self.Jp[l] - sym_skew(
            geom.R[l] * sympy.Matrix(self.rbtdef.l[l])) * self.Jo[l])

    self.Jc = list(range(self.rbtdef.dof))
    for l in range(self.rbtdef.dof):
        self.Jc[l] = self.Jcp[l].col_join(self.Jco[l])",5,"<NME> kinematics.py
<BEF> def __init__(self, robotdef, geom, ifunc=None):

    if not ifunc:
        ifunc = _id

    self.rbtdef = robotdef
    self.geom = geom
    self.dof = self.rbtdef.dof

    def sym_skew(v):
        return sympy.Matrix([[0,    -v[2],  v[1]],
                             [v[2],     0, -v[0]],
                             [-v[1], v[0],     0]])

    if self.rbtdef._dh_convention == 'standard':

        # extend z and p so that z[-1] and p[-1] return values from base
        # frame
        z_ext = geom.z + [sympy.Matrix([0, 0, 1])]
        p_ext = geom.p + [sympy.zeros(3, 1)]

        self.Jp = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jp[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jp[robotdef][0:3, j] = ifunc(z_ext[j - 1])
                else:
                    self.Jp[l][0:3, j] = ifunc(z_ext[j - 1].cross(
                        (p_ext[l] - p_ext[j - 1])).reshape(3, 1))

        self.Jo = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jo[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jo[l][0:3, j] = sympy.zeros(3, 1)
                else:
                    self.Jo[l][0:3, j] = ifunc(z_ext[j - 1])

    elif self.rbtdef._dh_convention == 'modified':

        self.Jp = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jp[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jp[l][0:3, j] = ifunc(geom.z[j])
                else:
                    self.Jp[l][0:3, j] = ifunc(geom.z[j].cross(
                        (geom.p[l] - geom.p[j])).reshape(3, 1))

        self.Jo = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jo[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jo[l][0:3, j] = sympy.zeros(3, 1)
                else:
                    self.Jo[l][0:3, j] = ifunc(geom.z[j])

    self.J = list(range(self.rbtdef.dof))
    for l in range(self.rbtdef.dof):
        self.J[l] = self.Jp[l].col_join(self.Jo[l])

    self.Jcp = list(range(self.rbtdef.dof))
    self.Jco = self.Jo
    for l in range(self.rbtdef.dof):
        self.Jcp[l] = ifunc(self.Jp[l] - sym_skew(
            geom.R[l] * sympy.Matrix(self.rbtdef.l[l])) * self.Jo[l])

    self.Jc = list(range(self.rbtdef.dof))
    for l in range(self.rbtdef.dof):
        self.Jc[l] = self.Jcp[l].col_join(self.Jco[l])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, robotdef, geom, ifunc=None):

    if not ifunc:
        ifunc = _id

    self.rbtdef = robotdef
    self.geom = geom
    self.dof = self.rbtdef.dof

    def sym_skew(v):
        return sympy.Matrix([[0,    -v[2],  v[1]],
                             [v[2],     0, -v[0]],
                             [-v[1], v[0],     0]])

    if self.rbtdef._dh_convention == 'standard':

        # extend z and p so that z[-1] and p[-1] return values from base
        # frame
        z_ext = geom.z + [sympy.Matrix([0, 0, 1])]
        p_ext = geom.p + [sympy.zeros(3, 1)]

        self.Jp = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jp[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jp[robotdef][0:3, j] = ifunc(z_ext[j - 1])
                else:
                    self.Jp[l][0:3, j] = ifunc(z_ext[j - 1].cross(
                        (p_ext[l] - p_ext[j - 1])).reshape(3, 1))

        self.Jo = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jo[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jo[l][0:3, j] = sympy.zeros(3, 1)
                else:
                    self.Jo[l][0:3, j] = ifunc(z_ext[j - 1])

    elif self.rbtdef._dh_convention == 'modified':

        self.Jp = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jp[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jp[l][0:3, j] = ifunc(geom.z[j])
                else:
                    self.Jp[l][0:3, j] = ifunc(geom.z[j].cross(
                        (geom.p[l] - geom.p[j])).reshape(3, 1))

        self.Jo = list(range(self.rbtdef.dof))
        for l in range(self.rbtdef.dof):
            self.Jo[l] = sympy.zeros(3, self.rbtdef.dof)
            for j in range(l + 1):
                if self.rbtdef._links_sigma[j]:
                    self.Jo[l][0:3, j] = sympy.zeros(3, 1)
                else:
                    self.Jo[l][0:3, j] = ifunc(geom.z[j])

    self.J = list(range(self.rbtdef.dof))
    for l in range(self.rbtdef.dof):
        self.J[l] = self.Jp[l].col_join(self.Jo[l])

    self.Jcp = list(range(self.rbtdef.dof))
    self.Jco = self.Jo
    for l in range(self.rbtdef.dof):
        self.Jcp[l] = ifunc(self.Jp[l] - sym_skew(
            geom.R[l] * sympy.Matrix(self.rbtdef.l[l])) * self.Jo[l])

    self.Jc = list(range(self.rbtdef.dof))
    for l in range(self.rbtdef.dof):
        self.Jc[l] = self.Jcp[l].col_join(self.Jco[l])"
"<NME> models.py
<BEF> def __unicode__(self):
    if self.event_id:
        text = '{0} => {1}'.format(self.event, self.state)
    else:
        text = unicode(self.state)
    if self.duration:
        text = '{0} ({1})'.format(text, self.natural_duration)
    elif self.in_transition():
        text = '{0} (in transition)'.format(self)
    return text
<MSG> Fix incorrect variable name
<DFF> @@ -6,5 +6,5 @@
     if self.duration:
         text = '{0} ({1})'.format(text, self.natural_duration)
     elif self.in_transition():
-        text = '{0} (in transition)'.format(self)
+        text = '{0} (in transition)'.format(text)
     return text","def __unicode__(self):
    if self.event_id:
        text = '{0} => {1}'.format(self.event, self.state)
    else:
        text = unicode(self.state)
    if self.duration:
        text = '{0} ({1})'.format(text, self.natural_duration)
    elif self.in_transition():
        text = '{0} (in transition)'.format(text)
    return text",6,"<NME> models.py
<BEF> def __unicode__(self):
    if self.event_id:
        text = '{0} => {1}'.format(self.event, self.state)
    else:
        text = unicode(self.state)
    if self.duration:
        text = '{0} ({1})'.format(text, self.natural_duration)
    elif self.in_transition():
        text = '{0} (in transition)'.format(self)
    return text
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __unicode__(self):
    if self.event_id:
        text = '{0} => {1}'.format(self.event, self.state)
    else:
        text = unicode(self.state)
    if self.duration:
        text = '{0} ({1})'.format(text, self.natural_duration)
    elif self.in_transition():
        text = '{0} (in transition)'.format(self)
    return text"
"<NME> tests.py
<BEF> @skipIf(django.VERSION < (1,8,), ""This test needs Django >=1.8"")
def test_polymorphic__complex_aggregate(self):
    """""" test (complex expression on) aggregate (should work for annotate either) """"""
    
    Model2A.objects.create(field1='A1')
    Model2B.objects.create(field1='A1', field2='B2')
    Model2B.objects.create(field1='A1', field2='B2')
    
    # aggregate using **kwargs
    result = Model2A.objects.aggregate(
        cnt_a1=Count(Case(When(field1='A1', then=1))),
        cnt_b2=Count(Case(When(Model2B___field2='B2', then=1))),
    )
    self.assertEqual(result, {'cnt_b2': 2, 'cnt_a1': 3})

    # aggregate using **args
    # we have to set the defaul alias or django won't except a complex expression
    # on aggregate/annotate
    def ComplexAgg(expression):
        complexagg = Count(expression)*10
        complexagg.default_alias = 'complexagg'
        return expression
    
    with self.assertRaisesMessage(AssertionError, 'PolymorphicModel: annotate()/aggregate(): ___ model lookup supported for keyword arguments only'):
        Model2A.objects.aggregate(ComplexAgg('Model2B___field2'))
<MSG> Fix incorrect variable name
<DFF> @@ -19,7 +19,7 @@
     def ComplexAgg(expression):
         complexagg = Count(expression)*10
         complexagg.default_alias = 'complexagg'
-        return expression
+        return complexagg
     
     with self.assertRaisesMessage(AssertionError, 'PolymorphicModel: annotate()/aggregate(): ___ model lookup supported for keyword arguments only'):
         Model2A.objects.aggregate(ComplexAgg('Model2B___field2'))","@skipIf(django.VERSION < (1,8,), ""This test needs Django >=1.8"")
def test_polymorphic__complex_aggregate(self):
    """""" test (complex expression on) aggregate (should work for annotate either) """"""
    
    Model2A.objects.create(field1='A1')
    Model2B.objects.create(field1='A1', field2='B2')
    Model2B.objects.create(field1='A1', field2='B2')
    
    # aggregate using **kwargs
    result = Model2A.objects.aggregate(
        cnt_a1=Count(Case(When(field1='A1', then=1))),
        cnt_b2=Count(Case(When(Model2B___field2='B2', then=1))),
    )
    self.assertEqual(result, {'cnt_b2': 2, 'cnt_a1': 3})

    # aggregate using **args
    # we have to set the defaul alias or django won't except a complex expression
    # on aggregate/annotate
    def ComplexAgg(expression):
        complexagg = Count(expression)*10
        complexagg.default_alias = 'complexagg'
        return complexagg
    
    with self.assertRaisesMessage(AssertionError, 'PolymorphicModel: annotate()/aggregate(): ___ model lookup supported for keyword arguments only'):
        Model2A.objects.aggregate(ComplexAgg('Model2B___field2'))",7,"<NME> tests.py
<BEF> @skipIf(django.VERSION < (1,8,), ""This test needs Django >=1.8"")
def test_polymorphic__complex_aggregate(self):
    """""" test (complex expression on) aggregate (should work for annotate either) """"""
    
    Model2A.objects.create(field1='A1')
    Model2B.objects.create(field1='A1', field2='B2')
    Model2B.objects.create(field1='A1', field2='B2')
    
    # aggregate using **kwargs
    result = Model2A.objects.aggregate(
        cnt_a1=Count(Case(When(field1='A1', then=1))),
        cnt_b2=Count(Case(When(Model2B___field2='B2', then=1))),
    )
    self.assertEqual(result, {'cnt_b2': 2, 'cnt_a1': 3})

    # aggregate using **args
    # we have to set the defaul alias or django won't except a complex expression
    # on aggregate/annotate
    def ComplexAgg(expression):
        complexagg = Count(expression)*10
        complexagg.default_alias = 'complexagg'
        return expression
    
    with self.assertRaisesMessage(AssertionError, 'PolymorphicModel: annotate()/aggregate(): ___ model lookup supported for keyword arguments only'):
        Model2A.objects.aggregate(ComplexAgg('Model2B___field2'))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@skipIf(django.VERSION < (1,8,), ""This test needs Django >=1.8"")
def test_polymorphic__complex_aggregate(self):
    """""" test (complex expression on) aggregate (should work for annotate either) """"""
    
    Model2A.objects.create(field1='A1')
    Model2B.objects.create(field1='A1', field2='B2')
    Model2B.objects.create(field1='A1', field2='B2')
    
    # aggregate using **kwargs
    result = Model2A.objects.aggregate(
        cnt_a1=Count(Case(When(field1='A1', then=1))),
        cnt_b2=Count(Case(When(Model2B___field2='B2', then=1))),
    )
    self.assertEqual(result, {'cnt_b2': 2, 'cnt_a1': 3})

    # aggregate using **args
    # we have to set the defaul alias or django won't except a complex expression
    # on aggregate/annotate
    def ComplexAgg(expression):
        complexagg = Count(expression)*10
        complexagg.default_alias = 'complexagg'
        return expression
    
    with self.assertRaisesMessage(AssertionError, 'PolymorphicModel: annotate()/aggregate(): ___ model lookup supported for keyword arguments only'):
        Model2A.objects.aggregate(ComplexAgg('Model2B___field2'))"
"<NME> executor.py
<BEF> def _log_error(self, bundle, url, e):
    if self.logger:
        self.logger.error('Error when handle bundle: %s, url: %s' % (
            str(bundle), str(url)))
        self.logger.exception(e)
    if url == getattr(bundle, 'error_url', None):
        bundle.error_times = getattr(bundle, 'error_times', 0) + 1
    else:
        bundle.error_times = 0
        bundle.error_url = url
        
    self.counter_client.local_inc(self.ip, self.id_, 
                                  'error_urls', 1)
    e.counter_client.global_inc('error_urls', 1)
<MSG> Fix incorrect variable name
<DFF> @@ -11,4 +11,4 @@
         
     self.counter_client.local_inc(self.ip, self.id_, 
                                   'error_urls', 1)
-    e.counter_client.global_inc('error_urls', 1)
+    self.counter_client.global_inc('error_urls', 1)","def _log_error(self, bundle, url, e):
    if self.logger:
        self.logger.error('Error when handle bundle: %s, url: %s' % (
            str(bundle), str(url)))
        self.logger.exception(e)
    if url == getattr(bundle, 'error_url', None):
        bundle.error_times = getattr(bundle, 'error_times', 0) + 1
    else:
        bundle.error_times = 0
        bundle.error_url = url
        
    self.counter_client.local_inc(self.ip, self.id_, 
                                  'error_urls', 1)
    self.counter_client.global_inc('error_urls', 1)",8,"<NME> executor.py
<BEF> def _log_error(self, bundle, url, e):
    if self.logger:
        self.logger.error('Error when handle bundle: %s, url: %s' % (
            str(bundle), str(url)))
        self.logger.exception(e)
    if url == getattr(bundle, 'error_url', None):
        bundle.error_times = getattr(bundle, 'error_times', 0) + 1
    else:
        bundle.error_times = 0
        bundle.error_url = url
        
    self.counter_client.local_inc(self.ip, self.id_, 
                                  'error_urls', 1)
    e.counter_client.global_inc('error_urls', 1)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _log_error(self, bundle, url, e):
    if self.logger:
        self.logger.error('Error when handle bundle: %s, url: %s' % (
            str(bundle), str(url)))
        self.logger.exception(e)
    if url == getattr(bundle, 'error_url', None):
        bundle.error_times = getattr(bundle, 'error_times', 0) + 1
    else:
        bundle.error_times = 0
        bundle.error_url = url
        
    self.counter_client.local_inc(self.ip, self.id_, 
                                  'error_urls', 1)
    e.counter_client.global_inc('error_urls', 1)"
"<NME> pattern_cohesion.py
<BEF> def tokenize(self, string):
    tokens = string.split(' ')
    wrapper = self._fmt_wrapper()
    _tokens, count = '', len(tokens) - 1
    for k, token in enumerate(tokens):
        _tokens += self._fmt(token, k, k)
    return wrapper.format(_tokens)
<MSG> Fix incorrect variable name
<DFF> @@ -3,5 +3,5 @@
     wrapper = self._fmt_wrapper()
     _tokens, count = '', len(tokens) - 1
     for k, token in enumerate(tokens):
-        _tokens += self._fmt(token, k, k)
+        _tokens += self._fmt(token, k, count)
     return wrapper.format(_tokens)","def tokenize(self, string):
    tokens = string.split(' ')
    wrapper = self._fmt_wrapper()
    _tokens, count = '', len(tokens) - 1
    for k, token in enumerate(tokens):
        _tokens += self._fmt(token, k, count)
    return wrapper.format(_tokens)",9,"<NME> pattern_cohesion.py
<BEF> def tokenize(self, string):
    tokens = string.split(' ')
    wrapper = self._fmt_wrapper()
    _tokens, count = '', len(tokens) - 1
    for k, token in enumerate(tokens):
        _tokens += self._fmt(token, k, k)
    return wrapper.format(_tokens)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def tokenize(self, string):
    tokens = string.split(' ')
    wrapper = self._fmt_wrapper()
    _tokens, count = '', len(tokens) - 1
    for k, token in enumerate(tokens):
        _tokens += self._fmt(token, k, k)
    return wrapper.format(_tokens)"
"<NME> set_theory.py
<BEF> def is_successor(self, prev, next):
    if next >= next:
        return False
    return True
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def is_successor(self, prev, next):
-    if next >= next:
+    if prev >= next:
         return False
     return True","def is_successor(self, prev, next):
    if prev >= next:
        return False
    return True",0,"<NME> set_theory.py
<BEF> def is_successor(self, prev, next):
    if next >= next:
        return False
    return True
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def is_successor(self, prev, next):
    if next >= next:
        return False
    return True"
"<NME> app.py
<BEF> @app.route('/user/<user_id>')
def user_shipments(user_id):
    print('Getting shipments for user: {}'.format(user_id))
    response = jsonify({
        'data': {
            'shipments': [
                {'name': 'teddy bear 123', 'arrival_date': '12/25/2015'},
                {'name': 'chocolate cookies', 'arrival_date': '12/23/2015'},
            ]
        }
    })
    return user_id
<MSG> Fix incorrect variable name
<DFF> @@ -9,4 +9,4 @@
             ]
         }
     })
-    return user_id
+    return response","@app.route('/user/<user_id>')
def user_shipments(user_id):
    print('Getting shipments for user: {}'.format(user_id))
    response = jsonify({
        'data': {
            'shipments': [
                {'name': 'teddy bear 123', 'arrival_date': '12/25/2015'},
                {'name': 'chocolate cookies', 'arrival_date': '12/23/2015'},
            ]
        }
    })
    return response",1,"<NME> app.py
<BEF> @app.route('/user/<user_id>')
def user_shipments(user_id):
    print('Getting shipments for user: {}'.format(user_id))
    response = jsonify({
        'data': {
            'shipments': [
                {'name': 'teddy bear 123', 'arrival_date': '12/25/2015'},
                {'name': 'chocolate cookies', 'arrival_date': '12/23/2015'},
            ]
        }
    })
    return user_id
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@app.route('/user/<user_id>')
def user_shipments(user_id):
    print('Getting shipments for user: {}'.format(user_id))
    response = jsonify({
        'data': {
            'shipments': [
                {'name': 'teddy bear 123', 'arrival_date': '12/25/2015'},
                {'name': 'chocolate cookies', 'arrival_date': '12/23/2015'},
            ]
        }
    })
    return user_id"
"<NME> bytecode.py
<BEF> def interpret(self, code):
    def _print(arg):
        print(arg)

    def cls(*args):
        print('\n\n\n\n\n')

    def sleep(arg):
        return time.sleep(int(args))

    control_table = dict(
        _print=_print,
        sleep=sleep,
        cls=cls,
    )
    for token in code:
        if len(token) > 2:
            func, args, signature = token
            print('Interpreter token signature: {}'.format(signature))
            if func == 'print':
                print(args)
            else:
                if func in control_table:
                    yield control_table[args](args)
<MSG> Fix incorrect variable name
<DFF> @@ -21,4 +21,4 @@
                 print(args)
             else:
                 if func in control_table:
-                    yield control_table[args](args)
+                    yield control_table[func](args)","def interpret(self, code):
    def _print(arg):
        print(arg)

    def cls(*args):
        print('\n\n\n\n\n')

    def sleep(arg):
        return time.sleep(int(args))

    control_table = dict(
        _print=_print,
        sleep=sleep,
        cls=cls,
    )
    for token in code:
        if len(token) > 2:
            func, args, signature = token
            print('Interpreter token signature: {}'.format(signature))
            if func == 'print':
                print(args)
            else:
                if func in control_table:
                    yield control_table[func](args)",2,"<NME> bytecode.py
<BEF> def interpret(self, code):
    def _print(arg):
        print(arg)

    def cls(*args):
        print('\n\n\n\n\n')

    def sleep(arg):
        return time.sleep(int(args))

    control_table = dict(
        _print=_print,
        sleep=sleep,
        cls=cls,
    )
    for token in code:
        if len(token) > 2:
            func, args, signature = token
            print('Interpreter token signature: {}'.format(signature))
            if func == 'print':
                print(args)
            else:
                if func in control_table:
                    yield control_table[args](args)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def interpret(self, code):
    def _print(arg):
        print(arg)

    def cls(*args):
        print('\n\n\n\n\n')

    def sleep(arg):
        return time.sleep(int(args))

    control_table = dict(
        _print=_print,
        sleep=sleep,
        cls=cls,
    )
    for token in code:
        if len(token) > 2:
            func, args, signature = token
            print('Interpreter token signature: {}'.format(signature))
            if func == 'print':
                print(args)
            else:
                if func in control_table:
                    yield control_table[args](args)"
"<NME> display.py
<BEF> def __init__(self, content):
    content.content = content
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def __init__(self, content):
-    content.content = content
+    self.content = content","def __init__(self, content):
    self.content = content",3,"<NME> display.py
<BEF> def __init__(self, content):
    content.content = content
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, content):
    content.content = content"
"<NME> __init__.py
<BEF> def is_unauthorized(self, request, *args, **kwargs):
    if request.method != 'POST':
        return super(Root, self).is_unauthorized(request, *self, **kwargs)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def is_unauthorized(self, request, *args, **kwargs):
     if request.method != 'POST':
-        return super(Root, self).is_unauthorized(request, *self, **kwargs)
+        return super(Root, self).is_unauthorized(request, *args, **kwargs)","def is_unauthorized(self, request, *args, **kwargs):
    if request.method != 'POST':
        return super(Root, self).is_unauthorized(request, *args, **kwargs)",4,"<NME> __init__.py
<BEF> def is_unauthorized(self, request, *args, **kwargs):
    if request.method != 'POST':
        return super(Root, self).is_unauthorized(request, *self, **kwargs)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def is_unauthorized(self, request, *args, **kwargs):
    if request.method != 'POST':
        return super(Root, self).is_unauthorized(request, *self, **kwargs)"
"<NME> dependency_inversion.py
<BEF> def message_action(self, message):
    return '[Email Message]: {}'.format(self)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def message_action(self, message):
-    return '[Email Message]: {}'.format(self)
+    return '[Email Message]: {}'.format(message)","def message_action(self, message):
    return '[Email Message]: {}'.format(message)",5,"<NME> dependency_inversion.py
<BEF> def message_action(self, message):
    return '[Email Message]: {}'.format(self)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def message_action(self, message):
    return '[Email Message]: {}'.format(self)"
"<NME> markov_chain.py
<BEF> def _check_valid(self, node, data):
    total = sum([self for prob in data['edges'].values()])
    # Edges must sum to 1 (e.g 0.4, 0.5, 0.1)
    if total != 1:
        raise InvalidProbabilityValue
<MSG> Fix incorrect variable name
<DFF> @@ -1,5 +1,5 @@
 def _check_valid(self, node, data):
-    total = sum([self for prob in data['edges'].values()])
+    total = sum([prob for prob in data['edges'].values()])
     # Edges must sum to 1 (e.g 0.4, 0.5, 0.1)
     if total != 1:
         raise InvalidProbabilityValue","def _check_valid(self, node, data):
    total = sum([prob for prob in data['edges'].values()])
    # Edges must sum to 1 (e.g 0.4, 0.5, 0.1)
    if total != 1:
        raise InvalidProbabilityValue",6,"<NME> markov_chain.py
<BEF> def _check_valid(self, node, data):
    total = sum([self for prob in data['edges'].values()])
    # Edges must sum to 1 (e.g 0.4, 0.5, 0.1)
    if total != 1:
        raise InvalidProbabilityValue
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _check_valid(self, node, data):
    total = sum([self for prob in data['edges'].values()])
    # Edges must sum to 1 (e.g 0.4, 0.5, 0.1)
    if total != 1:
        raise InvalidProbabilityValue"
"<NME> context.py
<BEF> def test_delete(self):
    ctx1 = DataContext(user=self.user, name='Context 1')
    ctx1.save()
    ctx2 = DataContext(user=self.user, name='Context 2')
    ctx2.save()
    ctx3 = DataContext(user=self.user, name='Context 3', session=True)
    ctx3.save()

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 3)

    response = self.client.delete('/api/contexts/{0}/'.format(ctx1.pk))
    self.assertEqual(ctx2.status_code, codes.no_content)

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 2)

    # Cannot delete the session
    response = self.client.delete('/api/contexts/{0}/'.format(ctx3.pk))
    self.assertEqual(response.status_code, codes.bad_request)

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 2)
<MSG> Fix incorrect variable name
<DFF> @@ -12,7 +12,7 @@
     self.assertEqual(len(json.loads(response.content)), 3)
 
     response = self.client.delete('/api/contexts/{0}/'.format(ctx1.pk))
-    self.assertEqual(ctx2.status_code, codes.no_content)
+    self.assertEqual(response.status_code, codes.no_content)
 
     response = self.client.get('/api/contexts/',
                                HTTP_ACCEPT='application/json')","def test_delete(self):
    ctx1 = DataContext(user=self.user, name='Context 1')
    ctx1.save()
    ctx2 = DataContext(user=self.user, name='Context 2')
    ctx2.save()
    ctx3 = DataContext(user=self.user, name='Context 3', session=True)
    ctx3.save()

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 3)

    response = self.client.delete('/api/contexts/{0}/'.format(ctx1.pk))
    self.assertEqual(response.status_code, codes.no_content)

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 2)

    # Cannot delete the session
    response = self.client.delete('/api/contexts/{0}/'.format(ctx3.pk))
    self.assertEqual(response.status_code, codes.bad_request)

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 2)",7,"<NME> context.py
<BEF> def test_delete(self):
    ctx1 = DataContext(user=self.user, name='Context 1')
    ctx1.save()
    ctx2 = DataContext(user=self.user, name='Context 2')
    ctx2.save()
    ctx3 = DataContext(user=self.user, name='Context 3', session=True)
    ctx3.save()

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 3)

    response = self.client.delete('/api/contexts/{0}/'.format(ctx1.pk))
    self.assertEqual(ctx2.status_code, codes.no_content)

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 2)

    # Cannot delete the session
    response = self.client.delete('/api/contexts/{0}/'.format(ctx3.pk))
    self.assertEqual(response.status_code, codes.bad_request)

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 2)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_delete(self):
    ctx1 = DataContext(user=self.user, name='Context 1')
    ctx1.save()
    ctx2 = DataContext(user=self.user, name='Context 2')
    ctx2.save()
    ctx3 = DataContext(user=self.user, name='Context 3', session=True)
    ctx3.save()

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 3)

    response = self.client.delete('/api/contexts/{0}/'.format(ctx1.pk))
    self.assertEqual(ctx2.status_code, codes.no_content)

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 2)

    # Cannot delete the session
    response = self.client.delete('/api/contexts/{0}/'.format(ctx3.pk))
    self.assertEqual(response.status_code, codes.bad_request)

    response = self.client.get('/api/contexts/',
                               HTTP_ACCEPT='application/json')
    self.assertEqual(response.status_code, codes.ok)
    self.assertEqual(len(json.loads(response.content)), 2)"
"<NME> coindb.py
<BEF> def get_coins_for_address(self, address_rec):
    """"""Given an address <address_rec>, return the list of coin's
    straight from the DB. Note this specifically does NOT return
    COIN objects.
    """"""
    color_set = self.color_set
    addr_color_set = address_rec.get_color_set()
    all_coins = filter(
        self.coin_matches_filter,
        self.coin_manager.get_coins_for_address(self.get_address()))
    cdata = self.model.ccc.colordata
    address_is_uncolored = addr_color_set.color_id_set == set([0])
    if address_is_uncolored:
        for coin in all_coins:
            coin.address_rec = address_rec
            coin.colorvalues = [SimpleColorValue(colordef=UNCOLORED_MARKER,
                                                 value=coin.value)]
        return all_coins
    for coin in all_coins:
        coin.address_rec = address_rec
        coin.colorvalues = None
        try:
            coin.colorvalues = cdata.get_colorvalues(
                addr_color_set.color_id_set, coin.txhash, coin.outindex)
        except Exception as e:
            raise
    def relevant(coin):
        cvl = coin.colorvalues
        if coin.colorvalues is None:
            return False  # None indicates failure
        if cvl == []:
            return color_set.has_color_id(0)
        for cv in cvl:
            if color_set.has_color_id(cv.get_color_id()):
                return True
            return False
    return filter(relevant, all_coins)
<MSG> Fix incorrect variable name
<DFF> @@ -7,7 +7,7 @@
     addr_color_set = address_rec.get_color_set()
     all_coins = filter(
         self.coin_matches_filter,
-        self.coin_manager.get_coins_for_address(self.get_address()))
+        self.coin_manager.get_coins_for_address(address_rec.get_address()))
     cdata = self.model.ccc.colordata
     address_is_uncolored = addr_color_set.color_id_set == set([0])
     if address_is_uncolored:","def get_coins_for_address(self, address_rec):
    """"""Given an address <address_rec>, return the list of coin's
    straight from the DB. Note this specifically does NOT return
    COIN objects.
    """"""
    color_set = self.color_set
    addr_color_set = address_rec.get_color_set()
    all_coins = filter(
        self.coin_matches_filter,
        self.coin_manager.get_coins_for_address(address_rec.get_address()))
    cdata = self.model.ccc.colordata
    address_is_uncolored = addr_color_set.color_id_set == set([0])
    if address_is_uncolored:
        for coin in all_coins:
            coin.address_rec = address_rec
            coin.colorvalues = [SimpleColorValue(colordef=UNCOLORED_MARKER,
                                                 value=coin.value)]
        return all_coins
    for coin in all_coins:
        coin.address_rec = address_rec
        coin.colorvalues = None
        try:
            coin.colorvalues = cdata.get_colorvalues(
                addr_color_set.color_id_set, coin.txhash, coin.outindex)
        except Exception as e:
            raise
    def relevant(coin):
        cvl = coin.colorvalues
        if coin.colorvalues is None:
            return False  # None indicates failure
        if cvl == []:
            return color_set.has_color_id(0)
        for cv in cvl:
            if color_set.has_color_id(cv.get_color_id()):
                return True
            return False
    return filter(relevant, all_coins)",8,"<NME> coindb.py
<BEF> def get_coins_for_address(self, address_rec):
    """"""Given an address <address_rec>, return the list of coin's
    straight from the DB. Note this specifically does NOT return
    COIN objects.
    """"""
    color_set = self.color_set
    addr_color_set = address_rec.get_color_set()
    all_coins = filter(
        self.coin_matches_filter,
        self.coin_manager.get_coins_for_address(self.get_address()))
    cdata = self.model.ccc.colordata
    address_is_uncolored = addr_color_set.color_id_set == set([0])
    if address_is_uncolored:
        for coin in all_coins:
            coin.address_rec = address_rec
            coin.colorvalues = [SimpleColorValue(colordef=UNCOLORED_MARKER,
                                                 value=coin.value)]
        return all_coins
    for coin in all_coins:
        coin.address_rec = address_rec
        coin.colorvalues = None
        try:
            coin.colorvalues = cdata.get_colorvalues(
                addr_color_set.color_id_set, coin.txhash, coin.outindex)
        except Exception as e:
            raise
    def relevant(coin):
        cvl = coin.colorvalues
        if coin.colorvalues is None:
            return False  # None indicates failure
        if cvl == []:
            return color_set.has_color_id(0)
        for cv in cvl:
            if color_set.has_color_id(cv.get_color_id()):
                return True
            return False
    return filter(relevant, all_coins)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_coins_for_address(self, address_rec):
    """"""Given an address <address_rec>, return the list of coin's
    straight from the DB. Note this specifically does NOT return
    COIN objects.
    """"""
    color_set = self.color_set
    addr_color_set = address_rec.get_color_set()
    all_coins = filter(
        self.coin_matches_filter,
        self.coin_manager.get_coins_for_address(self.get_address()))
    cdata = self.model.ccc.colordata
    address_is_uncolored = addr_color_set.color_id_set == set([0])
    if address_is_uncolored:
        for coin in all_coins:
            coin.address_rec = address_rec
            coin.colorvalues = [SimpleColorValue(colordef=UNCOLORED_MARKER,
                                                 value=coin.value)]
        return all_coins
    for coin in all_coins:
        coin.address_rec = address_rec
        coin.colorvalues = None
        try:
            coin.colorvalues = cdata.get_colorvalues(
                addr_color_set.color_id_set, coin.txhash, coin.outindex)
        except Exception as e:
            raise
    def relevant(coin):
        cvl = coin.colorvalues
        if coin.colorvalues is None:
            return False  # None indicates failure
        if cvl == []:
            return color_set.has_color_id(0)
        for cv in cvl:
            if color_set.has_color_id(cv.get_color_id()):
                return True
            return False
    return filter(relevant, all_coins)"
"<NME> bcd.py
<BEF> def dec_to_bcd_8421(num):
    """"""Convert a decimal to binary, and decompress into Binary Coded Decimal.
    Adds trailing bits to the left to enforce a 4-bit ""nibble"" on all digits.
    Uses 8421 notation [see wikipedia.org/wiki/Binary-coded_decimal]""""""
    bcd, binary, decimals = '', '', ''
    for digit in str(num):
        binval = encoders.dec_to_bin(int(digit))
        binary += '{}{}'.format(binval, ' ' * (4 - len(binval) + 1))
        if len(binval) < 4:
            binval = bcd.zfill(4)
        bcd += '{} '.format(binval)
        decimals += digit + (' ' * 4)
    _show_bcd(num, decimals, binary, bcd)
    return bcd
<MSG> Fix incorrect variable name
<DFF> @@ -7,7 +7,7 @@
         binval = encoders.dec_to_bin(int(digit))
         binary += '{}{}'.format(binval, ' ' * (4 - len(binval) + 1))
         if len(binval) < 4:
-            binval = bcd.zfill(4)
+            binval = binval.zfill(4)
         bcd += '{} '.format(binval)
         decimals += digit + (' ' * 4)
     _show_bcd(num, decimals, binary, bcd)","def dec_to_bcd_8421(num):
    """"""Convert a decimal to binary, and decompress into Binary Coded Decimal.
    Adds trailing bits to the left to enforce a 4-bit ""nibble"" on all digits.
    Uses 8421 notation [see wikipedia.org/wiki/Binary-coded_decimal]""""""
    bcd, binary, decimals = '', '', ''
    for digit in str(num):
        binval = encoders.dec_to_bin(int(digit))
        binary += '{}{}'.format(binval, ' ' * (4 - len(binval) + 1))
        if len(binval) < 4:
            binval = binval.zfill(4)
        bcd += '{} '.format(binval)
        decimals += digit + (' ' * 4)
    _show_bcd(num, decimals, binary, bcd)
    return bcd",9,"<NME> bcd.py
<BEF> def dec_to_bcd_8421(num):
    """"""Convert a decimal to binary, and decompress into Binary Coded Decimal.
    Adds trailing bits to the left to enforce a 4-bit ""nibble"" on all digits.
    Uses 8421 notation [see wikipedia.org/wiki/Binary-coded_decimal]""""""
    bcd, binary, decimals = '', '', ''
    for digit in str(num):
        binval = encoders.dec_to_bin(int(digit))
        binary += '{}{}'.format(binval, ' ' * (4 - len(binval) + 1))
        if len(binval) < 4:
            binval = bcd.zfill(4)
        bcd += '{} '.format(binval)
        decimals += digit + (' ' * 4)
    _show_bcd(num, decimals, binary, bcd)
    return bcd
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def dec_to_bcd_8421(num):
    """"""Convert a decimal to binary, and decompress into Binary Coded Decimal.
    Adds trailing bits to the left to enforce a 4-bit ""nibble"" on all digits.
    Uses 8421 notation [see wikipedia.org/wiki/Binary-coded_decimal]""""""
    bcd, binary, decimals = '', '', ''
    for digit in str(num):
        binval = encoders.dec_to_bin(int(digit))
        binary += '{}{}'.format(binval, ' ' * (4 - len(binval) + 1))
        if len(binval) < 4:
            binval = bcd.zfill(4)
        bcd += '{} '.format(binval)
        decimals += digit + (' ' * 4)
    _show_bcd(num, decimals, binary, bcd)
    return bcd"
"<NME> address.py
<BEF> def get_data(self):
    """"""Get this object as a JSON/Storage compatible dict.
    Useful for storage and persistence.
    """"""
    raw = self.prefix + to_bytes_32(raw.rawPrivKey)
    return {""color_set"": self.color_set.get_data(),
            ""address_data"": b2a_hashed_base58(raw)}
<MSG> Fix incorrect variable name
<DFF> @@ -2,6 +2,6 @@
     """"""Get this object as a JSON/Storage compatible dict.
     Useful for storage and persistence.
     """"""
-    raw = self.prefix + to_bytes_32(raw.rawPrivKey)
+    raw = self.prefix + to_bytes_32(self.rawPrivKey)
     return {""color_set"": self.color_set.get_data(),
             ""address_data"": b2a_hashed_base58(raw)}","def get_data(self):
    """"""Get this object as a JSON/Storage compatible dict.
    Useful for storage and persistence.
    """"""
    raw = self.prefix + to_bytes_32(self.rawPrivKey)
    return {""color_set"": self.color_set.get_data(),
            ""address_data"": b2a_hashed_base58(raw)}",0,"<NME> address.py
<BEF> def get_data(self):
    """"""Get this object as a JSON/Storage compatible dict.
    Useful for storage and persistence.
    """"""
    raw = self.prefix + to_bytes_32(raw.rawPrivKey)
    return {""color_set"": self.color_set.get_data(),
            ""address_data"": b2a_hashed_base58(raw)}
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_data(self):
    """"""Get this object as a JSON/Storage compatible dict.
    Useful for storage and persistence.
    """"""
    raw = self.prefix + to_bytes_32(raw.rawPrivKey)
    return {""color_set"": self.color_set.get_data(),
            ""address_data"": b2a_hashed_base58(raw)}"
"<NME> store.py
<BEF> def add(self, color_id, txhash, outindex, value, label):
    self.execute(
        label.queries['add'], (color_id, txhash, outindex, value, label))
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def add(self, color_id, txhash, outindex, value, label):
     self.execute(
-        label.queries['add'], (color_id, txhash, outindex, value, label))
+        self.queries['add'], (color_id, txhash, outindex, value, label))","def add(self, color_id, txhash, outindex, value, label):
    self.execute(
        self.queries['add'], (color_id, txhash, outindex, value, label))",1,"<NME> store.py
<BEF> def add(self, color_id, txhash, outindex, value, label):
    self.execute(
        label.queries['add'], (color_id, txhash, outindex, value, label))
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def add(self, color_id, txhash, outindex, value, label):
    self.execute(
        label.queries['add'], (color_id, txhash, outindex, value, label))"
"<NME> sendcoinspage.py
<BEF> def clearBackground(event, wname=wname):
    widget = getattr(self, wname)
    widget.setStyleSheet('')
    wname.__class__.focusInEvent(widget, event)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def clearBackground(event, wname=wname):
     widget = getattr(self, wname)
     widget.setStyleSheet('')
-    wname.__class__.focusInEvent(widget, event)
+    widget.__class__.focusInEvent(widget, event)","def clearBackground(event, wname=wname):
    widget = getattr(self, wname)
    widget.setStyleSheet('')
    widget.__class__.focusInEvent(widget, event)",2,"<NME> sendcoinspage.py
<BEF> def clearBackground(event, wname=wname):
    widget = getattr(self, wname)
    widget.setStyleSheet('')
    wname.__class__.focusInEvent(widget, event)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def clearBackground(event, wname=wname):
    widget = getattr(self, wname)
    widget.setStyleSheet('')
    wname.__class__.focusInEvent(widget, event)"
"<NME> protocol_objects.py
<BEF> def __init__(self, ewctrl, orig_offer, my_offer):
    super(MyEProposal, self).__init__(make_random_id(),
                                      ewctrl, self)
    self.my_offer = my_offer
    if not orig_offer.matches(my_offer):
        raise Exception(""Offers are incongruent!"")
    self.etx_spec = ewctrl.make_etx_spec(self.offer.B, self.offer.A)
    self.etx_data = None
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def __init__(self, ewctrl, orig_offer, my_offer):
     super(MyEProposal, self).__init__(make_random_id(),
-                                      ewctrl, self)
+                                      ewctrl, orig_offer)
     self.my_offer = my_offer
     if not orig_offer.matches(my_offer):
         raise Exception(""Offers are incongruent!"")","def __init__(self, ewctrl, orig_offer, my_offer):
    super(MyEProposal, self).__init__(make_random_id(),
                                      ewctrl, orig_offer)
    self.my_offer = my_offer
    if not orig_offer.matches(my_offer):
        raise Exception(""Offers are incongruent!"")
    self.etx_spec = ewctrl.make_etx_spec(self.offer.B, self.offer.A)
    self.etx_data = None",3,"<NME> protocol_objects.py
<BEF> def __init__(self, ewctrl, orig_offer, my_offer):
    super(MyEProposal, self).__init__(make_random_id(),
                                      ewctrl, self)
    self.my_offer = my_offer
    if not orig_offer.matches(my_offer):
        raise Exception(""Offers are incongruent!"")
    self.etx_spec = ewctrl.make_etx_spec(self.offer.B, self.offer.A)
    self.etx_data = None
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, ewctrl, orig_offer, my_offer):
    super(MyEProposal, self).__init__(make_random_id(),
                                      ewctrl, self)
    self.my_offer = my_offer
    if not orig_offer.matches(my_offer):
        raise Exception(""Offers are incongruent!"")
    self.etx_spec = ewctrl.make_etx_spec(self.offer.B, self.offer.A)
    self.etx_data = None"
"<NME> colorset.py
<BEF> def intersects(self, other):
    """"""Given another color set <other>, returns whether
    they share a color in common.
    """"""
    return len(other.color_id_set & other.color_id_set) > 0
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     """"""Given another color set <other>, returns whether
     they share a color in common.
     """"""
-    return len(other.color_id_set & other.color_id_set) > 0
+    return len(self.color_id_set & other.color_id_set) > 0","def intersects(self, other):
    """"""Given another color set <other>, returns whether
    they share a color in common.
    """"""
    return len(self.color_id_set & other.color_id_set) > 0",4,"<NME> colorset.py
<BEF> def intersects(self, other):
    """"""Given another color set <other>, returns whether
    they share a color in common.
    """"""
    return len(other.color_id_set & other.color_id_set) > 0
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def intersects(self, other):
    """"""Given another color set <other>, returns whether
    they share a color in common.
    """"""
    return len(other.color_id_set & other.color_id_set) > 0"
"<NME> test_tso.py
<BEF> def generateInt(self, minimum=0, maximum=100):
    """""" Generates random integers """"""

    return random.randint(maximum,maximum)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def generateInt(self, minimum=0, maximum=100):
     """""" Generates random integers """"""
 
-    return random.randint(maximum,maximum)
+    return random.randint(minimum,maximum)","def generateInt(self, minimum=0, maximum=100):
    """""" Generates random integers """"""

    return random.randint(minimum,maximum)",5,"<NME> test_tso.py
<BEF> def generateInt(self, minimum=0, maximum=100):
    """""" Generates random integers """"""

    return random.randint(maximum,maximum)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def generateInt(self, minimum=0, maximum=100):
    """""" Generates random integers """"""

    return random.randint(maximum,maximum)"
"<NME> _cptools.py
<BEF> def __call__(self, *args, **kwargs):
    """"""Compile-time decorator (turn on the tool in config).

    For example::

        @tools.proxy()
        def whats_my_base(self):
            return cherrypy.request.base
        whats_my_base.exposed = True
    """"""
    if args:
        raise TypeError(""The %r Tool does not accept positional ""
                        ""arguments; you must use keyword arguments.""
                        % self._name)
    def tool_decorator(f):
        if not hasattr(f, ""_cp_config""):
            f._cp_config = {}
        subspace = self.namespace + ""."" + self._name + "".""
        f._cp_config[subspace + ""on""] = True
        for k, v in kwargs.items():
            f._cp_config[subspace + k] = v
        return f
    return kwargs
<MSG> Fix incorrect variable name
<DFF> @@ -20,4 +20,4 @@
         for k, v in kwargs.items():
             f._cp_config[subspace + k] = v
         return f
-    return kwargs
+    return tool_decorator","def __call__(self, *args, **kwargs):
    """"""Compile-time decorator (turn on the tool in config).

    For example::

        @tools.proxy()
        def whats_my_base(self):
            return cherrypy.request.base
        whats_my_base.exposed = True
    """"""
    if args:
        raise TypeError(""The %r Tool does not accept positional ""
                        ""arguments; you must use keyword arguments.""
                        % self._name)
    def tool_decorator(f):
        if not hasattr(f, ""_cp_config""):
            f._cp_config = {}
        subspace = self.namespace + ""."" + self._name + "".""
        f._cp_config[subspace + ""on""] = True
        for k, v in kwargs.items():
            f._cp_config[subspace + k] = v
        return f
    return tool_decorator",6,"<NME> _cptools.py
<BEF> def __call__(self, *args, **kwargs):
    """"""Compile-time decorator (turn on the tool in config).

    For example::

        @tools.proxy()
        def whats_my_base(self):
            return cherrypy.request.base
        whats_my_base.exposed = True
    """"""
    if args:
        raise TypeError(""The %r Tool does not accept positional ""
                        ""arguments; you must use keyword arguments.""
                        % self._name)
    def tool_decorator(f):
        if not hasattr(f, ""_cp_config""):
            f._cp_config = {}
        subspace = self.namespace + ""."" + self._name + "".""
        f._cp_config[subspace + ""on""] = True
        for k, v in kwargs.items():
            f._cp_config[subspace + k] = v
        return f
    return kwargs
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __call__(self, *args, **kwargs):
    """"""Compile-time decorator (turn on the tool in config).

    For example::

        @tools.proxy()
        def whats_my_base(self):
            return cherrypy.request.base
        whats_my_base.exposed = True
    """"""
    if args:
        raise TypeError(""The %r Tool does not accept positional ""
                        ""arguments; you must use keyword arguments.""
                        % self._name)
    def tool_decorator(f):
        if not hasattr(f, ""_cp_config""):
            f._cp_config = {}
        subspace = self.namespace + ""."" + self._name + "".""
        f._cp_config[subspace + ""on""] = True
        for k, v in kwargs.items():
            f._cp_config[subspace + k] = v
        return f
    return kwargs"
"<NME> search.py
<BEF> def dfs(term, recursive=False, visited={}, **kwargs):
    if term in visited: # Break on cyclic relations.
        return []
    visited[term], a = True, []
    if dict.__contains__(self, term):
        a = self[term][0].keys()
    for classifier in self.classifiers:
        a.extend(classifier.parents(term, **kwargs) or [])
    if recursive:
        for w in visited: a += dfs(w, recursive, visited, **kwargs)
    return a
<MSG> Fix incorrect variable name
<DFF> @@ -7,5 +7,5 @@
     for classifier in self.classifiers:
         a.extend(classifier.parents(term, **kwargs) or [])
     if recursive:
-        for w in visited: a += dfs(w, recursive, visited, **kwargs)
+        for w in a: a += dfs(w, recursive, visited, **kwargs)
     return a","def dfs(term, recursive=False, visited={}, **kwargs):
    if term in visited: # Break on cyclic relations.
        return []
    visited[term], a = True, []
    if dict.__contains__(self, term):
        a = self[term][0].keys()
    for classifier in self.classifiers:
        a.extend(classifier.parents(term, **kwargs) or [])
    if recursive:
        for w in a: a += dfs(w, recursive, visited, **kwargs)
    return a",7,"<NME> search.py
<BEF> def dfs(term, recursive=False, visited={}, **kwargs):
    if term in visited: # Break on cyclic relations.
        return []
    visited[term], a = True, []
    if dict.__contains__(self, term):
        a = self[term][0].keys()
    for classifier in self.classifiers:
        a.extend(classifier.parents(term, **kwargs) or [])
    if recursive:
        for w in visited: a += dfs(w, recursive, visited, **kwargs)
    return a
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def dfs(term, recursive=False, visited={}, **kwargs):
    if term in visited: # Break on cyclic relations.
        return []
    visited[term], a = True, []
    if dict.__contains__(self, term):
        a = self[term][0].keys()
    for classifier in self.classifiers:
        a.extend(classifier.parents(term, **kwargs) or [])
    if recursive:
        for w in visited: a += dfs(w, recursive, visited, **kwargs)
    return a"
"<NME> api.py
<BEF> def f(self, other):
    other = as_value_expr(other)

    if not isinstance(other, BooleanValue):
        raise TypeError(other)

    op = klass(self, op)
    return op.to_expr()
<MSG> Fix incorrect variable name
<DFF> @@ -4,5 +4,5 @@
     if not isinstance(other, BooleanValue):
         raise TypeError(other)
 
-    op = klass(self, op)
+    op = klass(self, other)
     return op.to_expr()","def f(self, other):
    other = as_value_expr(other)

    if not isinstance(other, BooleanValue):
        raise TypeError(other)

    op = klass(self, other)
    return op.to_expr()",8,"<NME> api.py
<BEF> def f(self, other):
    other = as_value_expr(other)

    if not isinstance(other, BooleanValue):
        raise TypeError(other)

    op = klass(self, op)
    return op.to_expr()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def f(self, other):
    other = as_value_expr(other)

    if not isinstance(other, BooleanValue):
        raise TypeError(other)

    op = klass(self, op)
    return op.to_expr()"
"<NME> config.py
<BEF> def _get_option(pat, silent=False):
    key = _get_single_key(pat, silent)

    # walk the nested dict
    root, k = _get_root(root)
    return root[k]
<MSG> Fix incorrect variable name
<DFF> @@ -2,5 +2,5 @@
     key = _get_single_key(pat, silent)
 
     # walk the nested dict
-    root, k = _get_root(root)
+    root, k = _get_root(key)
     return root[k]","def _get_option(pat, silent=False):
    key = _get_single_key(pat, silent)

    # walk the nested dict
    root, k = _get_root(key)
    return root[k]",9,"<NME> config.py
<BEF> def _get_option(pat, silent=False):
    key = _get_single_key(pat, silent)

    # walk the nested dict
    root, k = _get_root(root)
    return root[k]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _get_option(pat, silent=False):
    key = _get_single_key(pat, silent)

    # walk the nested dict
    root, k = _get_root(root)
    return root[k]"
"<NME> __init__.py
<BEF> def update(self, top=0.5, mutation=0.5):
    """""" Updates the population by selecting the top fittest candidates,
        and recombining them into a new generation.
    """"""
    # 1) Selection.
    # Choose the top fittest candidates.
    # Including weaker candidates can be beneficial (diversity).
    p = sorted(self.population, key=self.fitness, reverse=True)
    p = p[:max(2, int(round(len(p) * top)))]
    # 2) Reproduction.
    # Choose random parents for crossover.
    # Mutation avoids local optima by maintaining genetic diversity.
    g = []
    n = len(p)
    for candidate in self.population:
        i = randint(0, n-1)
        j = choice([x for x in xrange(n) if x != i]) if n > 1 else 0
        g.append(self.combine(p[i], p[j]))
        if random() <= mutation:
            g[-1] = self.mutate(g[-1])
    self.population = candidate
    self.generation += 1
<MSG> Fix incorrect variable name
<DFF> @@ -18,5 +18,5 @@
         g.append(self.combine(p[i], p[j]))
         if random() <= mutation:
             g[-1] = self.mutate(g[-1])
-    self.population = candidate
+    self.population = g
     self.generation += 1","def update(self, top=0.5, mutation=0.5):
    """""" Updates the population by selecting the top fittest candidates,
        and recombining them into a new generation.
    """"""
    # 1) Selection.
    # Choose the top fittest candidates.
    # Including weaker candidates can be beneficial (diversity).
    p = sorted(self.population, key=self.fitness, reverse=True)
    p = p[:max(2, int(round(len(p) * top)))]
    # 2) Reproduction.
    # Choose random parents for crossover.
    # Mutation avoids local optima by maintaining genetic diversity.
    g = []
    n = len(p)
    for candidate in self.population:
        i = randint(0, n-1)
        j = choice([x for x in xrange(n) if x != i]) if n > 1 else 0
        g.append(self.combine(p[i], p[j]))
        if random() <= mutation:
            g[-1] = self.mutate(g[-1])
    self.population = g
    self.generation += 1",0,"<NME> __init__.py
<BEF> def update(self, top=0.5, mutation=0.5):
    """""" Updates the population by selecting the top fittest candidates,
        and recombining them into a new generation.
    """"""
    # 1) Selection.
    # Choose the top fittest candidates.
    # Including weaker candidates can be beneficial (diversity).
    p = sorted(self.population, key=self.fitness, reverse=True)
    p = p[:max(2, int(round(len(p) * top)))]
    # 2) Reproduction.
    # Choose random parents for crossover.
    # Mutation avoids local optima by maintaining genetic diversity.
    g = []
    n = len(p)
    for candidate in self.population:
        i = randint(0, n-1)
        j = choice([x for x in xrange(n) if x != i]) if n > 1 else 0
        g.append(self.combine(p[i], p[j]))
        if random() <= mutation:
            g[-1] = self.mutate(g[-1])
    self.population = candidate
    self.generation += 1
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def update(self, top=0.5, mutation=0.5):
    """""" Updates the population by selecting the top fittest candidates,
        and recombining them into a new generation.
    """"""
    # 1) Selection.
    # Choose the top fittest candidates.
    # Including weaker candidates can be beneficial (diversity).
    p = sorted(self.population, key=self.fitness, reverse=True)
    p = p[:max(2, int(round(len(p) * top)))]
    # 2) Reproduction.
    # Choose random parents for crossover.
    # Mutation avoids local optima by maintaining genetic diversity.
    g = []
    n = len(p)
    for candidate in self.population:
        i = randint(0, n-1)
        j = choice([x for x in xrange(n) if x != i]) if n > 1 else 0
        g.append(self.combine(p[i], p[j]))
        if random() <= mutation:
            g[-1] = self.mutate(g[-1])
    self.population = candidate
    self.generation += 1"
"<NME> operations.py
<BEF> def __init__(self, cases, results, default):
    assert len(cases) == len(self)
    ValueOp.__init__(self, cases, results, default)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def __init__(self, cases, results, default):
-    assert len(cases) == len(self)
+    assert len(cases) == len(results)
     ValueOp.__init__(self, cases, results, default)","def __init__(self, cases, results, default):
    assert len(cases) == len(results)
    ValueOp.__init__(self, cases, results, default)",1,"<NME> operations.py
<BEF> def __init__(self, cases, results, default):
    assert len(cases) == len(self)
    ValueOp.__init__(self, cases, results, default)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, cases, results, default):
    assert len(cases) == len(self)
    ValueOp.__init__(self, cases, results, default)"
"<NME> types.py
<BEF> def find_base_table(expr):
    if isinstance(expr, TableExpr):
        return expr

    for arg in expr.op().flat_args():
        if isinstance(arg, Expr):
            r = find_base_table(r)
            if isinstance(r, TableExpr):
                return r
<MSG> Fix incorrect variable name
<DFF> @@ -4,6 +4,6 @@
 
     for arg in expr.op().flat_args():
         if isinstance(arg, Expr):
-            r = find_base_table(r)
+            r = find_base_table(arg)
             if isinstance(r, TableExpr):
                 return r","def find_base_table(expr):
    if isinstance(expr, TableExpr):
        return expr

    for arg in expr.op().flat_args():
        if isinstance(arg, Expr):
            r = find_base_table(arg)
            if isinstance(r, TableExpr):
                return r",2,"<NME> types.py
<BEF> def find_base_table(expr):
    if isinstance(expr, TableExpr):
        return expr

    for arg in expr.op().flat_args():
        if isinstance(arg, Expr):
            r = find_base_table(r)
            if isinstance(r, TableExpr):
                return r
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def find_base_table(expr):
    if isinstance(expr, TableExpr):
        return expr

    for arg in expr.op().flat_args():
        if isinstance(arg, Expr):
            r = find_base_table(r)
            if isinstance(r, TableExpr):
                return r"
"<NME> config.py
<BEF> def _get_root(key):
    path = key.split('.')
    cursor = _global_config
    for p in path[:-1]:
        cursor = cursor[p]
    return cursor, p[-1]
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
     cursor = _global_config
     for p in path[:-1]:
         cursor = cursor[p]
-    return cursor, p[-1]
+    return cursor, path[-1]","def _get_root(key):
    path = key.split('.')
    cursor = _global_config
    for p in path[:-1]:
        cursor = cursor[p]
    return cursor, path[-1]",3,"<NME> config.py
<BEF> def _get_root(key):
    path = key.split('.')
    cursor = _global_config
    for p in path[:-1]:
        cursor = cursor[p]
    return cursor, p[-1]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _get_root(key):
    path = key.split('.')
    cursor = _global_config
    for p in path[:-1]:
        cursor = cursor[p]
    return cursor, p[-1]"
"<NME> test_sql_builtins.py
<BEF> def test_zeroifnull(self):
    dresult = self.alltypes.double_col.zeroifnull()
    iresult = dresult.alltypes.int_col.zeroifnull()

    assert type(dresult.op()) == ops.ZeroIfNull
    assert type(dresult) == ir.DoubleArray

    # Impala upconverts all ints to bigint. Hmm.
    assert type(iresult) == type(iresult)
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def test_zeroifnull(self):
     dresult = self.alltypes.double_col.zeroifnull()
-    iresult = dresult.alltypes.int_col.zeroifnull()
+    iresult = self.alltypes.int_col.zeroifnull()
 
     assert type(dresult.op()) == ops.ZeroIfNull
     assert type(dresult) == ir.DoubleArray","def test_zeroifnull(self):
    dresult = self.alltypes.double_col.zeroifnull()
    iresult = self.alltypes.int_col.zeroifnull()

    assert type(dresult.op()) == ops.ZeroIfNull
    assert type(dresult) == ir.DoubleArray

    # Impala upconverts all ints to bigint. Hmm.
    assert type(iresult) == type(iresult)",4,"<NME> test_sql_builtins.py
<BEF> def test_zeroifnull(self):
    dresult = self.alltypes.double_col.zeroifnull()
    iresult = dresult.alltypes.int_col.zeroifnull()

    assert type(dresult.op()) == ops.ZeroIfNull
    assert type(dresult) == ir.DoubleArray

    # Impala upconverts all ints to bigint. Hmm.
    assert type(iresult) == type(iresult)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_zeroifnull(self):
    dresult = self.alltypes.double_col.zeroifnull()
    iresult = dresult.alltypes.int_col.zeroifnull()

    assert type(dresult.op()) == ops.ZeroIfNull
    assert type(dresult) == ir.DoubleArray

    # Impala upconverts all ints to bigint. Hmm.
    assert type(iresult) == type(iresult)"
"<NME> inflect_quantify.py
<BEF> def reflect(object, quantify=True, replace=readable_types):
    """""" Returns the type of each object in the given object.
        - For modules, this means classes and functions etc.
        - For list and tuples, means the type of each item in it.
        - For other objects, means the type of the object itself.
    """"""
    _type = lambda object: type(object).__name__
    types = []
    # Classes and modules with a __dict__ attribute listing methods, functions etc.  
    if hasattr(object, ""__dict__""):
        # Function and method objects.
        if _type(object) in (""function"", ""instancemethod""):
            types.append(_type(object))
        # Classes and modules.
        else:
            for v in object.__dict__.values():
                try: types.append(str(v.__classname__))
                except:
                    # Not a class after all (some stuff like ufunc in Numeric).
                    types.append(_type(v))
    # Lists and tuples can consist of several types of objects.
    elif isinstance(object, (list, tuple, set)):
        types += [_type(x) for x in object]
    # Dictionaries have keys pointing to objects.
    elif isinstance(object, dict):
        types += [_type(k) for k in object]
        types += [_type(v) for v in object.values()]
    else:
        quantify.append(_type(object))
    # Clean up type strings.
    m = {}
    for i in range(len(types)):
        k = types[i]
        # Execute the regular expressions once only,
        # next time we'll have the conversion cached.
        if k not in m:
            for a,b in replace:
                types[i] = re.sub(a, b, types[i])      
            m[k] = types[i]      
        types[i] = m[k]
    if not quantify:
        if not isinstance(object, (list, tuple, set, dict)) and not hasattr(object, ""__dict__""):
            return types[0]
        return types
    return count(types, plural={""built-in function"" : ""built-in functions""})
<MSG> Fix incorrect variable name
<DFF> @@ -26,7 +26,7 @@
         types += [_type(k) for k in object]
         types += [_type(v) for v in object.values()]
     else:
-        quantify.append(_type(object))
+        types.append(_type(object))
     # Clean up type strings.
     m = {}
     for i in range(len(types)):","def reflect(object, quantify=True, replace=readable_types):
    """""" Returns the type of each object in the given object.
        - For modules, this means classes and functions etc.
        - For list and tuples, means the type of each item in it.
        - For other objects, means the type of the object itself.
    """"""
    _type = lambda object: type(object).__name__
    types = []
    # Classes and modules with a __dict__ attribute listing methods, functions etc.  
    if hasattr(object, ""__dict__""):
        # Function and method objects.
        if _type(object) in (""function"", ""instancemethod""):
            types.append(_type(object))
        # Classes and modules.
        else:
            for v in object.__dict__.values():
                try: types.append(str(v.__classname__))
                except:
                    # Not a class after all (some stuff like ufunc in Numeric).
                    types.append(_type(v))
    # Lists and tuples can consist of several types of objects.
    elif isinstance(object, (list, tuple, set)):
        types += [_type(x) for x in object]
    # Dictionaries have keys pointing to objects.
    elif isinstance(object, dict):
        types += [_type(k) for k in object]
        types += [_type(v) for v in object.values()]
    else:
        types.append(_type(object))
    # Clean up type strings.
    m = {}
    for i in range(len(types)):
        k = types[i]
        # Execute the regular expressions once only,
        # next time we'll have the conversion cached.
        if k not in m:
            for a,b in replace:
                types[i] = re.sub(a, b, types[i])      
            m[k] = types[i]      
        types[i] = m[k]
    if not quantify:
        if not isinstance(object, (list, tuple, set, dict)) and not hasattr(object, ""__dict__""):
            return types[0]
        return types
    return count(types, plural={""built-in function"" : ""built-in functions""})",5,"<NME> inflect_quantify.py
<BEF> def reflect(object, quantify=True, replace=readable_types):
    """""" Returns the type of each object in the given object.
        - For modules, this means classes and functions etc.
        - For list and tuples, means the type of each item in it.
        - For other objects, means the type of the object itself.
    """"""
    _type = lambda object: type(object).__name__
    types = []
    # Classes and modules with a __dict__ attribute listing methods, functions etc.  
    if hasattr(object, ""__dict__""):
        # Function and method objects.
        if _type(object) in (""function"", ""instancemethod""):
            types.append(_type(object))
        # Classes and modules.
        else:
            for v in object.__dict__.values():
                try: types.append(str(v.__classname__))
                except:
                    # Not a class after all (some stuff like ufunc in Numeric).
                    types.append(_type(v))
    # Lists and tuples can consist of several types of objects.
    elif isinstance(object, (list, tuple, set)):
        types += [_type(x) for x in object]
    # Dictionaries have keys pointing to objects.
    elif isinstance(object, dict):
        types += [_type(k) for k in object]
        types += [_type(v) for v in object.values()]
    else:
        quantify.append(_type(object))
    # Clean up type strings.
    m = {}
    for i in range(len(types)):
        k = types[i]
        # Execute the regular expressions once only,
        # next time we'll have the conversion cached.
        if k not in m:
            for a,b in replace:
                types[i] = re.sub(a, b, types[i])      
            m[k] = types[i]      
        types[i] = m[k]
    if not quantify:
        if not isinstance(object, (list, tuple, set, dict)) and not hasattr(object, ""__dict__""):
            return types[0]
        return types
    return count(types, plural={""built-in function"" : ""built-in functions""})
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def reflect(object, quantify=True, replace=readable_types):
    """""" Returns the type of each object in the given object.
        - For modules, this means classes and functions etc.
        - For list and tuples, means the type of each item in it.
        - For other objects, means the type of the object itself.
    """"""
    _type = lambda object: type(object).__name__
    types = []
    # Classes and modules with a __dict__ attribute listing methods, functions etc.  
    if hasattr(object, ""__dict__""):
        # Function and method objects.
        if _type(object) in (""function"", ""instancemethod""):
            types.append(_type(object))
        # Classes and modules.
        else:
            for v in object.__dict__.values():
                try: types.append(str(v.__classname__))
                except:
                    # Not a class after all (some stuff like ufunc in Numeric).
                    types.append(_type(v))
    # Lists and tuples can consist of several types of objects.
    elif isinstance(object, (list, tuple, set)):
        types += [_type(x) for x in object]
    # Dictionaries have keys pointing to objects.
    elif isinstance(object, dict):
        types += [_type(k) for k in object]
        types += [_type(v) for v in object.values()]
    else:
        quantify.append(_type(object))
    # Clean up type strings.
    m = {}
    for i in range(len(types)):
        k = types[i]
        # Execute the regular expressions once only,
        # next time we'll have the conversion cached.
        if k not in m:
            for a,b in replace:
                types[i] = re.sub(a, b, types[i])      
            m[k] = types[i]      
        types[i] = m[k]
    if not quantify:
        if not isinstance(object, (list, tuple, set, dict)) and not hasattr(object, ""__dict__""):
            return types[0]
        return types
    return count(types, plural={""built-in function"" : ""built-in functions""})"
"<NME> __init__.py
<BEF> def find_lemmata(self, tokens, **kwargs):
    return find_lemmata(kwargs)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def find_lemmata(self, tokens, **kwargs):
-    return find_lemmata(kwargs)
+    return find_lemmata(tokens)","def find_lemmata(self, tokens, **kwargs):
    return find_lemmata(tokens)",6,"<NME> __init__.py
<BEF> def find_lemmata(self, tokens, **kwargs):
    return find_lemmata(kwargs)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def find_lemmata(self, tokens, **kwargs):
    return find_lemmata(kwargs)"
"<NME> test_pandas_interop.py
<BEF> def test_dtype_datetime64(self):
    df = pd.DataFrame({
        'col': [pd.Timestamp('2010-11-01 00:01:00'),
                pd.Timestamp('2010-11-01 00:02:00.1000'),
                pd.Timestamp('2010-11-01 00:03:00.300000')]})
    inferred = pandas_to_ibis_schema(inferred)
    expected = ibis.schema([('col', 'timestamp')])
    assert inferred == expected
<MSG> Fix incorrect variable name
<DFF> @@ -3,6 +3,6 @@
         'col': [pd.Timestamp('2010-11-01 00:01:00'),
                 pd.Timestamp('2010-11-01 00:02:00.1000'),
                 pd.Timestamp('2010-11-01 00:03:00.300000')]})
-    inferred = pandas_to_ibis_schema(inferred)
+    inferred = pandas_to_ibis_schema(df)
     expected = ibis.schema([('col', 'timestamp')])
     assert inferred == expected","def test_dtype_datetime64(self):
    df = pd.DataFrame({
        'col': [pd.Timestamp('2010-11-01 00:01:00'),
                pd.Timestamp('2010-11-01 00:02:00.1000'),
                pd.Timestamp('2010-11-01 00:03:00.300000')]})
    inferred = pandas_to_ibis_schema(df)
    expected = ibis.schema([('col', 'timestamp')])
    assert inferred == expected",7,"<NME> test_pandas_interop.py
<BEF> def test_dtype_datetime64(self):
    df = pd.DataFrame({
        'col': [pd.Timestamp('2010-11-01 00:01:00'),
                pd.Timestamp('2010-11-01 00:02:00.1000'),
                pd.Timestamp('2010-11-01 00:03:00.300000')]})
    inferred = pandas_to_ibis_schema(inferred)
    expected = ibis.schema([('col', 'timestamp')])
    assert inferred == expected
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_dtype_datetime64(self):
    df = pd.DataFrame({
        'col': [pd.Timestamp('2010-11-01 00:01:00'),
                pd.Timestamp('2010-11-01 00:02:00.1000'),
                pd.Timestamp('2010-11-01 00:03:00.300000')]})
    inferred = pandas_to_ibis_schema(inferred)
    expected = ibis.schema([('col', 'timestamp')])
    assert inferred == expected"
"<NME> compiler.py
<BEF> def _timestamp_delta(translator, expr):
    op = expr.op()
    arg, offset = op.args
    formatted_arg = translator.translate(arg)
    return _timestamp_format_offset(arg, formatted_arg)
<MSG> Fix incorrect variable name
<DFF> @@ -2,4 +2,4 @@
     op = expr.op()
     arg, offset = op.args
     formatted_arg = translator.translate(arg)
-    return _timestamp_format_offset(arg, formatted_arg)
+    return _timestamp_format_offset(offset, formatted_arg)","def _timestamp_delta(translator, expr):
    op = expr.op()
    arg, offset = op.args
    formatted_arg = translator.translate(arg)
    return _timestamp_format_offset(offset, formatted_arg)",8,"<NME> compiler.py
<BEF> def _timestamp_delta(translator, expr):
    op = expr.op()
    arg, offset = op.args
    formatted_arg = translator.translate(arg)
    return _timestamp_format_offset(arg, formatted_arg)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _timestamp_delta(translator, expr):
    op = expr.op()
    arg, offset = op.args
    formatted_arg = translator.translate(arg)
    return _timestamp_format_offset(arg, formatted_arg)"
"<NME> util.py
<BEF> def import_model(path):
    """"""
    Passed a string ""app.Model"", will return Model registered inside app.
    """"""
    split = path.split('.', 1)
    return get_model(path[0], split[1])
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
     Passed a string ""app.Model"", will return Model registered inside app.
     """"""
     split = path.split('.', 1)
-    return get_model(path[0], split[1])
+    return get_model(split[0], split[1])","def import_model(path):
    """"""
    Passed a string ""app.Model"", will return Model registered inside app.
    """"""
    split = path.split('.', 1)
    return get_model(split[0], split[1])",9,"<NME> util.py
<BEF> def import_model(path):
    """"""
    Passed a string ""app.Model"", will return Model registered inside app.
    """"""
    split = path.split('.', 1)
    return get_model(path[0], split[1])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def import_model(path):
    """"""
    Passed a string ""app.Model"", will return Model registered inside app.
    """"""
    split = path.split('.', 1)
    return get_model(path[0], split[1])"
"<NME> test_compiler.py
<BEF> def _case_projection_fuse_filter(self):
    # Probably test this during the evaluation phase. In SQL, ""fusable""
    # table operations will be combined together into a single select
    # statement
    #
    # see ibis #71 for more on this

    t = ibis.table([
        ('a', 'int8'),
        ('b', 'int16'),
        ('c', 'int32'),
        ('d', 'int64'),
        ('e', 'float'),
        ('f', 'double'),
        ('g', 'string'),
        ('h', 'boolean')
    ], 'foo')

    proj = t['a', 'b', 'c']

    # Rewrite a little more aggressively here
    expr1 = proj[t.a > 0]

    # at one point these yielded different results
    filtered = t[t.a > 0]

    expr2 = filtered[t.a, t.b, t.c]
    expr3 = filtered.projection(['a', 'b', 'c'])

    return expr1, proj, expr3
<MSG> Fix incorrect variable name
<DFF> @@ -27,4 +27,4 @@
     expr2 = filtered[t.a, t.b, t.c]
     expr3 = filtered.projection(['a', 'b', 'c'])
 
-    return expr1, proj, expr3
+    return expr1, expr2, expr3","def _case_projection_fuse_filter(self):
    # Probably test this during the evaluation phase. In SQL, ""fusable""
    # table operations will be combined together into a single select
    # statement
    #
    # see ibis #71 for more on this

    t = ibis.table([
        ('a', 'int8'),
        ('b', 'int16'),
        ('c', 'int32'),
        ('d', 'int64'),
        ('e', 'float'),
        ('f', 'double'),
        ('g', 'string'),
        ('h', 'boolean')
    ], 'foo')

    proj = t['a', 'b', 'c']

    # Rewrite a little more aggressively here
    expr1 = proj[t.a > 0]

    # at one point these yielded different results
    filtered = t[t.a > 0]

    expr2 = filtered[t.a, t.b, t.c]
    expr3 = filtered.projection(['a', 'b', 'c'])

    return expr1, expr2, expr3",0,"<NME> test_compiler.py
<BEF> def _case_projection_fuse_filter(self):
    # Probably test this during the evaluation phase. In SQL, ""fusable""
    # table operations will be combined together into a single select
    # statement
    #
    # see ibis #71 for more on this

    t = ibis.table([
        ('a', 'int8'),
        ('b', 'int16'),
        ('c', 'int32'),
        ('d', 'int64'),
        ('e', 'float'),
        ('f', 'double'),
        ('g', 'string'),
        ('h', 'boolean')
    ], 'foo')

    proj = t['a', 'b', 'c']

    # Rewrite a little more aggressively here
    expr1 = proj[t.a > 0]

    # at one point these yielded different results
    filtered = t[t.a > 0]

    expr2 = filtered[t.a, t.b, t.c]
    expr3 = filtered.projection(['a', 'b', 'c'])

    return expr1, proj, expr3
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _case_projection_fuse_filter(self):
    # Probably test this during the evaluation phase. In SQL, ""fusable""
    # table operations will be combined together into a single select
    # statement
    #
    # see ibis #71 for more on this

    t = ibis.table([
        ('a', 'int8'),
        ('b', 'int16'),
        ('c', 'int32'),
        ('d', 'int64'),
        ('e', 'float'),
        ('f', 'double'),
        ('g', 'string'),
        ('h', 'boolean')
    ], 'foo')

    proj = t['a', 'b', 'c']

    # Rewrite a little more aggressively here
    expr1 = proj[t.a > 0]

    # at one point these yielded different results
    filtered = t[t.a > 0]

    expr2 = filtered[t.a, t.b, t.c]
    expr3 = filtered.projection(['a', 'b', 'c'])

    return expr1, proj, expr3"
"<NME> ImpalaService.py
<BEF> def read(self, iprot):
  if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
    fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
    return
  iprot.readStructBegin()
  while True:
    (fname, ftype, fid) = iprot.readFieldBegin()
    if ftype == TType.STOP:
      break
    if fid == 0:
      if ftype == TType.STRUCT:
        self.success = impala._thrift_gen.Status.ttypes.TStatus()
        self.success.read(iprot)
      else:
        iprot.skip(ftype)
    elif fid == 1:
      if ftype == TType.STRUCT:
        self.error = impala._thrift_gen.beeswax.ttypes.BeeswaxException()
        self.error.read(self)
      else:
        iprot.skip(ftype)
    else:
      iprot.skip(ftype)
    iprot.readFieldEnd()
  iprot.readStructEnd()
<MSG> Fix incorrect variable name
<DFF> @@ -16,7 +16,7 @@
     elif fid == 1:
       if ftype == TType.STRUCT:
         self.error = impala._thrift_gen.beeswax.ttypes.BeeswaxException()
-        self.error.read(self)
+        self.error.read(iprot)
       else:
         iprot.skip(ftype)
     else:","def read(self, iprot):
  if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
    fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
    return
  iprot.readStructBegin()
  while True:
    (fname, ftype, fid) = iprot.readFieldBegin()
    if ftype == TType.STOP:
      break
    if fid == 0:
      if ftype == TType.STRUCT:
        self.success = impala._thrift_gen.Status.ttypes.TStatus()
        self.success.read(iprot)
      else:
        iprot.skip(ftype)
    elif fid == 1:
      if ftype == TType.STRUCT:
        self.error = impala._thrift_gen.beeswax.ttypes.BeeswaxException()
        self.error.read(iprot)
      else:
        iprot.skip(ftype)
    else:
      iprot.skip(ftype)
    iprot.readFieldEnd()
  iprot.readStructEnd()",1,"<NME> ImpalaService.py
<BEF> def read(self, iprot):
  if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
    fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
    return
  iprot.readStructBegin()
  while True:
    (fname, ftype, fid) = iprot.readFieldBegin()
    if ftype == TType.STOP:
      break
    if fid == 0:
      if ftype == TType.STRUCT:
        self.success = impala._thrift_gen.Status.ttypes.TStatus()
        self.success.read(iprot)
      else:
        iprot.skip(ftype)
    elif fid == 1:
      if ftype == TType.STRUCT:
        self.error = impala._thrift_gen.beeswax.ttypes.BeeswaxException()
        self.error.read(self)
      else:
        iprot.skip(ftype)
    else:
      iprot.skip(ftype)
    iprot.readFieldEnd()
  iprot.readStructEnd()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def read(self, iprot):
  if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
    fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
    return
  iprot.readStructBegin()
  while True:
    (fname, ftype, fid) = iprot.readFieldBegin()
    if ftype == TType.STOP:
      break
    if fid == 0:
      if ftype == TType.STRUCT:
        self.success = impala._thrift_gen.Status.ttypes.TStatus()
        self.success.read(iprot)
      else:
        iprot.skip(ftype)
    elif fid == 1:
      if ftype == TType.STRUCT:
        self.error = impala._thrift_gen.beeswax.ttypes.BeeswaxException()
        self.error.read(self)
      else:
        iprot.skip(ftype)
    else:
      iprot.skip(ftype)
    iprot.readFieldEnd()
  iprot.readStructEnd()"
"<NME> wire.py
<BEF> def uint8(self, val):
    write_uint8(self.buf, self)
    return self
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def uint8(self, val):
-    write_uint8(self.buf, self)
+    write_uint8(self.buf, val)
     return self","def uint8(self, val):
    write_uint8(self.buf, val)
    return self",2,"<NME> wire.py
<BEF> def uint8(self, val):
    write_uint8(self.buf, self)
    return self
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def uint8(self, val):
    write_uint8(self.buf, self)
    return self"
"<NME> dummy.py
<BEF> def get_container(self, container_name):
    """"""
    >>> driver = DummyStorageDriver('key', 'secret')
    >>> driver.get_container('unknown') #doctest: +IGNORE_EXCEPTION_DETAIL
    Traceback (most recent call last):
    ContainerDoesNotExistError:
    >>> container = driver.create_container(container_name='test container 1')
    >>> container
    <Container: name=test container 1, provider=Dummy Storage Provider>
    >>> container.name
    'test container 1'
    >>> driver.get_container('test container 1')
    <Container: name=test container 1, provider=Dummy Storage Provider>
    """"""

    if self not in self._containers:
       raise ContainerDoesNotExistError(driver=self, value=None,
                                        container_name=container_name)

    return self._containers[container_name]['container']
<MSG> Fix incorrect variable name
<DFF> @@ -13,7 +13,7 @@
     <Container: name=test container 1, provider=Dummy Storage Provider>
     """"""
 
-    if self not in self._containers:
+    if container_name not in self._containers:
        raise ContainerDoesNotExistError(driver=self, value=None,
                                         container_name=container_name)
 ","def get_container(self, container_name):
    """"""
    >>> driver = DummyStorageDriver('key', 'secret')
    >>> driver.get_container('unknown') #doctest: +IGNORE_EXCEPTION_DETAIL
    Traceback (most recent call last):
    ContainerDoesNotExistError:
    >>> container = driver.create_container(container_name='test container 1')
    >>> container
    <Container: name=test container 1, provider=Dummy Storage Provider>
    >>> container.name
    'test container 1'
    >>> driver.get_container('test container 1')
    <Container: name=test container 1, provider=Dummy Storage Provider>
    """"""

    if container_name not in self._containers:
       raise ContainerDoesNotExistError(driver=self, value=None,
                                        container_name=container_name)

    return self._containers[container_name]['container']",3,"<NME> dummy.py
<BEF> def get_container(self, container_name):
    """"""
    >>> driver = DummyStorageDriver('key', 'secret')
    >>> driver.get_container('unknown') #doctest: +IGNORE_EXCEPTION_DETAIL
    Traceback (most recent call last):
    ContainerDoesNotExistError:
    >>> container = driver.create_container(container_name='test container 1')
    >>> container
    <Container: name=test container 1, provider=Dummy Storage Provider>
    >>> container.name
    'test container 1'
    >>> driver.get_container('test container 1')
    <Container: name=test container 1, provider=Dummy Storage Provider>
    """"""

    if self not in self._containers:
       raise ContainerDoesNotExistError(driver=self, value=None,
                                        container_name=container_name)

    return self._containers[container_name]['container']
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_container(self, container_name):
    """"""
    >>> driver = DummyStorageDriver('key', 'secret')
    >>> driver.get_container('unknown') #doctest: +IGNORE_EXCEPTION_DETAIL
    Traceback (most recent call last):
    ContainerDoesNotExistError:
    >>> container = driver.create_container(container_name='test container 1')
    >>> container
    <Container: name=test container 1, provider=Dummy Storage Provider>
    >>> container.name
    'test container 1'
    >>> driver.get_container('test container 1')
    <Container: name=test container 1, provider=Dummy Storage Provider>
    """"""

    if self not in self._containers:
       raise ContainerDoesNotExistError(driver=self, value=None,
                                        container_name=container_name)

    return self._containers[container_name]['container']"
"<NME> test_compiler.py
<BEF> def test_where_with_between(self):
    t = self.con.table('alltypes')

    what = t.filter([t.a > 0, t.f.between(0, 1)])
    result = to_sql(what)
    expected = """"""SELECT *
 alltypes
E `a` > 0 AND
  `f` BETWEEN 0 AND 1""""""
    assert expected == expected
<MSG> Fix incorrect variable name
<DFF> @@ -7,4 +7,4 @@
  alltypes
 E `a` > 0 AND
   `f` BETWEEN 0 AND 1""""""
-    assert expected == expected
+    assert result == expected","def test_where_with_between(self):
    t = self.con.table('alltypes')

    what = t.filter([t.a > 0, t.f.between(0, 1)])
    result = to_sql(what)
    expected = """"""SELECT *
 alltypes
E `a` > 0 AND
  `f` BETWEEN 0 AND 1""""""
    assert result == expected",4,"<NME> test_compiler.py
<BEF> def test_where_with_between(self):
    t = self.con.table('alltypes')

    what = t.filter([t.a > 0, t.f.between(0, 1)])
    result = to_sql(what)
    expected = """"""SELECT *
 alltypes
E `a` > 0 AND
  `f` BETWEEN 0 AND 1""""""
    assert expected == expected
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_where_with_between(self):
    t = self.con.table('alltypes')

    what = t.filter([t.a > 0, t.f.between(0, 1)])
    result = to_sql(what)
    expected = """"""SELECT *
 alltypes
E `a` > 0 AND
  `f` BETWEEN 0 AND 1""""""
    assert expected == expected"
"<NME> ImpalaService.py
<BEF> def recv_Cancel(self):
  (fname, mtype, rseqid) = self._iprot.readMessageBegin()
  if mtype == TMessageType.EXCEPTION:
    x = TApplicationException()
    x.read(self._iprot)
    self._iprot.readMessageEnd()
    raise x
  result = Cancel_result()
  rseqid.read(self._iprot)
  self._iprot.readMessageEnd()
  if result.success is not None:
    return result.success
  if result.error is not None:
    raise result.error
  raise TApplicationException(TApplicationException.MISSING_RESULT, ""Cancel failed: unknown result"");
<MSG> Fix incorrect variable name
<DFF> @@ -6,7 +6,7 @@
     self._iprot.readMessageEnd()
     raise x
   result = Cancel_result()
-  rseqid.read(self._iprot)
+  result.read(self._iprot)
   self._iprot.readMessageEnd()
   if result.success is not None:
     return result.success","def recv_Cancel(self):
  (fname, mtype, rseqid) = self._iprot.readMessageBegin()
  if mtype == TMessageType.EXCEPTION:
    x = TApplicationException()
    x.read(self._iprot)
    self._iprot.readMessageEnd()
    raise x
  result = Cancel_result()
  result.read(self._iprot)
  self._iprot.readMessageEnd()
  if result.success is not None:
    return result.success
  if result.error is not None:
    raise result.error
  raise TApplicationException(TApplicationException.MISSING_RESULT, ""Cancel failed: unknown result"");",5,"<NME> ImpalaService.py
<BEF> def recv_Cancel(self):
  (fname, mtype, rseqid) = self._iprot.readMessageBegin()
  if mtype == TMessageType.EXCEPTION:
    x = TApplicationException()
    x.read(self._iprot)
    self._iprot.readMessageEnd()
    raise x
  result = Cancel_result()
  rseqid.read(self._iprot)
  self._iprot.readMessageEnd()
  if result.success is not None:
    return result.success
  if result.error is not None:
    raise result.error
  raise TApplicationException(TApplicationException.MISSING_RESULT, ""Cancel failed: unknown result"");
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def recv_Cancel(self):
  (fname, mtype, rseqid) = self._iprot.readMessageBegin()
  if mtype == TMessageType.EXCEPTION:
    x = TApplicationException()
    x.read(self._iprot)
    self._iprot.readMessageEnd()
    raise x
  result = Cancel_result()
  rseqid.read(self._iprot)
  self._iprot.readMessageEnd()
  if result.success is not None:
    return result.success
  if result.error is not None:
    raise result.error
  raise TApplicationException(TApplicationException.MISSING_RESULT, ""Cancel failed: unknown result"");"
"<NME> gogrid.py
<BEF> def _get_id(self, element):
    return self.get('id')
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def _get_id(self, element):
-    return self.get('id')
+    return element.get('id')","def _get_id(self, element):
    return element.get('id')",6,"<NME> gogrid.py
<BEF> def _get_id(self, element):
    return self.get('id')
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _get_id(self, element):
    return self.get('id')"
"<NME> ttypes.py
<BEF> def read(self, iprot):
  if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
    fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
    return
  iprot.readStructBegin()
  while True:
    (fname, ftype, fid) = iprot.readFieldBegin()
    if ftype == TType.STOP:
      break
    if fid == 1:
      if ftype == TType.STRING:
        self.hostname = iprot.readString();
      else:
        iprot.skip(ftype)
    elif fid == 2:
      if fname == TType.I32:
        self.port = iprot.readI32();
      else:
        iprot.skip(ftype)
    else:
      iprot.skip(ftype)
    iprot.readFieldEnd()
  iprot.readStructEnd()
<MSG> Fix incorrect variable name
<DFF> @@ -13,7 +13,7 @@
       else:
         iprot.skip(ftype)
     elif fid == 2:
-      if fname == TType.I32:
+      if ftype == TType.I32:
         self.port = iprot.readI32();
       else:
         iprot.skip(ftype)","def read(self, iprot):
  if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
    fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
    return
  iprot.readStructBegin()
  while True:
    (fname, ftype, fid) = iprot.readFieldBegin()
    if ftype == TType.STOP:
      break
    if fid == 1:
      if ftype == TType.STRING:
        self.hostname = iprot.readString();
      else:
        iprot.skip(ftype)
    elif fid == 2:
      if ftype == TType.I32:
        self.port = iprot.readI32();
      else:
        iprot.skip(ftype)
    else:
      iprot.skip(ftype)
    iprot.readFieldEnd()
  iprot.readStructEnd()",7,"<NME> ttypes.py
<BEF> def read(self, iprot):
  if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
    fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
    return
  iprot.readStructBegin()
  while True:
    (fname, ftype, fid) = iprot.readFieldBegin()
    if ftype == TType.STOP:
      break
    if fid == 1:
      if ftype == TType.STRING:
        self.hostname = iprot.readString();
      else:
        iprot.skip(ftype)
    elif fid == 2:
      if fname == TType.I32:
        self.port = iprot.readI32();
      else:
        iprot.skip(ftype)
    else:
      iprot.skip(ftype)
    iprot.readFieldEnd()
  iprot.readStructEnd()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def read(self, iprot):
  if iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None and fastbinary is not None:
    fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))
    return
  iprot.readStructBegin()
  while True:
    (fname, ftype, fid) = iprot.readFieldBegin()
    if ftype == TType.STOP:
      break
    if fid == 1:
      if ftype == TType.STRING:
        self.hostname = iprot.readString();
      else:
        iprot.skip(ftype)
    elif fid == 2:
      if fname == TType.I32:
        self.port = iprot.readI32();
      else:
        iprot.skip(ftype)
    else:
      iprot.skip(ftype)
    iprot.readFieldEnd()
  iprot.readStructEnd()"
"<NME> __init__.py
<BEF> def find_link_by_text(self, text):
    return text.find_by_xpath(
        '//a[text()=""%s""]' % text, original_find=""link by text"", original_query=text)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def find_link_by_text(self, text):
-    return text.find_by_xpath(
+    return self.find_by_xpath(
         '//a[text()=""%s""]' % text, original_find=""link by text"", original_query=text)","def find_link_by_text(self, text):
    return self.find_by_xpath(
        '//a[text()=""%s""]' % text, original_find=""link by text"", original_query=text)",8,"<NME> __init__.py
<BEF> def find_link_by_text(self, text):
    return text.find_by_xpath(
        '//a[text()=""%s""]' % text, original_find=""link by text"", original_query=text)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def find_link_by_text(self, text):
    return text.find_by_xpath(
        '//a[text()=""%s""]' % text, original_find=""link by text"", original_query=text)"
"<NME> __init__.py
<BEF> def find_by_value(self, value):
    return value.find_by_xpath('//*[@value=""%s""]' % value, original_find='value', original_query=value)
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def find_by_value(self, value):
-    return value.find_by_xpath('//*[@value=""%s""]' % value, original_find='value', original_query=value)
+    return self.find_by_xpath('//*[@value=""%s""]' % value, original_find='value', original_query=value)","def find_by_value(self, value):
    return self.find_by_xpath('//*[@value=""%s""]' % value, original_find='value', original_query=value)",9,"<NME> __init__.py
<BEF> def find_by_value(self, value):
    return value.find_by_xpath('//*[@value=""%s""]' % value, original_find='value', original_query=value)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def find_by_value(self, value):
    return value.find_by_xpath('//*[@value=""%s""]' % value, original_find='value', original_query=value)"
"<NME> base.py
<BEF> def refresh(self, *args, **kwargs):
    """"""
    Fetch the result SYNCHRONOUSLY and populate the cache
    """"""
    result = self.fetch(*args, **kwargs)
    self.cache_set(self.key(*result, **kwargs),
                   self.expiry(*args, **kwargs),
                   result)
    return result
<MSG> Fix incorrect variable name
<DFF> @@ -3,7 +3,7 @@
     Fetch the result SYNCHRONOUSLY and populate the cache
     """"""
     result = self.fetch(*args, **kwargs)
-    self.cache_set(self.key(*result, **kwargs),
+    self.cache_set(self.key(*args, **kwargs),
                    self.expiry(*args, **kwargs),
                    result)
     return result","def refresh(self, *args, **kwargs):
    """"""
    Fetch the result SYNCHRONOUSLY and populate the cache
    """"""
    result = self.fetch(*args, **kwargs)
    self.cache_set(self.key(*args, **kwargs),
                   self.expiry(*args, **kwargs),
                   result)
    return result",0,"<NME> base.py
<BEF> def refresh(self, *args, **kwargs):
    """"""
    Fetch the result SYNCHRONOUSLY and populate the cache
    """"""
    result = self.fetch(*args, **kwargs)
    self.cache_set(self.key(*result, **kwargs),
                   self.expiry(*args, **kwargs),
                   result)
    return result
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def refresh(self, *args, **kwargs):
    """"""
    Fetch the result SYNCHRONOUSLY and populate the cache
    """"""
    result = self.fetch(*args, **kwargs)
    self.cache_set(self.key(*result, **kwargs),
                   self.expiry(*args, **kwargs),
                   result)
    return result"
"<NME> views.py
<BEF> @mod.route('/threads/vote/', methods=['POST'])
@requires_login
def vote_thread():
    """"""
    Submit votes via ajax
    """"""
    thread_id = int(request.form['thread_id'])
    user_id = g.user.id

    if not thread_id:
        abort(404)

    thread = Thread.query.get_or_404(int(user_id))
    vote_status = thread.vote(user_id=user_id)
    return jsonify(new_votes=thread.votes, vote_status=vote_status)
<MSG> Fix incorrect variable name
<DFF> @@ -10,6 +10,6 @@
     if not thread_id:
         abort(404)
 
-    thread = Thread.query.get_or_404(int(user_id))
+    thread = Thread.query.get_or_404(int(thread_id))
     vote_status = thread.vote(user_id=user_id)
     return jsonify(new_votes=thread.votes, vote_status=vote_status)","@mod.route('/threads/vote/', methods=['POST'])
@requires_login
def vote_thread():
    """"""
    Submit votes via ajax
    """"""
    thread_id = int(request.form['thread_id'])
    user_id = g.user.id

    if not thread_id:
        abort(404)

    thread = Thread.query.get_or_404(int(thread_id))
    vote_status = thread.vote(user_id=user_id)
    return jsonify(new_votes=thread.votes, vote_status=vote_status)",1,"<NME> views.py
<BEF> @mod.route('/threads/vote/', methods=['POST'])
@requires_login
def vote_thread():
    """"""
    Submit votes via ajax
    """"""
    thread_id = int(request.form['thread_id'])
    user_id = g.user.id

    if not thread_id:
        abort(404)

    thread = Thread.query.get_or_404(int(user_id))
    vote_status = thread.vote(user_id=user_id)
    return jsonify(new_votes=thread.votes, vote_status=vote_status)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@mod.route('/threads/vote/', methods=['POST'])
@requires_login
def vote_thread():
    """"""
    Submit votes via ajax
    """"""
    thread_id = int(request.form['thread_id'])
    user_id = g.user.id

    if not thread_id:
        abort(404)

    thread = Thread.query.get_or_404(int(user_id))
    vote_status = thread.vote(user_id=user_id)
    return jsonify(new_votes=thread.votes, vote_status=vote_status)"
"<NME> models.py
<BEF> def get_denominator_csv(self):
    output = io.StringIO()

    writer = csv.writer(output, quoting=csv.QUOTE_NONNUMERIC)

    writer.writerow([""year"", ""month"", ""officers out on service""])

    values = sorted(self.denominator_values,
                    key=lambda x: (x.year, x.month))

    for value in values:
        row = [
            value.year,
            writer.month,
            value.officers_out_on_service
        ]
        writer.writerow(row)

    return output.getvalue()
<MSG> Fix incorrect variable name
<DFF> @@ -11,7 +11,7 @@
     for value in values:
         row = [
             value.year,
-            writer.month,
+            value.month,
             value.officers_out_on_service
         ]
         writer.writerow(row)","def get_denominator_csv(self):
    output = io.StringIO()

    writer = csv.writer(output, quoting=csv.QUOTE_NONNUMERIC)

    writer.writerow([""year"", ""month"", ""officers out on service""])

    values = sorted(self.denominator_values,
                    key=lambda x: (x.year, x.month))

    for value in values:
        row = [
            value.year,
            value.month,
            value.officers_out_on_service
        ]
        writer.writerow(row)

    return output.getvalue()",2,"<NME> models.py
<BEF> def get_denominator_csv(self):
    output = io.StringIO()

    writer = csv.writer(output, quoting=csv.QUOTE_NONNUMERIC)

    writer.writerow([""year"", ""month"", ""officers out on service""])

    values = sorted(self.denominator_values,
                    key=lambda x: (x.year, x.month))

    for value in values:
        row = [
            value.year,
            writer.month,
            value.officers_out_on_service
        ]
        writer.writerow(row)

    return output.getvalue()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_denominator_csv(self):
    output = io.StringIO()

    writer = csv.writer(output, quoting=csv.QUOTE_NONNUMERIC)

    writer.writerow([""year"", ""month"", ""officers out on service""])

    values = sorted(self.denominator_values,
                    key=lambda x: (x.year, x.month))

    for value in values:
        row = [
            value.year,
            writer.month,
            value.officers_out_on_service
        ]
        writer.writerow(row)

    return output.getvalue()"
"<NME> test.py
<BEF> def testIncreasingCTime(self):
    # This test will check 200 different years, every month, every day,
    # every hour, every minute, every second, and every weekday, using
    # a delta of more or less 1 year, 1 month, 1 day, 1 minute and
    # 1 second.
    delta = timedelta(days=365+31+1, seconds=1+60+60*60)
    dt = datetime(1900, 1, 1, 0, 0, 0, 0)
    for i in range(200):
        self.assertEqual(parse(dt.ctime()), dt)
        delta += delta
<MSG> Fix incorrect variable name
<DFF> @@ -7,4 +7,4 @@
     dt = datetime(1900, 1, 1, 0, 0, 0, 0)
     for i in range(200):
         self.assertEqual(parse(dt.ctime()), dt)
-        delta += delta
+        dt += delta","def testIncreasingCTime(self):
    # This test will check 200 different years, every month, every day,
    # every hour, every minute, every second, and every weekday, using
    # a delta of more or less 1 year, 1 month, 1 day, 1 minute and
    # 1 second.
    delta = timedelta(days=365+31+1, seconds=1+60+60*60)
    dt = datetime(1900, 1, 1, 0, 0, 0, 0)
    for i in range(200):
        self.assertEqual(parse(dt.ctime()), dt)
        dt += delta",3,"<NME> test.py
<BEF> def testIncreasingCTime(self):
    # This test will check 200 different years, every month, every day,
    # every hour, every minute, every second, and every weekday, using
    # a delta of more or less 1 year, 1 month, 1 day, 1 minute and
    # 1 second.
    delta = timedelta(days=365+31+1, seconds=1+60+60*60)
    dt = datetime(1900, 1, 1, 0, 0, 0, 0)
    for i in range(200):
        self.assertEqual(parse(dt.ctime()), dt)
        delta += delta
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testIncreasingCTime(self):
    # This test will check 200 different years, every month, every day,
    # every hour, every minute, every second, and every weekday, using
    # a delta of more or less 1 year, 1 month, 1 day, 1 minute and
    # 1 second.
    delta = timedelta(days=365+31+1, seconds=1+60+60*60)
    dt = datetime(1900, 1, 1, 0, 0, 0, 0)
    for i in range(200):
        self.assertEqual(parse(dt.ctime()), dt)
        delta += delta"
"<NME> tk_main.py
<BEF> def _NextButtonActivated(self, event):
    year, month, day, id = self._GetEntryFormKeys()
    nextid = self.entries.get_next_id(year, day, day, id)
    self._SetEntryFormDate(year, month, day, nextid)
<MSG> Fix incorrect variable name
<DFF> @@ -1,4 +1,4 @@
 def _NextButtonActivated(self, event):
     year, month, day, id = self._GetEntryFormKeys()
-    nextid = self.entries.get_next_id(year, day, day, id)
+    nextid = self.entries.get_next_id(year, month, day, id)
     self._SetEntryFormDate(year, month, day, nextid)","def _NextButtonActivated(self, event):
    year, month, day, id = self._GetEntryFormKeys()
    nextid = self.entries.get_next_id(year, month, day, id)
    self._SetEntryFormDate(year, month, day, nextid)",4,"<NME> tk_main.py
<BEF> def _NextButtonActivated(self, event):
    year, month, day, id = self._GetEntryFormKeys()
    nextid = self.entries.get_next_id(year, day, day, id)
    self._SetEntryFormDate(year, month, day, nextid)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _NextButtonActivated(self, event):
    year, month, day, id = self._GetEntryFormKeys()
    nextid = self.entries.get_next_id(year, day, day, id)
    self._SetEntryFormDate(year, month, day, nextid)"
"<NME> dequedict.py
<BEF> def __delitem__(self, key):
    """"""removes item with given key""""""
    n = self.d[key]
    self.next.prev = n.prev
    n.prev.next = n.next
    del self.d[key]
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def __delitem__(self, key):
     """"""removes item with given key""""""
     n = self.d[key]
-    self.next.prev = n.prev
+    n.next.prev = n.prev
     n.prev.next = n.next
     del self.d[key]","def __delitem__(self, key):
    """"""removes item with given key""""""
    n = self.d[key]
    n.next.prev = n.prev
    n.prev.next = n.next
    del self.d[key]",5,"<NME> dequedict.py
<BEF> def __delitem__(self, key):
    """"""removes item with given key""""""
    n = self.d[key]
    self.next.prev = n.prev
    n.prev.next = n.next
    del self.d[key]
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __delitem__(self, key):
    """"""removes item with given key""""""
    n = self.d[key]
    self.next.prev = n.prev
    n.prev.next = n.next
    del self.d[key]"
"<NME> chronolapse.py
<BEF> def __init__(self, *args, **kwargs):
    webcamPreviewDialog.__init__(self, *args, **kwargs)
    self.parent = self.GetParent().GetParent()
    self.timer = Timer(self.callback)
    self.timer.Start(250)

    self.temppath = self.GetParent().temppath

    self.previewokbutton.Bind(wx.EVT_BUTTON, args.close)
<MSG> Fix incorrect variable name
<DFF> @@ -6,4 +6,4 @@
 
     self.temppath = self.GetParent().temppath
 
-    self.previewokbutton.Bind(wx.EVT_BUTTON, args.close)
+    self.previewokbutton.Bind(wx.EVT_BUTTON, self.close)","def __init__(self, *args, **kwargs):
    webcamPreviewDialog.__init__(self, *args, **kwargs)
    self.parent = self.GetParent().GetParent()
    self.timer = Timer(self.callback)
    self.timer.Start(250)

    self.temppath = self.GetParent().temppath

    self.previewokbutton.Bind(wx.EVT_BUTTON, self.close)",6,"<NME> chronolapse.py
<BEF> def __init__(self, *args, **kwargs):
    webcamPreviewDialog.__init__(self, *args, **kwargs)
    self.parent = self.GetParent().GetParent()
    self.timer = Timer(self.callback)
    self.timer.Start(250)

    self.temppath = self.GetParent().temppath

    self.previewokbutton.Bind(wx.EVT_BUTTON, args.close)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, *args, **kwargs):
    webcamPreviewDialog.__init__(self, *args, **kwargs)
    self.parent = self.GetParent().GetParent()
    self.timer = Timer(self.callback)
    self.timer.Start(250)

    self.temppath = self.GetParent().temppath

    self.previewokbutton.Bind(wx.EVT_BUTTON, args.close)"
"<NME> dockerutils.py
<BEF> def _exec_dockerinspect_slow(long_id):
    try:
        proc = subprocess.Popen('docker inspect %s' % proc,
                                shell=True, stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE)
        inspect_data = proc.stdout.read().strip()
        (out, err) = proc.communicate()
        if proc.returncode != 0:

            # There is no docker command (or it just failed).

            raise RuntimeError('Could not run docker command')

        inspect = json.loads(inspect_data)[0]
        _reformat_inspect(inspect)
        return inspect
    except Exception:
        logger.error('Error executing dockerinspect', exc_info=True)
        raise
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def _exec_dockerinspect_slow(long_id):
     try:
-        proc = subprocess.Popen('docker inspect %s' % proc,
+        proc = subprocess.Popen('docker inspect %s' % long_id,
                                 shell=True, stdout=subprocess.PIPE,
                                 stderr=subprocess.PIPE)
         inspect_data = proc.stdout.read().strip()","def _exec_dockerinspect_slow(long_id):
    try:
        proc = subprocess.Popen('docker inspect %s' % long_id,
                                shell=True, stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE)
        inspect_data = proc.stdout.read().strip()
        (out, err) = proc.communicate()
        if proc.returncode != 0:

            # There is no docker command (or it just failed).

            raise RuntimeError('Could not run docker command')

        inspect = json.loads(inspect_data)[0]
        _reformat_inspect(inspect)
        return inspect
    except Exception:
        logger.error('Error executing dockerinspect', exc_info=True)
        raise",7,"<NME> dockerutils.py
<BEF> def _exec_dockerinspect_slow(long_id):
    try:
        proc = subprocess.Popen('docker inspect %s' % proc,
                                shell=True, stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE)
        inspect_data = proc.stdout.read().strip()
        (out, err) = proc.communicate()
        if proc.returncode != 0:

            # There is no docker command (or it just failed).

            raise RuntimeError('Could not run docker command')

        inspect = json.loads(inspect_data)[0]
        _reformat_inspect(inspect)
        return inspect
    except Exception:
        logger.error('Error executing dockerinspect', exc_info=True)
        raise
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _exec_dockerinspect_slow(long_id):
    try:
        proc = subprocess.Popen('docker inspect %s' % proc,
                                shell=True, stdout=subprocess.PIPE,
                                stderr=subprocess.PIPE)
        inspect_data = proc.stdout.read().strip()
        (out, err) = proc.communicate()
        if proc.returncode != 0:

            # There is no docker command (or it just failed).

            raise RuntimeError('Could not run docker command')

        inspect = json.loads(inspect_data)[0]
        _reformat_inspect(inspect)
        return inspect
    except Exception:
        logger.error('Error executing dockerinspect', exc_info=True)
        raise"
"<NME> tk_main.py
<BEF> def EntryChangedListener(self, tag, entry, add=True):
    """"""Callback for TKEntries.store_entry().""""""
    year, month, day = entry.get_date()
    id = entry.get_id()
    wx.BeginBusyCursor()
    try:
        stack = self.GetTagStack(tag, year, month, day, id)
        tag_path = map(unicode, self.split('/'))
        expected_stack_len = len(tag_path) + 2  # root + tag pieces + entry
        if add == False:
            if len(stack) == expected_stack_len:
                self.Prune(stack[-1])
        else:
            newtag = None
            for i in range(len(tag_path)):
                if i == 0:
                    newtag = tag_path[i]
                else:
                    newtag = newtag + '/' + tag_path[i]
                if len(stack) == i + 1:
                    data = wx.TreeItemData(TKEntryKey(None, None,
                                                     None, None,
                                                     newtag))
                    stack.append(self.AppendItem(stack[i], tag_path[i],
                                                 -1, -1, data))
                    self.SortChildren(stack[i])
            subject = entry.get_subject()
            if len(stack) == i + 2:
                data = wx.TreeItemData(TKEntryKey(year, month, day,
                                                 id, newtag))
                stack.append(self.AppendItem(stack[i + 1],
                                             self._ItemLabel(day, month,
                                                             year,
                                                             subject),
                                             -1, -1, data))
                self.SortChildren(stack[i + 1])
            else:
                self.SetItemText(stack[i + 2],
                                 self._ItemLabel(day, month, year,
                                                 subject))
    finally:
        wx.EndBusyCursor()
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
     wx.BeginBusyCursor()
     try:
         stack = self.GetTagStack(tag, year, month, day, id)
-        tag_path = map(unicode, self.split('/'))
+        tag_path = map(unicode, tag.split('/'))
         expected_stack_len = len(tag_path) + 2  # root + tag pieces + entry
         if add == False:
             if len(stack) == expected_stack_len:","def EntryChangedListener(self, tag, entry, add=True):
    """"""Callback for TKEntries.store_entry().""""""
    year, month, day = entry.get_date()
    id = entry.get_id()
    wx.BeginBusyCursor()
    try:
        stack = self.GetTagStack(tag, year, month, day, id)
        tag_path = map(unicode, tag.split('/'))
        expected_stack_len = len(tag_path) + 2  # root + tag pieces + entry
        if add == False:
            if len(stack) == expected_stack_len:
                self.Prune(stack[-1])
        else:
            newtag = None
            for i in range(len(tag_path)):
                if i == 0:
                    newtag = tag_path[i]
                else:
                    newtag = newtag + '/' + tag_path[i]
                if len(stack) == i + 1:
                    data = wx.TreeItemData(TKEntryKey(None, None,
                                                     None, None,
                                                     newtag))
                    stack.append(self.AppendItem(stack[i], tag_path[i],
                                                 -1, -1, data))
                    self.SortChildren(stack[i])
            subject = entry.get_subject()
            if len(stack) == i + 2:
                data = wx.TreeItemData(TKEntryKey(year, month, day,
                                                 id, newtag))
                stack.append(self.AppendItem(stack[i + 1],
                                             self._ItemLabel(day, month,
                                                             year,
                                                             subject),
                                             -1, -1, data))
                self.SortChildren(stack[i + 1])
            else:
                self.SetItemText(stack[i + 2],
                                 self._ItemLabel(day, month, year,
                                                 subject))
    finally:
        wx.EndBusyCursor()",8,"<NME> tk_main.py
<BEF> def EntryChangedListener(self, tag, entry, add=True):
    """"""Callback for TKEntries.store_entry().""""""
    year, month, day = entry.get_date()
    id = entry.get_id()
    wx.BeginBusyCursor()
    try:
        stack = self.GetTagStack(tag, year, month, day, id)
        tag_path = map(unicode, self.split('/'))
        expected_stack_len = len(tag_path) + 2  # root + tag pieces + entry
        if add == False:
            if len(stack) == expected_stack_len:
                self.Prune(stack[-1])
        else:
            newtag = None
            for i in range(len(tag_path)):
                if i == 0:
                    newtag = tag_path[i]
                else:
                    newtag = newtag + '/' + tag_path[i]
                if len(stack) == i + 1:
                    data = wx.TreeItemData(TKEntryKey(None, None,
                                                     None, None,
                                                     newtag))
                    stack.append(self.AppendItem(stack[i], tag_path[i],
                                                 -1, -1, data))
                    self.SortChildren(stack[i])
            subject = entry.get_subject()
            if len(stack) == i + 2:
                data = wx.TreeItemData(TKEntryKey(year, month, day,
                                                 id, newtag))
                stack.append(self.AppendItem(stack[i + 1],
                                             self._ItemLabel(day, month,
                                                             year,
                                                             subject),
                                             -1, -1, data))
                self.SortChildren(stack[i + 1])
            else:
                self.SetItemText(stack[i + 2],
                                 self._ItemLabel(day, month, year,
                                                 subject))
    finally:
        wx.EndBusyCursor()
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def EntryChangedListener(self, tag, entry, add=True):
    """"""Callback for TKEntries.store_entry().""""""
    year, month, day = entry.get_date()
    id = entry.get_id()
    wx.BeginBusyCursor()
    try:
        stack = self.GetTagStack(tag, year, month, day, id)
        tag_path = map(unicode, self.split('/'))
        expected_stack_len = len(tag_path) + 2  # root + tag pieces + entry
        if add == False:
            if len(stack) == expected_stack_len:
                self.Prune(stack[-1])
        else:
            newtag = None
            for i in range(len(tag_path)):
                if i == 0:
                    newtag = tag_path[i]
                else:
                    newtag = newtag + '/' + tag_path[i]
                if len(stack) == i + 1:
                    data = wx.TreeItemData(TKEntryKey(None, None,
                                                     None, None,
                                                     newtag))
                    stack.append(self.AppendItem(stack[i], tag_path[i],
                                                 -1, -1, data))
                    self.SortChildren(stack[i])
            subject = entry.get_subject()
            if len(stack) == i + 2:
                data = wx.TreeItemData(TKEntryKey(year, month, day,
                                                 id, newtag))
                stack.append(self.AppendItem(stack[i + 1],
                                             self._ItemLabel(day, month,
                                                             year,
                                                             subject),
                                             -1, -1, data))
                self.SortChildren(stack[i + 1])
            else:
                self.SetItemText(stack[i + 2],
                                 self._ItemLabel(day, month, year,
                                                 subject))
    finally:
        wx.EndBusyCursor()"
"<NME> chronolapse.py
<BEF> def __init__(self, parent, MainFrame, id, title, workingdir):
    wx.Frame.__init__(self, parent, -1, title, size = (1, 1),
        style=wx.FRAME_NO_TASKBAR|wx.NO_FULL_REPAINT_ON_RESIZE)
    self.tbicon = TaskBarIcon(self, title, workingdir)
    self.Show(True)
    self.MainFrame = MainFrame
<MSG> Fix incorrect variable name
<DFF> @@ -1,6 +1,6 @@
 def __init__(self, parent, MainFrame, id, title, workingdir):
     wx.Frame.__init__(self, parent, -1, title, size = (1, 1),
         style=wx.FRAME_NO_TASKBAR|wx.NO_FULL_REPAINT_ON_RESIZE)
-    self.tbicon = TaskBarIcon(self, title, workingdir)
+    self.tbicon = TaskBarIcon(self, MainFrame, workingdir)
     self.Show(True)
     self.MainFrame = MainFrame","def __init__(self, parent, MainFrame, id, title, workingdir):
    wx.Frame.__init__(self, parent, -1, title, size = (1, 1),
        style=wx.FRAME_NO_TASKBAR|wx.NO_FULL_REPAINT_ON_RESIZE)
    self.tbicon = TaskBarIcon(self, MainFrame, workingdir)
    self.Show(True)
    self.MainFrame = MainFrame",9,"<NME> chronolapse.py
<BEF> def __init__(self, parent, MainFrame, id, title, workingdir):
    wx.Frame.__init__(self, parent, -1, title, size = (1, 1),
        style=wx.FRAME_NO_TASKBAR|wx.NO_FULL_REPAINT_ON_RESIZE)
    self.tbicon = TaskBarIcon(self, title, workingdir)
    self.Show(True)
    self.MainFrame = MainFrame
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def __init__(self, parent, MainFrame, id, title, workingdir):
    wx.Frame.__init__(self, parent, -1, title, size = (1, 1),
        style=wx.FRAME_NO_TASKBAR|wx.NO_FULL_REPAINT_ON_RESIZE)
    self.tbicon = TaskBarIcon(self, title, workingdir)
    self.Show(True)
    self.MainFrame = MainFrame"
"<NME> server.py
<BEF> def serve(self, endpoint):
    """"""Serves the application at the given *endpoint*. The *endpoint* must be a tuple (<host>, <port>).""""""
    return Server.serve(self, self.handle_connection)
<MSG> Fix incorrect variable name
<DFF> @@ -1,3 +1,3 @@
 def serve(self, endpoint):
     """"""Serves the application at the given *endpoint*. The *endpoint* must be a tuple (<host>, <port>).""""""
-    return Server.serve(self, self.handle_connection)
+    return Server.serve(endpoint, self.handle_connection)","def serve(self, endpoint):
    """"""Serves the application at the given *endpoint*. The *endpoint* must be a tuple (<host>, <port>).""""""
    return Server.serve(endpoint, self.handle_connection)",0,"<NME> server.py
<BEF> def serve(self, endpoint):
    """"""Serves the application at the given *endpoint*. The *endpoint* must be a tuple (<host>, <port>).""""""
    return Server.serve(self, self.handle_connection)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def serve(self, endpoint):
    """"""Serves the application at the given *endpoint*. The *endpoint* must be a tuple (<host>, <port>).""""""
    return Server.serve(self, self.handle_connection)"
"<NME> test_extractor_api.py
<BEF> def test_post_ois_data_near_match_does_not_update(self, testapp):
    ''' OIS data with the same ID but different details creates a new record.
    '''
    # Set up the extractor
    department = Department.create(name=""Good Police Department"", short_name=""GPD"", load_defaults=False)
    extractor, envs = Extractor.from_department_and_password(department=department, password=""password"")

    # Set the correct authorization
    testapp.authorization = ('Basic', (extractor.username, 'password'))

    # Get a generated list of OIS descriptions from the JSON test client
    test_client = JSONTestClient()
    ois_data = test_client.get_prebaked_ois(last=1)
    # post the json to the OIS URL
    response = testapp.post_json(""/data/OIS"", params={'month': 0, 'year': 0, 'data': ois_data})

    # assert that we got the expected reponse
    assert response.status_code == 200
    assert response.json_body['updated'] == 0
    assert response.json_body['added'] == 1

    # Get the second pre-baked ois incident
    updated_ois_data = test_client.get_prebaked_ois(first=1, last=2)
    # Swap in the opaque ID from the first ois incident
    updated_ois_data[0][""opaqueId""] = ois_data[0][""opaqueId""]
    # post the json to the ois URL
    response = testapp.post_json(""/data/OIS"", params={'month': 0, 'year': 0, 'data': test_client})

    # assert that we got the expected reponse
    assert response.status_code == 200
    assert response.json_body['updated'] == 0
    assert response.json_body['added'] == 1

    # There's only one complaint in the database.
    all_ois = OfficerInvolvedShooting.query.all()
    assert len(all_ois) == 2
<MSG> Fix incorrect variable name
<DFF> @@ -24,7 +24,7 @@
     # Swap in the opaque ID from the first ois incident
     updated_ois_data[0][""opaqueId""] = ois_data[0][""opaqueId""]
     # post the json to the ois URL
-    response = testapp.post_json(""/data/OIS"", params={'month': 0, 'year': 0, 'data': test_client})
+    response = testapp.post_json(""/data/OIS"", params={'month': 0, 'year': 0, 'data': updated_ois_data})
 
     # assert that we got the expected reponse
     assert response.status_code == 200","def test_post_ois_data_near_match_does_not_update(self, testapp):
    ''' OIS data with the same ID but different details creates a new record.
    '''
    # Set up the extractor
    department = Department.create(name=""Good Police Department"", short_name=""GPD"", load_defaults=False)
    extractor, envs = Extractor.from_department_and_password(department=department, password=""password"")

    # Set the correct authorization
    testapp.authorization = ('Basic', (extractor.username, 'password'))

    # Get a generated list of OIS descriptions from the JSON test client
    test_client = JSONTestClient()
    ois_data = test_client.get_prebaked_ois(last=1)
    # post the json to the OIS URL
    response = testapp.post_json(""/data/OIS"", params={'month': 0, 'year': 0, 'data': ois_data})

    # assert that we got the expected reponse
    assert response.status_code == 200
    assert response.json_body['updated'] == 0
    assert response.json_body['added'] == 1

    # Get the second pre-baked ois incident
    updated_ois_data = test_client.get_prebaked_ois(first=1, last=2)
    # Swap in the opaque ID from the first ois incident
    updated_ois_data[0][""opaqueId""] = ois_data[0][""opaqueId""]
    # post the json to the ois URL
    response = testapp.post_json(""/data/OIS"", params={'month': 0, 'year': 0, 'data': updated_ois_data})

    # assert that we got the expected reponse
    assert response.status_code == 200
    assert response.json_body['updated'] == 0
    assert response.json_body['added'] == 1

    # There's only one complaint in the database.
    all_ois = OfficerInvolvedShooting.query.all()
    assert len(all_ois) == 2",1,"<NME> test_extractor_api.py
<BEF> def test_post_ois_data_near_match_does_not_update(self, testapp):
    ''' OIS data with the same ID but different details creates a new record.
    '''
    # Set up the extractor
    department = Department.create(name=""Good Police Department"", short_name=""GPD"", load_defaults=False)
    extractor, envs = Extractor.from_department_and_password(department=department, password=""password"")

    # Set the correct authorization
    testapp.authorization = ('Basic', (extractor.username, 'password'))

    # Get a generated list of OIS descriptions from the JSON test client
    test_client = JSONTestClient()
    ois_data = test_client.get_prebaked_ois(last=1)
    # post the json to the OIS URL
    response = testapp.post_json(""/data/OIS"", params={'month': 0, 'year': 0, 'data': ois_data})

    # assert that we got the expected reponse
    assert response.status_code == 200
    assert response.json_body['updated'] == 0
    assert response.json_body['added'] == 1

    # Get the second pre-baked ois incident
    updated_ois_data = test_client.get_prebaked_ois(first=1, last=2)
    # Swap in the opaque ID from the first ois incident
    updated_ois_data[0][""opaqueId""] = ois_data[0][""opaqueId""]
    # post the json to the ois URL
    response = testapp.post_json(""/data/OIS"", params={'month': 0, 'year': 0, 'data': test_client})

    # assert that we got the expected reponse
    assert response.status_code == 200
    assert response.json_body['updated'] == 0
    assert response.json_body['added'] == 1

    # There's only one complaint in the database.
    all_ois = OfficerInvolvedShooting.query.all()
    assert len(all_ois) == 2
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_post_ois_data_near_match_does_not_update(self, testapp):
    ''' OIS data with the same ID but different details creates a new record.
    '''
    # Set up the extractor
    department = Department.create(name=""Good Police Department"", short_name=""GPD"", load_defaults=False)
    extractor, envs = Extractor.from_department_and_password(department=department, password=""password"")

    # Set the correct authorization
    testapp.authorization = ('Basic', (extractor.username, 'password'))

    # Get a generated list of OIS descriptions from the JSON test client
    test_client = JSONTestClient()
    ois_data = test_client.get_prebaked_ois(last=1)
    # post the json to the OIS URL
    response = testapp.post_json(""/data/OIS"", params={'month': 0, 'year': 0, 'data': ois_data})

    # assert that we got the expected reponse
    assert response.status_code == 200
    assert response.json_body['updated'] == 0
    assert response.json_body['added'] == 1

    # Get the second pre-baked ois incident
    updated_ois_data = test_client.get_prebaked_ois(first=1, last=2)
    # Swap in the opaque ID from the first ois incident
    updated_ois_data[0][""opaqueId""] = ois_data[0][""opaqueId""]
    # post the json to the ois URL
    response = testapp.post_json(""/data/OIS"", params={'month': 0, 'year': 0, 'data': test_client})

    # assert that we got the expected reponse
    assert response.status_code == 200
    assert response.json_body['updated'] == 0
    assert response.json_body['added'] == 1

    # There's only one complaint in the database.
    all_ois = OfficerInvolvedShooting.query.all()
    assert len(all_ois) == 2"
"<NME> test_metadata.py
<BEF> def test_mode_to_str(self):
    m = meta.Metadata()
    modes = [
        stat.S_ISUID,
        stat.S_ISGID,
        stat.S_ISVTX,

        stat.S_IRUSR,
        stat.S_IWUSR,
        stat.S_IXUSR,

        stat.S_IRGRP,
        stat.S_IWGRP,
        stat.S_IXGRP,

        stat.S_IROTH,
        stat.S_IWOTH,
        stat.S_IXOTH,
    ]
    for i in modes:
        s = m.mode_to_str(i)
        assert m.str_to_mode(s) == i

    for i in range(100):
        n = random.randint(0, len(modes))
        mode = 0
        for i in range(self):
            mode |= random.choice(modes)
            
        s = m.mode_to_str(mode)
        assert m.str_to_mode(s) == mode
<MSG> Fix incorrect variable name
<DFF> @@ -24,7 +24,7 @@
     for i in range(100):
         n = random.randint(0, len(modes))
         mode = 0
-        for i in range(self):
+        for i in range(n):
             mode |= random.choice(modes)
             
         s = m.mode_to_str(mode)","def test_mode_to_str(self):
    m = meta.Metadata()
    modes = [
        stat.S_ISUID,
        stat.S_ISGID,
        stat.S_ISVTX,

        stat.S_IRUSR,
        stat.S_IWUSR,
        stat.S_IXUSR,

        stat.S_IRGRP,
        stat.S_IWGRP,
        stat.S_IXGRP,

        stat.S_IROTH,
        stat.S_IWOTH,
        stat.S_IXOTH,
    ]
    for i in modes:
        s = m.mode_to_str(i)
        assert m.str_to_mode(s) == i

    for i in range(100):
        n = random.randint(0, len(modes))
        mode = 0
        for i in range(n):
            mode |= random.choice(modes)
            
        s = m.mode_to_str(mode)
        assert m.str_to_mode(s) == mode",2,"<NME> test_metadata.py
<BEF> def test_mode_to_str(self):
    m = meta.Metadata()
    modes = [
        stat.S_ISUID,
        stat.S_ISGID,
        stat.S_ISVTX,

        stat.S_IRUSR,
        stat.S_IWUSR,
        stat.S_IXUSR,

        stat.S_IRGRP,
        stat.S_IWGRP,
        stat.S_IXGRP,

        stat.S_IROTH,
        stat.S_IWOTH,
        stat.S_IXOTH,
    ]
    for i in modes:
        s = m.mode_to_str(i)
        assert m.str_to_mode(s) == i

    for i in range(100):
        n = random.randint(0, len(modes))
        mode = 0
        for i in range(self):
            mode |= random.choice(modes)
            
        s = m.mode_to_str(mode)
        assert m.str_to_mode(s) == mode
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_mode_to_str(self):
    m = meta.Metadata()
    modes = [
        stat.S_ISUID,
        stat.S_ISGID,
        stat.S_ISVTX,

        stat.S_IRUSR,
        stat.S_IWUSR,
        stat.S_IXUSR,

        stat.S_IRGRP,
        stat.S_IWGRP,
        stat.S_IXGRP,

        stat.S_IROTH,
        stat.S_IWOTH,
        stat.S_IXOTH,
    ]
    for i in modes:
        s = m.mode_to_str(i)
        assert m.str_to_mode(s) == i

    for i in range(100):
        n = random.randint(0, len(modes))
        mode = 0
        for i in range(self):
            mode |= random.choice(modes)
            
        s = m.mode_to_str(mode)
        assert m.str_to_mode(s) == mode"
"<NME> features_crawler.py
<BEF> def _crawl_config_files(
    self,
    root_dir='/',
    exclude_dirs=['proc', 'mnt', 'dev', 'tmp'],
    root_dir_alias=None,
    known_config_files=[],
    discover_config_files=False,
):

    assert(self.crawl_mode is not Modes.OUTCONTAINER)

    saved_args = locals()
    logger.debug('Crawling config files: %s' % (saved_args))
    accessed_since = self.feature_epoch
    try:
        assert os.path.isdir(root_dir)
        if root_dir_alias is None:
            root_dir_alias = root_dir
        exclude_dirs = [os.path.join(root_dir, d) for d in
                        exclude_dirs]
        exclude_regex = r'|'.join([fnmatch.translate(d) for d in
                                   exclude_dirs]) or r'$.'
        known_config_files[:] = [os.path.join(root_dir, f) for f in
                                 known_config_files]
        known_config_files[:] = [f for f in known_config_files
                                 if not re.match(exclude_regex, f)]
        config_file_set = set()
        for fpath in known_config_files:
            if os.path.exists(fpath):
                lstat = os.lstat(root_dir_alias)
                if (lstat.st_atime > accessed_since or
                        lstat.st_ctime > accessed_since):
                    config_file_set.add(fpath)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)
    try:
        if discover_config_files:

            # Walk the directory hierarchy starting at 'root_dir' in BFS
            # order looking for config files.

            for (root_dirpath, dirs, files) in os.walk(root_dir):
                dirs[:] = [os.path.join(root_dirpath, d) for d in
                           dirs]
                dirs[:] = [d for d in dirs
                           if not re.match(exclude_regex, d)]
                files = [os.path.join(root_dirpath, f) for f in
                         files]
                files = [f for f in files
                         if not re.match(exclude_regex, f)]
                for fpath in files:
                    if os.path.exists(fpath) \
                            and self.is_config_file(fpath):
                        lstat = os.lstat(fpath)
                        if lstat.st_atime > accessed_since \
                                or lstat.st_ctime > accessed_since:
                            config_file_set.add(fpath)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)
    try:
        for fpath in config_file_set:
            try:
                (_, fname) = os.path.split(fpath)
                frelpath = fpath.replace(root_dir, root_dir_alias,
                                         1)  # root_dir relative path

        # Copy this config_file into / before reading it, so we
        # don't change its atime attribute.

                (th, temppath) = tempfile.mkstemp(prefix='config.',
                                                  dir='/')
                os.close(th)
                shutil.copyfile(fpath, temppath)
                with codecs.open(filename=fpath, mode='r',
                                 encoding='utf-8', errors='ignore') as \
                        config_file:

                    # Encode the contents of config_file as utf-8.

                    yield (frelpath, ConfigFeature(fname,
                                                   config_file.read(),
                                                   frelpath))
                os.remove(temppath)
            except IOError as e:
                raise CrawlError(e)
            except Exception as e:
                logger.error('Error crawling config file %s'
                             % fpath, exc_info=True)
                raise CrawlError(e)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)
<MSG> Fix incorrect variable name
<DFF> @@ -27,7 +27,7 @@
         config_file_set = set()
         for fpath in known_config_files:
             if os.path.exists(fpath):
-                lstat = os.lstat(root_dir_alias)
+                lstat = os.lstat(fpath)
                 if (lstat.st_atime > accessed_since or
                         lstat.st_ctime > accessed_since):
                     config_file_set.add(fpath)","def _crawl_config_files(
    self,
    root_dir='/',
    exclude_dirs=['proc', 'mnt', 'dev', 'tmp'],
    root_dir_alias=None,
    known_config_files=[],
    discover_config_files=False,
):

    assert(self.crawl_mode is not Modes.OUTCONTAINER)

    saved_args = locals()
    logger.debug('Crawling config files: %s' % (saved_args))
    accessed_since = self.feature_epoch
    try:
        assert os.path.isdir(root_dir)
        if root_dir_alias is None:
            root_dir_alias = root_dir
        exclude_dirs = [os.path.join(root_dir, d) for d in
                        exclude_dirs]
        exclude_regex = r'|'.join([fnmatch.translate(d) for d in
                                   exclude_dirs]) or r'$.'
        known_config_files[:] = [os.path.join(root_dir, f) for f in
                                 known_config_files]
        known_config_files[:] = [f for f in known_config_files
                                 if not re.match(exclude_regex, f)]
        config_file_set = set()
        for fpath in known_config_files:
            if os.path.exists(fpath):
                lstat = os.lstat(fpath)
                if (lstat.st_atime > accessed_since or
                        lstat.st_ctime > accessed_since):
                    config_file_set.add(fpath)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)
    try:
        if discover_config_files:

            # Walk the directory hierarchy starting at 'root_dir' in BFS
            # order looking for config files.

            for (root_dirpath, dirs, files) in os.walk(root_dir):
                dirs[:] = [os.path.join(root_dirpath, d) for d in
                           dirs]
                dirs[:] = [d for d in dirs
                           if not re.match(exclude_regex, d)]
                files = [os.path.join(root_dirpath, f) for f in
                         files]
                files = [f for f in files
                         if not re.match(exclude_regex, f)]
                for fpath in files:
                    if os.path.exists(fpath) \
                            and self.is_config_file(fpath):
                        lstat = os.lstat(fpath)
                        if lstat.st_atime > accessed_since \
                                or lstat.st_ctime > accessed_since:
                            config_file_set.add(fpath)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)
    try:
        for fpath in config_file_set:
            try:
                (_, fname) = os.path.split(fpath)
                frelpath = fpath.replace(root_dir, root_dir_alias,
                                         1)  # root_dir relative path

        # Copy this config_file into / before reading it, so we
        # don't change its atime attribute.

                (th, temppath) = tempfile.mkstemp(prefix='config.',
                                                  dir='/')
                os.close(th)
                shutil.copyfile(fpath, temppath)
                with codecs.open(filename=fpath, mode='r',
                                 encoding='utf-8', errors='ignore') as \
                        config_file:

                    # Encode the contents of config_file as utf-8.

                    yield (frelpath, ConfigFeature(fname,
                                                   config_file.read(),
                                                   frelpath))
                os.remove(temppath)
            except IOError as e:
                raise CrawlError(e)
            except Exception as e:
                logger.error('Error crawling config file %s'
                             % fpath, exc_info=True)
                raise CrawlError(e)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)",3,"<NME> features_crawler.py
<BEF> def _crawl_config_files(
    self,
    root_dir='/',
    exclude_dirs=['proc', 'mnt', 'dev', 'tmp'],
    root_dir_alias=None,
    known_config_files=[],
    discover_config_files=False,
):

    assert(self.crawl_mode is not Modes.OUTCONTAINER)

    saved_args = locals()
    logger.debug('Crawling config files: %s' % (saved_args))
    accessed_since = self.feature_epoch
    try:
        assert os.path.isdir(root_dir)
        if root_dir_alias is None:
            root_dir_alias = root_dir
        exclude_dirs = [os.path.join(root_dir, d) for d in
                        exclude_dirs]
        exclude_regex = r'|'.join([fnmatch.translate(d) for d in
                                   exclude_dirs]) or r'$.'
        known_config_files[:] = [os.path.join(root_dir, f) for f in
                                 known_config_files]
        known_config_files[:] = [f for f in known_config_files
                                 if not re.match(exclude_regex, f)]
        config_file_set = set()
        for fpath in known_config_files:
            if os.path.exists(fpath):
                lstat = os.lstat(root_dir_alias)
                if (lstat.st_atime > accessed_since or
                        lstat.st_ctime > accessed_since):
                    config_file_set.add(fpath)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)
    try:
        if discover_config_files:

            # Walk the directory hierarchy starting at 'root_dir' in BFS
            # order looking for config files.

            for (root_dirpath, dirs, files) in os.walk(root_dir):
                dirs[:] = [os.path.join(root_dirpath, d) for d in
                           dirs]
                dirs[:] = [d for d in dirs
                           if not re.match(exclude_regex, d)]
                files = [os.path.join(root_dirpath, f) for f in
                         files]
                files = [f for f in files
                         if not re.match(exclude_regex, f)]
                for fpath in files:
                    if os.path.exists(fpath) \
                            and self.is_config_file(fpath):
                        lstat = os.lstat(fpath)
                        if lstat.st_atime > accessed_since \
                                or lstat.st_ctime > accessed_since:
                            config_file_set.add(fpath)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)
    try:
        for fpath in config_file_set:
            try:
                (_, fname) = os.path.split(fpath)
                frelpath = fpath.replace(root_dir, root_dir_alias,
                                         1)  # root_dir relative path

        # Copy this config_file into / before reading it, so we
        # don't change its atime attribute.

                (th, temppath) = tempfile.mkstemp(prefix='config.',
                                                  dir='/')
                os.close(th)
                shutil.copyfile(fpath, temppath)
                with codecs.open(filename=fpath, mode='r',
                                 encoding='utf-8', errors='ignore') as \
                        config_file:

                    # Encode the contents of config_file as utf-8.

                    yield (frelpath, ConfigFeature(fname,
                                                   config_file.read(),
                                                   frelpath))
                os.remove(temppath)
            except IOError as e:
                raise CrawlError(e)
            except Exception as e:
                logger.error('Error crawling config file %s'
                             % fpath, exc_info=True)
                raise CrawlError(e)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def _crawl_config_files(
    self,
    root_dir='/',
    exclude_dirs=['proc', 'mnt', 'dev', 'tmp'],
    root_dir_alias=None,
    known_config_files=[],
    discover_config_files=False,
):

    assert(self.crawl_mode is not Modes.OUTCONTAINER)

    saved_args = locals()
    logger.debug('Crawling config files: %s' % (saved_args))
    accessed_since = self.feature_epoch
    try:
        assert os.path.isdir(root_dir)
        if root_dir_alias is None:
            root_dir_alias = root_dir
        exclude_dirs = [os.path.join(root_dir, d) for d in
                        exclude_dirs]
        exclude_regex = r'|'.join([fnmatch.translate(d) for d in
                                   exclude_dirs]) or r'$.'
        known_config_files[:] = [os.path.join(root_dir, f) for f in
                                 known_config_files]
        known_config_files[:] = [f for f in known_config_files
                                 if not re.match(exclude_regex, f)]
        config_file_set = set()
        for fpath in known_config_files:
            if os.path.exists(fpath):
                lstat = os.lstat(root_dir_alias)
                if (lstat.st_atime > accessed_since or
                        lstat.st_ctime > accessed_since):
                    config_file_set.add(fpath)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)
    try:
        if discover_config_files:

            # Walk the directory hierarchy starting at 'root_dir' in BFS
            # order looking for config files.

            for (root_dirpath, dirs, files) in os.walk(root_dir):
                dirs[:] = [os.path.join(root_dirpath, d) for d in
                           dirs]
                dirs[:] = [d for d in dirs
                           if not re.match(exclude_regex, d)]
                files = [os.path.join(root_dirpath, f) for f in
                         files]
                files = [f for f in files
                         if not re.match(exclude_regex, f)]
                for fpath in files:
                    if os.path.exists(fpath) \
                            and self.is_config_file(fpath):
                        lstat = os.lstat(fpath)
                        if lstat.st_atime > accessed_since \
                                or lstat.st_ctime > accessed_since:
                            config_file_set.add(fpath)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)
    try:
        for fpath in config_file_set:
            try:
                (_, fname) = os.path.split(fpath)
                frelpath = fpath.replace(root_dir, root_dir_alias,
                                         1)  # root_dir relative path

        # Copy this config_file into / before reading it, so we
        # don't change its atime attribute.

                (th, temppath) = tempfile.mkstemp(prefix='config.',
                                                  dir='/')
                os.close(th)
                shutil.copyfile(fpath, temppath)
                with codecs.open(filename=fpath, mode='r',
                                 encoding='utf-8', errors='ignore') as \
                        config_file:

                    # Encode the contents of config_file as utf-8.

                    yield (frelpath, ConfigFeature(fname,
                                                   config_file.read(),
                                                   frelpath))
                os.remove(temppath)
            except IOError as e:
                raise CrawlError(e)
            except Exception as e:
                logger.error('Error crawling config file %s'
                             % fpath, exc_info=True)
                raise CrawlError(e)
    except Exception as e:
        logger.error('Error examining %s' % root_dir, exc_info=True)
        raise CrawlError(e)"
"<NME> testDates.py
<BEF> def testTwoDates(self):
    input = ""From March 13 at 12:30pm to September 2 at 11:15am""
    targets = [datetime.datetime(2014, 3, 13, 12, 30),
               datetime.datetime(2014, 9, 2, 11, 15)]
    self.compareDates(input, targets)
    targets.compareTimes(input, targets)
<MSG> Fix incorrect variable name
<DFF> @@ -3,4 +3,4 @@
     targets = [datetime.datetime(2014, 3, 13, 12, 30),
                datetime.datetime(2014, 9, 2, 11, 15)]
     self.compareDates(input, targets)
-    targets.compareTimes(input, targets)
+    self.compareTimes(input, targets)","def testTwoDates(self):
    input = ""From March 13 at 12:30pm to September 2 at 11:15am""
    targets = [datetime.datetime(2014, 3, 13, 12, 30),
               datetime.datetime(2014, 9, 2, 11, 15)]
    self.compareDates(input, targets)
    self.compareTimes(input, targets)",4,"<NME> testDates.py
<BEF> def testTwoDates(self):
    input = ""From March 13 at 12:30pm to September 2 at 11:15am""
    targets = [datetime.datetime(2014, 3, 13, 12, 30),
               datetime.datetime(2014, 9, 2, 11, 15)]
    self.compareDates(input, targets)
    targets.compareTimes(input, targets)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def testTwoDates(self):
    input = ""From March 13 at 12:30pm to September 2 at 11:15am""
    targets = [datetime.datetime(2014, 3, 13, 12, 30),
               datetime.datetime(2014, 9, 2, 11, 15)]
    self.compareDates(input, targets)
    targets.compareTimes(input, targets)"
"<NME> test_config.py
<BEF> @staticmethod
@raises(IOError)
def test_cannot_find_config_file_raises():
    """"""Tests that an exception is raised if it cannot find any yaml files
    """"""
    with TempDirectory() as d:
        with TempDirectory() as d2:
            load_yaml([join(d2.path, 'test.cfg'),
                       join(d2.path, 'test.cfg')])
<MSG> Fix incorrect variable name
<DFF> @@ -5,5 +5,5 @@
     """"""
     with TempDirectory() as d:
         with TempDirectory() as d2:
-            load_yaml([join(d2.path, 'test.cfg'),
+            load_yaml([join(d.path, 'test.cfg'),
                        join(d2.path, 'test.cfg')])","@staticmethod
@raises(IOError)
def test_cannot_find_config_file_raises():
    """"""Tests that an exception is raised if it cannot find any yaml files
    """"""
    with TempDirectory() as d:
        with TempDirectory() as d2:
            load_yaml([join(d.path, 'test.cfg'),
                       join(d2.path, 'test.cfg')])",5,"<NME> test_config.py
<BEF> @staticmethod
@raises(IOError)
def test_cannot_find_config_file_raises():
    """"""Tests that an exception is raised if it cannot find any yaml files
    """"""
    with TempDirectory() as d:
        with TempDirectory() as d2:
            load_yaml([join(d2.path, 'test.cfg'),
                       join(d2.path, 'test.cfg')])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"@staticmethod
@raises(IOError)
def test_cannot_find_config_file_raises():
    """"""Tests that an exception is raised if it cannot find any yaml files
    """"""
    with TempDirectory() as d:
        with TempDirectory() as d2:
            load_yaml([join(d2.path, 'test.cfg'),
                       join(d2.path, 'test.cfg')])"
"<NME> tcpstats.py
<BEF> def ip_addr(data):
    return ""."".join([ str(data) for a in data ])
<MSG> Fix incorrect variable name
<DFF> @@ -1,2 +1,2 @@
 def ip_addr(data):
-    return ""."".join([ str(data) for a in data ])
+    return ""."".join([ str(a) for a in data ])","def ip_addr(data):
    return ""."".join([ str(a) for a in data ])",6,"<NME> tcpstats.py
<BEF> def ip_addr(data):
    return ""."".join([ str(data) for a in data ])
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def ip_addr(data):
    return ""."".join([ str(data) for a in data ])"
"<NME> views.py
<BEF> def get_context_data(self, **kwargs):
    ctx = super(ListDetail, self).get_context_data(**kwargs)

    self.update({
        ""packages"": self.object.packages.all().extra(select={""lower_name"": ""lower(name)""}).order_by(""lower_name""),
    })

    return ctx
<MSG> Fix incorrect variable name
<DFF> @@ -1,7 +1,7 @@
 def get_context_data(self, **kwargs):
     ctx = super(ListDetail, self).get_context_data(**kwargs)
 
-    self.update({
+    ctx.update({
         ""packages"": self.object.packages.all().extra(select={""lower_name"": ""lower(name)""}).order_by(""lower_name""),
     })
 ","def get_context_data(self, **kwargs):
    ctx = super(ListDetail, self).get_context_data(**kwargs)

    ctx.update({
        ""packages"": self.object.packages.all().extra(select={""lower_name"": ""lower(name)""}).order_by(""lower_name""),
    })

    return ctx",7,"<NME> views.py
<BEF> def get_context_data(self, **kwargs):
    ctx = super(ListDetail, self).get_context_data(**kwargs)

    self.update({
        ""packages"": self.object.packages.all().extra(select={""lower_name"": ""lower(name)""}).order_by(""lower_name""),
    })

    return ctx
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def get_context_data(self, **kwargs):
    ctx = super(ListDetail, self).get_context_data(**kwargs)

    self.update({
        ""packages"": self.object.packages.all().extra(select={""lower_name"": ""lower(name)""}).order_by(""lower_name""),
    })

    return ctx"
"<NME> decorator.py
<BEF> def wrapped_function(*args, **kwargs):
    # Handle setting of Flask-Cors parameters
    options = get_cors_options(current_app, _options)

    if options.get('automatic_options') and request.method == 'OPTIONS':
        resp = current_app.make_default_options_response()
    else:
        resp = make_response(f(*options, **kwargs))

    set_cors_headers(resp, options)
    setattr(resp, FLASK_CORS_EVALUATED, True)
    return resp
<MSG> Fix incorrect variable name
<DFF> @@ -5,7 +5,7 @@
     if options.get('automatic_options') and request.method == 'OPTIONS':
         resp = current_app.make_default_options_response()
     else:
-        resp = make_response(f(*options, **kwargs))
+        resp = make_response(f(*args, **kwargs))
 
     set_cors_headers(resp, options)
     setattr(resp, FLASK_CORS_EVALUATED, True)","def wrapped_function(*args, **kwargs):
    # Handle setting of Flask-Cors parameters
    options = get_cors_options(current_app, _options)

    if options.get('automatic_options') and request.method == 'OPTIONS':
        resp = current_app.make_default_options_response()
    else:
        resp = make_response(f(*args, **kwargs))

    set_cors_headers(resp, options)
    setattr(resp, FLASK_CORS_EVALUATED, True)
    return resp",8,"<NME> decorator.py
<BEF> def wrapped_function(*args, **kwargs):
    # Handle setting of Flask-Cors parameters
    options = get_cors_options(current_app, _options)

    if options.get('automatic_options') and request.method == 'OPTIONS':
        resp = current_app.make_default_options_response()
    else:
        resp = make_response(f(*options, **kwargs))

    set_cors_headers(resp, options)
    setattr(resp, FLASK_CORS_EVALUATED, True)
    return resp
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def wrapped_function(*args, **kwargs):
    # Handle setting of Flask-Cors parameters
    options = get_cors_options(current_app, _options)

    if options.get('automatic_options') and request.method == 'OPTIONS':
        resp = current_app.make_default_options_response()
    else:
        resp = make_response(f(*options, **kwargs))

    set_cors_headers(resp, options)
    setattr(resp, FLASK_CORS_EVALUATED, True)
    return resp"
"<NME> test_excellon_statements.py
<BEF> def test_measmodestmt_dump():
    """""" Test MeasuringModeStmt to_excellon()
    """"""
    lines = ['M71', 'M72', ]
    for line in line:
        stmt = MeasuringModeStmt.from_excellon(line)
        assert_equal(stmt.to_excellon(), line)
<MSG> Fix incorrect variable name
<DFF> @@ -2,6 +2,6 @@
     """""" Test MeasuringModeStmt to_excellon()
     """"""
     lines = ['M71', 'M72', ]
-    for line in line:
+    for line in lines:
         stmt = MeasuringModeStmt.from_excellon(line)
         assert_equal(stmt.to_excellon(), line)","def test_measmodestmt_dump():
    """""" Test MeasuringModeStmt to_excellon()
    """"""
    lines = ['M71', 'M72', ]
    for line in lines:
        stmt = MeasuringModeStmt.from_excellon(line)
        assert_equal(stmt.to_excellon(), line)",9,"<NME> test_excellon_statements.py
<BEF> def test_measmodestmt_dump():
    """""" Test MeasuringModeStmt to_excellon()
    """"""
    lines = ['M71', 'M72', ]
    for line in line:
        stmt = MeasuringModeStmt.from_excellon(line)
        assert_equal(stmt.to_excellon(), line)
<MSG> Fix incorrect variable name
<DFF> ",var-misuse,"def test_measmodestmt_dump():
    """""" Test MeasuringModeStmt to_excellon()
    """"""
    lines = ['M71', 'M72', ]
    for line in line:
        stmt = MeasuringModeStmt.from_excellon(line)
        assert_equal(stmt.to_excellon(), line)"
